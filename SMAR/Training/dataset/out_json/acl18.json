[
  {
    "conf": "acl18",
    "idd": 330,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Story is about learning mapping from text to vision.\\n\\nFinding 1: Imagined vectors, f(text), outperform original visual vectors in 7/7 word similarity tasks.\\n\\nSo, why are mapped vectors multimodal? We conjecture: Continuity.\\nOutput vector is nothing but the input vector transformed by a continuous map: f(X) = X08.\\n\\nFinding 2 (not in AAAI paper): Vectors imagined with an untrained network do even better."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "BPO (elie male)\\n\\nMotivation: Applications (e.g., zero-shot image tagging, zero-shot translation or cross-modal retrieval):\\n- Use linear or NN maps to bridge modalities/spaces.\\n- Then, they tag/translate based on neighborhood structure of mapped vectors f(X).\\n\\nResearch question: Is the neighborhood structure of f(X) similar to that of Y? Or rather to X?\\n\\nHow to measure similarity of 2 sets of vectors from different spaces? Idea: mean nearest neighbor overlap (mNNO)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "BPO elie male)e@ Mappings f: Vv\\n- Y to bridge modalities Y and y: e Linear (lin): f(x) = Wox + boe Feed-forward neural net (nn): f(x) = Wio(Wox + bo) + byye led)O yy {SSSre XS Le gsg Ss Se> é2, ll a)ee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "2. Experiments\\n\\nDefinition\\n\\nNearest Neighbor Overlap (NNO(v_i, z_i)) = number of K nearest neighbors that two paired data points v_i, z_i share in their respective spaces.\\n\\nThe mean NNO is:\\n\\n1mNNO(V,\\nZ) = Re Σ NNO(v_i, z_i)\\nNN0 = {V_aog, V_tiger, V_lion}\\nNNO(V_aets, Z_oat) = 2NN*(Z_eat) = {Z_mouse, Z_tiger, Z_lion}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Te experiments = 1401-141\\n\\nGoal: Learn map f : X > Y and calculate mNNO(Y, f(X)). Compare it with mNNO(X, f(X)).\\n\\nExperimental Setup:\\n- Datasets:\\n(i) ImageNet;\\n(ii) IAPR TC-12;\\n(iii) Wikipedia.\\n- Visual features: VGG-128 and ResNet.\\n- Text features: ImageNet (GloVe and word2vec); IAPRTC-12 & Wikipedia (biGRU).\\n- Loss: MSE = 3 ||f(x)\\n- y||. We also tried max-margin and cosine."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Peery Experiment 1\\n\\nExperiment 1: Results\\n- ResNet\\n- A(X)      Y\\n- A(X)      X\\n- f(X)      Y\\n- F(X)\\n\\nlin   0.681*   0.262   0.723*   0.236\\nnn    0.622\"    0.273   0.682*   0.246\\n- Tol\\nlin   0.379*   0.241   0.339*   0.229\\nnn    0.354     0.27    0.326*   0.256\\n- IoT\\nlin   0.358    0.214   0.382*   0.163\\nnn    0.336\"    0.219   0.331*   0.180\\n- Tot\\nlin   0.48*    0.2     0.419*   0.167\\nnn    0.413*   0.225   0.372*   0.182\\n- IoT\\nlin   0.235*   0.156   0.235*   0.143\\nnn    0.269°    0.161   0.282*   0.148\\n- Tt\\nlin   0.574    0.156   0.6\"    0.148\\nnn    0.521\"    0.156   0.511*   0.151\\n\\nTable: X, f(X) and Y, f(X) denote mNNO'°(X, f(X)) and 10mNNOTM'(Y, f(X)), respectively."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "rae Experiments\\n\\nExperiment 2\\n\\nGoal: Map X with an untrained net f and compare performance of X with that of f(X).\\n\\nWe \"ablate\" from Experiment 1 the learning part and the choices of loss and output vectors.\\n\\nExperimental Setup\\n\\nEvaluate vectors in:\\n\\n(i) Semantic similarity: SemSim, Simlex-999 and SimVerb-3500.\\n\\n(ii) Relatedness: MEN and WordSim-353.\\n\\n(iii) Visual similarity: VisSim."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Paty Eynerime\\n\\nExperiment 2: Results\\n\\nWS-353\\n- Men\\n- SemSim\\n- Cos Eucl\\n- Cos Eucl\\n- Cos Eucl\\n\\nfn (GloVe) 0.632 0.634 0.795 0.791* 0.75\" 0.744\"\\nfin (GloVe) 0.63 0.606 0.798 0.781 0.763 0.712\\nGloVe 0.632 0.601 0.801 0.782 0.768 0.716\\nfn (ResNet) 0.402 0.408\" 0.556 0.554* 0.512 0.513\\nfin (ResNet) 0.425 0.449 0.566 0.534 0.533 0.514\\nResNet 0.423 0.457 0.567 0.535 0.534 0.516\\n\\nVisSim\\n- SimLex\\n- SimVerb\\n- Cos Eucl\\n- Cos Eucl\\n- Cos Eucl\\n\\nfn (GloVe) 0.594\" 0.59* 0.369 0.363\" 0.313 0.301\"\\nfin (GloVe) 0.602* 0.576 0.369 0.341 0.326 0.23\\nGloVe 0.606 0.58 0.371 0.34 0.32 0.235\\nfn (ResNet) 0.527* 0.526\" 0.405 0.406 0.178 0.169\\nfin (ResNet) 0.541 0.498 0.409 0.404 0.198 0.182\\nResNet 0.543 0.501 0.409 0.403 0.211 0.199\\n\\nTable: Spearman correlations between human ratings and similarities (cosine or Euclidean) predicted from embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Ree Umm\\n\\nConclusions and Future Work\\n\\nConclusions:\\n- Neighborhood structure of f(X) more similar to X than Y.\\n- Neighborhood structure of embeddings not significantly disrupted by mapping them with an untrained net.\\n\\nFuture Work:\\n- How to mitigate the problem?\\n- Discriminator (adversarial) trying to guess whether the sample is from Y or f(X).\\n- Incorporate pairwise similarities into loss function."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Thank you!\\n\\nQuestions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 329,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction: Sentence acceptability: the extent to which a sentence is natural to native speakers.\\nIt encompasses semantic, syntactic, and pragmatic plausibility and other non-linguistic factors such as memory limitation.\\nGrammaticality, by contrast, is a theoretical concept that measures the syntactic well-formedness of a sentence.\\nHere we are interested in predicting acceptability judgments."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation: We previously explored using unsupervised probabilistic methods to predict sentence acceptability, and found some success.\\nIt provides evidence that linguistic knowledge can be represented as a probabilistic system, addressing foundational questions concerning the categorical nature of grammatical knowledge."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Acceptability in Context\\n\\nIn previous experiments, sentence acceptability was judged (by humans) or predicted (by models) independently of context.\\nHere we extend the research to investigate the impact of context on acceptability.\\nContext is defined as the full document environment surrounding a sentence.\\nSpecifically, we want to understand the influence of context on:\\n- Human acceptability ratings\\n- Model prediction of acceptability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Human Acceptability Ratings in Context\\n\\nWe perform round-trip translation of sentences (e.g.\\nEN -> FR -> EN) from English Wikipedia to generate a set of sentences with varying degrees of acceptability.\\n\\nWe use MTurk to collect acceptability judgments (rated on a 4-point scale).\\n\\nAnnotation task was run twice: first without context, and second within the document context.\\n\\nWe collect multiple ratings for a sentence and take the mean.\\n\\nHuman acceptability ratings:\\n- without context = h;\\n- with context = ht"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Instructions and guidelines:\\nTo do this HIT you must be a native speaker of English. We have inserted control to identify this.\\nIf your judgments are non-native then your HITS will most likely be rejected.\\nPlease assess each of the following highlighted sentences (in bold) for naturalness using the four-point scale given after each sentence.\\nEach sentence occurs within an context. You are shown the sentences preceding and following the sentence orate.\\nYou can expand the text in each direction, as you wish, by using the indicated buttons.\\n\\nDescription of scoring:\\nThe following scale should be used for scoring:\\n- 4 = Good\\n- 3 = Mostly good, a little odd\\n- 2 = Not very good, but can understand the gist of the sentence\\n- 1 = Bad; can't interpret the sentence\\n\\nExamples of:\\n- Mary had a little lamb\\n- Tom told little Mary this hat\\n\\nNote: You must rate all sentences for the work to be approved.\\n1. Anthony Philip \"Tony\" Thistwall (born\\n1941) is Professor of Applied Economics at the University of Kent.\\nHe made a significant contribution to the regional economy.\\nAnalysis of unemployment and inflation; the theory of balance of payments, in particular the economics of growth and development in developing countries.\\nHe is the author of the bestselling textbook \"Economics of Development: Theory and Evidence\" (Palgrave Macmillan) now in its sixth edition.\\nShow the rating:\\n- 1 = Bad\\n- 2 = Not very good\\n- 3 = Mostly good\\n- 4 = Good\\n2. Anthony Philip \"Tony\" Thistwall (born\\n1941) is Professor of Applied Economics at the University of Kent.\\nHe made a significant contribution to the regional economy.\\nAnalysis of unemployment and inflation; the theory of balance of payments, in particular the economies of growth and development in developing countries.\\nHe is the author of the bestselling textbook \"Economics of Development: Theory and Evidence\" (Palgrave Macmillan) now in its sixth edition.\\nShow the rating:\\n- 1 = Bad\\n- 2 = Not very good\\n- 3 = Mostly good\\n- 4 = Good\\n3. Anthony Philip \"Tony\" Thistwall (born\\n1941) is Professor of Applied Economics at the University of Kent.\\nHe made a significant contribution to the regional economy.\\nAnalysis of unemployment and inflation; the theory of balance of payments, in particular the economies of growth and development in developing countries.\\nHe is the author of the bestselling textbook \"Economics of Development: Theory and Evidence\" (Palgrave Macmillan) now in its sixth edition.\\nShow the rating:\\n- 1 = Bad\\n- 2 = Not very good\\n- 3 = Mostly good\\n- 4 = Good\\n4. Anthony Philip \"Tony\" Thistwall (born\\n1941) is Professor of Applied Economics at the University of Kent.\\nHe made a significant contribution to the regional economy.\\nAnalysis of unemployment and inflation; the theory of balance of payments, in particular the economics of growth and development in developing countries.\\nHe is the author of the bestselling textbook \"Economics of Development: Theory and Evidence\" (Palgrave Macmillan) now in its sixth edition.\\nShow the rating:\\n- 1 = Bad\\n- 2 = Not very good\\n- 3 = Mostly good\\n- 4 = Good\\n5. Anthony Philip \"Tony\" Thistwall (born\\n1941) is Professor of Applied Economics at the University of Kent.\\nHe made a significant contribution to the regional economy.\\nAnalysis of unemployment and inflation; the theory of balance of payments, in particular the economics of growth and development in developing countries.\\nHe is the author of the bestselling textbook \"Economics of Development: Theory and Evidence\" (Palgrave Macmillan) now in its sixth edition.\\nShow the rating:\\n- 1 = Bad\\n- 2 = Not very good\\n- 3 = Mostly good\\n- 4 = Good"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "With-context h* Against Without-context h~ Ratings OX,a8 a Teg I xKX OX8 3 cm Ma Rie= X XK ERE Pee x3 2.5 ix, ax 3 77E151 ,1 15 2 25 3 35 4 mean hTM per sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Observations: Pearson's r = 0.80 between ht and h-.\\n\\nContext boosts acceptability ratings most for ill-formed sentences.\\n\\nSurprisingly, context reduces acceptability for the most acceptable sentences.\\n\\nContext \"compresses\" distribution of ratings.\\n\\nOne-vs-rest correlation, performance of a single annotator against the rest: 0.628 for h~ and 0.293 for ht.\\n\\nLow correlation is explained by the compression effect of context\\n- good and bad sentences are now less separable."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Modelling Acceptability with Unsupervised Models\\n\\n1stm: standard LSTM language model\\n\\ntdlm: a topically driven language model; language model is driven by a topic vector automatically learnt on the document context.\\n\\n4 variants at test time:\\n- Use only the sentence as input: lstmTM and tdlm;\\n- Use both sentence and context as input: 1stm* and tdlm*.\\n\\n1stmTM incorporates context by feeding it to the LSTM network and taking the final state as the initial state for the current sentence.\\n\\nModels trained on 100K English Wikipedia articles (40M tokens)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Acceptability Measures\\n\\nTo map sentence probability to acceptability, we compute several acceptability measures, which are designed to normalize sentence length and word frequency.\\n\\nlog P = C & P = L\\n\\nP = probability of the sentence given by a model;\\nU = unigram probability of the sentence;\\nL = sentence length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Results\\n\\nIstm tdlm tdlm~ 0.584 = 0.633 0.640 0.653 ht 0.503 0.546 0.557 = 0.568\\n\\nAcross all models (1stm or tdlm) and human ratings (h~ or h*), using context attest time improves performance.\\n\\ntdlm consistently outperforms 1stm (even tdlm~ > lstm*).\\n\\nLower correlation when predicting sentence acceptability judged with context.\\n\\nIt suggests h* ratings are more difficult to predict than h~, which corresponds to the low one-vs-rest human performance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Summary: Context positively influences acceptability, particularly for ill-formed sentences.\\n\\nBut it also has the reverse effect for well-formed sentences.\\n\\nIncorporating context (during training or testing) helps modelling acceptability.\\n\\nPrediction performance declines when tested on acceptability ratings judged with context, due to the \"compression\" effect of ratings.\\n\\nFuture work: investigate why context reduces acceptability for highly acceptable sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 15,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Simple and Effective Text Simplification Using Semantic and Neural Methods\\nElior Sulem\\nOmri Abend\\nAri Rappoport\\nMow yA Aw ye\\nTHE HEBREW UNIVERSITY OF JERUSALEM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Text Simplification\\n\\nLast year I read the book John authored.\\n\\nJohn wrote a book.\\n\\nOriginal sentence: One or several simpler sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Last year I read the book John authored. John wrote a book.\\n\\nOriginal sentence\\n\\nOne or several simpler sentences\\n\\nMultiple motivations\\n\\nTM =) Preprocessing for Natural Language Processing tasks e.g., machine translation, relation extraction, parsing\\n\\nTM =) Reading aids, Language Comprehension e.g., people with aphasia, dyslexia, 2nd language learners"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Text Simplification\\n\\nLast year I read the book John authored\\n- John wrote a book.\\n\\nOriginal sentence: One or several simpler sentences\\n\\nMultiple operations => Word or phrase substitution\\n\\nLexical => Sentence splitting\\n\\n=> Deletion + Structural"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "- Both structural and lexical simplification.\\n- The first simplification system combining structural transformations, using semantic structures, and neural machine translation.\\n- Compares favorably to the state-of-the-art in combined structural and lexical simplification.\\n- Alleviates the over-conservatism of MT-based systems."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Overview\\n1. Current approaches and challenges\\n\\n1.1 Conservatism in MT-Based Simplification\\n\\n1.2 Sentence splitting in Text Simplification\\n2. Direct Semantic Splitting (DSS)\\n\\n2.1 The semantic structures\\n\\n2.2 The semantic rules\\n3. Combining DSS with Neural Text Simplification\\n4. Experiments\\n5. Results\\n6. Human Evaluation Benchmark\\n7. Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Current Approaches and Challenges\\n\\nMT-Based Simplification\\n\\nSentence simplification as monolingual machine translation\\n\\nModels\\n- Phrase-Based SMT (Specia, 2010; Coster and Kauchak, 2011; Wubben et al., 2012; Stajner et al.,\\n2015)\\n- Syntax-Based SMT (Xu et al.,\\n2016)\\n- Neural Machine Translation (Nisioi et al., 2017; Zhang et al., 2017; Zhang and Lapata, 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Current Approaches and Challenges\\n\\nMT-Based Simplification\\n\\nSentence simplification as monolingual machine translation\\n\\nCorpora\\n- English / Simple Wikipedia (Zhu et al., 2010; Coster and Kauchak, 2011; Hwang et al.,\\n2015)\\n- Newsela (Xu et al., 2015)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Conservatism in MT-Based Simplification\\n\\nIn both SMT and NMT Text Simplification, a large proportion of the input sentences are not modified.\\n(Alva-Manchego et al., 2017; on the Newsela corpus). It is confirmed in the present work (experiments on Wikipedia):\\n\\nFor the NTS system (Nisioi et al.,\\n2017) / Moses (Koehn et al.,\\n2007)\\n- 66% / 80% of the input sentences remain unchanged.\\n- None of the references are identical to the source.\\n- According to automatic and human evaluation, the references are indeed simpler.\\n\\nConservatism in MT-Based simplification is excessive."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Sentence Splitting in Text Simplification\\n\\nSplitting in NMT-Based Simplification\\n- Sentence splitting is not addressed.\\n- Rareness of splittings in the simplification training corpora. (Narayan and Gardent, 2014; Xu et al., 2015).\\n- Recently, corpus focusing on sentence splitting for the Split-and-Rephrase task (Narayan et al.,\\n2017) where the other operations are not addressed."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Sentence Splitting in Text Simplification\\n\\nDirectly modeling sentence splitting\\n1. Hand-crafted syntactic rules:\\n- Compilation and validation can be laborious (Shardlow,\\n2014)\\n- Many rules are often involved (e.g., 111 rules in Siddharthan and Angrosh,\\n2014) for relative clauses, appositions, subordination and coordination.\\n- Usually language specific."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Sentence Splitting in Text Simplification\\n\\nDirectly modeling sentence splitting\\n1. Hand-crafted syntactic rules:\\nExample: V W z p X [rc REL PR** Y] Z.\\n- {(a) V W X Z\\n(b) W Y}\\n\\nNoun phrase\\n- Relative clause\\n- Relative Pronoun\\n\\nOne of the two rules for relative clauses in Siddharthan, 2004."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Sentence Splitting in Text Simplification\\n\\nDirectly modeling sentence splitting\\n2. Using semantics for determining potential splitting points\\n\\nNarayan and Gardent (2014)\\n- HYBRID\\n- Discourse Semantic Representation (DRS) structures for splitting and deletion.\\n- Depends on the proportion of splittings in the training corpus.\\n\\n=> We here use an intermediate way: Simple algorithm to directly decompose the sentence into its semantic constituents."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Direct Semantic Splitting (DSS)\\n- A simple algorithm that directly decomposes the sentence into its semantic components, using 2 splitting rules.\\n- The splitting is directed by semantic parsing.\\n- The semantic annotation directly captures shared arguments.\\n- It can be used as a preprocessing step for other simplification operations.\\n\\nDSS NMT-Based Simplification\\n\\nInput sentence\\n-\\n\\nSplit sentence\\n-\\n\\nOutput Sentence\\n\\nSplitting Deletions, Word substitutions\\n\\nReduces conservatism is"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- Based on typological and cognitive theories (Dixon, 2010, 2012; Langacker, 2008), He came back home played piano.\\n\\nParallel Scene (H)\\n\\nLinker (L)\\n\\nParticipant (A)\\n\\nProcess (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- Stable across translations (Sulem, Abend and Rappoport,\\n2015)\\n\\na \" L NNLO . NX | and eo ' He came back home played piano\\n\\nParallel Scene (H)\\n\\nLinker (L)\\n\\nParticipant (A)\\n\\nProcess (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- Used for the evaluation of MT, GEC and Text Simplification (Birch et al., 2016; Choshen and Abend, 2018; Sulem et al.,\\n2018) a. \" L _~He came back home played piano Parallel Scene (H) Linker (L) Participant (A) Process (P) 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- Explicitly annotates semantic distinctions, abstracting away from syntax (like AMR; Banarescu et al.,\\n2013)\\n- Unlike AMR, semantic units are directly anchored in the text.\\n\\n4 of \" L NN He came back home played piano\\n\\nParallel Scene (H)\\nLinker (L)\\nParticipant (A)\\nProcess (P)\\n19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- UCCA parsing: TUPA parser (Hershcovich et al., 2017,\\n2018)\\n- Shared Task in Sem-Eval 2019\\n\\nHe came back home played piano\\nParallel Scene (H)\\nLinker (L)\\nParticipant (A)\\nProcess (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- Scenes evoked by a Main Relation (Process or State).\\n- A \"L NN He came back home played piano\\n- Parallel Scene (H)\\n- Linker (L)\\n- Participant (A)\\n- Process (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- A Scene may contain one or several Participants.\\n\\nHe came back home, played piano.\\n\\nParallel Scene (H)\\n\\nLinker (L)\\n\\nParticipant (A)\\n\\nProcess (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- A Scene can provide additional information on an established entity: it is then an Elaborator Scene.\\n- Parallel Scene (H)\\n- Participant (A)\\n- Process (P)\\n- State (S)\\n- Center (C)\\n- Elaborator (E)\\n- Relator (R)\\n\\nwhich has 4 satellites"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- A Scene may also be a Participant in another Scene: It is then a Participant Scene.\\n\\nAW 4, @eP o. «UZ o\\ v Mary\\n\\nParallel Scene (H)\\n\\nLinker (L) a P surprised. His\\n\\nqParticipant (A)\\n\\nProcess (P) arrival"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "The Semantic Structures\\n\\nSemantic Annotation: UCCA (Abend and Rappoport,\\n2013)\\n- In the other cases, Scenes are annotated as Parallel Scenes. A Linker may be included.\\n- He came back home\\n- played piano\\n- Parallel Scene (H)\\n- Linker (L)\\n- Participant (A)\\n- Process (P)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "The Semantic Rules\\n\\nMain idea: Placing each Scene in a different sentence.\\n\\n* Fits with event-wise simplification (GlavaS and Stajner,\\n2013)\\n\\nHere we only use semantic criteria.\\n- It was also investigated in the context of Text Simplification evaluation: SAMSA measure (Sulem, Abend and Rappoport, NAACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Rule 1: The Semantic Rules\\n\\nParallel Scenes\\n\\nHe came back home and played piano.\\n\\nHe came back home. He played piano."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Rule 1: The Semantic Rules\\n\\nParallel Scenes\\n\\nHe came back home, played piano.\\n\\nHe layed piano."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Rule 2: The Semantic Rules Elaborator Scenes\\n\\nA. NA\\nHe observed the planet which has 14 satellites.\\nHe observed the planet. Planet has 14 satellites."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Rule 2: The Semantic Rules Elaborator\\n\\nScenes A @Aa POHe y _/PNE observed\\n\\nA @Athe Yarig % S->S-U(Sce,-C,)|Se,|...|Sc, planet which M@Sa satellites A0 A IED Sebrenees Elaborator Scenes Vv Ss rN\\n\\nInput sentence observed without the Elaborator Scenes, Planet yg AC preserving the Minimal Center has the planet in satellites 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "The Semantic Rules\\n- No regeneration module\\n- Grammatical errors resulting from the split are not addressed by the rules; e.g., no article regeneration.\\n- The output is directly fed into the NMT component.\\n\\nExample:\\nHe observed the planet which has 14 satellites.\\nHe observed the planet. Planet has 14 satellites."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "The Semantic Rules\\n- Participant Scenes are not separated here to avoid direct splitting in these cases:\\n- Nominalizations: His arrival surprised Mary.\\n- Indirect speech: He said John went to school.\\n- More transformations would be required for splitting in these cases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Combining DSS with Neural Text Simplification\\n\\nAfter DSS, the output is fed to an MT-based simplification system.\\n\\nWe use a state-of-the-art NMT-based TS system, NTS (Nisioi et al., 2017).\\n\\nThe combined system is called SENTS."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Combining DSS with Neural Text Simplification\\n- NTS was built using the OpenNMT (Klein et al.,\\n2017) framework.\\n\\nWe use the NTS-w2v provided model where word2vec embeddings are used for the initialization.\\n\\nBeam search is used during decoding.\\nWe explore both the highest (h1) and a lower ranked hypothesis (h4), which is less conservative.\\n\\nNTS model trained on the corpus of Hwang et al., 2015 (~280K sentence pairs).\\n\\nIt was tuned on the corpus of Xu et al., 2016 (2000 sentences with 8 references)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Experiments Corpus: Test set of Xu et al., 2016: 359 sentences, each with 8 references\\n\\nAutomatic evaluation:\\n- BLEU (Papineni et al.,\\n2002)\\n- SARI (Xu et al.,\\n2016)\\n\\nConservatism statistics: e.g., percentage of sentences copied from the input (% Same) 35"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Experiments\\n\\nHuman evaluation:\\n- First 70 sentences of the corpus\\n- 3 annotators\\n- native English speakers\\n- 4 questions for each input-output pair\\nQ1: Is the output fluent and grammatical?\\nQ2: Does the output preserve the meaning of the input?\\nQ3: Is the output simply comprehendible?\\n- 4 parameters:\\nGrammaticality (G)\\nMeaning Preservation (P)\\nSimplicity (S)\\nStructural Simplicity (StS)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Results\\n\\nAutomatic evaluation: BLEU, SARI\\n\\nHuman evaluation (first 70 sentences):\\n\\nG\\n- Grammaticality: 1 to 5 scale\\nS\\n- Simplicity: -2 to +2 scale\\nP\\n- Meaning Preservation: 1 to 5 scale\\nStS\\n- Structural Simplicity: -2 to +2 scale\\n\\n===> Identity gets the highest BLEU score and the lowest SARI scores. 37"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Results\\n\\nAutomatic evaluation: BLEU, SARI\\n\\nHuman evaluation (first 70 sentences):\\n\\nG\\n- Grammaticality: 1 to 5 scale\\nS\\n- Simplicity: -2 to +2 scale\\nP\\n- Meaning Preservation: 1 to 5 scale\\nStS\\n- Structural Simplicity: -2 to +2 scale\\n\\nThe two SENTS systems outperform HYBRID in terms of BLEU, SARI, G, M and S.\\nSENTS-h1 has the best StS score. 38"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Results\\n\\nAutomatic evaluation: % Same, SARI\\n\\nHuman evaluation (first 70 sentences):\\n- G\\n- Grammaticality: 1 to 5 scale\\n- S\\n- Simplicity: -2 to +2 scale\\n- P\\n- Meaning Preservation: 1 to 5 scale\\n- StS\\n- Structural Simplicity: -2 to +2 scale\\n\\n==> Compared to NTS, SENTS reduces conservatism and increases simplicity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Results\\n\\nAutomatic evaluation: % Same, SARI\\n\\nHuman evaluation (first 70 sentences):\\nG\\n- Grammaticality: 1 to 5 scale\\nS\\n- Simplicity: -2 to +2 scale\\nP\\n- Meaning Preservation: 1 to 5 scale\\nStS\\n- Structural Simplicity: -2 to +2 scale\\n\\n==> Compared to DSS, SENTS improves grammaticality and increases structural simplicity, since deletions are performed by the NTS component."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Results\\n\\nReplacing NTS by Statistical MT\\n- Combination of DSS and Moses: SEMoses\\n- The behavior of SEMoses is similar to that of DSS, confirming the over-conservatism of Moses (Alva-Manchego et al.,\\n2017) for simplification.\\n- All the splitting points from the DSS phase are preserved.\\n\\nReplacing the parser by manual annotation\\n- In the case of SEMoses, meaning preservation is improved.\\nSimplicity degrades, possibly due to a larger number of annotated scenes.\\n- In the case of SENTS-h1, high simplicity scores are obtained."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Human Evaluation Benchmark*\\n\\n1960 sentence pairs-\\n70 source sentences-\\n28 systems-\\n3 annotators-\\n4 parameters\\n\\nData: https://github.com/eliorsulem/simplification-acl201842"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Conclusion (1)\\n- We presented here the first simplification system combining semantic structures and neural machine translation.\\nOur system compares favorably to the state-of-the-art in combined structural and lexical simplification.\\n- This approach addresses the conservatism of MT-based systems.\\n- Sentence splitting is performed without relying on a specialized corpus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Conclusion (2)\\n\\nSentence splitting is treated as the decomposition of the sentence into its Scenes (as in SAMSA evaluation measure; Sulem, Abend and Rappoport, NAACL 2018).\\n\\nFuture work will leverage UCCA's cross-linguistic applicability to support multi-lingual text simplification and simplification pre-processing for MT."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Thank you Elior Sulem\\nData: https://github.com/eliorsulem/simplification-acl2018\\neliors@cs.huji.ac.il\\nwww.cs.huji.ac.il/~eliors\\nmoywins TMI AW OITA ye\\nTHE HEBREW UNIVERSITY OF JERUSALEM 45"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 194,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Language (of late age in reyny | LteTVI N=) (crema MT e161 OY-Lel Ground truth sequences lie in a union of low-dimensional subspaces where sequences convey the same message.\\n\\nFrance won the world cup for the second time.\\n\\nFrance captured its second world cup title.\\n\\nSome words in the vocabulary share the same meaning.\\n\\nCapture, conquer, win, gain, achieve, accomplish, ...\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing ©"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Contributions\\n\\nTake into consideration the nature of the target language space with:\\n- A token-level smoothing for a \"robust\" multi-class classification.\\n- A sequence-level smoothing to explore relevant alternative sequences.\\n\\nACL 2018, Melbourne\\n\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Maximum likelihood estimation (MLE) For a pair (x, y), we model the conditional distribution:\\n\\np(y|x) = p(y|x)\\n\\nGiven the ground truth target sequence y*:\\n\\nValue(y*,\\nx) =\\n- In p(y*|x)\\n\\n= D(y||y*) || p(y|x)\\n\\n= Yo D((v|e) || o(v|e, x))\\n\\nM. Elbayad | Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Maximum likelihood estimation (ML) of yoyo Lme(y*,\\nx) = -In p(y*|x)\\n\\nff = Da (5(vIy\")IlPa(v1x))\\n\\nir '=D Da((velvé)ileo(velte))\\n\\niifi of Issues: Zero-one loss, all the outputs y 4 y* are treated equally.\\nDiscrepancy at the sentence level between the training (1-gram) and evaluation metric (4-gram). ACL 2018, Melbourne M.\\nElbayad\\n- Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Loss smoothing\\n- 5(y*) rly'Dy (S(vly*)lPe(ylx)) lRamLlY\\nX) = Di (tr(ly*)IlPe(y|x)) corouz eta,\\n2016) ACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing 5:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Loss smoothing KW7 nAi5(y*) (resp. 6(yz)) rr(yly*) (resp. rr(velvé)) Du(6(yly*) || Pe(ylx)) Lead (Y*\\nx) = Dar (VIY\") IlPo(Y1X)) (vorouzi et al,\\n2016) es yrSD ((velye) l\\oolvelhe))\\n- RAmL(Y\"X) = DY) Dra (re(velve)| Po yel he)t=1 t=1 ACL 2018, Melbourne M.\\nElbayad || Token-level and Sequence-level Loss Smoothing 5:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Token-level smoothing ACL 2018, Melbourne\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Loss smoothing | Token-level reparameterization:\\n\\nUniform label smoothing over all words in the vocabulary:\\n\\nL(vel) = O(vel) + 7-u(V) (Szegedy et al.\\n2016)\\n\\nWe can leverage word co-occurrence statistics to build a non-uniform and \"meaningful\" distribution.\\n\\nACL 2018, Melbourne M. Elbayad | Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Loss smoothing\\n\\nPrerequisite: A word embedding w (e.g. Glove) in the target space and a distance d.\\n\\n1 ~ d(w(ve), w(ve)) rebalye) = z exw (- SOD OED) with a temperature T st. r- --> 6.70Z. St. S rr(Melyf) = 1\\n\\nMEVACL 2018, Melbourne\\n\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Loss smoothing | Token-level microwave stove refrigerator, microwave stove refrigerator on counter / cabinets = cabinets appliances appliances stainless = 0.12 = 0.70\\n- ACL 2018, Melbourne M. Elbayad | Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Loss smoothing | Token-level Relevance (Y's\\nx) = >> Data (level v2) (level he) (4)t=1T *AVE=> Do mbvelvé oe (HH) (5)t=1 ev Polyt\\n\\nWe can estimate the exact KL divergence for every target token. No approximation needed. ACL 2018, Melbourne M.\\nElbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "e smoothing | Sequence-level era YX) = Da (rr(vly*)Ilee(ylx))\\n\\nPrerequisite: A distance d in the sequences space V\",n EN.1\\n- d(y, y*Vly') = 5 exe (qe iZ st. > r(yly7) = 1 yeV\" nen\\n\\nPossible (pseudo-)distances:\\n- Hamming\\n- Edit\\n- 1-BLEU\\n- 1-CIDEr\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "e smoothing Sequence-level Can we evaluate the partition function Z for a given reward?\\n\\n1\\n- d(y,y*) Lr\\nf) = S exp{ -~-~ ], r(y leve) Z z p ( 7 = dyy') LS oe See (= y ev\", ne N We can approximate Z for Hamming distance.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 13:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "eys smoothing Sequence-level | Hamming distance\\n\\nAssumption: consider only sequences of the same length as y* (d(y, y') = 0 if |y| = |y'|).\\n\\nWe partition the set of sequences V with respect to their distance to the ground truth y*:\\n\\nSa = {y ∈ V | d(y, y*) = 4},\\n\\nyr = U Sa,\\n\\nVd,\\n\\nad': San Sq = @.\\n\\nThe reward in each subset is a constant. The cardinality of each subset is known.\\n\\ndB =\\n- = Visiiew (-2) dACL 2018, Melbourne M. Elbayad | Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "eys5 smoothing Sequence-level | Hamming distance\\n\\nWe can easily draw from r- with Hamming distance:\\n- Sample a distance d from {0,..., T}.\\n- Pick d positions in the sequence to be changed among {1,..., T}.\\n- Sample substitutions from V of the vocabulary.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 45:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "eys smoothing Sequence-level | Hamming distance\\n\\nWe can easily draw from r- with Hamming distance:\\n\\nSample a distance d from {0,..., T}.\\nPick d positions in the sequence to be changed among {1,..., T}.\\nSample substitutions from V of the vocabulary.\\n\\nMonte Carlo estimation:\\n\\nlRamlY\"\\nx) = Da(rr(vly\")|lPo(ylx)) (6) = -E,, [log po(.[x)] + cst (7)\\nit(wt) RAF » log pa(y'|x) (8)\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "easing smoothing Sequence-level | Other distances\\n\\nWe cannot \"easily\" sample from more complicated rewards such as BLEU or CIDEr.\\n\\nImportance sampling:\\n\\nr(y) = -E_q [log p_o(y|x)] (9)\\n\\nr = -E_q [log p_s(y)] (10)\\n\\ni(y|x) = -D_{C} (w || log p_o(y|l)) (11)\\n\\nChoose q the reward distribution relative to Hamming distance.\\n- ACL 2018, Melbourne M. Elbayad\\n- Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "eys5 smoothing\\n\\nSequence-level | Support reduction\\n\\nbramu(Y\\nx) = Da(rr(vly\")IIPo(ylx)) (6)\\n\\nCan we reduce the support of r,?\\n\\n1\\n- d(y,y*)\\n- d(y,y*) xy i a\\n- dy,y\") _ 'rey) = Zen ( : .Z= > exp : yeyr\\n\\nReduce the support from Vl\"! to ye where Veup C V. Vsub = Vpatch : tokens occurring in the SGD mini-batch.\\n\\nVsub = Vrefs : tokens occurring in the available references.\\n\\nACL 2018, Melbourne M. Elbayad\\n\\n|| Token-level and Sequence-level Loss Smoothing ag:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "eys smoothing\\n\\nSequence-level | Lazy training\\nDefault training\\nLazy training\\n\\nrami(Y\"\\nx) = Er, [log po(-|x)]\\nrami (Y*.X) = -E,, [log pe(.x)]\\nline Linefy ~7 > log poly'lx)\\ni ~7 di log poly'lx)l=1\\nI=1\\nVI, y! is:\\nVI, y! is: forwarded in the RNN.\\nnot forwarded in the RNN.\\nused as target.\\nused as target.\\n\\nlog pe(y|y_i,\\nx)\\nlog pe(y|y_*,\\nx)\\n\\nACL 2018, Melbourne\\nM. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "eys smoothing\\n\\nSequence-level | Lazy training\\n\\nDefault training\\n\\nLazy training\\n\\nrami(Y\"\\nx) = Er, [log po(-|x)]\\n\\nrami (Y*.X) = -E,, [log pe(.1x)]\\n\\nis isee | ah, |& -T [log poly'lx) & -T Vlog poly'lx)\\n\\nI=1\\n\\nI=1\\n\\nVI, y! is:\\n\\nVI, y! is:\\n\\nforwarded in the RNN.\\n\\nnot forwarded in the RNN.\\n\\nused as target.\\n\\nused as target.\\n\\nlog pe(yilyi,\\nx)\\n\\nlog pe(yily*.\\nx)\\n\\nComplexity : O(2L.A)\\n\\nComplexity: O((L + 1)A)\\n\\nA= |y||@ceu|, where Oce) are the cell parameters.\\n\\nwsACL 2018, Melbourne\\n\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "m4 Octal alela lesACL 2018, Melbourne\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Image captioning on MS-COCO | setup\\n\\nGround truth 5 captions for every image.\\n- PS A\\n- soccer players pushing against each other as they try to get to the ball\\n- 2 man standing next to another man while kicking a soccer ball\\n- two men in a soccer field chasing a ball\\n- two soccer players pushing each other for the ball\\n- two soccer players appear to be pushing each other\\n\\nGenerated: Train 82k: a couple of men playing a game of soccer\\n\\nDev 5k\\n\\nGround truth Test 5k\\n- a small blue plane sitting on top of a field\\n- an airplane painted blue with black and white stripes\\n- model airplane with an American insignia and stripes on wings (Lin et al. 2014, Karpathy et al.\\n2015)\\n- an old warplane is on display in a field\\n- a blue small plane standing at the airstrip\\n- a small plane is sitting on the grass\\n\\nTop-down attention (Anderson et al.\\n2017) ACL 2018, Melbourne M. Elbayad | Token-level and Sequence-level Loss Smoothing 20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Image captioning on MS-COCO.\\n\\nResults\\nLoss\\nReward\\nVocab\\nBLEU-1\\nBLEU-4\\nCIDEr\\n\\nMLE\\n73.40\\n33.11\\n101.63\\n\\nTok\\nGlove, cosine\\n74.01\\n33.25\\n102.81\\n\\nACL 2018, Melbourne\\n\\nM. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Image captioning on MS-COCO.\\n\\nResults Loss Reward View BLEU-1 BLEU-4 CIDEr\\n\\nMLE 73.40 33.11 101.63\\n\\nToken Glove, cosine 74.01 33.25 102.81\\n\\nSeq Hamming 73.12 32.71 101.25 (Gouzi et al.\\n2016)\\n\\nSeq Hamming Vpatch 73.26 32.73 101.90\\n\\nSeq, lazy Hamming Vpatch 73.43 32.95 102.03\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Image captioning on MS-COCO.\\n\\nResults\\n\\nLoss        Reward      Vocab     BLEU-1     BLEU-4     CIDEr\\n\\nMLE                       73.40      33.11       101.63\\n\\nToken Glove, cosine       74.01      33.25       102.81\\n\\nSeq Hamming v            73.12      32.71       101.25\\n\\nSeq Hamming Vpatch       73.26      32.73       101.90\\n\\nSeq, lazy Hamming Voatch  73.43      32.95       102.03\\n\\nSeq CIDEr Voatch         73.50      33.04       102.98\\n\\nSeq CIDEr Vrets          73.42      32.91       102.23\\n\\nSeq, lazy CIDEr Vea      73.92      33.10       102.64\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Image captioning on MS-COCO.\\n\\nResults Loss Reward View\\nBLEU-1 BLEU-4 CIDEr\\nMLE 73.40 33.11 101.63\\nTok Glove, cosine 74.01 33.25 102.81\\nSeq Hamming 12.01 101.25\\nSeq Hamming Vpatch 13.26 32.73 101.90\\nSeq, lazy Hamming Vpatch 13.43 32.95 102.03\\nSeq CIDEr Vpatch 73.50 33.04 102.98\\nSeq CIDEr Vrets 73.42 32.91 102.23\\nSeq, lazy CIDEr Vea 73.92 33.10 102.64\\nTok-Seq CIDEr Vee 74.28 33.34 103.81\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing 21."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Machine translation | setup Architecture: Bi-LSTM encoder-decoder with attention (Bahdanau et al.\\n2015)\\n\\nCorpora: IWSLT'14 DE>EN WMT'14 EN>FR\\n\\nPairs:\\n\\nTrain 153k\\nTrain 12M\\n\\nDev 7k\\nDev 6k\\n\\nTest 7k\\nTest 3k\\n\\n|V| = 22k words.\\n|V| = 30k words.\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing 22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Machine translation | Results Loss Reward Vsup WMT '14 En->Fr IWSLT '14 De>En MLE 30.03 2055 tok Glove, cosine 30.19 27.83 ACL 2018, Melbourne M.\\nElbayad\\n\\nToken-level and Sequence-level Loss Smoothing 23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Machine translation | Results\\n\\nLoss     Reward     Vsup\\n\\nWMT'14 En->Fr                IWSLT'14 De->En\\n\\nMLE                     30.03          2055tok\\nGlove, cosine           30.19          21.83\\nSeq Hamming v           30.85          27.98 (Norouzi et al.\\n2016)\\nSeq Hamming Vpatch      31.18          28.54\\nSeq BLEU-4\\n- Voaten     31.29          28.53\\n\\nACL 2018, Melbourne M. Elbayad\\n\\n|| Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Machine translation | Results\\n\\nLoss                Reward              Vsup\\n\\nWMT'14 En->Fr      IWSLT'14 De>En\\n\\nMLE                 30.03              2055tok Glove, cosine\\n30.19              21.83\\n\\nSeq Hamming v       30.85              27.98\\n\\nSeq Hamming Vpatch  31.18              28.54\\n\\nSeq BLEU-4 Vpatch   31.29              28.53\\n\\nTok-Seq Hamming Vpatch 31.36         28.70\\n\\nTok-Seq BLEU-4 Vossen  31.39         28.74\\n\\nACL 2018, Melbourne M. Elbayad\\n- Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Conclusion ACL 2018, Melbourne\\nM. Elbayad\\nIl Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Takeaways\\n\\nImproving over MLE with:\\n- Sequence-level smoothing: an extension of RAML (Norouzi et al.\\n2016)\\n- Reduced support of the reward distribution.\\n- Importance sampling.\\n- Lazy training.\\n\\nACL 2018, Melbourne\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Takeaways\\n\\nImproving over MLE with:\\n- Sequence-level smoothing: an extension of RAML (Norouzi et al.\\n2016)\\n- Reduced support of the reward distribution.\\n- Importance sampling.\\n- Lazy training.\\n- Token-level smoothing: smoothing across semantically similar tokens instead of the usual uniform noise.\\n\\nBoth schemes can be combined for better results.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 25:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Future work\\n- Validate on other seq2seq models besides LSTM encoder-decoders.\\n- Validate on models with BPE instead of words.\\n- Sequence-level smoothing: Experiment with other distributions for sampling other than the Hamming distance.\\n- Token-level smoothing: Sparsify the reward distribution for scalability.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 26"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "ACL 2018, Melbourne\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "smoothing Combination Hyper-parameters: a, @1, @2 € (0,\\n1) (Va, @=1- a). Combining ML and RAML:\\nfRAML ol\"\\nX) = ORamL(Y*\\nx) + Gbwe(y*,\\nx) (12)\\nCAML co Y*)\\nX) = OMY\",\\nx) + Olawe(Y*,\\nx) (13)\\nCombining the smoothing schemes:\\ntok mORAML oy ao Y*\\nx) = aE, [Cw (y, x)] + Qe (7\\nx) = aE, [ardiuily\\nX) + @2bwe(y, x)] + Gis (arb (¥*,\\nx) + Girlwe(Y*, x). (14)\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Training time\\n\\nAverage wall time to process a single batch (10 images 50 captions) when training the RNN language model with fixed CNN (without attention) on a Titan X GPU.\\n\\n| Loss | MLE | Tok | Seq | Seq lazy | Seq | Seq lazy | Seq | Seq lazy | Tok-Seq | Tok-Seq | Tok-Seq |\\n| Reward | | Glove sim | Hamming | Vsub | v | v | Voatch | Vbatch = Vrets | Vref | v | Voatch | Vrets ms/batch |\\n\\n| 347 | 359 | 300 | 349 | 395 | 337 | 401 | 336 | 445 | 446 | 453\\n\\nACL 2018, Melbourne M. Elbayad\\n\\nToken-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Generated captions\\n\\nGround truth: 'two zebras standing in a grassy field and one is eating grass a zebra looking up as another grazes in a field the zebras are grazing out in the field.\\n\\nWier a group of zebras stand together in a field GZ several zebras eating grass in a wildlife park\\n\\nGenerated: | dat \\ Baseline: a couple of zebras standing on top of a grass covered field/AW Seq: a couple of zebras standing on top of a grass covered field Tok: 2 couple of zebras standing next to each other on a field Tok-Seq: a couple of zebras are standing in a field\\n\\nGround truth: a bunch of bananas and an orange sitting in a pile bananas and an orange are sitting together on the cloth five yellow bananas and one orange orange together a tangerine sitting on top of some bananas there is one orange laying among five bananas\\n\\nGenerated: Baseline: a bunch of bananas sitting on a table Seq: a close up of a bunch of bananas Tok: 2 bunch of bananas that are on a table Tok-Seq: a bunch of bananas sitting next to a banana\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 31"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Gr etarele -) kere wel nS 1g leaSource (en) | think it's conceivable that these data are used for mutual benefit.\\n\\nTarget (fr) J'estime qu'il est concevable que ces données soient utilisées dans leur intérêt mutuel.\\n\\nMLE Je pense qu'il est possible que ces données soient utilisées pour des fins réciproques.\\n\\nTok-Seq Je pense qu'il est possible que ces données soient utilisées pour le bénéfice mutuel.\\n\\nSource (en) | The public will be able to enjoy the technical prowess of young skaters, some of whom, like Hyeres' young star, Lorenzo Palumbo, have already taken part in top-notch competitions.\\n\\nTarget (fr) Le public pourra admirer les prouesses techniques de jeunes qui, pour certains, fréquentent déjà les compétitions au plus haut niveau, à l'instar du jeune prodige hyérois Lorenzo Palumbo.\\n\\nMLE Le public sera en mesure de profiter des connaissances techniques des jeunes garçons, dont certains, à l'instar de la jeune star américaine, Lorenzo, ont déjà participé à des compétitions de haut niveau.\\n\\nTok-Seq Le public sera en mesure de profiter de la finesse technique des jeunes musiciens, dont certains, comme la jeune star de l'entreprise, Lorenzo, ont déjà pris part à des compétitions de gymnastique.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "MS-COCO server results\\n\\nBLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE-L CIDEr SPICE\\n\\nGoogle NICt (Vinyals et al.,\\n2015)\\n71.3 89.5 54.2 80.2 40.7 69.4 30.9 58.7\\n\\nHard-Attention (Xu et al.,\\n2015)\\n70.5 88.1 52.8 77.9 38.3 65.8 27.7 53.7\\n\\nATT-FCN* (You et al.,\\n2016)\\n73.1 90.0 56.5 81.5 42.4 70.9 31.6 59.9\\n\\nReview Nett (Yang et al.,\\n2016)\\n72.0 90.0 55.0 81.2 41.4 70.5 31.3 59.7\\n\\nAdaptive* (Lu et al.,\\n2017)\\n74.8 92.0 58.4 84.5 44.4 74.4 33.6 63.7\\n\\nSCST:Att2all*t (Rennie et al.,\\n2017)\\n78.1 93.7 61.9 86.0 47.0 75.9 35.2 64.5\\n\\nLSTM-a3t+to (Yao et al.,\\n2017)\\n78.7 93.7 62.7 86.7 47.6 76.5 35.6 65.2\\n\\nUp-Down t (Anderson et al.,\\n2017)\\n80.2 95.2 64.1 88.8 49.1 79.4 36.9 68.5\\n\\n* = Ours: Tok-Seq CIDEr\\n72.6 89.7 55.7 80.9 41.2 69.8 30.2 58.3\\n\\nOurs: Tok-Seq CIDEr a\\n74.9 92.4 58.5 84.9 44.8 75.1 34.3 64.7\\n\\ni = Table: MS-COCO's server evaluation.\\n(+) for ensemble submissions, (T) for submissions with CIDEr optimization, and (°) for models using additional data.\\n\\nACL 2018, Melbourne\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "P. Anderson, X. He, C. Buehler, D. Teney, M. Johnson, S. Gould, and L. Zhang.\\n2017. Bottom-up and top-down attention for image captioning and visual question answering.\\narXiv preprint arXiv:1707.07998.\\n\\nJ. Lu, C. Xiong, D. Parikh, and R. Socher.\\n2017. Knowing when to look: Adaptive attention via a visual sentinel for image captioning. In CVPR.\\n\\nS. Rennie, E. Marcheret, Y. Mroueh, J. Ross, and V. Goel.\\n2017. Self-critical sequence training for image captioning. In CVPR.\\n\\nO. Vinyals, A. Toshev, S. Bengio, and D. Erhan.\\n2015. Show and tell: A neural image caption generator. In CVPR.\\n\\nK. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhutdinov, R. Zemel, and Y. Bengio.\\n2015. Show, attend and tell: Neural image caption generation with visual attention. In CML.\\n\\nACL 2018, Melbourne\\n\\nM. Elbayad || Token-level and Sequence-level Loss Smoothing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Z. Yang, Y. Yuan, Y. Wu, R. Salakhutdinov, and W. Cohen.\\n2016. Encode, review, and decode: Reviewer module for caption generation. In NIPS.\\n\\nT. Yao, Y. Pan, Y. Li, Z. Qiu, and T. Mei.\\n2017. Boosting image captioning with attributes. In CLR.\\n\\nQ. You, H. Jin, Z. Wang, C. Fang, and J. Luo.\\n2016. Image captioning with semantic attention. In CVPR.\\n\\nACL 2018, Melbourne M. Elbayad || Token-level and Sequence-level Loss Smoothing 36"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 128,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "DyOE nir-scir Complex Model Wins\\n\\nInitial [B-ARGO.0.001, /BARGO 01]\\n\\nTowards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation\\n\\nWanxiang Che, Yijia Liu, Yuxuan Wang, Bo Zheng, Ting Liu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "CB wesc 9326.592.592 2891.523.591 2290.590\\n20.5 Dependency Parsing NMTu Baseline\\nmsearch SOTA\\na Distillation = Ensemble\\nmu Baseline\\nmssearch SOTA\\nug Distillation = Ensemble"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "CB wesc 9326.592.5 06 0.8 | AA 92 2s | 2.691.5 1.323.591 | 2290.590 20.5 4 Dependency Parsing NMTu Baseline msearch SOTA a Distillation = Ensemble mu Baseline mssearch SOTA ug Distillation = Ensemble"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "QR ansom Classification vs. Structured Prediction Structured ( ) x > Y retol (orte) s Vir Y2 r Yn"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Classification vs. Structured Prediction\\n\\nI like this book sir om JeFX / XR /1X AN/H\\n\\nI like this book\\n\\n7 Predictor"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "(anSearch-based Structured Prediction I like this book/B/ixA/B -O-_-CO-_-O--_ 0ee ee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "- p(a|s) that Controls Search process \"Ply | J, like) CMC Mebock R/BK/ixz/B"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "(an Generic p(a |\\ns) Learning Algorithm argmax l(y=this) p(y | I, like) I like this book"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Problems of the Generic Learning Algorithm\\nAmbiguities in training data\\n\"both this and the seems reasonable\"\\nI me this book"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "QR vscm Problems of the Generic Learning Algorithm\\n\\nAmbiguities in training data\\n\\nTraining and test discrepancy\\n\\n\"both this and the seems reasonable\"\\n\\n\"What if I made wrong decision?\"\\n\\nI make this book B/ERIEA/F J/--Q-O"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "QR vscm Solutions in Previous Works\\n\\nAmbiguities in training data\\n\\nTraining and test discrepancy\\n\\nEnsemble (Dietterich,\\n2000)\\n\\nExplore (Ross and Bagnell,\\n2010)\\n\\nI me fis book"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Where We Are\\n\\nKnowledge Distillation\\n\\nAmbiguities in training data\\n\\nTraining and test discrepancy\\n\\nI'm making this book"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Knowledge Distillation\\n\\nLearning from negative log-likelihood\\n\\nLearning from knowledge distillation\\n\\nargmax l(y=this) p(y | I, like)\\nargmax sum, q(y) p(y | J, like)\\n\\ng(y | I, like) is the output distribution of a teacher model (e.g. ensemble)\\n\\nOn supervised data\\nargmax I(y=this) p(y | f, like)\\nsum, q(y) p(y | J, like)\\n\\n(1\\n-\\na) 0.5 A + a 0.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Knowledge Distillation: from Where Learning from knowledge distillation argmax sum, q(y) P(y | I, like).\\n\\nAmbiguities in training data\\n- Ensemble (Dietterich,\\n2000)\\n\\nWe use an ensemble of M structure predictors as the teacher q"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "(anKD on Supervised (reference) Data(y=this) p(y | J, like) sum, Q(y) p(y | J, like)(l-a) i + a... \"4\" Tike | this\\n- book Pt/BW/A/B -&_ @- 6 @_ ©OOO -@"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "QR asked on explored data sum, Q(y) p(y | I, like, the).\\n\"AI like / books <3 > / .R/S UX A/F | \"nae idan an Training and test discrepancy.\\n\\nExplore (Ross and Bagnell, 2010). We use teacher q to explore the search space & learn from KD on the explored data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "QR vscm\\n\\nExperiments\\n\\nTransition-based Dependency Parsing\\nLAS\\nNeural Machine Translation\\nBLEU\\n\\nPenn Treebank (Stanford dependencies)\\nIWSLT 2014 de-en\\n\\nBaseline 90.83\\nBaseline 22.79\\n\\nEnsemble (20) 92.73\\nEnsemble (10) 26.26\\n\\nDistill (reference, a = 1.0) 91.99\\nDistill (reference, a = 0.8) 24.76\\n\\nDistill (exploration) 92.00\\nDistill (exploration) 24.64\\n\\nDistill (both) 92.14\\nDistill (both) 25.44\\n\\nBallesteros et al. (2016) (dyn. oracle) 91.42\\nMIXER (Ranzato et al.\\n2015) 20.73\\n\\nAndor et al. (2016) (local, B=1) 91.02\\nWiseman and Rush (2016) (local B=1) 22.53\\nWiseman and Rush (2016) (global B=1) 23.83"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "QR vscmAnalysis:\\n- Why the Ensemble Works Better?\\n- Examining the ensemble on the \"problematic\" states.\\n- Optimal-yet-ambiguous\\n- Non-optimal; I mention this book"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "IR HIT-SCIR Analysis: K\\n\\nWhy the Ensemble Works Better?\\n- Examining the ensemble on the \"problematic\" states.\\n- Testbed: Transition-based dependency parsing.\\n- Tools: dynamic oracle, which returns a set of reference actions for one state.\\n- Evaluate the output distributions against the reference actions.\\n\\noptimal\\n- yet\\n- ambiguous       non\\n- optimal\\n\\nBaseline      68.59      89.59\\n\\nEnsemble      74.19      90.90"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "(5 Analysis: Is it Feasible to Fully Learn from KD w/o NLL?\\n\\n91.9\\n91.93\\nMt\\n664\\nvee\\n26.95\\n21-19\\n27.04\\n96.96\\n91.49\\n91-55\\n-\\n55.9\\n20:09\\n26.21\\noo\\n91.39\\n91.19\\n90.9\\n24.0\\n\\n01\\n02\\n03\\n04\\n05\\n06\\nO07\\n08\\n09\\n1\\n0\\n01\\n02\\n03\\n04\\n05\\n06\\n07\\n08\\n09\\n\\n1 Transition-based Parsing\\nNeural Machine Translation\\n\\nFully learning from KD is feasible"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Analysis: CB rentals Learning from KD Stable?\\nBaseline sccm\\nDistill (both):\\nTransition-based Parsing Neural Machine Translation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "QR vscm\\n\\nConclusion\\n- We propose to distill an ensemble into a single model both from reference and exploration states.\\n- Experiments on transition-based dependency parsing and machine translation show that our distillation method significantly improves the single model's performance.\\n- Analysis gives empirically guarantee for our distillation method."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "(5 Thanks and Q/A"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 86,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Target-Oriented Sentiment Classification\\n- Introduction\\n- Problem Formulation\\n- Transformation Networks for Target-Oriented Sentiment Classification\\n- Motivation\\n- The proposed model\\n- Experiment\\n- Settings\\n- Comparative Study"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Outline\\n- Target-Oriented Sentiment Classification\\n- Introduction\\n- Problem Formulation\\n- Motivation\\n- The proposed model\\n- Settings\\n- Comparative Study"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction\\n\\nTarget-Oriented Sentiment Classification (TOSC) is to detect the overall opinions/sentiments of the user review towards the given opinion target.\\nTOSC is a supporting task of Target/Aspect-based Sentiment Analysis [5].\\nTOSC has been investigated extensively in other names:\\n- Aspect-level Sentiment Classification [1, 7, 10, 11, 12].\\n- Targeted Sentiment Prediction [6, 14].\\n- Target-Dependent Sentiment Classification [2, 9]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Problem Formulation\\n\\nTOSC is a typical classification task but the input texts come from two sources:\\n- Target: explicitly mentioned phrase of opinion target, also called \"aspect term\" or \"aspect\".\\n- Context: the original review sentence or the sentence without target phrase.\\n\\nTOSC is to predict the overall sentiment of the context towards the target.\\n- [Boot time] is super fast, around anywhere from 35 seconds to 1 minute.\\nThis review conveys positive sentiment over the input \"Boot time\".\\n- Great [food] but the [service] is dreadful.\\nGiven the target \"food\", the sentiment polarity is positive while if the input target is \"service\", it becomes negative."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Outline\\n\\nIntroduction\\n\\nProblem Formulation\\n\\nTransformation Networks for Target-Oriented Sentiment Classification\\n\\nMotivation\\n\\nThe proposed model\\n\\nSettings\\n\\nComparative Study"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Convolutional Neural Network (CNN) is more suitable for this task than Attention-based Models [1, 6, 7, 10, 11, 12, 13].\\n- Sentiments towards the targets are usually determined by key phrases.\\nExample: This [dish] is my favorite and I always get it and never get tired of it.\\n- CNN, whose aim is to capture the most informative n-grams (e.g., \"is my favorite\") in the sentence, should be a suitable model.\\n- Attention-based weighted combination of the entire word-level features may introduce some noise (e.g., \"never\" and \"tired\" in the above sentence).\\n\\nWe employ proximity-based CNN rather than attention-based RNN as the top-most feature extractor."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "CNN likely fails in cases where a sentence expresses different sentiments over multiple targets.\\n- Example: great [food] but the [service] was dreadful!\\n\\nCNN cannot fully explore the target information via vector concatenation.\\n\\nCombining context information and word embedding is an effective way to represent a word in the convolution-based architecture [4].\\n\\nOur Solution:\\n\\n(i) We propose a \"Target-Specific Transformation\" (TST) component to better consolidate the target information with word representations.\\n\\n(ii) We design two context-preserving mechanisms \"Adaptive Scaling\" (AS) and \"Lossless Forwarding\" (LF) to combine the contextualized representations and the transformed representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Most of the existing works do not discriminate different words in the same target phrase.\\n\\nIn the target phrase, different words would not contribute equally to the target representation.\\n\\nFor example, in \"amd turin processor\", phrase head \"processor\" is more important than \"amd\" and \"turin\".\\n\\nOur TST solves this problem in two steps:\\n\\n(i) Explicitly calculating the importance scores of the target words.\\n\\n(ii) Conducting word-level association between the target and its context."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Model Overview\\n\\nFigure: Architecture of TNet."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Model Overview\\n\\nThe proposed TNet consists of the following three components:\\n- (BOTTOM) Bi-directional LSTM for memory building\\n- Generating contextualized word representations.\\n- (MIDDLE) Deep Transformation architecture for learning target-specific word representations\\n- Refining word-level representations with the input target and the contextual information.\\n- (TOP) Proximity-based convolutional feature extractor\\n- Introducing position information to detect the most salient features more accurately."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Deep Transformation Architecture stacks multiple Context-Preserving Transformation (CPT) layers.\\n- Deeper network helps to learn more abstract features (He et al., CVPR 2016; Lecun et al., Nature 2015).\\n\\nRevolution of Depth 22152 layers\\n\\nImageNet Classification top-5 error (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "CPT Layer\\n\\nThe functions of the CPT layer are twofold:\\n- Incorporating opinion target information into the word-level representations.\\n- Generating context-aware target-specific representations conditioned on the i-th word representation fed to the j-th layer:\\n\\nH(y, A_t) = exp(A_t h_r) / Σ exp(A_a h_r)\\n\\nFigure: Target-Specific Transformation (TST)\\n\\nHO: component(A_y) = g(W A_I? : 17] + 87),"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "CPT Layer\\n\\nPreserving context information for the upper layers\\n- We design two Context-Preserving Mechanisms to add context information back to the transformed word features\\n\\n(i) Adaptive Scaling (AS) (Similar to Highway Connection [8]):\\n\\nt{ = o(Wrransht + Brrons)\\n\\nHD = 2 6 M4\\n- Oyo.\\n\\n(ii) Lossless Forwarding (LF) (Similar to Residual Connection [3]):\\n\\nIH DZAY\\n-\\nA) 4 BO),"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "This component aims to capture the most salient feature w.r.t. the current target for sentiment prediction.\\nAs observed in (Chen et al., 2017; Li and Lam, 2017), distance information is effective for better locating the salient features.\\n- Basic idea: Up-weighting the words close to the target and down-weighting those far away from the target.\\n- Convolutional neural network (Kim,\\n2014) is used to extract features from the weighted word representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Outline\\n\\nIntroduction\\n\\nProblem Formulation\\n\\nMotivation\\n\\nThe proposed model\\n\\nExperiment Settings\\n\\nComparative Study"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Datasets\\n- LAPTOP, REST: datasets from SemEval 4 ABSA challenge, containing the user reviews from laptop domain and restaurant domain respectively.\\n- TWITTER: a dataset built in (Dong et al., 2014), containing twitter posts and the opinion targets are annotated.\\n\\nCompared Models\\n\\nTraditional Models:\\n- SVM (Kiritchenko et al., 2014).\\n\\nAttention-based Models:\\n- ATAE-LSTM (Wang et al.,\\n2016)\\n- MemNet (Tang et al.,\\n2016)\\n- IAN (Ma et al.,\\n2017)\\n- BILSTM-ATT-G (Liu and Zhang,\\n2017)\\n- RAM (Chen et al., 2017).\\n\\nOther Neural Models:\\n- AdaRNN (Dong et al.,\\n2014)\\n- TD-LSTM (Tang et al.,\\n2016)\\n- AE-LSTM (Wang et al.,\\n2016)\\n- CNN-ASP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Main Results\\n\\nModels             LAPTOP                       REST                        TWITTER\\nACC        Macro-F1        ACC        Macro-F1        ACC        Macro-F1\\nTNet variants\\nPNetLF        76.01     71.477             80.79     ~- 70.84         ~- 74.687  73.36\\nTNet-AS      76.54     71.75               ? = 71.27   14 74.97      14 73.60\\nSVM          70.49     . 80.167\\n- 63.40   \" 63.30\\nAdaRNN\\n-\\n-\\n-\\n-   66.305               65.905\\nAE-LSTM      68.90     \"\\n- 76.60\\n-\\n-\\n-\\nATAE-LSTM    68.70     ! . 77.208           * ' °- IAN\\n72.108\\n- 78.60   °\\n-\\n-\\n-\\nCNN-ASP      72.46     65.31              77.82  65.11  73.27  71.77\\nTD-LSTM      71.83     68.43              78.00  66.73  66.62  64.01\\nMemNet       70.33     64.09              78.16  65.83  68.50  66.91\\nBILSTM-ATT-G 74.37     69.90              80.38  70.78  72.70  70.84\\nRAM          75.01     70.51              79.79  68.86  71.88  70.33\\n\\n@ The proposed TNet-LF and TNet-AS consistently outperform the baselines.\\n- TNet variants perform well on both user reviews (LAPTOP & REST) and twitter posts (TWITTER)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Ablation Experiment Models\\n\\nLAPTOP REST TWITTER TREC\\n\\nMacro-FI__ ACC Macro-FI__ ACC Macro-FI\\n\\nTNet variants\\n- TNetLF Teor 71a? 80.79 70.84 74.68 73.36\\n- TNet-AS 76.54 71.75\\n- 70.69 71.27 74.97 73.60\\n- TST-ATT-CNN\\n- SOS-CSS\\n- T-SC\\n- COSSC\\n- SSSC\\n- OWOD\\n- C\\n- CTCOCPT\\n\\nAlternatives\\n- LSTM-FC-CNN-LF 75.59 70.60 80.41 70.28 73.70 72.82\\n- LSTM-FC-CNN-AS 75.78 70.72 80.23 70.06 74.28 72.60\\n- TNet w/o transformation 73.30 68.25 78.90 65.86 72.0 70.57\\n- TNet w/o context 73.91 68.87 80.07 69.01 74.51 73.05\\n- Ablated TNet Wet-LF w/o position 75.13 70.63 79.86 69.69 73.83 72.49\\n- TNet-AS w/o position 75.27 70.03 79.79 69.78 73.84 72.47\\n\\nUsing attention (ATT) and fully-connected layer (FC) to replace CPT layer makes the performance worse.\\n\\nEach component/element in TNet contributes to the overall performance improvement."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Impact of CPT layer number\\n\\nWe conduct experiments on the held-out training data of LAPTOP and vary layer number L from 2 to 10, increased by\\n2.\\n\\nIncreasing the layer number can increase the performance but the results will go down when L > 4 due to the limited training data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Case Study\\n\\nSentence 1: BILSTM-ATT-GRAM TNet-LF TNet-ASI. Air has higher resolution but the fonts are small.\\n\\nSentence 2: Great food but the service is dreadful.\\n\\nSentence 3: Sure it's not light and slim but the features make up for it 100%.\\n\\nSentence 4: Not only did they have amazing sandwiches, soup, pizza, etc., but their homemade sorbets are out of this world!\\n\\nSentence 5: Startup times are incredibly long\\n- over two minutes.\\n\\nSentence 6: I am pleased with the fast log on, speedy Wi-Fi connection and the long battery life (> 6 hrs).\\n\\nSentence 7: The staff should be a bit more friendly.\\n\\nOur TNet can make correct predictions when the opinion is target-specific, e.g., \"long\" in the 5th and the 6th example.\\nTNet can capture the salient features for target sentiment prediction accurately."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Summary: Our TNet employs CNN as a feature extractor to detect the salient features, avoiding introducing the noises.\\nArmed with target-specific word representation and proximity information, the TNet variants can predict the sentiment w.r.t.\\nthe target more accurately."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "References:\\n\\n[1] P. Chen, Z. Sun, L. Bing, and W. Yang. Recurrent attention network on memory for aspect sentiment analysis.\\nIn Proceedings of EMNLP, pages 463-472,\\n2017.\\n\\n[2] L. Dong, F. Wei, C. Tan, D. Tang, M. Zhou, and K. Xu.\\nAdaptive recursive neural network for target-dependent twitter sentiment classification.\\nIn Proceedings of ACL, pages 49-54,\\n2014.\\n\\n[3] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition.\\nIn Proceedings of CVPR, pages 770-778,\\n2016.\\n\\n[4] S. Lai, L. Xu, K. Liu, and J. Zhao. Recurrent convolutional neural networks for text classification.\\nIn Proceedings of AAAI, volume 333, pages 2267-2273,\\n2015.\\n\\n[5] B. Liu. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1-167,\\n2012.\\n\\n[6] J. Liu and Y. Zhang. Attention modeling for targeted sentiment. In Proceedings of EACL, pages 572-577,\\n2017.\\n\\n[7] D. Ma, S. Li, X. Zhang, and H. Wang. Interactive attention networks for aspect-level sentiment classification.\\nIn Proceedings of IJCAI, pages 4068-4074, 2017."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "[8] R. K. Srivastava, K. Greff, and J. Schmidhuber. Highway networks. arXiv preprint arXiv:1505.00387,\\n2015.\\n\\n[9] D. Tang, B. Qin, X. Feng, and T. Liu. Effective Istms for target-dependent sentiment classification.\\nIn Proceedings of COLING, pages 3298-3307, 2016a.\\n\\n[10] D. Tang, B. Qin, and T. Liu. Aspect level sentiment classification with deep memory network.\\nIn Proceedings of EMNLP, pages 214-224, 2016b.\\n\\n[11] Y. Tay, A. T. Luu, and S. C. Hui.\\nLearning to attend via word-aspect associative fusion for aspect-based sentiment analysis.\\narXiv preprint arXiv:1712.05403,\\n2017.\\n\\n[12] Y. Wang, M. Huang, X. Zhu, and L. Zhao. Attention-based Istm for aspect-level sentiment classification.\\nIn Proceedings of EMNLP, pages 606-615,\\n2016.\\n\\n[13] M. Yang, W. Tu, J. Wang, F. Xu, and X. Chen. Attention based Istm for target dependent sentiment classification.\\nIn Proceedings of AAAI, pages 5013-5014, 2017."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "[14] M. Zhang, Y. Zhang, and D.-T. Vo. Gated neural networks for targeted sentiment analysis.\\nIn Proceedings of AAAI, pages 3087-3093, 2016."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 314,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "semantic Role Labeling (SRL) © Find out \"who did what to whom\" in text\\n- Capture predicate-argument structures.\\n\\nARGO [eater ARG! meal with friends]\\n\\niWAM-COM | comitative -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "semantic Role Labeling (SRL) © Find out \"who did what to whom\" in text\\n- Capture predicate-argument structures. Anco [eatery ARG meal | |7 \"i with friends} 99] tiAM-COM comitative\\n- ARCO) eae A ea [Be| pizza with friends ace a \\2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "SRL as BIO Tagging: 2: BAM. LAM -AM- [AME AME -AM- PRP || PRP | PRP | PRP PRP PRPae\\n\\nMany tourists visit Disney to meet their favorite cartoon characters.\\n\\nNeeds target predicate as input! (Prior works typically used gold predicates)\\n\\nCollobert et al., 2011, Zhou and Xu, 2015, He et al., 2017, inter alia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "SRL as BIO Tagging\\n\\nMany tourists visit Disney to meet their favorite cartoon characters.\\n\\nNeeds to re-run the tagger for each predicate."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "SRL as Predicting Word-Span Relations\\nAM-PR\\nPalae ARG1\\n[Many tourists visit Disney]\\n0\\nfmeei har favor cartoon characters\\nOoARGO ARG1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "SRL as Predicting Word-Span Relations\\n\\nP=)\\n2) alaé ARG1 Disney] to [meet her Tavorte cartoon characters\\n\\nSARGO ARG1\\n\\nAdvantages:\\n- Jointly predict predicates\\n- Span-level features (similar to Punyakanok, FitzGerald, inter alia)\\n\\nChallenge:\\n- Too many possible edges (n? argument spans x n predicates)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Our Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Our Model: Overview\\n\\nCompany tourists visit Disney to meet their favorite cartoon characters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Our Model: Overview\\n\\nConstruct span representations for all n spans!\\n\\nMany tourists visit Disney to meet their favorite cartoon characters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Our Model: Overview\\n\\nLocal classifier over labels (including NULL)\\n\\nLabel for all possible (predicate, argument) pairs\\n\\nNode & Edge\\n\\nRepresentation\\n\\nConstruct span representations for all spans!\\n\\nWord & Char Embeddings\\n\\nMany tourists visit Disney to meet their favorite cartoon characters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Our Model: Overview\\n\\nLocal classifier over labels (including NULL)\\n\\nLabel for all possible (predicate, argument) pairs\\n\\nGreedy beam pruning for spans\\n- Construct span representations for all spans!\\n\\nAny tourists visit Disney to meet their favorite cartoon characters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Local Label\\n\\nSpan Representations Classifiers Pruning\\n\\nRepresentation\\n\\nMany tourists visit Disney to meet their favorite cartoon characters (Same as Lee et al., 2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Local Label\\n\\nSpan\\n\\nRepresentations Classifiers Pruning [BILSTM(w1 : Wn) → BELSTM(wy : Wn) Env] if de hcecealbcolind left context Je.\\nright context\\n\\nSer 7-se- la ed SSP PSD DSSS (LC -Ca Cas ak Ce Cok CoC Word & Char SF NE NE OM ONS ONS ONS XG Embeddings C® @G8 C8 C8 CO C8 CO CO CO CO\\n\\nMany tourists visit Disney to meet their favorite cartoon characters (Same as Lee et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Local Label\\nSpan Representations Classifiers Pruning LSTM boundary points [BILSTM(w : Wn) → BILSTM(w1 : Wn)]\\nEND1 = START Span Representation\\n\\nMany tourists visit Disney to meet their favorite cartoon characters (Same as Lee et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "(1) Span fs\\n(3) SpanFecreeenietions\\n(2) Local Label Classifiers\\nPruninLabeling\\nARGOSoftmax\\nARG1ARG2Node & Edge =Representation\\n2 e\\CC® C8 C8 OC8F COCO OF OCOD OO OCOD OOg ae OR SR eR OR oR BR OB\\ni(LCase Col Cas Cad edoWord & Char\\nEONS ME ONS ONE OMS ONS MEEmbeddings\\nC® CGO C8 C8 CO C8 CO C8 CO\\nMany tourists visit Disney to meet their favorite cartoon characters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "(1) Span fs\\n\\n(3) SpanFecreeenietions\\n\\n(2) Local Label Classifiers\\n\\nPruninLabeling\\n\\n)SoftmaxNode & EdgeScores\\n\\nton® @Representation\\n\\n2 e\\Hiah og 89 oR ae CC® C8 C8 ODO OO COSoS oS YN fh) fh of Nf i(LCase Col Cas Cad edoWord & Char SF NE ONE ON ONE ONS OMS OMEEmbeddings C® CGO C8 C8 CO C8 CO C8 CO\\n\\nMany tourists visit Disney to meet their favorite cartoon characters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "(1) Span\\n\\n(3) Span Fecreeenietions\\n\\n(2) Local Label Classifiers Prunin Labeling Softmax Node & Edge Scores\\n\\nton® eSpan\\n\\nese 90 al Representation e\\CC® C8 C8 OC8F COCO OF OCOD OO OCOD OO SoS oS YN fh) fh of Nf i(LCase Col Cas Cad edo Word & Char EONS ME ONS ONE OMS ONS ME Embeddings C® CGO C8 C8 CO C8 CO C8 CO COM\\n\\nany tourists visit Disney to meet their favorite cartoon characters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "(1) Span fs\\n\\n(3) SpanFecreeenietions\\n\\n(2) Local Label Classifiers\\n\\nPruning Labeling\\n\\nSoftmax P(y_pred) = exp(pred) / Σ exp(pred)\\n\\nScores\\n\\nRepresentation\\n\\nMany tourists visit Disney to meet their favorite cartoon characters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Representations\\n\\n(2) Local Label Classifiers\\n\\nSun(c(pred, arg, /) = ®, (pred) ∈ (arg, pred)@{iLEISBolan teriet)\\n\\nMany tourists meet"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Soyrecaniatione\\n\\n(2) Local Label Classifiers\\n\\n(pred, arg, /) = 6, (arg) + &, (pred) + 6, (arg, pred) @{iOARGO)\\n\\nMany tourists, \"meet\"\\n\\nMany tourists, \"meet\"\\n\\nPred./Arg.\\n\\nMany tourists, \"meet\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "(1) Span \"c: (3) SpanRecreeenietiars (2) Local Label Classifiers Prunino(pred, arg, /) = ®,(arg) + ®,(pred) +\\n6) (arg, pred) ARGO(\"Many tourists\", \"meet\", «) = 0 ©Petar (\"Many tourists\", \"meet\", ARGO) © oO (\"Many tourists\", \"meet\", ARG1) OARGO) (entany tourists\", \"meet\") lb J EARS) (Many tourists\", \"meet\") Pred/A .\\n¥rea/Arg. ®,(\"Many tourists\" ®, (\"meet\") Ct\\ni) GANG et©ee@ OOMany tourists 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "(1) Span\\n(2) Local Label\\n- Representations\\n- Classifiers\\n(3) Span Pruning O(n²) arguments, O(n) predicates, -> O(n⁰) edges!\\nSpan\\nRepresentation ?\\n\\nMany tourists visit Disney to meet their favorite cartoon characters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "(1) Span\\n\\n(2) Local Label; Representations Classifiers\\n\\n(3) Span Pruning®, (\"many tourists\") = 2.5 Only keep top O(n) spans.\\nUsing their unary scores ®, (\"tourists visit Disney\") = -0.8 Formest iSpan 000\\n\\nRepresentation?\\nAN Ly 4 + /9\\ lomy SLRS SEREESSoS oS YN fh) fh of Nf i(LCase Col Cas Cad edoTe me CF ME ON OM ONS ONS ONS ONE\\n\\nEmbeddings CO @GO© CGO CO GOH CO CO CO CO\\n\\nMany tourists visit Disney to meet their favorite cartoon characters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Results & Analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "End-to-End SRL Results\\n\\nWM He17 M@ Ours TM He17 (Ensemble) M Ours + ELMo\\n- BIO-based, es85\\n- PIPELINED Predicate\\n\\n1D pene 81.276.870.870\\n- csreeeeeeeeeeeeeeeeeereneeeeeneeeeee\\nGB seseceeeeececeneteanenasnaasscsssassts\\npoveeeecceeeeeeneeeanannsscssaaaes 65:\\nscvctintctntntctnteteteie sstctctctetctntntcteee\\npcvctntntctetntcteteie 60\\n\\nCoNLO5 WS Test\\nCoNLO05 Brown Test\\nCoNLL2012 (OntoNotes)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "End-to-End SRL Results\\n\\nWM He17 M@ Ours TM He17 (Ensemble) M Ours + ELMo\\n\\nQOH BOT Soren\\n\\none 31.9 825 82.7 nog 82.9 cael 76.8 eg\\n\\n[70 = | 63.5 10.1 a Lae 65\\n- With ELMo, over 3 points improvement over SotA ensemble!\\n\\n*ELMo: Deep Contextualized Word Representations, Peters et al., 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Span-based vs. BIO\\nBIO Span-based (He17) (this work)\\nInputs\\nPredicate\\nSentence\\nPredicate Identification\\nPipelined\\nJoint\\nGlobal Consistency\\nLong-range Dependency"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Span-based vs.\\nBIOBIO Span-based (He17) (this work) (Sentence, Inputs ee) Sentence D Due to the strong independence pipelined Joint assumption we make.\\nGlobal Consistency 'Long-range Dependency 24"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Span-based vs. BIOBIO Span-based (He17) (this work) (Sentence, Inputs ee)\\n\\nSentenceD\\n\\nDue to the strong independence assumption, we make.\\nGlobal Con by allowing direct interaction between predicates and arguments. Long-range Dependency"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Conclusion\\n- Joint prediction of predicates and arguments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Conclusione\\n\\nJoint prediction of predicates and arguments\\n- Our recipe:\\n1. Contextualized span representations.\\n2. Local label classifiers.\\n3. Greedy span pruning."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Conclusion\\n- Joint prediction of predicates and arguments.\\n\\nOur recipe:\\n1. Contextualized span representations; RP, ost\\n2. Local label classifiers\\n3. Greedy span pruning\\n\\nFuture work: Improve global consistency, use span representations for downstream tasks, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "THANK YOU!\\nvs ¥Code and pertained models:\\n1 https://github.com/luheng/Isgn"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 175,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Read the question carefully!\\n\\nName:\\n\\nDirections: Read the questions carefully and write neat literate solutions in the space provided.\\n1. Show that [AAB > C] > [A (B > C)] is a tautology by using (a) a truth table\\n\\nPlease read the questions carefully.\\nPlease draw the cash flow diagram that you are going to approach to solve the problems then solve the details in solving the problems.\\nMissing Cash Flow Diagram is a deductible point 20% of the total points for each question.\\n1) The TechEdge Corporation offers two forms of 4-year service for a loop water purification system used in the manufacture of semiconductor and high-speed digital devices."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Tabular QA Visual QA Reading Comprehension\\n\\nPeyton Manning became the first quarterback ever to lead two different teams to multiple Super Bowls.\\nHe is also the oldest quarterback ever to play in a Super Bowl at age\\n39.\\nThe past record was held by John Elway, who led the Broncos to victory in Super Bowl XXXIII at age 38 and is currently Denver's Executive Vice President of Football Operations and General Manager.\\n\\nQ: How many medals did India win?\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\n\\nQ: What is the name of the quarterback who was 38 in Super Bowl XXXIII?\\n\\nA: John Elway\\n\\nNeural Programmer (2016) Kazemi and Elqursh (2017) model. Yu et al (2018) model.\\n33.5% accuracy on VQA 1.0 dataset 84.6 F-1 score on SQUADWiki Table Questions (state of the art = 66.7%)\\n\\nHave the models read the question carefully?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Visual QA Kazemi and Elqursh (2017) model. 61.1% on VQA dataset (state of the art = 66.7%)\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\n\\nA: very"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Visual QA Kazemi and Elqursh (2017) model.\\n\\n61.1% on VQA dataset (state of the art = 66.7%)\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How asymmetrical are the white bricks on either side of the building?\\nA: very"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Visual QA Kazemi and Elqursh (2017) model. 61.1% on VQA dataset (state of the art = 66.7%)\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How asymmetrical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How big are the white bricks on either side of the building?\\nA: very"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Visual QA Kazemi and Elqursh (2017) model.\\n\\n61.1% on VQA dataset (state of the art = 66.7%)\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How asymmetrical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How big are the white bricks on either side of the building?\\nA: very\\n\\nQ: How spherical are the white bricks on either side of the building?\\nA: very\\n\\nQ: How fast are the bricks speaking on either side of the building?\\nA: very"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "QA over tables\\n\\nNeural Programmer (2016) 33.5% validation accuracy on WikiTableQuestions dataset (state of the art)\\n\\nQ: Which country won the most medals?\\n- Cuba\\n- Mexico\\n- Ecuador\\n- Argentina"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "QA over tables\\n\\nNeural Programmer (2016)\\n33.5% validation accuracy on WikiTableQuestions dataset (state of the art)\\n\\nQ: Which country won the most number of medals?\\nB Neural Programmer:\\n- Mexico (bronze)\\n- Argentina\\n- Ecuador\\n- Venezuela"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Test/dev accuracy does not show us the entire picture"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Jia and Liang (2017): Adversarial Attacks on Reading Comprehension Models\\nEMNLP 2017 Outstanding Paper Award\\n\\nAdd an adversarial sentence to the paragraph to fool the model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Jia and Liang (2017): Adversarial Attacks on Reading Comprehension Models\\n\\nEMNLP 2017 Outstanding Paper Award\\n\\nAdd an adversarial sentence to the paragraph to fool the model\\n\\nArticle: Nikola Tesla\\n\\nParagraph: \"In January 1880, two of Tesla's uncles put together enough money to help him leave Gospic for Prague where he was to study.\\nUnfortunately, he arrived too late to enroll at Charles-Ferdinand University; he never studied Greek, a required subject; and he was illiterate in Czech, another required subject.\\nTesla did, however, attend lectures at the university, although, as an auditor, he did not receive grades for the courses.\"\\n\\nQuestion: \"What city did Tesla move to in 1880?\"\\n\\nAnswer: Prague\\n\\nModel Predicts: Prague"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Jia and Liang (2017): Adversarial Attacks on Reading Comprehension Models\\nEMNLP 2017 Outstanding Paper Award\\n\\nAdd Sent\\nAdd an adversarial sentence to the paragraph to fool the model.\\n\\n(Step\\n1)\\n(Step\\n2)\\nMutate\\n\\nGenerate question\\nFake answer\\n\\nArticle: Nikola Tesla\\n\\nWhat city did Tadakatsu move to?\\n\\nChicago\\n\\nParagraph: \"In January 1880, two of Tesla's uncles (Step\\n3) put together enough money to help him leave Gospic for Prague where he was to study.\\nUnfortunately, he arrived too late to enroll at Charles-Ferdinand University; he never studied Greek, a required subject; and he was illiterate in Czech, another required subject.\\nTesla did, however, attend lectures at the university; although, as an auditor, he did not receive grades for the courses.\"\\n\\nQuestion: \"What city did Tesla move to in 1880?\"\\n\\nAnswer: Prague\\n\\nModel Predicts: Prague\\n\\nAdversary Adds: Tadakatsu moved to the city of Chicago in\\n1881.\\n\\nModel Predicts: Chicago"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Jia and Liang (2017): Adversarial Attacks on Reading Comprehension Models\\nEMNLP 2017 Outstanding Paper Award\\n- Highly successful attacks: over 16 models, F1 score drops from 75% to 36%.\\n- Their takeaway: reading comprehension models are overly stable; unable to distinguish a sentence that answers the question from one that merely has words common with the question."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Jia and Liang (2017): Adversarial Attacks on Reading Comprehension Models\\nEMNLP 2017 Outstanding Paper Award\\n\\nHighly successful attacks: over 16 models, F1 score drops from 75% to 36%.\\nTheir takeaway: reading comprehension models are overly stable; unable to\\ndistinguish a sentence that answers the question from one that merely has\\nwords common with the question.\\n\\nQuestion for us: How does overstability manifest? Why do their attacks work?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Our contributions:\\n- A workflow based on attributions (word importances) to understand input-output behavior of networks.\\n- Identify weaknesses in the networks as suggested by attributions.\\n- Craft adversarial examples by exploiting the weaknesses.\\n- Explain and improve Jia and Liang (2017)'s attacks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Attributions\\n\\nProblem statement: Attribute a complex deep network's prediction to input features, relative to a certain baseline (informationless) input.\\n\\nE.g.: attribute an object recognition network's prediction to its pixels, a text sentiment network's prediction to individual words.\\n\\nExplain F(input)\\n- F(baseline) in terms of input features."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Integrated Gradients (Sundararajan et al. (2017), ICML)\\n\\nDefinition 1 (Integrated Gradients)\\n\\nGiven an input x and baseline x', the integrated gradient along the i-th dimension is defined as follows.\\n\\nIG(z,\\na) = ∫(a) [∇F(x' + α(x\\n- x'))] dα\\nwhere ∇F is the gradient of F along the i-th dimension at x.\\n\\nWhy Integrated Gradients?\\n- Axiomatic justification (see Sundararajan et al. (2017) for details)\\n- Ease of implementation; only gradient computations required\\n- Running time < 0.5 seconds for a given input example"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Visual QA attributions\\n\\nQ: How symmetrical are the white bricks on either side of the building?\\nA: very.\\n\\nHow symmetrical are the white bricks on either side of the building?\\n- red: high attribution\\n- blue: negative attribution\\n- gray: near-zero attribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Overstability\\n\\nDrop all words from the dataset except ones which are frequently top attributions.\\n\\nE.g. How many players scored more than 10 goals?\\n- How many"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Overstability Drop all words from the dataset except ones which are frequently top attributions. E.g.\\nHow many players scored more than 10 goals?\\n- How many Visual QA Neural Programmer num. words in vocab color, many, what, how, doing, or, where, there, ...\\nmany, tm_token, how, number, total, after, ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Adversarial Examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Stopword deletion attack\\n\\nDelete contentless words from the question: how, tell, did, me, my, our, are, is, were, this, on, would, and, for, should, be, do, |, have, had, the, there, look, give, has, was, we, get, does, a, an, 's, that, by, based, in, of, bring, with, to, from, whole, being, been, want, wanted, as, can, see, doing, got, sorted, draw, listed, chart, only\\n\\nNeural Programmer's accuracy falls from 33.5% to 28.5%\\n\\nVQA model's accuracy falls from 61.1% to 52.0%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Subject ablation attack\\n\\nReplace the subject of a question with a low-attribution noun from the vocabulary\\n\\nLow-attribution nouns\\n\\nWhat is the man doing?\\n- What is the tweet doing?\\n\\n' tweet '\\n\\nHow many children are there?\\n- How many tweets are there?\\n\\n' childhood ', ' copyrights ', ' mornings ',\\n\\nirspomanae VQA model's response remains the same 75.6% of the time on questions that it originally answered correctly\\n\\n' topless ', ' critter ', ' jumper ', ' fits '"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Prefix a content-free phrase to the question\\n\\nNeural Programmer Visual QA\\n\\nOriginal accuracy: 33.5%\\nOriginal accuracy: 61.1%\\n\\nAttack phrase                     Prefix                  Prefix Accuracy\\nin not a lot of words            20.6%\\nin not a lot of words            35.5%\\nif it's all the same             21.8%\\nin not many words               32.5%\\nin not many words               15.6%\\nwhat is the answer to          31.7%\\none way or another              23.5%\\nUnion of all three              19%\\nUnion of above attacks        11.4%\\n\\nBaseline prefixee\\nLow attribution                     tell me                      515%\\nplease answer                      32.3%\\nanswer this                           55.1%\\ndo you know                       31.2%\\nwords > answer this for me  49.8%\\nUnion of baseline prefixes     30.6%\\nUnion of baseline prefixes     46.9%\\n28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Operator triggers in Neural Programmer\\n\\nOperator Triggers\\n\\nselect [tm_token, many, how, number, or, total, after, before, only]\\n\\nprev [before, many, than, previous, above, how, at, most]\\n\\nfirst [tm_token, first, before, after, who, previous, or, peak]\\n\\nreset [many, total, how, number, last, least, the, first, of]\\n\\ncount [many, how, number, total, of, difference, between, long, times]\\n\\nnext [after, not, many, next, same, tm_token, how, below]\\n\\nlast [last, or, after, tm_token, next, the, chart, not]\\n\\nmfe [most, cm_token, same]\\n\\nmin [least, the, not]\\n\\nmax [most, largest]\\n\\ngeq [at, more, least, had, over, number, than, many]\\n\\nprint [tm_token]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Prefix a content-free phrase to the question\\n\\nNeural Programmer Visual QA\\n\\nOriginal accuracy: 33.5%\\nOriginal accuracy: 61.1%\\n\\nAttack phrase Prefix\\n\\nAccuracy\\n\\nin not a lot of words\\n20.6%\\n\\nin not a lot of words\\n35.5%\\n\\nif it's all the same\\n21.8%\\n\\nin not many words\\n32.5%\\n\\nin not many words\\n15.6%\\n\\nwhat is the answer to\\n31.7%\\n\\none way or another\\n23.5%\\n\\nUnion of all three\\n19%\\n\\nUnion of above attacks\\n11.4%\\n\\nBaseline prefixee Low-attribution\\n\\ntell me\\n515%\\n\\nplease answer\\n32.3%\\n\\nanswer this\\n55.1%\\n\\ndo you know\\n31.2%\\n\\nwords > answer this for me\\n49.8%\\n\\nUnion of baseline prefixes\\n30.6%\\n\\nUnion of baseline prefixes\\n46.9%\\n\\n30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Predicting the effectiveness of Jia and Liang (2017)'s adversarial attacks\\n\\nAttacks are more likely to be effective when high-attribution words are present in the adversarial sentence.\\nOnly low-attribution words are mutated.\\n\\nQuestion:\\n\\nADDSENT attack that does not work.\\n\\nAttack that works:\\n\\nJeff Dean was the mayor of Bracco. Jeff Dean was the mayor of Melfi.\\n\\nWho was Count of Melfi?\\n\\nSamak was prime minister of Abhisit Vejjajiva, who was chief minister.\\n\\nWhat country was Abhisit Vejjajiva from?\\n\\nThe country of Chicago, despite having been born in Leeds.\\n\\nBorn in Newcastle?\\n\\nAccording to net state product, Adelaide ranked 7 in Australia.\\n\\nAccording to gross state product, Jaide ranks 7 in New Zealand. (as a prefix)\\n\\nWhen did the Methodist Protestant Church split from the Presbyterian Anglican in 1805?\\n\\nSplit from the Methodist Episcopal Church?\\n\\nRed: high attribution, blue: negative attribution, gray: near-zero attribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Summary\\n\\nAn attribution-based workflow to look inside and understand weaknesses of a model. Explained how overstability manifests\\n- QA networks do not focus on the right words!\\n\\nCrafted adversarial examples and improved Jia and Liang (2017)'s attacks.\\n\\nOutlook\\n\\nDeep learning practitioners can easily use attributions to look inside models.\\n- Adding soft network constraints\\n- E.g. add bias to attention vector so as to limit the influence of \"how\", \"what\", etc.\\n- Informed enrichment of datasets\\n- E.g. add more questions with word \"symmetrical\" such that answer is not \"very\"."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "If you would like to use our attribution-based workflow to understand your deep network/model, https://github.com/pramodkaushik/acl18_results\\n\\nContact me: pramodkm@uchicago.edu\\n\\nPing me on Whova!\\n\\nThank you!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 209,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "DIC eee aRecipe for whipped cream frosting:\\n- Put cream cheese and whipping cream into a bowl.\\n- Add sugar and vanilla.\\n- Beat the mixture until the cream can hold a stiff peak.\\n- Cover cakes with this frosting that won't melt at room temperature.\\n\\nOtherwise you'll be left with soggy cupcakes. Some relations can be left implicit; others can't."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "This paper: Recovering implicit relations\\n\\nThe availability of implicit relations alongside explicit cues is a puzzle for existing models of coherence relations.\\nAlso, a further challenge to discourse parsing.\\n\\nEvidence from conjunction-insertion experiments: Results show role for inference alongside explicit cues."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "A puzzle: Deduction of implicit information from juxtaposed sentences\\n\\nIt's too far to walk. Let's take the bus.\\n\\nInfer alternatives: walk/bus as means of transport\\n\\nInfer causal relation: too far, therefore bus\\n\\nIt's too far to walk so let's take the bus.\\n\\nAssumption: A passage marks its coherence relation either explicitly or implicitly\\n- i.e., if explicit connective is present, no need for further inference about additional relations.\\n\\n50%\\n\\nIt's too far to walk. Instead let's take the bus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Back to the puzzle»\\n\\nSuppose that assumption is wrong: It is not simply a choice of marking a coherence relation either explicitly or implicitly.\\n\\nQuestion: When should we posit an implicit relation alongside an explicit cue? Why?\\n\\nEstablishing the possibility of multiple concurrent relations is a first step towards the related question of what leads people to see them."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Multiple types of multiplicity. Multiple alternative analyses (Mann & Thompson 1988; inter alia) where I sang.\\nJohn danced.\\n\\nMultiple connectives for same relation (Fraser 2013).\\nJohn made a fool of himself at the restaurant, so as a result, we avoid going there.\\n\\nMultiple relations from same connective (Miltsakaki et al. 2005; Prasad et al. 2008, 2014).\\nWe avoid that restaurant since John made a fool of himself there."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Multiple types of multiplicity.\\nMultiple connectives for distinct relations (Asher & Lascarides 2003; Cuenca & Marin 2009; Fraser 2013; Prasad et al.\\n2014) bought the apartment but then I rented it out.\\nMultiple inferred relations (Prasad et al. 2008, 2014; Dunietz et al. 2017).\\n\\nInstead, it's too far to walk.\\nLet's take the bus.\\n\\nNew result: Systematic inference of relations, distinct from ones explicitly cued.\\nIt's too far to walk: Instead, let's take the bus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Experimental Design: Conjunction-insertion\\nConnText University of Edinburgh\\n\\nTrial: I don't mind walking; in fact, it's good exercise.\\nConjunction: or\\nBecause None at all.\\n\\nOnce you have made your selections, press submit to complete the trial.\\n\\nTo share additional comments about this trial, please click here.\\n\\nJudgments for 50 adverbials, each in 50+ passages, each passage judged by 28 people.\\n70,000+ data points"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Passages in dataset: Materials: for each adverbial, 50+ passages (mostly) from NYTimes Annotated Corpus (Sandhaus, 2008).\\n\\nHalf originally explicit \"Nervous?\\nNo, my leg's not shaking,\" said Griffey, who caused everyone to laugh; indeed his right foot was shaking.\\nAuthor=BECAUSE.\\n\\nHalf originally implicit Sellers are usually happy, too; after all they are the ones leaving with money. Author=NONE.\\n\\nAdverbials include:\\n- ACTUALLY\\n- AFTER ALL\\n- FIRST OF ALL\\n- FOR EXAMPLE\\n- FOR INSTANCE\\n- IN FACT\\n- IN OTHER WORDS\\n- INDEED\\n- INSTEAD\\n- NEVERTHELESS\\n- NONETHELESS\\n- ON THE ONE HAND\\n- ON THE OTHER HAND\\n- OTHERWISE\\n- SPECIFICALLY\\n- THEN\\n- THEREFORE\\n- THUS\\n- ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Experimental Design: Single Response\\n\\nEach passage viewed by 28 participants.\\n\\nInstructions: Find conjunctions that best reflect the meaning of \"I don't mind walking; in fact, it's good exercise.\"\\n\\nCatch trials: You can lead a horse to water, but you can't make it drink."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Experimental Design: Single Response\\n\\nVariability within adverbials: Does the adverbial elicit the same conjunction for all passages?\\n- If deterministic\\n- If not"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Experimental Results: Implicit passages\\n\\nWe saw some consistency in semantically related adverbial pairs, but also differences for a given adverbial.\\n\\nnevertheless\\nnonetheless\\n\\nfor instance\\nfor example\\n\\nand\\nbecause\\nbut\\nso\\nother\\nnone"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "HM and @ because MW before TM® but HM or HM so other Hi none, in fact, on the other hand, nevertheless, nonetheless\\n\\n= 28 = I ra = 28 28 = 21 21 21 21 14 14 14 147 7 7 70 0 0 0 then actually instead however\\n\\n= 28 28 = 28 28 21 21 21 21 14 14 14 147 Vi £ ih 0 0 0 0 indeed specifically in general first of all\\n\\n= 28 28 wm 28 28 [ panege i I I | a | l | 21 21 21 21 14 14 14 147 7 7 70 0 0 0 thus in other words otherwise on the one hand\\n\\n= 28 28 28 28 CTi il 21 21 21 | 21 14 14 14 |\\n14. . ee Al 0 0 0 0 therefore for instance for example after all\\n\\n= 28 I | | 28 28 o = 21 21 | ll 21 | | | 21 14 14 14 147 7 7 70 0 0 0\\n\\n13/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "CA mele ace alt: Different conjunctions can reveal different attachments: \"Nervous?\\nNo, my leg's not shaking,\" said Griffey, who caused everyone to laugh; indeed his leg was shaking.\\nBECAUSE 13 Participants = BECAUSE 11 Participants = BUT We didn't intend to have such examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "CA mele ace alt Adverbial-specific patterns arise: e.g., Author-Participant divergence with otherwise \"The Ravitch camp has had about 25 fund-raisers and has scheduled 20 more.\\nThirty others are in various stages of planning,\" Ms. Marcus said.\\n\"It has to be highly organized otherwise it's total chaos,\" she added.\\nAuthor=OR17 Participants=OR11 Participants=BECAUSE Not noise Not evidence of ambiguity Improbable combinations, but perfectly fine 15/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "SUE AAO\\n\\nMultiple connectives: Establish necessity of entertaining implicit relations when adverbial is present.\\n\\nContext sensitivity: Adverbial alone does not completely predict discourse relation.\\n\\nInformative disagreement: Demonstrate possibility of divergent valid annotations and what they arise from."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "RO Ayo eA Orme as Lexical semantics of adverbial licenses one conjunction.\\n\\nInference from passage content licenses another.\\n\\nGouges are deep scratches that must be filled as well as colored; otherwise, they will collect dirt and become permanently discolored.\\n\\nOtherwise encodes 'otherness' (OR).\\n\\nPassage requires causal reasoning (BECAUSE).\\n\\nFor the plane to Paris, there are only a few tickets left; instead, you could go via Amsterdam.\\n\\nInstead encodes substitution (OR).\\n\\nPassage may permit emphasis on contrast (BUT).\\n\\nPassage may permit causal reasoning (SO).\\n\\n17/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "RON ure eC Mm Cea Adverbial meaning of 'otherness' from otherwise and instead.\\nAdditional pragmatic inference from passage content. Passages may elicit significantly different responses.\\n\\nWas this evidence of different analyses across annotators or would the same annotator endorse more than one conjunction?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Materials:\\n- 48 passages with otherwise (to assess perceived functional role of the otherwise clause)\\n- 16 passages with instead (minimal pairs to test parallel/non-parallel readings)\\n- Passages for in other words and after all\\n\\nParticipants: 28 participants\\n\\nTask 1: Identify best conjunction(s) for meaning of connection\\n\\nTask 2 (for otherwise): Identify a paraphrase of that meaning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "4 e, e e Otherwise: passages with different roles argumentation Proper placement of the testing device is an important issue otherwise the test results will be inaccurate.\\n\\n\"a reason to place the test properly is to avoid inaccuracy\"\\n\\nenumeration A baked potato, plonked on a side plate with sour cream flecked with chives, is the perfect accompaniment otherwise you could serve a green salad and some good country bread.\\n\\n\"there are two choices for a side: potato or salad\"\\n\\n\"a reason to have a potato is to avoid a salad\"\\n\\nexception Mr. Lurie and Mr. Jarmusch actually catch a shark, a thrashing 10-footer otherwise the action is light.\\n\\n\"shark catching is a special case; generally action is light\"\\n\\n\"there are two choices for the film: sharks or light action\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "There was no flight scheduled to Paris yesterday\\n- instead there were several to Amsterdam.\\n\\nPrediction: BUT\\n\\nThere were too few flights scheduled to Paris yesterday\\n- instead we went to Amsterdam.\\n\\nPrediction: SO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Results:\\n\\nOtherwise, argumentation\\n\\nProper placement of the testing device is an important issue; otherwise, the test results will be inaccurate.\\n- Prediction confirmed: OR & BECAUSE\\n- Choice\\n- But\\n- A\\n- B\\n- C\\n- D\\n- E\\n- F\\n- G\\n- H\\n- J\\n- K\\n- L\\n- M\\n- N\\n- O\\n- P\\n- Miso\\n- AND\\n- Because\\n- 20- or\\n- Z\\n- BM\\n- or\\n- sut\\n- OR,\\n- SO\\n- Pan\\n-\\nI)\\n- or,\\n- and\\n- OR,\\n- BECAUSE\\n\\n0- a = || AND, OR, BUT\\n\\nBe\\nBe\\nBR\\nBE\\nBR\\nBE\\nBR\\nBE\\nBV\\nBE\\nBV\\nBE\\nBP\\nBP\\nAND, OR, SO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "e@Results: Otherwise enumeration\\n\\nA baked potato, plonked on a side plate with sour cream flecked with chives, is the perfect accompaniment; otherwise, you could serve a green salad and some good country bread.\\n\\nPrediction confirmed: OR & BUT Choice\\n\\nBUTA B Cc D E F G H J K L M N O P"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "eResults: Otherwise, Mr. Lurie and Mr.\\nJarmusch actually catch a shark, a thrashing 10-footer; otherwise, the action is light.\\n\\nPrediction confirmed: BUT only\\n\\nChoice A B C D E F G H | J K L M N O P BUT\\n\\nMain effect of 3-way underlying category on BUT (p<0.001) 24/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Results: There was no flight scheduled to Paris yesterday; instead, there were several to Amsterdam.\\n\\nThere were too few flights scheduled to Paris yesterday; instead, we went to Amsterdam.\\n\\nPrediction confirmed: main effect of condition on use of BUT/SO (p<0.001)\\n\\nChoice A B € D E i G H | J K L M N O BUT c 10-ey AND 8° | Ml Because se ov Es BS BEE BS BEBE SS SB ZT BSS as se ssl OOP ff £f £S EE EE EE ES ES SS Se Fe Fe Fe FE FE PB tro connective] 25/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Summary: Choosing among alternatives\\n\\nMultiple co-occurring relations\\n\\nIt's too far to walk. Let's take the bus.\\n\\nInference even with explicit cues\\n\\nIt's too far to walk; instead, let's take the bus.\\n\\nBetter to take the bus or otherwise you'll have to walk.\\n\\nInformative disagreement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusion & Future Work\\n\\nWhat participants chose can be explained in terms of the lexical semantics of discourse adverbials and properties of the passages that lead to particular inferences.\\n\\nWith 'otherwise', inference aligns with the perceived function of the passage: argumentation, enumeration, exception.\\n\\nWhat leads to this functional inference?\\n\\nWith 'instead', inference seems to align in part with what licenses the adverbial.\\nWe know what can license 'instead' but we have yet to fully correlate these possibilities with what is inferred."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Thanks! NUANCE CA Edinburgh FOUNDATION"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Researcher Multiple ARGUMENTATION 401 (91.5%)\\n4 Z3\\n18 ENUMERATION 23 364 (81.4%)\\n46\\n14 EXCEPTION 21 29 393 (87.7%)\\n5\\n\\nTable 1: Researcher labels assigned to otherwise passages vs. labels implied by participant paraphrases\\n\\nProper placement of the testing device is an important issue; otherwise the test results will be inaccurate.\\nA reason to place the test properly is to avoid inaccuracy.\\nInaccurate test results are a special case; generally, proper placement is important.\\n29/32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Democrats insist that the poor should be the priority, and that tax relief should be directed at them otherwise they lack a cogent vision of the needs of a new economy.\\nHe said that the proposed bill would give states more flexibility in deciding whether they wanted to use the Federal money for outright grants to municipalities or to set up loan programs; otherwise it left last fall's Congressional legislation unchanged."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "\"In other words\" Unfortunately, nearly 75,000 acres of tropical forest are converted or deforested every day.\\nIn other words, an area the size of Central Park disappears every 16 minutes.\\n\\nIn other words encodes 'otherness' (OR) reformulation conveys consequence (SO) Unfortunately, nearly 75,000 acres of tropical forest are converted or deforested every day.\\n\\nI don't know where I heard that in other words an area the size of Central Park disappears every 16 minutes.\\n\\nIntervening material blocks adjacency preferred for OR/SO, allowing more uses of BUT to emerge.\\n\\nChoice BUT Q A B C C D E F G H\\n\\nJ K L M N O P so 8 ,.= Be os Be 0 tt BE oS BE BE GR BS Be Be Be eco* PP PP PP PP PP PE PP PP PP PE PE PP PP PP PE PE FR fora a aa a a a a a a a aa a a a a o aocs cs cs cs cs cs cs -- cs cs cs cs cs cs cs --"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 328,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n\\nIntroduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "ML as an engineering discipline\\n\\nA mature engineering discipline should be able to predict the cost of a project before it starts.\\nCollecting/producing training data is typically the most expensive part of an ML or NLP project.\\nWe usually have only the vaguest idea of how accuracy is related to training data size and quality.\\nMore data produces better accuracy. Higher quality data (closer domain, less noise) produces better accuracy.\\nBut we usually have no idea how much data or what quality of data is required to achieve a given performance goal.\\nImagine if engineers designed bridges the way we build systems!\\n\\nSee statistical power analysis for experimental design, e.g., Cohen (1992)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Goals of this research project: Given desiderata (accuracy, speed, computational and data resource pricing, etc.) for an ML/NLP system, design for a system that meets these.\\nExample: design a semantic parser for a target application domain that achieves 95% accuracy across a given range of queries.\\n\\nWhat hardware/software should I use?\\n\\nHow many labelled training examples do I need?\\n\\nIdea: Extrapolate performance from small pilot data to predict performance on much larger data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "What this paper contributes:\\n\\nStudies different methods for predicting accuracy on a full dataset from results on a small pilot dataset.\\nWe propose a new accuracy extrapolation task, provide results for the 9 extrapolation methods on 8 text corpora.\\n\\nUses the fastText document classifier and corpora (Joulin et al., 2016).\\n\\nInvestigates three extrapolation models and three item weighting functions for predicting accuracy as a function of training data size.\\n\\nEasily inverted to estimate training size required to achieve a target accuracy.\\n\\nHighlights the importance of hyperparameter tuning and item weighting in extrapolation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Outline\\nEmpirical models of accuracy vs training data size\\n6/16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Overview\\n\\nExtrapolation models of how error e (= 1\\n- accuracy) depends on training data size n:\\n- Power law: e(n) = b n^-α\\n- Inverse square-root: e(n) = a + b n^(-1/2)\\n- Biased power law: e(n) = a + b n^(-γ)\\n\\nExtrapolation model estimated from multiple runs using weighted least squares regression.\\nModel trained on different-sized subsets of pilot data. Same test set is used to evaluate each run.\\nThe evaluation of each model training/test run is a training data point for extrapolation model.\\n\\nWeighting functions for least squares regression:\\n- constant weight (1)\\n- linear weight (n)\\n- binomial weight (n choose\\nk)\\n\\nSee e.g., Haussler et al. (1996); Mukherjee et al. (2003); Figueroa et al. (2012); Beleites et al.\\n(2013); Hajian-Tilaki (2014); Cho et al. (2015); Sun et al. (2017); Barone et al. (2017); Hestness et al. (2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Outline\\n\\nAccuracy extrapolation task\\n8/16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Accuracy extrapolation task\\n\\nFastText document classifier\\n\\nCorpus Labels\\nTrain (K)\\n- Test (K) & data\\namazon review full 30000\\nyelp review polarity 2560 38\\nJoulin et al. (2016)'s\\npolarity also = train/test divisions\\nsougou news 5450 60\\nyahoo answers 70 4400 60\\n\\nPilot data is 0.5 or 0.1 of yelp review full 5 650 50\\n\\nGoal: use pilot data to predict test accuracy when trained on full train data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Extrapolation on ag_news corpus\\n\\nExtrapolation with biased power-law models (f(n) = a + bn) and random pilot data binomial weights (n =\\n6)\\n\\nExtrapolation from a 0.5 training data is generally good\\n\\nExtrapolation from 1 10\" 18 0.1 training data is poor\\n\\nPlot data size unless hyperparameters are optimised at each subset of pilot data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Relative residuals (ε6/ε\\n-\\n1) on dev corporate agents are seen between ±0.050. Extrapolation: Mean = ~0.01, ±0.03. Factors:\\n- n nie*(1-e)\\n- n mve*(1-e)\\n- n me*(1-e)\\n- n me*(1-e)\\n\\n1/16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "RMS relative residuals on test corpora:\\n- Sogou\\n- Yahoo\\n- Eldata\\n- Review \"het answers\" review\\n\\nOverall=0.1\\n\\n0.1016 0.2752 0.0519 0.0496\\n\\n0.1510 < 0.1 0.0209 0.1900 0.0264 0.0406 0.0986 = 0.5\\n\\n0.0338 0.0438 0.0254 0.0160\\n\\n0.0315 < 0.5 0.0049 0.0390 0.0053 0.0046 0.0200\\n\\nBased on dev corpora results, use:\\n- Biased power law model (é(n) = a + bn°)\\n- Binomial item weights (°/e:1\\n- «)\\n\\nEvaluate extrapolations with RMS of relative residuals (é/e-1).\\n\\nLarger pilot data => smaller extrapolation error.\\n\\nOptimise hyperparameters at each pilot subset => smaller extrapolation error."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Outline\\n\\nConclusions and future work\\n\\n13/16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Conclusions and future work\\n\\nThe field needs methods for predicting how much training data a system needs to achieve a target performance.\\nWe introduced an extrapolation task for predicting a classifier's accuracy on a large dataset from a small pilot dataset.\\nHighlight the importance of hyperparameter tuning and item weighting.\\n\\nFuture work:\\n- Extrapolation methods that don't require expensive hyperparameter optimization."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "We are recruiting PhD students and Postdocs!\\n- Centre for Research in AI and Language (CRAIL), Macquarie University\\n- Parsing\\n- Dialog\\n- Deep Unsupervised Learning\\n- Language in Context\\n- Vision and Language\\n- Language for Robot Control\\n\\nWe are recruiting top PhD students and Postdoc researchers with generous pay and top-up scholarships to $41K tax-free.\\n\\nSend CV and sample papers to Mark.Johnson@MQ.edu.au."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Barone, A. V. M., Haddow, B., Germann, U., and Sennrich, R. (2017).\\nRegularization techniques for fine-tuning in neural machine translation. CoRR, abs/1707.09920.\\n\\nBeleites, C., Neugebauer, U., Bocklitz, T., Krafft, C., and Popp, J. (2013).\\nSample size planning for classification models. Analytica chimica acta, 760:25-33.\\n\\nCho, J., Lee, K., Shin, E., Choy, G., and Do, S. (2015).\\nHow much data is needed to train a medical image deep learning system to achieve necessary high accuracy?\\narXiv:1511.06348.\\n\\nCohen, J. (1992). A power primer. Psychological bulletin, 112(1):155.\\n\\nFigueroa, R. L., Zeng-Treitler, Q., Kandula, S., and Ngo, L. H. (2012).\\nPredicting sample size required for classification performance. BMC medical informatics and decision making, 12(1):8.\\n\\nHajian-Tilaki, K. (2014). Sample size estimation in diagnostic test studies of biomedical informatics.\\nJournal of biomedical informatics, 48:193-204.\\n\\nHaussler, D., Kearns, M., Seung, H. S., and Tishby, N. (1996).\\nRigorous learning curve bounds from statistical mechanics. Machine Learning, 25(2).\\n\\nHestness, J., Narang, S., Ardalani, N., Diamos, G., Jun, H., Kianinejad, H., Patwary, M. M. A., Yang, Y., and Zhou, Y.\\n(2017). Deep learning scaling is predictable, empirically. arXiv:1712.00409.\\n\\nJoulin, A., Grave, E., Bojanowski, P., and Mikolov, T. (2016). Bag of tricks for efficient text classification.\\narXiv:1607.01759.\\n\\nMukherjee, S., Tamayo, P., Rogers, S., Rifkin, R., Engle, A., Campbell, C., Golub, T. R., and Mesiroy, J. P. (2003).\\nEstimating dataset size requirements for classifying DNA microarray data.\\nJournal of computational biology, 10(2):119-142.\\n\\nSun, C., Shrivastava, A., Singh, S., and Gupta, A. (2017).\\nRevisiting unreasonable effectiveness of data in deep learning era. arXiv:1707.02968."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 192,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Executing Context-Dependent Instructions\\n\\nTask: map a sequence of instructions to actions\\n\\nExisting Work Today\\n\\nRepresentations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Executing a Sequence of Instructions\\n- Empty out the leftmost beaker of purple chemical.\\n- Then, add the contents of the first beaker to the second.\\n- Mix it.\\n- Then, drain 1 unit from it.\\n- Same for 1 more unit."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Problem Setup\\n\\nTask: Follow sequence of instructions\\n\\nLearning from instructions and corresponding world states\\n- Empty out the leftmost beaker of purple chemical.\\n- Then, add the contents of the first beaker to the second.\\n- Mix it.\\n- Then, drain 1 unit from it.\\n- Same for 1 more unit."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "- Context-dependent language understanding\\n- Static environments Miller et al. 1996, Zettlemoyer and Collins 2009, Suhr et al.\\n2018 (e.g., large database) Long et al. 2016,\\n- Environments that change over time while instructions are given Chen and Mooney 2011, Chen 2012, Artzi and Zettlemoyer 2013, Artzi et al.\\n2014, Andreas and varying levels of supervision in 2016, (Biel et al. 2016, Misra et al. 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "1. Attention-based model for generating sequences of system actions that modify the environment\\n2. Exploration-based learning procedure that avoids biases learned early in training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "1 2 3 4 5 6 7\\n- Each beaker is a stack\\n- Actions are pop, push, push, push"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Meaning Representation\\n- High-level Ore\\n- Representation\\n- Program Engineering\\n- vs. pop 2;\\n- pop 2;\\n- pop 2;\\n- System push 2 brown;\\n- Learning Actions push 2 brown;\\n- Abstractions push 2 brown;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Meaning Representation\\n- High-level ORE Representation\\n- Program Engineering\\n- System\\n- Learning Actions\\n- Abstractions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Model Previous instructions = Current instruction\\n- Throw out first beaker\\n- Pour sixth beaker into last one\\n- It turns brown\\n\\nOutput: a sequence of actions\\n- Attend over each input\\n- Current state when generating actions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Model Previous instructions = issi(isé<-;~*é*~*~*~*~TM~C\\nCurrent instruction\\nThrow out first beaker\\nPour sixth beaker into last one\\nIt turns brown\\nFTUUOU EBGUueououd ou ou\\nInitial state\\nCurrent state\\nEncode instructions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Model UOAUUOEU Encode states"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Model view output first baler Power which bar it last on a Terms brown reter tT err ftHOUH UUUUOEE Oe o sweet o e TT Be cone ers\\n\\na. Initialize decoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Previous instructions = Current instruction\\n\\nThrow out first beaker\\nPour sixth beaker into last one\\nIt turns brown\\n\\nCurrent instruction: Attend over current instruction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Throw out first beaker.\\n\\nPour sixth beaker into last one. It turns brown.\\n\\nInitial state = Ss\\n- sSS.\\n\\nAttention FT OUOUuUD ne.\\n\\nCurrent Instruction: Current state: reAttend over previous instructions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Previous instructions = Current instruction\\n\\nThrow out first beaker\\n\\nPour sixth beaker into last one\\n\\nIt turns brown\\n\\nCurrent state: ones\\n\\nInitial state: Attend over initial state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Previous instructions\\nCurrent instruction\\nThrow out first beaker\\nPour sixth beaker into last one\\nIt turns brown\\n\\nInitial state\\nCurrent instruction\\nPrevious instructions\\nCurrent state\\nAttend over current state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Previous instructions = = =\\n\\nCurrent instruction © Throw out first beaker.\\n\\nPour fifth beaker into last one.\\n\\nIt turns brown.\\n\\nCurrent state: initial state\\n\\nPredict action"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "- Model\\n- Throw out first beaker\\n- Pour sixth beaker into last one, it turns brown\\n- Execute action, update state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Previous instructions == ssitsi\\n\\nCurrent instruction: Throw out first beaker. Pour sixth beaker into last one. It turns brown. HUH BEAU\\n\\nCurrent state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "- Model > Tow out ft leaker Pour sch beaker indo lst oe Romnatnotincere eee ete ee aHOHOU BUUUae 8 obayy eeMPTP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Model HHUUU UUUbueoud oebeniese | eeaie"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Throw out first beaker.\\n\\nPour sixth beaker into last one.\\n\\nIt turns brown."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Previous instructions. Current instruction: Throw out first beaker. Pour sixth beaker into last one. It turns brown."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Previous instructions = ~~ Current instruction | Throw out first beaker. Pour sixth beaker into last one.\\nIt turns brown.\\n\\nCurrent state\\n- { push 7 brown |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Learning from World State Annotation\\n- Goal: learn a policy that maps from instructions and environment states to actions\\n- Empty out the leftmost beaker of purple chemical.\\n- Then, add the contents of the first beaker to the second.\\n- Mix it.\\n- Then, drain 1 unit from it.\\n- Some for 1 more wait."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Learning from World State Annotation\\n- Goal: learn a policy that maps from instructions and environment states to actions\\n- Approach: Learn through exploring the environment and observing rewards\\n- Policy gradient with contextual bandit\\n- Challenge: overcome biases acquired early during learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Reward Function Action @ Source state Cy Target state R(s, a, s') = P(s, a, s') + (s')\\n- (8)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Reward Function Action @source state Cy Target state R(s,a,s') = P(s,a, θ) + $(s')\\n- o(s) + lif A stops the sequence and s' is the goal state\\n- lif A stops the sequence and s' is not the goal state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Reward Function Action @source state Cy Target state R(s,a,s') = P(s,a,s') + @(s')\\n- (s) + lif S is closer to the goal state than Ss (moved closer)\\n- lif S is closer to the goal state than S (moved further)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Learning Example\\n\\nIteration #1 Start:\\n\\nGoal:\\n\\nAction and Rewards:\\n\\nRollout: Rewards: pop O push O"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Learning Example\\n\\nIteration #1 Start:\\n\\nAdd the third beaker to the first\\n\\nGoal:\\n\\nAction Se\\n\\nRewards:\\n\\nRollout:\\n\\nRewards:\\n- pop 0\\n- push 1 green;\\n- pop 3;\\n- push 1 yellow;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Learning Example Alteration #1 Start:\\n\\nAdd the third beaker to the first\\n\\nGoal:\\n\\nAction\\n\\nRewards:\\n\\nRollout: Rewards:\\n- pop 1\\n- push 0\\n- pop 2;\\n- push 1 green;\\n- No positive reward\\n- pop 3;\\n- +1 for push actions\\n- push 1 yellow;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Learning Example\\n\\nIteration #2 Start:\\n\\nAdd the third beaker to the first\\n\\nGoal:\\n\\nAction and Rewards:\\n\\nRollout: Rewards:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Learning Example\\n\\nIteration #2 Start:\\n\\nAdd the third beaker to the first\\n\\nGoal:\\n\\nAction\\n\\nRewards:\\nRollout:\\n\\nRewards:\\npop L if push O 2\\npop 3;\\n1.push i green;\\npop 1;\\n+1 push 1 green;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Learning Example Alteration #2 Start:\\n\\nAdd the third beaker to the first\\n\\nGoal:\\n\\nAction\\n\\nRewards:\\n\\nRollout:\\n\\nRewards:\\n- pop 3\\n- push 0\\n- pop 3; +4\\n- push 1 green; -1\\n- No positive reward\\n- pop 1; +1\\n- for push actions\\n- push 1 green; ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Learning Example\\n\\nIteration #3 Start:\\n\\nAdd the third beaker to the first Goal:\\n\\nAction\\n\\nRewards:\\n\\nRollout:\\n\\nRewards:\\n- pop 3\\n- push 0\\n- pop 3; +4\\n- pop 3; +\\n- Quickly learned a\\n- pop 1; = strong bias against\\n- push actions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "- Early during learning, model learns it can get positive reward by predicting the pop actions\\n- Less likely to get positive reward with push action\\n- Becomes biased against push\\n- During later exploration, push is never sampled!\\n- Compounding effect: never learns to generate push actions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "single-step Reward Observation\\n- Our approach: observe reward of all actions by looking one step ahead during exploration.\\n- Observe reward for actions like push"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "For each training example:\\n1. Rollout: sample sequence of state-action pairs from the current policy\\n2. For each state visited in the rollout,\\nA. For each possible action, execute Single-step action and observe reward Observation\\n3. Update parameters based on observed rewards for all states and actions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "simple Exploration Start state\\nC) --\\nC) -- C. +. +.\\nOnly observe states along sampled trajectory single-step Reward Observation Observe sampled states and single-step ahead"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "single-step Observation Iteration #4 Start: Add the third beaker to the first Goal:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "single-step Observation Iteration #4 Start: Add the third beaker to the first Goal: Rollout: Current State: SSpop 3; Single-Steppop 3; Actions: 1; Single-step Observation:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "single-step Observation Iteration #4\\nStart: ©] | EJ\\nAdd the third beaker to the first\\nGoal: = E] ¥ |\\nRollout: Current State: SSpop 3; |\\nSingle-Step !pop 3; UU :\\nActions: 1;\\n.p ee Single-step + Pop 1;\\nObservation:\\n- |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "single-step Observation Iteration #4 Start: ©]\\nAdd the third beaker to the first\\nGoal: = E]\\nRollout: Current State: SSpop 3;\\nSingle-Step !pop 3;\\nActions: 1;\\nObservation: ! \"t+ pop 2;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "single-step Observation\\nIteration #4\\nStart: © | EJ\\nAdd the third beaker to the first\\nGoal: = E\\nRollout: Current State: SSpop 3;\\nSingle-Steppop 3;\\nUU: Actions: 1;\\n-\\nSingle-step 1 Pop S:\\nObservation:\\npop 4;\\npop 3;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "single-step Observation Iteration #4\\nStart: © | EJ\\nAdd the third beaker to the first\\nGoal: = E\\nRollout: Current State: SSpop 3;\\nSingle-Step pop 3;\\nActions: 1;\\niPOP Single-step + POP\\n\\nObservation:\\n\"1 pop 2; a\\n7 pop 3; +1 push 1 orange;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "single-step ObservationIteration #4\\nStart: ©]\\nGoal: = E] ¥\\nRollout: Current State: SS-> pop 3;\\nSingle-Step pop 3;\\nActions: pop 1;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "single-step Observation\\n\\nIteration #4\\n\\nStart: ©\\n\\nEJ Add the third beaker to the first\\n\\nGoal:\\n\\nRollout:\\n\\nCurrent State: SS -> pop 3;\\n\\nSingle-Step\\n\\n! pop 3;\\n\\nHuu Actions:\\n- pop 1;\\n- pop 4;\\n- pop 2;\\n- pop 3;\\n- push 1 orange"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "single-step Observation\\nIteration #4 Start:\\nAdd the third beaker to the first\\nGoal:\\nRollout: Current State: SSpop 3;\\nSingle-Step → pop 3: Hue : Actions: pop 1;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "single-step Observation Iteration #4\\nStart:\\nAdd the third beaker to the first\\nGoal:\\nRollout: Current State: SSpop 3;\\nSingle-Step:\\npop 3:\\nHue Actions:\\npop 1;\\ni pop 1;\\ni -4 pop 2;\\n- 1 pop 3;\\n+ 1 push 1 orange"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "single-step ObservationIteration #4 Start: ©] | EJ Add the third beaker to the first Goal: = E] ¥ | Rollout: Current State: SSpop 3; | Single-Step !pop 3; Huu : Actions:\\n- pop 1;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "single-step ObservationIteration #4 Start: ©] | EJ Add the third beaker to the first Goal: = E] ¥ | Rollout: Current State: SSpop 3; | Single-Step !pop 3; Huu: Actions:\\n- pop 1;\\n- pop 1;\\n- pop 2;\\n- pop 3;\\n- push 1 orange + 4 push 1 yellow |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Experimental Setup\\n- SCONE (Long et al. 2016): Alchemy, Scene, Tangrams\\n- Training data: start state and a sequence of instructions and goal states\\n- Standard evaluation metric: after following a sequence of instructions, is the world state correct?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "1\\n2\\n3\\n4\\n5\\n6\\n7\\npop 2;\\npop 2;\\npop 2;\\npush 2 brown;\\npush 2 brown;\\npush 2 brown;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "8B12 3 4 56 7 8 9 10 The person with a red shirt and a blue hat moves to the right end remove_person 7 remove_hat 7 add_person 10 red add_hat 10 blue"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Tangrams rise 1234\\n\\nSwap the third and fourth figures\\n\\nRemove 4\\n\\nInsert 3 boat"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Results Long et al. 2016\\nMM Guu et al. 2017\\nTM SESTRA 70\\n- Outperforming previous methods by up to 25%, while mapping directly to system actions.\\n\\nAlchemy\\nScene Tangrams\\n\\nFinal state accuracy\\nTest Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Results\\n\\nLong et al. 2016\\nMM Guu et al. 2017\\n\\nTM SESTRA\\nSupervised\\n- Outperforms previous methods by up to 25%, while mapping directly to system actions.\\n- Performance is comparable to direct supervision.\\n\\nAlchemy\\nScene Tangrams\\nFinal state accuracy\\nTest Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "M@ SESTRA MW Policy Gradient TM Contextual Bandit 8071.860\\n- Single-step observations 40 overcome biases that get a model stuck on ReAlchemy\\n\\nH] Scene Tangrams? Final state accuracy Development Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Without Previous Instructions\\nWithout World State Context\\nNeed access to\\n3:1\\nPrevious Instructions\\n- Need access to a world state\\nAlchemy\\nScene Tangrams?\\nFinal state accuracy\\nDevelopment Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "An attention-based model for generating sequences of atomic actions that modify the environment.\\n\\nExploration-based learning procedure that avoids biases learned early in training.\\n\\nhttps://github.com/clic-lab/sconeSea"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 360,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Roadmap\\n\\nIntroduction & background\\n- Adaptive knowledge sharing in Multi-Task Learning\\n- Experiments & analysis\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Improving NMT in low-resource scenarios\\n\\nNMT is notorious!\\n\\nBilingually low-resource scenario: large amounts of bilingual training data is not available.\\n- IDEA: Use existing resources from other tasks and train one model for all tasks using multi-task learning.\\n\\nThis effectively injects inductive biases to help improve the generalisation of NMT.\\n- Auxiliary tasks: Semantic Parsing, Syntactic Parsing, Named Entity Recognition"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Encoders-Decoders for Individual Tasks\\n\\nMachine Translation\\n\\nSemantic Parsing\\n\\nSyntactic Parsing\\n\\nNamed-Entity Recognition\\n- Acme Corp. in 2006"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Sharing Scenario\\nsentence Name\\nentities\\nSSi\\nen\\nGe Multitask\\nSemantic graph\\nMachine Translation | encoder Decoder\\nRecognition"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Partial Parameter Sharing\\n\\nZaremoodi & Haffari, NAACL, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Adaptive Knowledge Sharing in MTL\\n- Sharing the parameters of the recurrent units among all tasks\\n- Task interference\\n- Inability to leverage commonalities among subsets of tasks controlling the information flow in the hidden states\\n- Multiple experts in handling different kinds of information\\n- Adaptively share experts among the tasks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Adaptive Knowledge Sharing in MTLPIDEAP\\n\\nMultiple experts in handling different kinds of information adaptively share experts among the tasks.\\n\\nExtend the recurrent units with multiple blocks. Each block has its own information flow through time.\\n\\nRouting mechanism: to softly direct the input to these blocks.\\n\\nNetwork: 5\\n\\nBlock 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Adaptive Knowledge Sharing Routing: sp = tanh(W,\\na) and Wi), hy + bs), (2). (shared i . i shared askT = softmax(W, -s ; + 6), x = T{i]er > h, We we Ti[i]hy?\\n> i = [h, By ]Blocks: zp = o(WH#? + UPh?, +), hy = tanh(W,)\\na) + Uh)? + b)), r = 6 WOE#? + UOAM, + o), rn = Mon, 40\\n-\\n2) of\".\\n\\nNetwork i mave h® ViinH ;nath@) ya[ica h(4)ne 1 Task Block | tXt"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Adaptive Knowledge Sharing\\n- We use the proposed recurrent unit inside encoder and decoder."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Experiments\\n\\nLanguage Pairs: English to Farsi/Vietnamese\\nEn > vi | 133,290 | 1,553 | 1,268\\n\\nDatasets:\\n- English to Farsi: TED corpus & LDC2016E93\\n- English to Vietnamese: IWSLT 2015 (TED and TEDX talks)\\n- Semantic parsing: AMR corpus (newswire, weblogs, web discussion forums and broadcast conversations)\\n- Syntactic parsing: Penn Treebank\\n- NER: CONLL NER Corpus (newswire articles from the Reuters Corpus)\\n\\nNMT Architecture: GRU for blocks, 400 RNN hidden states and word embedding\\n\\nNMT best practice:\\n- Optimisation: Adam\\n- Byte Pair Encoding (BPE) on both source/target\\n\\nEvaluation metrics: PPL, TER and BLEU"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "13 2726122511 242310>im 22ma| 9 2120| a197 18 SNMT @& MTL (Full) & MTL (Partial) | MTL (Routing) SNMT @& MTL (Full) & MTL (Partial) | MTL (Routing) English > Farsi English > Vietnamese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Experiments (English to Farsi) 70.50.450.40.350.25: L L\\n\\nosBlock 1\\nBlock 2\\nBlock 3= MT\\nSemantic = Sntacic = NER\\n\\nAverage block usage.\\n\\nBlocks specialisation:\\n\\nBlock 1: MT, Semantic Parsing,\\nBlock 2: Syntactic/Semantic Parsing,\\nBlock 3: NER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusion: Address the task interference issue in MTL by extending the recurrent units with multiple blocks, with a trainable routing network."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Questions? Paper:"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 107,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Overview\\n- Motivation\\n- Syntactic Distance based Parsing Framework\\n- Model\\n- Experimental Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "ICLR 2018: Neural Language Modeling by Jointly Learning Syntax and Lexicon\\n- Supervised Constituency Parsing with Syntactic Distance\\n- am [Shen et al. 2018]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Chart Neural Parsers Transition based Neural Parser see CYK table is a steps bracket\\n- [ve | 7 . oe Se le.\\n| r PRP MD VBP Ss 5-6 sh (like/VBP) no label p21 OyA3I Fae oe Gh Emo, fet fre] coke ale peer eee pasS\\n- NP\\n- (NP tah, 12=!18 | comb label S | os 585 NP V, VP a NP Det! N\\n- (a) gold parse tree\\n- (b) static oracle actions [she] eats\\n1. Greedy decoding:\\n2. High computational cost: In completed tree (the shift and reduce steps may not match).\\n3. Complicated loss function:\\n4.\\nExposure bias The model is never exposed to its own mistakes during training [Stern et al., 2017; Cross and Huang, 2016]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Intuitions\\n\\nOnly the order of split (or combination) matters for reconstructing the tree.\\n\\nenjoys Lb playing tennis Can we model the order directly?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Syntactic distance\\n\\nDefinition 2.1. Let T be a parse tree that contains a set of leaves (w₀, ..., wₙ).\\nThe height of the lowest common ancestor for two leaves (wᵢ, wⱼ) is noted as dᵢ.\\nThe syntactic distances of T can be any vector of scalars d = (d₁, ..., dₙ) that satisfy:\\n\\nsign(dᵢ\\n- dⱼ) = sign(dᵢ₋₁\\n- dᵢ)\\n\\nFor each split point, their syntactic distances should share the same order as the height of the related node S₁ S₂"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Convert to binary trees Sads iesM NPRe Wz S ) She She enjoys\\n\\nVP j ; pete O [S-VP] Ves NP enjoys ee. playing\\n\\nO NP tennis playing tennis [Stern et al., 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Algorithm 1 Binary Parse Tree to Distance. (U represents the concatenation operator of lists)\\n\\nTree to Distance\\n\\n1: function DISTANCE(node)\\n2: if node is leaf then\\n3: d <- || [node.tag]\\n4: height <- 0\\n5: else\\n6: height <- maximum height of its children\\n7: d, c, t, h <- Distance(child)\\n8: d, c, t, h <- Distance(child) plus 1\\n9: d <- d U [A]\\n10: c <- c U [node.label]\\n11: t <- t U [node.tag]\\n12: end if\\n13: return d, c, t, h\\n14: end function"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "She enjoys playing tennis."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Distance to Tree\\n\\nAlgorithm 2 Distance to Binary Parse Tree\\n\\n1: function TREE(d, c,\\nt)\\n2: if d = || then\\n3: node = Leaf(t)\\n4: Split point for each bracket is the one with maximum distance.\\n6: child = Tree(dz, C,\\nt)\\n7: child = Tree(d, cs,\\nt)\\n8: node = Node(child, child, -)\\n9: end if\\n10: return node\\n11: end function"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Distance to Trees is she enjoys playing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Framework for inferring the distances and labels\\n\\nLabels for non-leaf nodes\\n\\nLabels for leaf nodes\\n\\nDistances"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Inferring the distances."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Inferring the distances\\nd1\\nd2\\nd3\\nd4\\nd5\\n\\nShe enjoys playing tennis."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Pairwise learning-to-rank loss for distances\\nList = [1\\n- sign(d;\\n- dj)(ds\\n- d)]*1901, x>Osign(z) = (0, \"a= (0-1, a variant of hinge loss"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Pairwise learning-to-rank loss for distances\\nLi = )_ [1\\n- sign(d_i\\n- d_j)(d_i\\n- d_j)] * 19\\nWhile d_i > d_j:\\nWhile d_i < d_j:\\nL = | (d_i\\n- d_j) | (d_i\\n- d_j)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Inferring the Labelsios. Ido dl d2 d3 d4 d5."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Inferring the Labels"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Putting it together L = Drape + LK"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Putting it together\\n\\nShe enjoys playing tennis."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Experiments:\\n\\nPenn Treebank Model\\nLP   LR   FI\\nEnsemble Single Model\\nShindo et al. (2012)\\n-\\n- 92.4\\nVinyals et al. (2015)\\n-\\n- 88.3\\nVinyals et al. (2015)\\n-\\n- 90.5\\nZhu et al. (2013) 90.7 90.2 90.4\\n\\nSemi-supervised\\nDyer et al. (2016)\\n- + 89.8\\nZhu et al. (2013) 91.5 91.1 91.3\\nWatanabe and Sumita (2015)\\n-\\n- 90.7\\nVinyals et al. (2015)\\n-\\n- 92.8\\n\\nCross and Huang (2016) 92.1 90.5 91.3\\n\\nRe-ranking\\nLiu and Zhang (2017b) PEO ecm oler\\nCharniak and Johnson (2005) 91.8 91.2 91.5\\nStern et al. (2017a) 93.0 20 SN Ors\\nHuang (2008) 07.9\\n990) 017\\nLiu and Zhang (2017a)\\n- = OLB\\nDyer et al. (2016)\\nGaddy et al. (2018)\\n-\\n- 92.1\\nI Stern et al. (2017b) 92.5 92.5 92.5\\n\\nOur Model 92.0 91.7 91.8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Experiments:\\n\\nChinese Treebank\\n\\nModel                  LP      LR      FI\\n\\nSemi-supervised\\n\\nSingle Model\\n\\nZhu et al. (2013)     86.8   84.4   85.6\\nCharniak (2000)      82.1   79.6   80.8\\nWang and Xue (2014)  =\\n-      86.3\\nZhu et al. (2013)     84.3   82.1   83.2\\nWang et al. (2015)\\n-\\n-      86.6\\nWang et al. (2015)\\n-\\n-      83.2\\n\\nRe-ranking\\n\\nWatanabe and Sumita (2015)\\n-\\n-      84.3\\nCharniak and Johnson (2005)  83.8   80.8   82.3\\nDyer et al. (2016)\\n-\\n-      846\\nDyer et al. (2016)\\n-\\n-      86.9\\nLiu and Zhang (2017b)  85.9   985:285.5\\nLiu and Zhang (2017a)\\n-\\n-      86.1\\nOur Model             86.6   86.4   86.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Experiments: Detailed statistics in PTB and CTB\\n\\ndev/test result\\n\\nPrec. Recall Fl label accuracy\\n\\nlabeled | 91.7/92.0 91.8/91.7 91.8/91.8\\n\\nPTB unlabeled | 93.0/93.2 93.0/92.8 93.0/93.0\\n\\nBaaS labeled | 89.4/86.6 89.4/86.4 89.4/86.5\\n\\na unlabeled | 91.1/88.9 91.1/88.6 91.1/88.8\\n\\npease"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Experiments: Ablation Test\\n\\nModel           LP     LR    Fl\\nFull model     92.0  91.7  91.8\\nw/o top LSTM   91.0  90.5  90.7\\nw/o Char LSTM  92.1  91.7  91.9\\nw/o embedding   91.9  91.6  91.7\\nw/o MSE loss   90.3  90.0  90.1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Experiments: Parsing Speed Model # sents/sec\\n\\nPetrov and Klein (2007) 6.2\\n\\nZhu et al. (2013) 89.5\\n\\nLiu and Zhang (2017b) 79.2\\n\\nStern et al. (2017a) va\\n\\nOur model | A |\\n\\nOur model w/o tree inference 351"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Conclusions and Highlights\\n- A novel constituency parsing scheme: predicting tree structure from a set of real-valued scalars (syntactic distances).\\n- Completely free from compounding errors.\\n- Strong performance compared to previous models, and\\n- Significantly more efficient than previous models.\\n- Easy deployment: The architecture of the model is no more than a stack of standard recurrent and convolutional layers."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "One more thing...\\n- The research in rank loss is well-studied in the topic of learning-to-rank, since 2005 (Burges et al. 2005).\\n- Models that are good at learning these syntactic distances are not widely known until the rediscovery of LSTM in 2013 (Graves 2013).\\n- Efficient regularization methods for LSTM didn't become mature until 2017 (Merity 2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Yikang Shen, Zhouhan Lin\\nThank you! MILA, Université de Montréal\\nyikang.shn, lin.zhouhan@gmail.com\\nQuestions?\\nCode: Paper:"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 90,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "What is Natural Language Inference (NLI)?\\n\\nPremise: A soccer game with multiple males playing.\\n\\nHypothesis: Some men are playing a sport.\\n\\nEntailment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "What is Natural Language Inference (NLI)?\\n\\nPremise: An older and younger man smiling.\\n\\nPremise:\\n\\nHypothesis: Two men are smiling and laughing at the cats playing on the floor.\\n\\nNeutral"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "What is Natural Language Inference (NLI)?\\n\\nPremise: A black race car starts up in front of a crowd of people.\\n\\nHypothesis: A man is driving down a lonely road."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Applications\\n- Question Answering\\n- Machine Translation\\n- Semantic Search\\n- Text Summarization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Discourse Marker\\n- A discourse marker is a word or a phrase that plays a role in managing the flow and structure of discourse.\\n\\nExamples:\\n- so\\n- because\\n- and\\n- but\\n- or..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Discourse Marker & NLI?\\nBut\\nBecause\\nIf\\nAlthough\\nAnd\\nSo\\n\\nEntailment\\nNeutral\\nContradiction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Related Works\\n- Datasets\\n- SNLI (Bowman et al.,\\n2015)\\n- MultiNLI (Williams et al.,\\n2017)\\n- eSOTA Neural Network Models\\n- CAFE (Tay et al.,\\n2017)\\n- KIM (Chen et al.,\\n2017)\\n- DIIN (Gong et al., 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Related Works\\n- Transfer Learning for NLI\\n- Skip-thoughts (Vendrov et al.,\\n2016)\\n- Cove (McCann et al.,\\n2017)\\n\\nDiscourse Marker Applications\\n- DisSent (Nie et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Discourse Marker Prediction\\n\\nIt's rainy outside but we will not take the umbrella.\\n\\nIt's rainy outside + But + We will not take the umbrella.\\n\\nSo\\n\\nBecause\\n\\nBut\\n\\n(S1,\\n52) -- BCU aed -- = ~ MM If"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Discourse Marker Prediction To Be Transferred\\n\\nSentence 1 Pore nn UTM Sentence Representations\\n\\nLast hidden state\\nMax pooling over all the hidden states\\nPrediction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Discourse Marker Augmented Network (NLI Model)\\n\\nEncoding Layer\\n\\nPremise\\n\\nHypothesis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Discourse Marker Augmented Network (NLI Model)\\n\\nSentence Representations\\n\\nPre-trained 1\\n- OO 777 C\\n- @DMP Model:\\n- @\\n- C0\\n- OO\\n- premise\\n- pkeyW Giove\\n- char\\n- Pos [NER]\\n- EM BiLSTMS\\n- O\\n- 0\\n- O\\n- O\\n- <O\\n- CO\\n- OO\\n- {cove [ros Ne]\\n- Hypothesis Monee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Discourse Marker Augmented Network (NLI Model) Interaction\\n\\nSimilarity Matrix\\n\\nThe sentence representation of the premise\\nthe representation of the hypothesis\\n\\nThe i-th word of the premise\\nThe j-th word of the hypothesis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Discourse Marker Augmented Network (NLI Model)\\n\\nThe sentence representation of the hypothesis\\n\\nThe sentence representation of the premise\\n\\naed = softmax(W[pTM; uTM; p\" o u\"-r, O Fal)\\n\\nModeling vector of the premise\\n\\nModeling vector of the hypothesis\\n\\nSimilarity Matrix"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "e eTraining Cross Entropy Loss 1 NkJcr(9) = -% S| log(d/') ke P: \"A smiling costumed woman is holding an umbrella.\"\\n\\nCorrect Label: neutral\\n\\nH: \"A happy woman in a fairy costume holds an umbrella.\"\\n\\nOriginal Labels: neutral, neutral, entailment, entailment, neutral"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Training Jri(®) = -Epnrcjpx) [RL {U\"})] ele poe ind that predicts the R(1, {I*}) = a; in {I*} J(O) = AJcx(9) + (1\\n-\\nA) Jrz(9)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Experiments (Datasets)\\n- Stanford Natural Language Inference (SNLI) (Bowman et al.,\\n2015) 570k human annotated sentence pairs\\n- Multi-Genre Natural Language Inference (MultiNLI) (Williams et al.,\\n2017) 57.12433k human annotated sentence pairs\\n- BookCorpus (Zhu et al.,\\n2015) 6.5M pairs of sentences for discourse markers"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experiments (Results)\\n\\nMultiNLI Method\\n- SNLI\\n- 300D LSTM encoders (Bowman et al.,\\n2016) 80.6\\n- 300D Tree-based CNN encoders (Mou et al.,\\n2016) 82.1\\n- Sentence Encoding\\n- 4096D BiLSTM with max-pooling (Conneau et al.,\\n2017) 84.5\\n\\nBased Models\\n- 600D Gumbel TreeLSTM encoders (Choi et al.,\\n2017) 86.0\\n- 600D Residual stacked encoders (Nie and Bansal,\\n2017) 86.0 74.6 73.6\\n- Gated-Att BiLSTM (Chen et al.,\\n2017) 73.2 73.6\\n- 100D LSTMs with attention (Rocktischel et al.,\\n2016) 83.5\\n- 300D re-read LSTM (Sha et al.,\\n2016)\\n- DIIN (Gong et al.,\\n2018) 88.0 78.8 77.1\\n- Biattentive Classification Network (McCann et al.,\\n2017) 88.1\\n\\nOther Neural Network Models\\n- 300D CAFE (Tay et al.,\\n2017) 88.5 78.7 71.9\\n- KIM (Chen et al., 2017b) 88.6\\n- 600D ESIM + 300D Syntactic TreeLSTM (Chen et al.,\\n2017) 88.6\\n- BiMPM (Ensemble) (Wang et al.,\\n2017) 88.8\\n- DIIN (Ensemble) (Gong et al.,\\n2018) 88.9 80.0 78.7\\n- KIM (Ensemble) (Chen et al., 2017b) 89.1\\n\\nEnsemble Models\\n- 300D CAFE (Ensemble) (Tay et al.,\\n2017) 89 80.2 79.0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Experiments (Analysis)\\n\\nAblation Model Accuracy\\n- Only Sentence Encoder Model: 83.37\\n- No Sentence Encoder Model: 87.24\\n- No REINFORCE: 88.41\\n- DMAN: 88.83"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Experiments\\n\\n(a) Discourse markers augmentation\\n\\n(b) Without discourse markers augmentation\\n\\nPremise: \"Three young men in hoods standing in the middle of a quiet street facing the camera.\"\\n\\nHypothesis: \"Three people sit by a busy street bare-headed.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Conclusion\\n- We solve the task of the natural language inference via transferring knowledge from another supervised task.\\n- We propose a new objective function to make full use of the labels' information.\\n- In the future work, we would like to explore some other transfer learning sources."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Thank You!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 110,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Noun Compounds: Two or more nouns function as a unit to create a new concept: hot dog, hot dog bun, hot dog bun package.\\nWe focus on two-word compounds.\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations, ACL 2018."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Noun Compounds: Two or more nouns function as a unit to create a new concept, hot dog, hot dog bun, hot dog bun package...\\nWe focus on two-word compounds.\\n\\nExpress implicit relationships between the constituent nouns:\\n- apple cake: cake made of apples\\n- birthday cake: cake eaten on a birthday\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Noun Compounds: Two or more nouns function as a unit to create a new concept: hot dog, hot dog bun, hot dog bun package...\\n\\nWe focus on two-word compounds.\\n\\nExpress implicit relationships between the constituent nouns:\\n- apple cake: cake made of apples\\n- birthday cake: cake eaten on a birthday\\n\\nThey are like \"text compression devices\" [Nakov, 2013]. We're pretty good at decompressing them!\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "We are good at interpreting noun-compounds.\\nWe easily interpret noun-compounds, even when we see them for the first time.\\nAvered Shwartz and Ido Dagan\\nParaphrase to explicate: revealing implicit noun-compound relations\\nACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "We are good at interpreting noun-compounds. We easily interpret noun-compounds even when we see them for the first time.\\nWhat is a \"parsley cake\"?\\n- cake eaten on parsley?\\n- cake with parsley?\\n- cake for parsley?\\n\\nA...Avered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations « ACL2018 3/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "We are good at interpreting noun-compounds. We easily interpret noun-compounds.\\nEven when we see them for the first time.\\n\\nWhat is a \"parsley cake\"? Is it a cake eaten on parsley? Is it a cake with parsley? Is it a cake for parsley?\\n\\nhttp://www.bazekalim.com\\n\\nVered Shwartz and Ido Dagan\\n\\n+ Paraphrase to explicate: revealing implicit noun-compound relations\\n\\n+ ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Generalizing Existing Knowledge: What can cake be made of?\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Generalizing Existing Knowledge: What can cake be made of? Parsley (sort of) fits into this distribution.\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Generalizing Existing Knowledge: What can cake be made of? Parsley (sort of) fits into this distribution.\\nSimilar to \"selectional preferences\" [Pantel et al., 2007].\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018 4/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "We need computers to interpret noun compounds.\\n\\nAdd an event title to create a morning meeting tomorrow.\\n\\nTime: Morning\\n\\nCovered: Shwartz and Ido Dagan\\n- Paraphrase to explicate: revealing implicit noun-compound relations\\n- ACL2018 5/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Noun-Compound Interpretation Tasks\\n\\nBracketing\\n\\n[pumpkin spice latte]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Noun-Compound Interpretation Tasks\\n\\nBracketing\\n\\n[pumpkin spice] latte\\n\\nCompositionality Prediction\\n\\nis spelling bee related to bee?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Noun-Compound Interpretation Tasks\\n\\nBracketing\\n\\n[pumpkin spice] latte\\n\\nCompositionality Prediction\\n\\nis spelling bee related to bee?\\n\\nRelation Classification\\n\\napple cake -> ingredient\\n\\nbirthday cake + time"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Noun-Compound Interpretation Tasks\\n\\nBracketing\\n\\n[pumpkin spice] latte\\n\\nCompositionality Prediction\\n\\nis spelling bee related to bee?\\n\\nRelation Classification\\n\\nParaphrasing\\n\\napple cake -> ingredient cake made of apples\\n\\nbirthday cake + time cake eaten on a birthday\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Noun-Compound Paraphrasing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Motivation\\n\\nGiven a noun-compound w, wp, express the relation between the head w2 and the modifier w, with multiple prepositional and verbal paraphrases [Nakov and Hearst, 2006].\\n- olive oil --- [w2] extracted from [w1]\\n- apple oo ma of [Wi] ground attack ---- [wo] from [wi]\\n- boat whistle ---- [wy] located in [ws]\\n- sea bass ----. two] Live in [wi] game room\\n- [W2] used for [wi] service door\\n- [Wa] for [w1] baby oil\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018 8/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Evaluation Setting\\n\\nAvailable dataset: SemEval 2013 task 4 [Hendrickx et al., 2013]\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Evaluation Setting\\n\\nAvailable dataset: SemEval 2013 task 4 [Hendrickx et al., 2013]\\n\\nA ranking rather than a retrieval task\\n\\nSystems get a list of noun compounds\\n\\nVered Shwartz and Ido Dagan\\n\\n+ Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n\\n+ ACL 2018 9/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Evaluation Setting\\n\\nAvailable dataset: SemEval 2013 task 4 [Hendrickx et al., 2013]\\n\\nA ranking rather than a retrieval task\\n\\nSystems get a list of noun compounds\\n\\nExtract paraphrases from free text\\n\\nRank them\\n\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\nACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Evaluation Setting\\n\\nAvailable dataset: SemEval 2013 task 4 [Hendrickx et al., 2013]\\n- A ranking rather than a retrieval task\\n- Systems get a list of noun compounds\\n- Extract paraphrases from free text\\n- Rank them\\n- Evaluated for correlation with human judgments\\n- Gold paraphrase score: how many annotators suggested it?\\n\\nVered Shwartz and Ido Dagan\\n\\n+ Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n\\n+ ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Prior Methods (1/2)\\n\\nBased on constituent co-occurrences: \"cake made of apple\"\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018 10/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Prior Methods (1/2) Based on constituent co-occurrences: \"cake made of apple\"\\n\\nProblems:\\n1. Many unseen compounds, no paraphrases in the corpus\\n2. Rare: parsley cake or highly lexicalized: ice cream\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018 10/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Prior Methods (1/2) Based on constituent co-occurrences: \"cake made of apple\"\\n\\nProblems:\\n1. Many unseen compounds, no paraphrases in the corpus\\n2. Many compounds with just a few paraphrases\\n\\nCan we infer \"cake containing apple\" given \"cake made of apple\"?\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018 10/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Prior Methods (1/2) Based on constituent co-occurrences: \"cake made of apple\"\\n\\nProblems:\\n1. Many unseen compounds, no paraphrases in the corpus\\n2. Rare: parsley cake or highly lexicalized: ice cream\\n3. Many compounds with just a few paraphrases\\n- Can we infer \"cake containing apple\" given \"cake made of apple\"?\\n\\nPrior work provides partial solutions to either (1) or (2)\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018 10/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Prior Methods (2/2)\\n1.\\nMELODI [Van de Cruys et al., 2013]: Represent NC by applying a function to its constituent distributional vectors: vec(apple cake) = f(vec(apple), vec(cake))\\n\\nm Predict paraphrase templates given NC vector\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Prior Methods (2/2)\\n1. MELODI [Van de Cruys et al., 2013]:\\n- Represent NC by applying a function to its constituent distributional vectors: vec(apple cake) = f(vec(apple), vec(cake))\\n- Predict paraphrase templates given NC vector\\n- Generalizes for similar unseen NCs, e.g. pear tart\\n2. IIITH [Surtani et al., 2013]:\\n- Learn \"is-a\" relations between paraphrases: e.g. \"[W2] extracted from [W:]\" C \"[w2] made of [w,]\"\\n\\nOur solution: multi-task learning to address both problems\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Vered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Multi-task Reformulation Training example {w1 = apple, w2 = cake, p = \"[w2] made of [w]\"}\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\nACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Multi-task Reformulation Training example {w1 = apple, w2 = cake, p = \"[w2] made of [w]\"}\\n1. Predict a paraphrase p for a given NC ww: What is the relation between apple and cake?\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Multi-task Reformulation\\n\\nTraining example {w1 = apple, w2 = cake, p = \"[w2] made of [w1]\"}\\n1. Predict a paraphrase p for a given NC w1: What is the relation between apple and cake?\\n2. Predict w1 given a paraphrase p and w2: What can cake be made of?\\n3. Predict w2 given a paraphrase p and w1: What can be made of apple?\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Main Task (1): Predicting Paraphrases\\n\\nWhat is the relation between apple and cake?\\n\\nb= 78LF] | @8) apple | (78) [wa] containing [wi] | (131) [w2] made of [wa] m\\n\\nEncode placeholder [p] in \"cake [p] apple\" using biLSTM\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018\\n\\n14/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Main Task (1): Predicting Paraphrases\\n\\nWhat is the relation between apple and cake?\\n\\npj = 78\\nBake) (apple) made (28) apple (78) containing (134) made of\\n\\nEncode placeholder [p] in \"cake [p] apple\" using biLSTM.\\n\\nPredict an index in the paraphrase vocabulary.\\n\\nVered Shwartz and Ido Dagan\\n+ Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n+ ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Main Task (1): Predicting Paraphrases\\n\\nWhat is the relation between apple and cake?\\n\\npj = 78\\n\\nFake)\\n\\n(apple) made\\n\\nEncode placeholder [p] in \"cake [p] apple\" using biLSTM\\n\\nPredict an index in the paraphrase vocabulary\\n\\nFixed word embeddings, learned placeholder embeddings\\n\\nVered Shwartz and Ido Dagan\\n\\n+ Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n\\n+ ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Main Task (1): Predicting Paraphrases\\n\\nWhat is the relation between apple and cake?\\n\\npj = 78 [ (23) made | am\\n\\nEncode placeholder [p] in \"cake [p] apple\" using biLSTM\\n\\nm Predict an index in the paraphrase vocabulary\\n\\nm Fixed word embeddings, learned placeholder embeddings\\n\\nm (1) Generalizes NCs: pear tart expected to yield similar results\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Helper Task (2): Predicting Missing Constituents\\n\\nWhat can cake be made of?\\n\\nWi = 28\\n\\nLd(esrmade ||m Encode placeholder in \"cake made of [w1]\" using biLSTM\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Helper Task (2): Predicting Missing Constituents\\n\\nWhat can cake be made of?\\n\\nWy = 28\\n\\nLdm Encode placeholder in \"cake made of [w1]\" using biLSTM\\n\\nm Predict an index in the word vocabulary\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018\\n\\n15/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Helper Task (2): Predicting Missing Constituents\\n\\nWhat can cake be made of?\\n\\nWi = 28\\n\\nLd(eared ]MGS eset} am Encode placeholder in \"cake made of [w1]\" using biLSTM.\\n\\nPredict an index in the word vocabulary.\\n\\n(2) Generalizes paraphrases: \"[w2] containing [w1]\" expected to yield similar results.\\n\\nVered Shwartz and Ido Dagan\\n\\n+ Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n\\n+ ACL2018 15/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Training Data Collected from Google N-grams\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\nACL 2018 16/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Training Data Collected from Google N-grams\\nInput: Set of NCSim Templates of POS tags (e.g. \"[w2] verb prep [w1]\")\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018\\n16/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Training Data Collected from Google N-grams\\n\\nInput: Set of NCslm Templates of POS tags (e.g. \"[w2] verb prep [w1]\")\\n\\nWeighting by frequency and length\\n\\n140k instances\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Ranking Model: Predict top k paraphrases for each noun compound\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Ranking Model: Predict top k paraphrases for each noun compound.\\nLearn to re-rank the paraphrases to better correlate with human judgments. Vered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Ranking Model: Predict top k paraphrases for each noun compound.\\nLearn to re-rank the paraphrases to better correlate with human judgments.\\nSVM pair-wise ranking with the following features:\\n- POS tags in the paraphrase\\n- Prepositions in the paraphrase\\n- Length\\n- Special symbols\\n- Similarity to predicted paraphrase\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Results 6028\\n\\n[J MELODI [Van de Cruys et al., 2013] [J SemEval 2013 Baseline [Hendrickx et al., 2013] [] SFS [Verstey, 2013] 406 [Jit fsurtani et al., 2013] 40\\n- I PaNiC [Shwartz and Dagan, 2018] 28.4 28.2 25.8 23.1 23.1 20 17.9\\n- non-isomorphic\\n- isomorphic"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Results 6028\\n\\n[J MELODI [Van de Cruys et al., 2013]\\n[J SemEval 2013 Baseline [Hendrickx et al., 2013]\\nSFS [Verstey, 2013]\\n[Jit fsurtani et al., 2013]\\nI PaNiC [Shwartz and Dagan, 2018]\\n\\n28.4\\n28.2\\n25.8\\n23.1\\n23.1\\n20\\n17.9\\n- non-isomorphic\\n- isomorphic\\n- rewards\\n- recall\\n- precision"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Results 6028\\n\\n[J MELODI\\n\\n[Van de Cruys et al., 2013]\\n\\n[J SemEval 2013 Baseline\\n\\n[Hendrickx et al., 2013]\\n\\n[] SFS\\n\\n[Verstey, 2013]\\n\\n[Jit fsurtani et at, 2013]\\n\\n40 = I PaNiC\\n\\n[Shwartz and Dagan, 2018]\\n\\n28.4 28.2 25.8 23.1 23.1 20 17.9\\n- non-isomorphic\\n- isomorphic\\n- rewards\\n- recall\\n- only\\n- precision\\n- and precision"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Results 6028\\n\\n[J MELODI [Van de Cruys et al., 2013]\\n[J SemEval 2013 Baseline [Hendrickx et al., 2013]\\n[SFS [Verstey, 2013]\\n[Jit fsurtani et al., 2013]\\n\\n40 = I PaNiC [Shwartz and Dagan, 2018]\\n28.4\\n28.2\\n25.8\\nA 23.4\\n20\\n17.9\\n- non-isomorphic\\n- isomorphic\\n- \"conservative\"\\n\\nT T models\\n- rewards\\n- recall only\\n- precision\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018 19/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Error Analysis\\n\\nFalse Positive\\n1. Valid, missing from gold-standard (\"discussion by group\")\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations « ACL2018 20/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Error Analysis\\n\\nFalse Positive\\n1. Valid, missing from gold-standard (\"discussion by group\")\\n2. Too specific (\"life of women in community\")\\n3. Incorrect prepositions\\n\\n(2) (6) (3) (5) (4)\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations « ACL2018 20/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Error Analysis\\n\\nFalse Positive\\n1. Valid, missing from gold-standard (\"discussion by group\")\\n2. Too specific (\"life of women in community\")\\n3.\\nIncorrect prepositions E.g., n-grams don't respect syntactic structure: \"rinse away the oil from baby 's head\" => \"oil from baby\"\\n4. Syntactic errors\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations « ACL2018 20/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Error Analysis\\n\\nFalse Positive\\n1. Valid, missing from gold-standard (\"discussion by group\")\\n2. Too specific (\"life of women in community\")\\n3. Incorrect prepositions\\nE.g., n-grams don't respect syntactic structure: \"rinse away the oil from baby’s head\" => \"oil from baby\"\\n4. Syntactic errors\\n5. Borderline grammatical (\"force of coalition forces\")\\n6. Other errors\\n\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations + ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Error Analysis\\n\\nFalse Negative\\n1. Long paraphrase (n >\\n5)\\n\\nVered Shwartz and Ido Dagan + Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018 21/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Error Analysis\\n\\nFalse Negative\\n\\n(1) Long paraphrase (n >\\n5)\\n(2) Determiners ('mutation of a gene')\\n\\n(3) Vered Shwartz and Ido Dagan\\n(4) Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Error Analysis\\n\\nFalse Negative\\n\\n(1) Long paraphrase (n >\\n5)\\n\\n(2) Determiners (\"mutation of a gene\")\\n\\n(3) Inflected constituents (\"holding of shares\")\\n\\n(4) Vered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Recap: A model for generating paraphrases for given noun-compounds\\nVered Shwartz and Ido Dagan\\n- Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL2018 22/23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Recap: A model for generating paraphrases for given noun-compounds.\\n\\nBetter generalization abilities:\\n- Generalize for unseen noun-compounds.\\n- Embed semantically-similar paraphrases in proximity.\\n\\nImproved performance in challenging evaluation settings.\\n\\nVered Shwartz and Ido Dagan\\nParaphrase to Explicate: Revealing Implicit Noun-Compound Relations\\nACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "References\\n\\nHendrick, J., Kozareva, Z., Nakov, P., Séaghdha, D., Szpakowicz, S., and Veale, T. (2013).\\nSemEval-2013 task 4: Free paraphrases of noun compounds. In SemEval, pages 138-143.\\n\\nNakov, P. (2013). On the interpretation of noun compounds: Syntax, semantics, and entailment.\\nNatural Language Engineering, 19(03):291-330.\\n\\nNakov, P. and Hearst, M. (2006). Using verbs to characterize noun-noun relations.\\nIn International Conference on Artificial Intelligence: Methodology, Systems, and Applications, pages 233-244. Springer.\\n\\nPantel, P., Bhagat, R., Coppola, B., Chklovski, T., and Hovy, E. (2007).\\nISP: Learning inferential selectional preferences. In ACL, pages 564-571.\\n\\nShwartz, V. and Dagan, I. (2018). Paraphrase to explicate: Revealing implicit noun-compound relations.\\nIn ACL, Melbourne, Australia.\\n\\nSurtani, N., Batra, A., Ghosh, U., and Paul, S. (2013).\\nliit-h: A corpus-driven co-occurrence based probabilistic model for noun compound paraphrasing.\\nIn SemEval, pages 153-157.\\n\\nVan de Cruys, T., Afantenos, S., and Muller, P. (2013).\\nMelodi: A supervised distributional approach for free paraphrasing of noun compounds. In SemEval, pages 144-147.\\n\\nVersley, Y. (2013). Sfs-tue: Compound paraphrasing with a language model and discriminative reranking.\\nIn SemEval, pages 148-152.\\n\\nVered Shwartz and Ido Dagan. Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations\\n- ACL 2018."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 312,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "CONTEXT AND OBJECTIVES\\n\\nContext\\nSemantic specialization of word embeddings. Most approaches follow Retrofitting [Faruqui et al., 2015].\\nA priori set of lexical semantic relations bring word vectors closer if they are part of similarity relations (synonymy, lexical association ...).\\nMove them away from each other if they are part of dissimilarity relations (antonymy ...).\\n\\nObjectives of Pseudofit\\nImproving word embeddings for semantic similarity without a priori lexical relations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "PRINCIPLES: GENERAL PERSPECTIVE\\n\\nTheoretical hypothesis: homogeneous corpus C: equal split of C in 2 parts: C1 and C2.\\n\\nDistributional representation of a word w from a corpus C = disrep(w) = set of contexts.\\n\\ndistrep(w) ≠ distrep.(w).\\n\\nHypothesis: differences between disrep(w) and distrep.(w) are contingent.\\n\\nBringing distrep(w) and distrep.(w) closer > more general (and better) distributional representation of w."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "PRINCIPLES: IMPLEMENTATION\\n\\nDistributional representations\\n- dense representations: Skip-Gram [Mikolov et al., 2013]\\n\\nNotion of pseudo-sense\\n- 2 sub-corpora > 2 representation spaces\\n- require projection in a shared space > source of disturbances\\n- instead, 1 corpus but 2 pseudo-senses for each word\\n\\npseudo-sense\\n- arbitrarily split the occurrences of a word into two or more subsets\\n\\nOverall process\\n- generation of distributional contexts for pseudo-senses\\n- turning pseudo-sense contexts into dense representations\\n- convergence of pseudo-word representations > more general word representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "REPRESENTATIONS OF PSEUDO-WORDS\\n\\nGeneration of contexts\\n- 2 successive occurrences of a word > 2 different pseudo-senses\\n- 3 representations / word\\n- 2 pseudo-senses + word itself > for each occurrence, generation of contexts for the current pseudo-sense + word\\n- « frequency trick »: adding the representation of the word > avoiding the impact of having half the occurrences for each pseudo-sense\\n\\nA policeman was arrested by another policeman.\\n\\nTARGET CONTEXT\\nTARGET CONTEXT\\nTARGET CONTEXT\\n- policeman, a policeman, another policeman\\n- be policeman, be policeman, by policeman\\n- arrest (x2)\\n- policeman, arrest policeman\\n- arrest policeman by (2)\\n- policeman, by policeman another\\n\\nBuilding of dense representations\\n- word2vec [Levy & Goldberg, 2014]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "CONVERGENCE OF PSEUDO-WORD REPRESENTATIONS\\n\\nPrinciples\\n\\n3 representations / word w: v (word); v1, v2 (pseudo-senses)\\nv, v1 and v2: supposed to be semantically equivalent = 3 similarity relations: (v, v1), (v, v2) and (v1, v2)\\napplication of a semantic specialization method for word embeddings to v, v1 and v2 with the similarity relations between them\\n- final representation for w: v after its \"specialization\"\\n\\nImplementation\\n\\nspecialization method: PARAGRAM [Wieting et al., 2015]\\ncomparable to Retrofitting but includes an automatically generated repelling component\\nfor each target word to specialize, selection of a repelling word, either randomly or according to their dissimilarity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "INTRINSIC EVALUATION\\n\\nExperimental setup\\n- 1 billion lemmatized words randomly selected from the Annotated English Gigaword corpus [Napoles et al., 2012] at the level of sentences\\n- word embeddings built with the best parameters from [Baroni et al., 2014]\\n- focus on nouns.\\n\\nWord similarity evaluation\\n- Spearman's rank correlation between human judgments and similarity between vectors for 3 representative datasets of word pairs\\n\\nINITIAL 49.5 78.3 65.6\\nPseudofit 51.2 79.9 68.0\\nRetrofitting 49.6 77.4 65.0\\nCounter-fitting 49.5 77.2 64.9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "SYNONYM EXTRACTION\\nEvaluation framework\\nGold Standard: WordNet's synonyms\\n2.9/word evaluated words = 11,481 nouns\\nfrequency > 20\\n- for each evaluated noun, retrieval of its 100 nearest neighbors\\nneighbors ranked from most similar (Cosine) to less similar\\nInformation Retrieval (IR) paradigm\\nevaluated word = query; neighbors = docs\\nIR measures: MAP, R-precision, precision@{1, 2, 5}\\n\\nINITIAL\\n13.0\\n15.2\\n18.3\\n13.1\\n7.1\\nPseudofit\\n+2.5\\n+3.3\\n+3.0\\n+2.5\\n+1.8\\nx 100|8NUNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "SENTENCE SIMILARITY\\nEvaluation task\\n- Semantic Textual Similarity: STS Benchmark dataset [Cer et al., 2017]\\n- Pearson rank correlation between human judgments and similarity between sentences for a set of reference sentence pairs.\\n- Computation of sentence similarity: strong baseline approach based on word embeddings.\\n- Sentence representation: elementwise addition of the embeddings of the plain words of the sentence.\\n- Use of Pseudofit max (fus-max-pooling) embeddings, defined for nouns, verbs, and adjectives.\\n- Sentence similarity: Cosine between sentence representations.\\n\\nINITIAL 63.2\\nPseudofit max (fus-max-pooling) 66.0\\nBest baseline (Cer et al.,\\n2017) 56.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "CONCLUSIONS AND PERSPECTIVES\\n\\nTo sum up- Pseudofit: method for improving word embeddings towards semantic similarity without external semantic relations- method based on the convergence of several representations built from the same corpus > more general representation* successful intrinsic and extrinsic evaluations for word similarity, synonym extraction and sentence similarity.\\n\\nResearch directions\\n- transposition of Pseudofit with several corpora\\n- link with researches about meta-embeddings and ensembles of word embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Commissariat à l'énergie atomique et aux énergies alternatives\\nInstitut List | CEA SACLAY NANO-INNOV | BAT. 861\\n- PC14291191\\nGif-sur-Yvette Cedex\\n- FRANCE\\n\\nÉtablissement public à caractère industriel et commercial | RCS Paris B 775 685 019"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 202,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Task-completion dialogue as optimal decision making\\n- Reinforcement learning using real or simulated experience\\n- Deep Dyna-Q\\n- Evaluation methodology\\n- Simulated user evaluation\\n- Human-in-the-loop evaluation\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "An Example Dialogue with Movie-Bot\\n\\nTurn 1 usr: can I get 2 tickets for race\\n\\nTurn 1 sys: What date would you like to watch it?\\n- Actual dialogues can be more complex:\\n- Speech/Natural language understanding errors\\n- Input may be spoken language form\\n\\nTurn 6 usr: Need to reason under uncertainty\\n- Constraint violation\\n\\nTurn 8 usr: Revise information collected earlier\\n\\nTurn 10 usr: thanks\\n\\nSource code available at https://github.com/MiuLab/TC-Bot"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Task-oriented, slot-filling, Dialogues\\n\\nDomain: movie, restaurant, flight, ...\\n\\nSlot: information to be filled in before completing a task\\n\\nFor Movie-Bot: movie-name, theater, number-of-tickets, price, ...\\n\\nIntent (dialogue act):\\n\\nInspired by speech act theory (communication as action) request, confirm, inform, thank-you, ...\\n\\nSome may take parameters: thank-you(), request(price), inform(price=$10)\\n\\n\"Is Kungfu Panda the movie you are looking for?\"\\n\\nal confirm(moviename=\"kungfu panda\") :"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Dialog Manager (DM) \"Find me a Request (movie; Bill Murray movie\" Saale ee actor = bill murray), Knowledge Base Understanding (LU) eset ie\\n- \"When was it Request released\" Natural Language (release_year) SET Generation / Synthesis 6 uoe amazon echo 4 Entity-Centric Knowledge Basei 2 Hi, how can I help?\\n\\nMovie Actor car:\\n\\nGroundhog Day Bill Murray 1993\\n\\nAustralia Nicole Kidman\\n\\nMad Max: Fury Road 2015"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "A unified view: dialogue as optimal decision making\\n- Dialogue as a Markov Decision Process (MDP)\\n- Given state s, select action a according to (hierarchical) policy\\n- Receive reward r, observe new state a'\\n- Continue the cycle until the episode terminates.\\n\\nGoal of dialogue learning: find optimal policy to maximize expected rewards\\n\\nInfo Bots Understanding of user\\n- Clarification questions, Relevance of answer (Q&A bot over KB, Web etc.)\\n- Intent (belief state) Answers\\n- # of turns\\n\\nTask Completion Bots Understanding of user\\n- Dialog act + slot_value\\n- Task success rate (Movies, Restaurants, ...)\\n- Goal (belief state) # of turns\\n\\nSocial Bot Conversation history Response Engagement (Xiaolce)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Task-completion dialogue as RLI\\n\\n* Observation and actions\\n* Raw representation (utterances in natural language form)\\n* Word\\n* Semantic representation (intent-slot-value form)\\n\\nRequesting:\\n* Reward\\n* +10 upon successful termination\\n* -10 upon unsuccessful termination\\n* -1 per turn\\n\\nRaw semantic pioneered by [Levin+ 00]\\nOther early examples: [Singh+ 02; Pietquin+ 04; Williams & Young 07; etc.]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "RL vs. SL (supervised learning)\\n\\nDifferences from supervised learning:\\n- Learn by trial-and-error (\"experimenting\")\\n- Need efficient exploration\\n- Optimize long-term reward\\n- Need temporal credit assignment\\n\\nSimilarities to supervised learning:\\n- Input/feature\\n- Generalization and representation\\n- Hierarchical problem solving\\n- True label\\n- Teacher"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Learning with real users\\n\\n@ Human-Human conversation data\\n\\nSupervised/imitation learning\\n- Expensive: need large amounts of real experience except for very simple tasks\\n\\nDialog agent\\n- Risky: bad experiences (during exploration) drive users away\\n\\nActing RLi with real experience:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Learning with user simulators:\\n- BiEimmenetmmch conversation data\\n- Inexpensive: generate large amounts of supervised/imitative simulated experience for free\\n- Overfitting: discrepancy between real users and simulators\\n- Dialog agent simulated experience"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Dyna-Q: integrating planning and learning\\n- combining model-free and model-based RL planning\\nupdate tabular methods and linear function approximation\\n- search\\n- direct reinforcement learning\\n- earning\\n- world model learning\\n- Model\\n- planning/search control"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Deep Dyna-Q (DDQ): Integrating Planning for Dialogue Policy Learning\\n\\nDDQ Based on Dyna-Q Supervised/Imitation Policy as DNN, trained using DQN learning.\\n- Apply to dialogue: simulated user as world model;\\n- Planning\\n- Limited real user experience\\n- Large amounts of simulated experience;\\n- World model Acting Direct (simulated user)\\n\\nLimited real experience is used to improve dialogue agent.\\n\\nWorld model (simulated user) Model learning real experience (limited)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Task-completion DDQ dialogue agent\\nSemantic Dialogue Manager\\nDial State Track\\nNLU\\nModel State Representation\\nDialogue Policy\\nSystem Action"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "The world model architecture.\\nMulti task MLP\\nReward\\nUser action\\nTermination\\n- Task-Specific representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Dialogue System Evaluation\\n- Metrics: what numbers matter?\\n- Success rate: # Successful Dialogues / # All Dialogues\\n- Average turns: average number of turns in a dialogue\\n- User satisfaction\\n- Consistency, diversity, engaging, ...\\n- Latency, backend retrieval cost, ...\\n- Methodology: how to measure those numbers?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Evaluation methodology\\n\\nLab user simulated.\\n\\nUrbis ItSs5 JY K user simulation scalability.\\n\\nK JY JY small-scale human evaluation flexibility (lab, Mechanical Turk, ...).\\n\\nVv ane expense K JY large-scale deployment (optionally with continuing risk Vv) K Y incremental refinement."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "A Simulator for E2E Neural Dialogue System [i+ 17]\\nText Input: 'Time t-2 Are there any action movies to see this weekend?\\n\\nLanguage Understanding (LU)\\nNatural Language Generation (NLG)\\n\\nSemantic Frame B =\\nrequest_movie: genre=action, date=this weekend\\n\\nError Model Controller\\nUser Dialogue Action\\n- Inform(location=San Francisco)\\nSystem Action/Management\\nBackend Policy (DM)\\nDatabase request_location\\nUser Agenda Modeling\\nUser Simulator\\nEnd-to-End Neural Dialogue System"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Agenda-based Simulated User (Schatzmann & Young\\n09)\\nUser state consists of (agenda, goal); goal is fixed throughout dialogue.\\nAgenda is maintained (stochastically) by a first-in-last-out stack.\\n\\nNew episode, user goal:\\n\\nUser: Which theater can I book 3 tickets for 10 Cloverfield Lane?\\n\\nAgent: What time would you like to see it?\\n\"ticket\": \"UNK\"\\n\\nUser: Which theater and start time are available?\\n\"theater\": \"UNK\"\\n\"starttime\": \"UNK\"\\ntomorrow?\\n\\nAgent: 11:45am is available.\\n\\nUser: Which theater is available?\\n\\nAgent: Regal LA Live Stadium 14 is available.\\n\"numberofpeople\": \"3\",\\n\"date\": \"tomorrow\",\\n\\nUser: Could you help me to book the tickets?\\n\\nAgent: Okay\\n- I was able to book 3 tickets for you to see\\n\"moviename\": \"10 Cloverfield Lane\" at Regal LA Live Stadium 14 at 11:45am tomorrow.\\n\\nUser: Thank you.\\n\\nAgent: Thank you.\\n\\nImplementation of a simplified user simulator: https://github.com/MiuLab/TC-Bot"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Simulated user evaluation\\n- DQN vs DDQ\\n- K: number of planning steps\\n- P as-K=2\\n- DQN\\n- DDQ(2)\\n\\n95 50 100 150 200 250 300 350 400 Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Simulated user evaluation\\n\\nK: number of planning steps\\n\\nwr any eye (generating K simulated dialogues per real dialogue)\\n\\nK = 2, 5, 10, 20\\n- DDQ(2)\\n- PDQ(5)\\n- DDQ(10)\\n- DDQ(20)\\n\\n50 100 150 200 250 300 350 400 Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Impact of world model quality\\n- DQN (10): 0.9 e perfect world model 0.8 wosE 0.5 a 0.30.2 0.1\\n\\n=== DON\\n- DQN (10) 005 50 100 150 200 250 300 350 400 Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Impact of world model quality?\\n\\nDQN(10) 0.9e perfect world model\\nDDQN(10): pretrained on labeled data, and updated using real dialogue on the fly\\nfda 0.30:2\\n- ponOL == UDO(I10)\\n- DQN(10)\\n\\n50 100 150 200 250 300 350 400 Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "- DQN(10) a perfect world model = LORNA0.7\\n- DDQ(10): pretrained on labeled data, and updated using real dialogue on the fly\\n- DDQ(10, rand-init): pretrained on labeled data, and updated using real dialogue on the fly\\n- DDQ(10, fixed): pretrained on labeled data, and updated using real dialogue"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Human-in-the-loop experiments\\n- learning dialogue via interacting with real users\\n- DDQ agents significantly outperform \"the DQN agent\". A larger K leads to more aggressive planning and better results.\\nPre-training world model with human conversational data improves the learning efficiency and the agent's performance.\\n\\n0.1\\nar\\n50\\n100\\n150\\n200\\nEpoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Conclusion and Future Work\\n\\nDeep Dyna-Q: integrating planning for dialogue policy learning\\n- Improves learning efficiency\\n- Make the best use of limited real user experiences\\n\\nFuture research\\n- Learning when to switch between real and simulated users\\n- Exploration in planning\\n- Exploration: trying actions to improve the world model\\n- Exploitation: trying to behave in the optimal way given the current world model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Microsoft Dialogue Challenge at SLT-2018\\n07/16/2018: Registration is now open.\\n\\nTask: build E2E task-completion dialogue systems\\nData: labeled human conversations in 3 domains\\nExperiment platform with built-in user simulators for training and evaluation\\nFinal evaluation in simulated setting and by human judges\\n\\nMore information: https://github.com/xiul-msr/e2e_dialog_challenge"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 181,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "NATURAL LANGUAGE GENERATION\\n\\nNon-linguistic data > natural language\\n\\nSubject         Relation        Object\\nAarhus_Airport  cityServed      Aarhus, Denmark\\nAarhus_Airport  elevation       25.0\\nAarhus_Airport  runwayName      10R/28L\\n\\nThe Aarhus Airport is located in Aarhus, Denmark. It is situated 25.0 meters above sea level.\\nThe airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "REFERRING EXPRESSION GENERATION (REG)\\n\\nTask responsible for generating references to discourse entities\\n\\nSubject Relation Object\\n\\nAarhus Airport, cityServed Aarhus, Denmark\\n\\nAarhus Airport, elevation 25.03\\n\\nAarhus Airport; runwayName 10R/28L\\n\\nREG\\n\\nThe Aarhus Airport is located in Aarhus, Denmark. It is situated 25.03 meters above sea level.\\nThe airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Novel \"end-to-end\" NLG models\\n\\nGeneration of delexicalized templates from different meaning representations...\\n- AMR\\n- template\\n- text (Konstas et al.,\\n2017)\\n- Dialog Act\\n- template\\n- dialogue text (Wen et al.,\\n2015)\\n- RDF triples\\n- template\\n- text\\n\\nWebNLG Challenge (Gardent et al., 2017)... for accounting data sparsity and unseen entities (Konstas et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "WebNLG corpus 25,298 text describing 9,674 triple sets Manually delexicalized"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "TEMPLATE GENERATION\\n\\nSubject Relation Object\\n\\nSUBJECT-1 cityServed OBJECT-1\\n\\nSUBJECT-1 elevation OBJECT-2\\n\\nSUBJECT-1 runwayName OBJECT-3\\n\\ntemplate\\n\\nSUBJECT-1 is located in OBJECT-1.\\n\\nSUBJECT-1 is situated OBJECT-2 meters above sea level.\\n\\nSUBJECT-1 has a runway called OBJECT-3."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "WIKIFICATION\\n\\nTag Entity\\n\\nSUBJECT-1 Aarhus_Airport\\n\\nOBJECT-1 Aarhus, Denmark\\n\\nOBJECT-2 25.0\\n\\nOBJECT-3 10R/28L\\n\\nWiki\\n\\nAarhus_Airport is located in Aarhus, Denmark.\\n\\nAarhus_Airport is situated 25.0 meters above sea level.\\n\\nAarhus_Airport has a runway called 10R/28L.\\n\\nConversion in constant time"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nThe airport has a runway called 10R/28L.\\n\\nUnderestimated process so far."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "PROBLEMA Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nThe airport has a runway called 10R/28L. REG is crucial for the coherence of the text"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Extensively studied in pipeline architectures of NLGGREC Challenges (Belz et al.,\\n2010)\\n\\nDecisions taken by different subtasks (modular)\\n\\nChoice of referential form\\n\\nSurface realization\\n\\nBottlenecks\\n\\nFeature engineering\\n\\nDifficulties in developing and maintaining\\n\\nPropagation of errors in cascade along the modules"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "End-to-end REG approach taking context into account\\n\\nNo need for feature engineering\\n\\nChoice of referential and surface realization in one go!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Target reference to be realized\\n\\nPre-context Lowercased, tokenized and delexicalized piece of text before the target reference\\n\\nPos-context Lowercased, tokenized and delexicalized piece of text after the target reference"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "NEURALREGFOS Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nAarhus Airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "NEURALREGFOS Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nAarhus Airport has a runway called 10R/28L. EOSconeetpos-context1 Aarhus, Denmark"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Encoder Attention\\n- Decoder architecture\\n\\nContext encoders\\n\\nVector representations for pre- and post-contexts\\n\\nDecoder\\n\\nCombining representations and decoding the referring expression"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Aarhus Airport is located in Aarhus, Denmark.\\nIt is situated 25.0 meters above sea level."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Aarhus Airport | EOS Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport has a runway called 10R/28L. = EOS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Aarhus Airport is located 25.0 meters above sea level. Aarhus, Denmark. Aarhus Airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "It EOS Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "DECODERS\\n- Dec (Si-1, lei, Vy, ' Viarget 1); = beam(softmax(W,s; + b)) evaluation of 3 methods to compute\\n- ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "SEQ2SEO Average and concat matrixes?\") and p?)s(k) 1 OWN 7 (0)ho=y Di Nia(pre) (pos)o = Th a)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "CATT Concatenative attention of = TM anh(WOs) + UO A®)Q® = exp(e)TP Lrat &XPE;n)(kk) _ NV (&,4C= Dj=! ai Nh;C= ee, an"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "HIERARCHICAL Attention (Libovicky and Helcl,\\n2017) = YT ann Ws). + UM)pg = exp(e;) Dn exp(e;) k\\nk) (kc = Ea A Upc"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "NEURALREGSi = Daec(Si-1, (ci, Vy ' Viarget |)\\nNeuralREG+Seq2Seqc; = [ave(h?\"TM), ave(h?\")]\\nNeuralREG+CAttc; = [attend(h?\"), attend(h?\")]\\nNeuralREG+HierAttc; = hierattend(attend(h?\"), attend(h?))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "WebNLG corpus 25,298 text describing 9,674 triple sets\\nManually delexicalized 78,901 references to 1,483 entities\\nTrain: 63,031\\n- Dev: 7,127\\n- Test: 8,743"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "BASELINES Only Names Ferreira"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "(WikilD) : underline\\n- whitespace Aarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nAarhus Airport has a runway called 10R/28L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "FERREIRA Choice of referential form (Castro Ferreira et al.,\\n2016)\\n\\nAarhus Airport is located in Aarhus, Denmark. Aarhus Airport is situated 25.0 meters above sea level.\\nAarhus Airport has a runway called 10R/28L.\\n\\nL form Names, is located in Name\\n2. Pronouns y; is situated Name 3 meters above sea level. Descriptions has a runway called Name g."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Surface Realization NAMEg, is located in NAMEy. PRONOUNc is situated NAMEg 3 meters above sea level.\\nDESCRIPTION has a runway called NAMEgs.\\n\\nPick the most frequent referring expression, given entity, form, syntactic position and referential status.\\nFeatures extracted from the dependency tree of the wikified text."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "AUTOMATIC EVALUATION REG metrics\\n\\nAccuracy, string edit distance and pronoun accuracy\\n\\nText metrics\\n\\nText accuracy and BLEU"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "REG METRICS\\n\\nAcc String Pronoun Only Names\\n- Ferreira\\n- Neural REG + Seq2Seq 74% 2.32 75%\\n- Neural REG + CAtt 74% 2.25 75%\\n- Neural REG + HierAtt 73% 2.36 73%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "TEXT METRICS Acc BLEU \"Only Names = S\\n- 15% 69.03\" Ferreira st * é \"t * ~ 'ité ' i GSC * SCT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Material\\n144 trials (= 6 triple set sizes x 4 instances x 6 text versions)\\n\\nMethod\\nLatin square design\\n24 trials/list (= 144 trials ~ 6 lists)\\n60 participants (10 participants/list)\\n\\nMetrics\\nFluency, Grammaticality and Clarity\\n7-Likert scale"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "HUMAN EVALUATION\\n\\nFluency      Grammar      Clarity\\n\\nOnly Names\\n\\nFerreira\\n- NeuralREG+Seq2Seq     4.95     4.82\\n- NeuralREG+CAtt        5.23     4.95     5.26\\n- NeuralREG+HierAtt     5.07     4.90     5.13\\n- Original              5.41     5.17     5.42"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "First end-to-end approach for REG in text discourse\\n\\nImprovements over reference accuracy and text fluency\\n\\nConcatenative attention (CAtt) best decoding method\\n\\nDelexicalized version of WebNLG corpus\\n\\nUseful resource for NLG in general\\n\\nData and code available\\n\\nhttps://github.com/ThiagoCF05/NeuralREG"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "QUESTIONS?\\n\\nModel Text\\n\\nAlan Shepard was born in New Hampshire on 1923-11-18.\\nBefore his death in California, he had been awarded the Distinguished Service Medal by the United States Navy, an award higher than the Department of Commerce Gold Medal.\\n\\nThank you! :-)\\nhttps://github.com/ThiagoCF05/NeuralREG"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "SETTINGS\\n\\nLayers LSTM\\n\\nTraining Method Adam\\n\\nMatrices init Xavier\\n\\nBatch Size 40\\n\\nEpochs 60\\n\\nEmbedding Size 300\\n\\nHidden Layer Size 512\\n\\nDropout 0.2/0.3"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 179,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Co-Authors: John Hewitt, Dan Roth\\nCo-First Author Advisor: G. Bren Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Derivational Morphology\\n\\nacest employer\\n\\nemployment\\n\\nintensely\\n\\nintense\\n\\n-Nomar\\n\\nintensity\\n\\n@ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Derivational Morphology\\n\\nemployer\\n\\nemployment\\n\\nintensely intense\\n- Nommar intensity root word ---> derived word G\\n\\nPenn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Derivational Morphology Aces employ\\n- RE sucypover ® intense\\n- Nominaynore"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Motivation\\nMachine translation\\nText simplification\\nLanguage generation\\n@ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Challenges\\n- Suffix ambiguity\\n- Orthographic irregularity\\nG '@ Penn Engineering 7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Suffix Ambiguity | I have an observament! @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Suffix Ambiguity \"I have an observation!\" grounding foundation ground alignment RESULTG ' Penn Engineering 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Suffix Ambiguity \"I have an observament!\" grounding foundation result valid"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Orthographic Irregularity speak -- speech @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Orthographic Irregularities speak -- speech creak RESULTG '@ Penn Engineering 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Orthographic Irregularity speak -- speech creak -----> *creech G '@ Penn Engineering 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Orthographic Irregularity speak -- speech creak -----> *ereech- creaking Gy & Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Orthographic Irregularities speak -- speech creak -----> ereech\\n- creaking RESULT. erupt ----- eruption bankrupt aeG '@ Penn Engineering 16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Orthographic Irregularities speak -- speech creak\\n- *ereech\\n- creaking\\n- RESULT\\n- erupt\\n- eruption\\n- bankrupt a. *bankruption\\n\\nG ' Penn Engineering 7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Orthographic Irregularities speak -- speech creak -----> *ereech- creaking\\n\\nRESULT .erupt ----- eruption\\n\\nbankrupt -e *bankruptien- bankruptcy\\n\\nG ' Penn Engineering 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Model Overview\\n- orthographic:\\n- wise\\n- Lo,5\\n- suffix ambiguity\\n- wisely Adverb\\n- on veg aggregation\\n- distributional:\\n- orthographic irregularity\\n- G @B Penn Engineering\\n- grap g y s"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Model Overview\\n- Adverb @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Model Overview:\\n- Orthographic suffix ambiguity\\n- Distributional orthographic irregularity\\n\\n@B Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Model Overview\\nHt wisely\\na) aggregation\\nG '@ Penn Engineering ."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Model Overview\\n\\northographic: suffix ambiguity a. Gy Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Orthographic Model\\n- Seq2Seq baseline\\n- Dictionary-constrained decoding\\n- Reranking with frequency information\\n\\nG '@ Penn Engineering 25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Seq2Seq Baseline\\nDepth #45aWG, Benn Engineering a 26"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Seq2Seq Baseline\\nPenn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Seq2Seq Baseline\\nHee, Penn Engineering 28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Seq2Seq Baseline"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Seq2Seq Baseline\\nComposition, Penn Engineering 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Dictionary-Constrained Decoding\\n\\nSeq2Seq models generate suffix ambiguity many unattested words, but are reasonable guesses grounding foundation groundment groundal RESULT '@ Penn Engineering 31"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Dictionary-Constrained Decoding\\n\\nSeq2Seq models generate suffix ambiguity many unattested words, but are reasonable guesses grounding.\\n- Intuition: constrain model's grounding to only generate known ground words.\\n\\nRESULTG ' Penn Engineering 32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Dictionary-Constrained Decoding X = {a, b, #} G '@ Penn Engineering 33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Dictionary-Constrained Decoding X = {a, b, #} a ie abaabo SEos c\\n- eT] ba: babbb G '@ Penn Engineering 34"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Dictionary-Constrained Decoding\\nY = {a, b, #}.\\na ie aba vatababb bagco;\\n-baa eae 1]ba) bab oobbG '@ Penn Engineering 36"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Dictionary-Constrained Decoding x = {a, b, #} ie aba Flom abb (coe) baeo Retebb G '@ Penn Engineering 37"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Dictionary-Constrained Decoding = {a, b, #}. log p(b | ab)\\n- G '@ Penn Engineering 38"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Dictionary-Constrained Decoding = {a, b, #}\\n- log p, (abb) i; abb: @G '@ Penn Engineering 39"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Dictionary-Constrained Decoding\\nx = {a, b, #}\\nL = {a, ab, aba, ba}\\naa abaaboSEos c- eT]ba: babbbG '@ Penn Engineering 41"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Dictionary-Constrained Decoding\\nX = {a, b, #}\\nL = {a, ab, aba, ba}\\nF(y) = y\\nab: 6\\nba\\n\\nSearch over tries induced from dictionary\\nG, & Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Reranking with Frequency Information refute @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Reranking with Frequency Information\\n\\nRESULT | Model Output Model Score\\n- refutation -1.1\\n- refutation -1.2\\n- refute -4.8\\n- refute -5.6\\n- refutation -8.7\\n\\nGy & Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Reranking with Frequency Information\\nrefute\\nModel Output\\nModel Score\\nrefutation\\n- 1.2\\nG'S Penn Engineering 45"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Reranking with Frequency Information\\nrefute\\nModel Output\\nModel Score\\nneg Deepareqrefution -1\\n50\\nrefutation \"9\\n143G '@ Penn Engineering'"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Reranking with Frequency Information\\n\\nRESULT | Model Output\\n\\nModel Score Log Corpus Reranker\\n\\nReranker Freq Output Score\\n\\nrefutation\\n- I.1 5.0\\n\\nrefutation 0.5\\n\\nrefutation 12\\n\\npe refutation\\n\\naleG '@ Penn Engineering 47"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Model Overview\\ndistributional: G Benn Engineering SPS irregularity ts"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Distributional Model\\n- Orthographic information can be unreliable. Orthographic\\n- Semantic transformation irregularity remains the same.\\n\\nRESULT speak\\n- speech\\n\\ncreak\\n- *ereech\\n- creaking\\n\\nG, 'Penn Engineering 50"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Distributional Model Intuition\\n\\ncats\\n- cat + ox ~ oxen\\n\\nG '@ Penn Engineering 51"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Distributional Model Intuition, validity cats\\n- cat + ox ~ oxenue valid \" | unwilling G ' Penn Engineering 52"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Distributional Model Intuition,\\nLe validity cats\\n- cat + ox ~ oxen unwillingness\\n\\nLearn non-linear function per transformation valid \" | unwilling G, 'Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Distributional Model Intuition, validity cats\\n- cat + Ox ~ oxen unwillingness Learn non-linear function per transformation Independent of valid unwilling orthography G, 'Penn Engineering a"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Distributional Model @ JAB OSe\\n- 4 §é Jagent & non-linear iefunction G @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Aggregation Model\\nORTHOGRAPHIC approvation\\n- 0.2 approval\\nDISTRIBUTIONAL approval\\n- 0.1\\n-\\nnon-linear function\\nG' Penn Engineering an"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Aggregation Model\\n\\nOrtho Score Distributional Score\\n- approvation -0.9\\n- approval -0.6\\n- bankruption -0.3\\n- bankruptcy = 0.8\\n- stroller -0.8\\n- strolls -0.9\\n\\nG '@ Penn Engineering 60"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Aggregation Model\\n\\nOrtho Score\\n\\nDistributional Score\\n\\nAggregation Selection\\n- approvation -0.9\\n- approval -0.6\\n- bankruptcy -0.3\\n- bankruption -0.8\\n- expertly -0.5\\n- expertly\\n- stroller -0.8\\n- strolls -0.9\\n- stroller\\n\\nG ' Penn Engineering 61"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Experiments Penn (6; o & Engineering a"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Cotterell et al. 2017\\n\\nBecta cerea ot ec =r\\n\\nADVERB\\n\\nwisely --> simulation\\n\\nRESULT\\n\\nrecite ---> recital\\n\\noverstate ---> overstatement\\n\\nmodel ---> yodeler\\n\\nAGENT\\n\\nsurvive ---> survivor\\n\\nintense --> intensity\\n\\nNOMINAL\\n\\neffective --> effectiveness\\n\\npessimistic --> pessimism\\n\\nG '@ Penn Engineering ea"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Experiment Details\\n- 30 random restarts\\n- Token information: Google Book NGrams\\n- 360k unigram types\\n- Token counts aggregated\\n- Google News pre-trained word embeddings\\n- Evaluation: full-token match accuracy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Results Legend\\nSeq2Seq\\nDistributional\\nAggregation\\nDictionary-Constrained Decoding\\nFrequency-Based Reranking\\nBenn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Results 8580 Be UNconst TRAINED 75 | 3 65 <xg « Hl Const RAINED 5550 orl 4540 | DIsT SEQ AGGR SEQ + FREQ AGGR + FREQ GC wi mile ail aie Cotterell et al.\\nae = G, 'Penn Engineering au 66"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Results 8580 Be UNconst TRAINED 75 |> 79 g = 8 65 § 6055504540 __ DISTG '@ Penn Engineering 67"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "8580 Be UNconstTRAINED75 | F 70cg 65£ 60g2 55504540 | DIsT SEQ6 Til iliCotterell et al. G '@ Penn Engineering aul? 68"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Significant improvement when combining Dist and SEQ8580\\n\\nBe UNconstTRAINED75x.g 6s & 60g 55504540\\n\\nL_DIST SEQ AGGRGy aff} mGCotterell et al. @ Penn Engineering 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Frequency statistics are a valuable signal Cotterell et al. @ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Combined model still outperforms separate models\\n\\nBe UNconst TRAINED 75 Eg 65 60 g2 55 50 45 40\\n\\nL __ AGGR SEQ + FREQ AGGR + FREQ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Hl ConstRAINED\\n-504540\\n- SEQ AGGR\\n- SEQ+FREQ\\n- AGGR+FREQ\\nam GCotterell et al.\\naa =Ga '@ Penn Engineering Bol? 72"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "22% and 37% relative error reductions over SEQ8580 HB Unconstrained 75.8 65g \"H1 Constrained 55504540\\nAGGR AGGR+FREQ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Results by Transformation\\n100 §) Base vine\\n90 riii|||| Cotterell et al.\\n80 one\\na\\n70 Hi Accr-\\n60 Ban\\n50 all\\n) O2\\n40 '2 BM) Accr+FReQ+Dict\\n30 7mallll\\n6 tT: NOMINAL RESULT AGENT ADVERB ie plG '@ Penn Engineering vias"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Results by Transformation 100\\n\\nCotterell et al.: \"@ Penn Engineering\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "Results by Transformation\\n\\n10090 i80 | a. 70 a i Hi Accr& 60 es\\n\\nI\\n\\ni aanspp PT te£ 40 a a =\\n- 30 J jt i\\n- 20 |\\n- :\\n- 10\\n\\nte | LdGi SPem Engineering °"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Results by Transformation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Results by Transformation\\n100 §) Basevine\\n90 Cotterell et al.\\n80 Te a\\n70 Hi Accro\\n60 EEE\\n50 alll) OZ\\n40 BM) Accr+FReQ+Dict\\n30 7: mill O6 TL: NOMINAL RESULT AGENT ADVERB =n plG '@ Penn Engineering 78"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "Results by Transformation\\n\\nBasevine\\n\\nCotterell et al.\\n\\nNOMINAL RESULT AGENT ADVERB"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "Results by Transformation 100 NOMINAL = ; §) Basevine equivalent -----> {equivalence, equivalency} a 90 Cotterell et al.\\n2017.\\n70 Hi Accr & 60 ea] OGiit 50 *° BM) Accr + FReQ + Dict 30 os° mill 010 t NOMINAL RESULT AGENT ADVERB « rlG ' Penn Engineering 80"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "What does each model do well?\\n- Distributional Model Improvement over Seq2seq, per suffix\\n\\nZLog Suffix Frequency (Training Corpus)\\n\\nPenn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "What does each model do well?\\n- Distributional Model Improvement over Seq2seq, per suffix: Distributional does best.\\n- Orthographic does best."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "What does each model do well?\\n- A Distributional Model Improvement over Seq2seq, per suffix\\n- Distributional methodology does best\\n- Orthographic classification\\n- Suffix Frequency (Training Corpus)\\n\\n@Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "What does each model do well?\\n\\nDistributional Model Improvement over Seq2seq, per suffix\\n\\nDistributional enhancement does best as key for sponsorship sign.\\n\\nLog Suffix Frequency (Training Corpus)\\nG Penn Engineering 85"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "What does each model do well?\\n- Distributional Model Improvement over Seq2seq, per suffix n2gSs?\\n%33 a & Orthographic 8a ptign F ally & -4 = does best oO icatipno atign 5 : hd ion To 6 ef lyom -8Ss 0 1 2 3 4 5 6 7 Log Suffix Frequency (Training Corpus) G '@ Penn Engineering oe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "What does each model do well?\\n\\nDistributional Model\\nImprovement over Seq2seq, per suffix\\n- w2v: ADVERB; wise --> wisely\\n- So. ADVERB. quick --> quickly\\n\\nOrthographic\\nGa ptign ally\\ndoes best, atign: tonnn\\n\\nLog Suffix Frequency (Training Corpus)\\nG '® Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 83,
        "texts": [
          "What does each model do well?\\n- A Distributional Model Improvement over Seq2seq, per suffix\\n- Distributional n does best\\n- Orthographic does best\\n- RESULT: investment\\n- RESULT: inspiration\\n\\nLog Suffix Frequency (Training Corpus)\\n@ Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 84,
        "texts": [
          "Conclusione\\n\\nAggregation model for English derivational morphology\\n- Dictionary-constrained decoding\\n- Frequency-based reranking\\n- Distributional model per-transformation\\n- Best open- and closed-vocabulary models demonstrate 22% and 37% reduction in error\\n- New state-of-the-art results G, 'Penn Engineering &"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 85,
        "texts": [
          "Code & Data\\n\\nCode https://github.com/danieldeutsch/derivational-morphology\\n\\nData https://github.com/ryancotterell/derivational-paradigms\\n\\nPowered by dy/netG @Penn Engineering"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 86,
        "texts": [
          "References\\n- Cotterell et al. 2017, Paradigm completion for derivational morphology.\\nEMNLP '@ Penn Engineering 91"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 87,
        "texts": [
          "Thank you! G A&E..."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 100,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Sentence Representation in Conversations\\n\\nTraditional System: hand-crafted semantic frames [Inform location=Pittsburgh, time=now]\\n- Not scalable to complex domains\\n\\nNeural dialog models: continuous hidden vectors\\n- Directly output system responses in words\\n- Hard to interpret & control\\n\\n[Ritter et al 2011, Vinyals et al 2015, Serban et al 2016, Wen et al 2016, Zhao et al 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Why discrete sentence representation?\\n1. Interpretable & controllability & multimodal distribution\\n2. Semi-supervised Learning [Kingma et al 2014 NIPS, Zhou et al 2017 ACL]\\n3. Reinforcement Learning [Wen et al 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Why discrete sentence representation?\\n\\nOur goal: Latent Actions X = What time do you want to travel? Recognition 772\\n\\nEncoder Decoder Scalability & Model Interpretability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Baseline: Discrete Variational Autoencoder (VAE) with discrete K-way latent variables z and RNN recognition & generation network.\\nReparametrization using Gumbel-Softmax [Jang et al., 2016; Maddison et al., 2016]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Baseline: Discrete Variational Autoencoder (VAE)\\n\\nx' = schedule a meeting\\n\\nRecognition. Generation\\n\\nNetwork (R) a(x)\\n\\nNetwork (G) x = schedule a meeting\\n\\nFAIL to learn meaningful z because of posterior collapse (z is constant regardless of\\nx)\\n\\nMANY prior solutions on continuous VAE, e.g. (not exhaustive), yet still open-ended questions\\n- KL-annealing,\\n- decoder word dropout [Bowman et al 2015]\\n- Bag-of-word loss [Zhao et al 2017]\\n- Dilated CNN decoder [Yang et al 2017]\\n- Wake-sleep [Shen et al 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Anti-Info Nature in Evidence Lower Bound (ELBO) Write ELBO as an expectation over the whole dataset Lyaz = E_x [E_z (log p_e (x|z)\\n- KL (g_x (z|x) || p(z))]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Anti-Info Nature in Evidence Lower Bound (ELBO)\\n\\nWrite ELBO as an expectation over the whole dataset\\nLvaz = Ex [Ege (z|x) [log pg (x|z)] (1)\\n- KL(q(z|x) || p(z))]\\n\\nExpand the KL term, and plug back in:\\nEx [KL(q(z|x) || p(z))] = (2)\\n\\nMaximize ELBO\\n\\nI(Z,\\nX) + KL(q(z) || p(z))\\n- Minimize I(Z,\\nX) to 0\\n- Posterior collapse with powerful decoder.\\n\\nLvan = Ey(z|x) p(x) log p(x|z) (3)\\n- I(Z,\\nX)\\n- KL(q(z) || p(z))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Discrete Information VAE (DI-VAE)\\n\\nA natural solution is to maximize both data log likelihood and mutual information.\\n\\nLyazr + 1(Z,X) = (4) Ege (z|x) p(x) (log Dc (x|z) | ~ KL(q(z) || p(z))\\n\\nMatch prior result for continuous VAE. [Mazhazni et al 2015, Kim et al 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Discrete Information VAE (DI-VAE)\\n\\nAnatural solution is to maximize both data log likelihood & mutual information.\\nLynn + 1(Z,X) = (4)Ege (z|x)p(x) [log Dc (x|z)| ~ KL(q(z) || p(z))\\n\\nMatch prior result for continuous VAE. [Mazhazni et al 2015, Kim et al 2017]\\n\\nPropose Batch Prior Regularization (BPR) to minimize KL [q(z) || p(z)] for discrete latent variables:\\n- NN: mini-batch size.\\n- Z(z) X- zixn) = q'(z (5) q(z)\\n- N S gz(len) = 4 (2)\\n\\nFundamentally different from KL-annealing, since /\\n- k \" ji KL(q'(z) || p(z)) _ Sod (z _\\nk) log 4\\n\\nBPR is non-linear. = p(z =\\nk) (6) 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Learning from Context Predicting (DI-VST)\\n- Skip-Thought (ST) is a well-known distributional sentence representation [Hill et al 2016].\\nThe meaning of sentences in dialogs is highly contextual, e.g. dialog acts.\\n\\nWe extend DI-VAE to Discrete Information Variational Skip Thought (DI-VST).\\n\\nLpivst = E[log (p(z|x)p(x))]\\n- KL(q(z)||p(z)) (7)\\n\\nXp = how I can help you?\\n\\nXn = what time?\\n\\nx = schedule a meeting"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Integration with Encoder-Decoders\\n\\nResponse P(x|c,\\nz)\\nDialog Context c\\nResponse x\\nOptional: penalize decoder if generated x not exhibiting\\nz = Larr(Ox) = Ege (z|x)p(c,x) [log Yr (Zl F(€, Z))]\\n[Hu et al 2017] (9)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Integration with Encoder-Decoders\\nDialog Context c13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Evaluation Datasets\\n1. Penn Tree Bank (PTB) [Marcus et al 1993]:\\na. Past evaluation dataset for text VAE [Bowman et al 2015]\\n2. Stanford Multi-domain Dialog Dataset (SMD) [Eric and Manning 2017]:\\na. 3,031 Human-Woz dialog dataset from 3 domains: weather, navigation & scheduling.\\n3. Switchboard (SW) [Jurafsky et al 1997]:\\na. 2,400 human-human telephone non-task-oriented dialogues about a given topic.\\n4. Daily Dialogs (DD) [Li et al 2017]:\\na. 13,188 human-human non-task-oriented dialogs from chat room."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "The Effectiveness of Batch Prior Regularization (BPR) Model\\n\\nPPL KL(q||p) I(x,\\nz)\\n\\nFor referenced PTB RNNLM\\n- VAE 73.49 15.94\\n- DAE: Autoencoder + Gumbel Softmax DAE 66.49 2.20 0.349\\n- DVAE: Discrete VAE with ELBO loss DVAE 70.84 0.315 0.286\\n- DI-VAE 52.53 0.133 1.18\\n- DI-VAE: Discrete VAE + BPR\\n- DD RNNLM 31.15\\n\\nDST Xp: 28.23 0.588 1.359\\n\\nFor context-predicting Xn 28.16\\n- DVST Xp: 30.36 0.007 = 0.081\\n- DST: Skip thought + Gumbel Softmax\\n- X7: 30.71\\n- DVST: Variational Skip Thought\\n- DEVST 284 Gles L028 Xn: 27.94\\n- DI-VST: Variational Skip Thought + BPR\\n\\nTable 1: Results for various discrete sentence representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "The Effectiveness of Batch Prior Regularization (BPR)\\n\\nModel | PPL | KL(q||p) | I(x,\\nz)\\n\\nFor autoreferencing PTB:\\n- RNNLM: 116.22\\n- VAE: 73.49 | 15.94*\\n- DAE: Autoencoder + Gumbel Softmax: 66.49 | 2.20 | 0.349\\n- DVAE: Discrete VAE with ELBO loss: 70.84 | 0.315 | 0.286\\n- DI-VAE: 52.53 | 0.133 | 1.18e\\n- DI-VAE: Discrete VAE + BPR\\n- DD: RNNLM: 31.15\\n- DST Xp: 28.23 | 0.588 | 1.359\\n- For context-predicting Xn: 28.16\\n- DVST Xp: 30.36 | 0.007 | 0.081\\n- DST: Skip thought + Gumbel Softmax: 30.71\\n- DVST: Variational Skip Thought\\n- DEVST: 284\\n- Gles: L028\\n- Xn: 27.94\\n- DI-VST: Variational Skip Thought + BPR\\n\\nTable 1: Results for various discrete sentence representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "How large should the batch size be? When batch size N = 0\\n\\nA large batch size leads to more meaningful latent actions.\\n\\nSlowly increasing KL\\n\\nImprove PPL\\n\\n|(x,z) is not the final goal."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Interpolation in the Latent Space\\n\\nSo you can keep record of all the checks you write.\\n\\nSo you can get all kinds of information and credit cards.\\n\\nSo you can keep track of all the credit cards.\\n\\nSo you kind of look at the credit union.\\n\\nSo you know of all the credit cards.\\n\\nYeah because you know of all the credit cards.\\n\\nRight you know at least a lot of times.\\n\\nRight you know a lot of times.\\n\\nTable 9: Interpolating from the source sentence (top) to a target sentence (bottom) by sequentially setting the source latent code to the target code."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Differences between DI-VAE & DI-VST\\n\\nModel Sample utterances\\n\\nDI-VAE cluster utterances based on the DI-VAE | scheduling |\\n- sys: okay, scheduling a yoga activity with Tom for the 8th at 2pm.\\n- sys: okay, scheduling a meeting for 6 pm on Tuesday with your boss to go over the quarterly report.\\n\\nDI-VST cluster utterances based on the context: DI-VST | ask sched- |\\n- usr: find out if it's safe.\\n- usr: find nearest coffee shop.\\n- usr: when is my football activity and who is going with me?\\n- usr: tell me when my dentist appointment is?\\n- usr: how about other coffee?\\n- usr: 11 am please."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Interpreting Latent Actions\\n\\nM=3, K=5. The trained R will map any utterance into a, -a, -a. E.g. How are you?\\n- Automatic Evaluation on SW & DD\\n- Compare latent actions with Act Topic | Act Emotion human annotations.\\n\\nDI-VAE | 0.48 0.08 | 0.18 0.09\\nHomogeneity [Rosenberg and DI-VST | 0.33 0.13 0.34 0.12 Fitcheiberge, 2007].\\n\\nTable 3: Homogeneity results (bounded [0, 1]). The higher the more correlated."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "BD he \"P Institute\\n\\nInterpreting Latent Actions\\n\\nM=3, K=5. The trained R will map any utterance into a,-a,-a,. E.g. How are you?\\n- Human Evaluation on SMDe\\n- Expert look at 5 examples and give a name to the latent actions\\n\\nE DI-VAE | 85.6% 0.52 71.3%\\nDLVST | 93.3% 0.48 74.9%\\n\\n5 workers look at the expert name and the others.\\n\\nTable 4: Human evaluation results on judging the homogeneity of latent actions in SMD.\\nSelect the ones that match the expert name."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Predict Latent Action by the Policy Network.\\nProvide useful measure about the SMD;\\nAE-ED | 3.045 (51.5% sys 52.4% usr 50.5%) complexity of the domain.\\nST-ED | 1.695 (75.5% sys 82.1% usr 69.2%)\\nUsr > Sys & Chat > Task\\n- Predict latent actions from DI-VAE is harder\\nAE-ED | 4.47 (35.8%) 4.46 (31.68%)\\nST-ED | 3.89 (47.5%) 3.68 (33.2%)\\n- Two types of latent actions have their own pros & cons, which one's better is application dependent."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Interpretable Response Generations\\n\\nHer: Where does my friend live?\\n\\nExamples of interpretable dialog model | Action Generated Responses\\n- Give loc info\\n- Tom is at 753 University Ave, 8 miles away.\\n- Comfort Inn is at 7 miles away.\\n- Give user info\\n- Your home address is 5671 Barringer Street.\\n- Target response\\n- Your home is at 10 Ames Street.\\n- Give loc info\\n- Jill's house is 8 miles away at 247 Alta Mesa Ave.\\n- Interpretable meaning\\n- Jill lives at 347 Alta Mesa Ave."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Conclusions & Future Work\\n- An analysis of ELBO that explains the posterior collapse issue for Sentence VAE.\\n- DI-VAE and DI-VST for learning rich sentence latent representation and integration with encoder-decoders.\\n- Learn better context-based latent actions.\\n- Encode human knowledge into the learning process.\\n- Learn structured latent action space for complex domains.\\n- Evaluate dialog generation performance in human study."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Thank you!\\nCode & Data: github.com/snakeztc/NeuralDialog-LAED26"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Semantic Consistency of the Generation\\n\\nUse the recognition network as a classifier to predict the latent action z' based on the generated response x'.\\n\\nDomain | AE-ED +a | ST-ED +Lat\\n\\nReport accuracy by comparing z and z'.\\n\\nSMD 93.5% 94.8% | 91.9% 93.8%\\n\\nDD 88.4% 93.6% | 78.5% 86.1%\\n\\nWhat we learned?\\n\\nSW 84.7% 94.6% | 57.3% 61.3%\\n- DI-VAE has higher consistency than DI-VST\\n\\nTable 6: Results for attribute accuracy with and without attribute loss.\\n- DI-VST more than DI-VAE\\n- DI-VST is not directly helping generating x\\n- ST-ED doesn't work well on SW due to complex context pattern\\n- Spoken language and turn taking"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "What defines Interpretable Latent Actions\\n\\nDefinition: Latent action is a set of discrete variables that define the high-level attributes of an utterance (sentence) X.\\nLatent action is denoted as Z.\\n\\nTwo key properties:\\n- Z should capture salient sentence-level features about the response X.\\n- The meaning of latent symbols Z should be independent of the context C.\\n\\nWhy context-independent?\\n- If the meaning of Z depends on C, then it is often impossible to interpret Z since the possible space of C is huge!\\n\\nConclusion: context-independent semantics ensures each assignment of Z has the same meaning in all contexts."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 184,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "8 Introduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Trending of Social Media\\n\\nTOP SOCIAL PLATFORMS\\n\\n2,000 MONTHLY ACTIVE USERS (MAU)\\n\\n2017\\n\\nFacebook\\nYouTube\\nInstagram\\nTwitter\\nSnapchat\\nReddit\\nPinterest\\nTumblr\\nLinkedIn\\n\\n(https://blog.bufferapp.com/)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Veye Name Tagging\\n\\nWhat is Name Tagging?\\n\\nFrance defeated Croatia in World Cup final at Luzhniki Stadium.\\n\\nWhy important?\\n- Provide inputs to downstream applications\\n- Searching\\n- Recommendation\\n- Knowledge graph construction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Real Madrid midfielder Toni Kroos has revealed why he snubbed Cristiano Ronaldo's birthday party, following their humiliating derby defeat to Atletico Madrid.\\n\\nRonaldo received a lot of criticism for hosting his birthday party just hours after his side lost 4-0 to Atletico, and although Kroos understands it was difficult to cancel the party, he feels the timing wasn't right.\\n\\n\"I was invited to Cristiano Ronaldo's party.\\nI didn't go because I knew what could happen,\" he told German TV station ZDF.\\n\"It wasn't the moment to have a party after losing 4-0 against Atletico.\\nIt's also true that many people had been invited and cancelling it wouldn't have been easy.\"\\n\\nThe 25-year-old, who won the World Cup with Germany in Brazil, also insisted that recent media reports of a Real Madrid 'crisis' were thrown out of proportion.\\n\"We should take a step back and look at the whole picture in the face of what is being said.\\nWe have only lost the one game,\" Kroos added.\\n\\n\"I think that many teams would love to suffer a crisis like ours.\\nOf course we should be criticised if we play a bad game, as we did that day, without doubt.\"\\n\\nKroos joined Los Blancos for €30 million last summer and started all but two games for Real, assisting 12 goals and scoring one.\\n\\nDo you think Real Madrid will return to their form from before Christmas? Have your say in the comments section below."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Challenges of Name Tagging in Social Media\\n- Language Variations\\n\\nI luv juuustin\\n\\nBad segmentation\\n\\nAlison wonderland\\n\\nDiplox juaz\\n\\nB2B ayee\\n- Within word white spaces\\n\\nLETS GO LAKERS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "So eye e e e Utilization of Vision, 5ap esas aa a op\\n\"Sa ae © wer: Seed y\\nModern Baseball played an intimate surprise set at Shea\\n2015-2016 NBA Rookie of the Year\\nDifficult cases based on text only\\nSnap Inc. Z%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Task Definition: Multimedia Input: image-sentence pair\\n\\nColts Have 4th Best QB Situation in NFL with Andrew Luck #ColtStrong\\n\\nOutput: tagging results with Andrew Luck #ColtStrong on sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Overview"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Our work\\n- Sequence Labeling Model\\n- Bidirectional Long Short-Term Memory Networks (BLSTM)\\n- Word Representations\\n- Generations of Conditional Random Fields (CRF)\\n- Joint Tags Prediction\\n- State-of-the-art for News Articles (Lample et al.\\n2016)\\n- Visual Attention Model (Bahdanau et al.,\\n2014)\\n- Extract Visual Features from Image Regions that are Most Related to Accompanying Sentences\\n- Modulation Gate before CRFs\\n- Combine Word Representation with Visual Features based on their Relatedness"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Gx 12® Overall Framework\\n\\nMultimodal Input\\n- B-PER\\n- PER\\n- PER\\n- PER\\n\\nI encode 'Florence and the Machine'\\n- text surprises ill teen with\\n- private concert : CRF CRF CRF CRF CRF\\n- ile a 5\\n- Jt Ls oo ooi Lh\\n- mm ; 5 nein 5 ia a 26 rau) (a) (ee) eG)\\n\\nMeays I\" : a : = 1 > ; ' 1 Sa\"Es p> get ( TA (ie iF : ||] Oooo (sm) (sm) Backward\\n- (a eh : CEE LSTM Rea Cooa)\\n- Pag! Hl ;i Poe bb Me\\n- A | Il sceussca cere estesmnaeiiares lie mecssusovetinesmnascewensll (istw =!\\n\\nForward Attention Model\\n- LSTM1\\n- i: ct fe: Laa. : [| [ | [ | [|\\n\\nword\\n- Co\\n- CJ | | [| embedding T\\n- e charel\\n- 4 H H 4 representations\\n\\nCoo' Florence and the Machine_ Visual Attention Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Sequence Labeling\\n- BLSTM\\n- CRF (Lample et al.\\n2016)\\n\\nLet y = 0 (Wait, + Wh_i + f_h)\\nf_h = o(W_a p_t + W_h r_h_{t-1} + b_f)\\nl_t = (et\\n- = tanh(W_a e_t + W_h h_{t-1} + b_c)\\n\\nLet c = fr(oai1thogForward LSTM)\\nLSTM 1, LSTM 1, LSTM 1\\n\\nLet x, H, M, and h be the input, memory, and hidden state at time t respectively.\\nW_eis, W_his, W_r, W_h, W_a, W_h_e, W_r_o, and W are weight matrices.\\n\\nσ is the element-wise product function and σF is the element-wise sigmoid function."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Attention Model for Text Related Visual Features Localizations\\n\\nFlorence and the Machine\\n\\nOutputs from convolutional layer query\\n\\nV = {Vj, Vo, V3, ..., Vn}\\n\\noe = aj = tanh(Wr, aT + Wy, aVi + ba)\\n\\nAttention\\n\\ncalculate\\n\\nexp(e;)\\n\\nInput sentence\\n\\nInput image\\n\\nC = S aiV; Context Vector i = !"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Modulation Gate\\nQUOTATION\\nGaleUV visual contexts\\noutput Legend\\n\\n* Multiplication representations\\n* (a) activation function (sigmoid)\\n* activation function (tanh)\\n\\nVisual gate visual contexts\\n\\nBy = o(Wyh; ai Ove + by)\\n\\nVisual context Bw = o(Wwh; + Uwe + by)\\n\\nWord representation m = tanh(Wmh; + Umve + bm)\\n\\nVisually tuned word representation Wm = Bw: hi + By + m"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "iExperiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "- Dat t@ Snap Caption Dataset and Twitter DataSet (image + text)\\nTopics: Sports, concerts and other social events\\nNamed Entity Types: Person, Organization, Location and MISC\\n\\nTraining\\nDevelopment\\nTesting\\n\\nSnap\\nSentence 4,817 1,032 1,033\\nTokens 39,035 8,334 8,110\\n\\nTwitter\\nSentence 4,290 1,432 1,459\\nTokens 68,655 22,872 23,051\\n\\nSize of the dataset in numbers of sentences and tokens"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "- R ItSnap Captions Tweets Model ABLSTM-CRF 57.71 58.65 58.18 | 78.88 77.47 78.17\\n- Global Image Vector | 57.84 | 59.61 | 79.75 77.32 78.51\\n- Visual Attention | 65.53 | 57.03 | 60.98 | 80.81 | 77.36 | 79.05\\n- Gate controlled visual attention 66.67 57.84 61.94 | 81.62 79.90 80.75"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "- At time of coverage, Blake Thompson offers old and new experiences at first concert in four years.\\n- Blake Lively shows Trail Blazers 110-99 go up 2-0 in #Cannes2016.\\n- How Steve Jobs and Apple changed modern society.\\n- The defending champ Sandeul shirts at the ready for our hometown game today.\\n- ARMY put up a huge ad in Times Square for BTS's 4th Duet Song Festival anniversary!\\n- Snap Inc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "The nice image of [PER Kevin Love] and [PER Kyle Korver] during 1st half\\n\\n#NBAFinals #Cavs\\n\\nLooking forward to editing some SBU baseball shots from Saturday.\\n\\nPoor alignment between image and blur.\\n\\nImages wrong visual attention sentence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Future Work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "The Joint Multimodal Grounding and Name Tagging\\n\\nFine Grained Name Tagging\\n- San Francisco Giants\\n- New York Giants\\n- Belfast Giants\\n\\nGiants won the game."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Thank you. Questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 105,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Language Change\\n\\nLanguages change over time. Both an internal and external process. Fundamentally social.\\nIndividuals acquire language and transmit it to future generations. New variants propagate through populations.\\n\\nModelling Change\\n\\nMust model how the individual reacts to linguistic input and to the community."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Example\\n- The Cot-Caught Merge\\n\"cot\" is pronounced the same as \"caught\"\\n\\nMinimal pairs distinguished by /p/~/>/ become homophones.\\n- \"Don\" / \"Dawn\"\\n- \"collar\" / \"caller\"\\n\\nMerged:\\n- knotty / naughty\\n- pawned / ponded"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Example\\n- The Cot-Caught Merge\\n\"cot\" is pronounced the same as \"caught\"\\nPresent in many dialects of North American English:\\n- Eastern New England\\n- Western Pennsylvania\\n- Lower Midwest\\n- Canada (all)\\nMerged\\nUnmerged"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Example\\n- The Cot-Caught Mergere /p/ \"cot\" is pronounced the same as /ɔ/ \"caught\" and present in many dialects of North American English.\\n\\nEastern New England\\n\\nWestern Pennsylvania\\n\\nLower Midwest\\n\\nCanada (all)\\n\\nMerged at... Spreading into Rhode Island Unmerged (Johnson 2007)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Example\\n- The Cot-Caught Mergere: \"cot\" is pronounced the same as \"caught.\" Present in many dialects of North American English, it is found in Eastern New England, Western Pennsylvania, and the Lower Midwest.\\n\\nMerged: Spreading into Rhode Island\\nUnmerged: Families with non-merged parents and older siblings but merged younger siblings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Existing Frameworks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n3. Algebraic Frameworks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Three Classes of Framework\\n1. Swarm Frameworks\\n- Individual agents on a grid moving randomly and interacting (ABM)\\n- e.g., Harrison et al. 2002, Satterfield 2001, Schulze et al. 2008, Stanford & Kenny 2013"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Three Classes of Framework\\n1. Swarm Frameworks\\n- Individual agents on a grid moving randomly and interacting (ABM)\\n- e.g., Harrison et al. 2002, Satterfield 2001, Schulze et al. 2008, Stanford & Kenny 2013\\n- Bloomfield (1933)'s Principle of Density for free\\n- Diffusion is straightforward\\n- Not a lot of control over the network\\n- Thousands of degrees of freedom\\n- Should run many, many times\\n- Slow"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n- Speakers are nodes in a graph, edges are possibility of interaction\\n- e.g., Baxter et al. 2006, Baxter et al. 2009, Blythe & Croft 2012, Fagyal et al.\\n2010, Minett & Wang 2008, Kauhanen 2016"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n- Speakers are nodes in a graph, edges are possibility of interaction\\n- e.g., Baxter et al. 2006, Baxter et al. 2009, Blythe & Croft 2012, Fagyal et al.\\n2010, Minett & Wang 2008, Kauhanen 2016\\n- Much more control over network structure\\n- Easy to model concepts from the sociolinguistic literature (e.g., Milroy & Milroy)\\n- Nodes only interact with immediate neighbours -> slow and less realistic?\\n- Practically implemented as random interactions between neighbours -> same problem as #1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n3. Algebraic Frameworks\\n- Expected outcome of interactions is calculated analytically\\n- e.g., Abrams & Strogatz 2003, Baxter et al.\\n2006, Minett & Wang 2008, Niyogi & Berwick 1997, Yang 2000, Niyogi & Berwick 2009"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n3. Algebraic Frameworks\\n- Expected outcome of interactions is calculated analytically\\n- e.g., Abrams & Strogatz 2003, Baxter et al.\\n2006, Minett & Wang 2008, Niyogi & Berwick 1997, Yang 2000, Niyogi & Berwick 2009\\n- Closed-form solution rather than simulation -> faster and more direct\\n- No network structure! Always implemented over perfectly mixed populations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Three Classes of Frameworks\\n1. Swarm Frameworks\\n2. Network Frameworks\\n3. Algebraic Frameworks\\n\\nThis proliferation of \"boutique\" frameworks is a problem. An ad hoc framework risks \"overfitting\" the patterns.\\nComparison between frameworks is challenging."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Our Framework"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Best of All Worlds\\n\\nImpose density effects on a network structure and calculate the outcome of each iteration analytically"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Best of All Worlds\\n\\nImpose density effects on a network structure and calculate the outcome of each iteration analytically.\\n\\nSwarm+ Captures the Principle of Density\\n\\nNetwork+ Models key facts about social networks\\n\\nAlgebraic+ No random process in the core algorithm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "The Model Language change as a two-step loop\\n1. Propagation: Variants distribute through the network\\n2. Acquisition: Individuals internalize them"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Vocabulary: That which is transmitted\\n\\nLanguage\\n- Variant\\n- Sample\\n\\nGrammar = Variety = Latent Variable"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Binary Grammar Examples: {Merged grammar, Non-merged grammar}\\nL: Merged or non-merged instances of cot and caught words\\nG: {Dived-generating grammar, Dove-generating grammar}\\nL: Instances of the past tense of dive as dived or dove\\nG: {have+NEG = haven't got grammar, have+NEG = don't have grammar}\\nL: Instances of haven't got and instances of don't have"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "The Model Language change as a two-step loop\\n1. Propagation: L distributes through the network\\n2. Acquisition: Individuals react to L to create G"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "The Model\\n1. Propagation: L distributes through the network Generic. Not problem-specific."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Intuition behind Propagation Algorithm\\n\\nFor T iterations,\\n\\nFor the individual at each node\\n\\nBegin travelling;\\n\\nWhile travelling\\n\\nRandomly select outgoing edge by weight and follow it OR stop;\\n\\nIncrease chance of stopping next time;\\n\\nEnd\\n\\nInteract with the individual at the current node;\\n\\nEnd\\n\\nEnd"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Intuition behind Propagation Algorithm\\n\\nFor T iterations,\\n\\nFor the individual at each node\\n\\nNodes are not individuals.\\n\\nIndividuals \"stand on\" nodes\\n\\nEnd"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Intuition behind Propagation Algorithm\\n\\nBegin travelling; Individuals \"travel\" along edges and find someone to interact with"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Intuition behind Propagation Algorithm\\n\\nWhile travelling, individuals connected by randomly select outgoing edge shorter or higher weighted by weight and follow it or stop; paths are more likely to increase chance of stopping next time; interact.\\n\\nEnd interact with the individual at the current node;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Intuition behind Propagation Algorithm\\n\\nFor T iterations, flow the individual at each node travelling.\\nRather than simulating outgoing edge interactions in a loop, follow it or stop; calculate a closed-form solution at the current node."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "The Propagation Function E = G' a (1\\n- (1\\n-\\na) A)?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "The Propagation Function = T\\n- E = G' a(I\\n- (1\\n-\\na)\\nA)\\n\\nThe Linguistic Environment E is a g x n matrix: n individuals, g possible grammars.\\nFor each individual, the proportion of input drawn from each grammar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "The Propagation Function\\n- T\\n- E = G a(I\\n- (1\\n-\\na)\\nA)\\n\\nThe Linguistic Environment\\n\\nDistribution of Grammars of the previous generation\\n\\nG is a ranking matrix\\n\\nProportions by which each individual produces L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "The Propagation Function\\n- T\\n- E = G' a(l\\n- (1\\n-\\na)\\nA)\\n\\nThe Linguistic Environment\\n\\nDistribution of Grammars\\n\\nInteraction Probabilities\\n- A is an adjacency matrix\\n- The probabilities that nodes i, j interact given that the number of steps travelled declines by a geometric distribution and parameter from that distribution [0, 1]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "The Acquisition Function Problem-specific should take E as input and produce G as output.\\nIn the simplest case (neutral change), G = E. The following case study uses a variational learner."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Case Study\\n\\nSpread of the Cot-Caught Merger"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009) Learners will acquire the merged grammar iff more than ~17% of their environment is merged"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\n\\nLearners will acquire the merged grammar iff more than ~17% of their environment is merged.\\n- Accounts for mergers' tendency to spread (Labov 1994).\\n- 17% is close to the merged rate estimated in Johnson 2007."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\n\\nLearners will acquire the merged grammar if more than ~17% of their environment is merged.\\n- Accounts for mergers' tendency to spread (Labov 1994).\\n- 17% is close to the merged rate estimated in Johnson\\n2007.\\n- In a perfectly mixed model, population will immediately fix at 100%."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\nClaim: The merged grammar has a processing advantage"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\nClaim: The merged grammar has a processing advantage\\nClaim: Merged listeners have a lower rate of initial misinterpretation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\n\\nClaim: The merged grammar has a processing advantage\\n\\nClaim: Merged listeners have a lower rate of initial misinterpretation\\n\\nClaim: Only minimal pairs are relevant"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\nClaim: The merged grammar has a processing advantage.\\nClaim: Merged listeners have a lower rate of initial misinterpretation.\\nClaim: Only minimal pairs are relevant.\\nIf speaker A and listener B are both non-merged, B misunderstands A at the rate of mishearing one vowel for the other (A said /p/ but B heard /3/)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\nClaim: The merged grammar has a processing advantage\\nClaim: Merged listeners have a lower rate of initial misinterpretation\\nClaim: Only minimal pairs are relevant\\n\\nIf speaker A and listener B are both non-merged, B misunderstands A at the rate of mishearing one vowel for the other (A said /p/ but B heard /ɛ/).\\nIf A+ speaks to B-, B initially misunderstands whenever A+ says /p/ when B expects /ɾ/ and vice versa."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Model for Merger Acquisition (Yang\\n2009)\\n\\nClaim: The merged grammar has a processing advantage.\\n\\nClaim: Merged listeners have a lower rate of initial misinterpretation.\\n\\nClaim: Only minimal pairs are relevant.\\n\\nIf speaker A- and listener B- are both non-merged, B- misunderstands A- at the rate of mishearing one vowel for the other (A- said /p/ but B- heard /3/).\\n\\nIf A+ speaks to B-, B- initially misunderstands whenever A+ says /p/ when B- expects /3/ and vice-versa.\\n\\nIf A- or A+ speaks to B+, B+ cannot hear A-'s distinctions.\\n\\nInitial misunderstandings come down to lexical access\\n- if the intended meaning is not the most frequent meaning (Carmazza et al\\n2001) 43"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Variational Model for Merger Acquisition\\n\\nProbability of initial misunderstanding depends on minimal pair frequencies e mix merged (+) and non-merged (-) speakers in the environment."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Variational Model for Merger Acquisition\\n\\nProbability of initial misunderstanding depends on minimal pair frequencies.\\n\\nWe mix merged (+) and non-merged (-) speakers in the environment.\\n\\nUsing minimal pair frequencies estimated from SUBTLEXus and a variational learner, learners will acquire the merged grammar iff more than ~17% of their environment is merged (Yang 2009)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Acquisition Function\\n\\nTwo Grammars:\\n- Merged grammar g\\n- Non-merged grammar g\\n\\nPrecomputed Acquisition Function\\n\\nAn individual acquires 100% g, if >17% environment is generated by the g, else acquire 100% g."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Network Model: 100 clusters of 75 individuals each.\\nEach cluster is centralized randomly such that some community members are better (Merged) connected than others (Non-Merged)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Network Model: 100 clusters of 75 individuals each.\\nEach cluster is centralised randomly such that some community members are better connected than others.\\nOne cluster begins 100% merged (Massachusetts). The rest start 100% non-merged (Rhode Island)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Network Model\\n100 clusters of 75 individuals each.\\nEach cluster is centralised randomly such that MA some community members are better connected than others.\\nOne cluster begins 100% merged (Massachusetts). The rest start 100% non-merged (Rhode Island).\\nHalf the RI clusters are connected to the MA cluster (the \"Frontier\").\\nRI (Non-Merged) 49"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Network Model\\n\\n100 clusters of 75 individuals each.\\nEach cluster is centralized randomly such that some community members are better connected than others.\\nOne cluster begins 100% merged (Massachusetts). The rest start 100% non-merged (Rhode Island).\\nHalf the RI clusters are connected to the MA cluster (the \"Frontier\").\\nTwo members of each RI cluster are randomly connected to other clusters."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Merger Rate in Rhode Island over Time\\n\\nThe average merger rate across all 100 Rhode Island clusters follows an S-shape.\\nThe 99 RI community cluster curves are also S-shaped and staggered in time.\\n- Steep slopes = rapid change."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Conclusions\\n\\nThe Propagation Function removes the need to simulate interactions.\\n\\nIs widely applicable rather than made-to-order.\\n\\nThe Cot-Caught Application predicts behaviour consistent with the empirical data and with principles of language change."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "End Acknowledgements: Implementation: Charles Yang github.com/jkodner@5/NetworksAndLangChange Mitch Marcuse NDSEG Fellowship (US ARO)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Variational Learner (Yang\\n2000)\\n\\nLearners consider multiple grammars g, g simultaneously\\n\\nP(g,) = p, P(g.) = q, p t q = 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Variational Learner (Yang\\n2000) e Learners consider multiple\\nP(g,)=p, P(g,)=9, ptq=1 grammars g,, g, simultaneously\\n\\nEach g is penalised when it fails to parse an input."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Variational Learner (Yang\\n2000) Learners consider multiple\\n\\nP(g) = p, P(g) = q, p + q = 1; granularity 9, simultaneous\\n\\np(y |\\ng) parses input. Each g is penalized when it\\n\\np = (1\\n- y)p, if g fails to parse an input. The g with lower penalty\\n\\nlim P = C / (C +\\nC) probability has the advantage\\n\\nlim g =\\n- /(C + C)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Variational Learner (Yang\\n2000) learners consider multiple grammars g₁, g₂ simultaneously. Each g is penalized when it cannot parse an input.\\nThe g with lower penalty probability has the advantage.\\n\\nIf mature speakers adopt one grammar categorically, the one with smaller C wins."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Variational Model for Merger Acquisition\\n\\nPenalty probabilities depend on minimal pair frequencies, mixed merged (+) and non-merged (-) speakers in the environment."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Variational Model for Merger Acquisition\\n\\nPenalty probabilities depend on minimal pair frequencies, mix merged (+) and non-merged (-) speakers in the environment.\\n\\nm, n = frequencies of each member of a minimal pair.\\n\\nH = 2.m + n\\n\\n€ = probability of mishearing one vowel for the other\\n\\nC = (1/H)Z,min(m,\\nn) hearing the less freq word\\n\\nC = (1/H)2, [p, ((1-€)m + €n) mishearing + input + p(€_m + €n)] misinterpreting\\n- input"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Results\\n- Updating Connections\\nSocial connections change constantly\\n\\n100 PEVEEAE Benes Clusters\\nRewire the edges (recalculate\\nA) at every iteration\\n\\n80 VayYi\\n60 f Wy\\n40 A- SL\\n20 LE\\nLeaZing gay°\\n\\n20\\n40\\n60\\n80\\n100\\n120\\n\\nIteration #\\nCluster Merger Rates\\nRhode Island Avg\\n60"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Results\\n- Updating Connections\\n\\nSocial connections change constantly.\\n\\nRewire the edges (recalculate\\nA) at every iteration.\\n\\nThe outcome is similar, but clusters tipping points are temporally closer.\\n\\nNo cluster remains particularly well or poorly connected for long.\\n\\nCluster Merger Rates\\n\\nRhode Island Avg"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Fractional Updating\\n\\nThe merger spreads rapidly enough to 100 Percent Merged by distinguishing older and younger siblings.\\nOnly a fraction of the population is of the correct age at any moment.\\n\\nUpdate only 10% of random nodes at every iteration.\\n\\nIteration # Cluster Merger Rates Rhode Island Avg 62"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Fractional Updating\\n\\nThe merger spreads rapidly enough to distinguish older and younger siblings.\\nOnly a fraction of the population is of the correct age at any moment.\\n- Update only 10% of random nodes at every iteration.\\n\\nSimilar outcome with wider spread between cluster \"tipping points.\"\\n\\nThe simulation took about 5x as long because of the iteration.\\n- Cluster Merger Rates\\n- Rhode Island Avg 63"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Results\\n- Network Size\\n\\nTested our network size assumptions.\\n\\n100 People\\n\\nRepeat the experiment with 40 clusters of 18 individuals each.\\n\\n80 Fail\\n\\n60 / / i= Wi=\\n\\n15 ro | fl i/\\n\\n20 !\\n\\n10 20 30 40 50 60 70 80\\n\\nIteration #\\n\\nCluster Merger Rates\\n\\nRhode Island Avg 64"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Results\\n- Network Size\\n\\nTested our network size assumptions\\n100.\\n\\nRepeat the experiment with 40 clusters of 18 individuals each.\\n\\nQualitatively similar. The S-shape is less S-shaped.\\n\\nIndividual clusters show a step pattern.\\n\\nIteration #\\n\\nCluster Merger Rates\\n\\nRhode Island Avg 65"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Results\\n- Community Averages\\n\\nAt small network sizes, the community average 100 percent is more sensitive to random connections.\\n\\nRepeat the small-scale experiment 10 times.\\n\\nIterations:\\n- 3\\n- 80\\n- 605\\n- 40\\n- 20\\n- f\\n- YyhpSa\\n- 20\\n- 40\\n- 60\\n- 80\\n- 100\\n- 120\\n- 140\\n- 160\\n\\nTrial Averages: 66"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Results\\n- Community Averages\\n\\nAt small network sizes, the community average is 100 percent more sensitive to random connections.\\n\\nRepeat the small-scale experiment 10 times.\\n\\nThe slope is consistent in most simulations. A few simulations show aberrant behaviour.\\n\\n20  j  YyLifeSs  °° |00 20 40 60 80 100 120 140 160\\n\\nIteration # Trial Avgs67"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 190,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "semantic Role Labelling\\n\\nJohn surreptitiously ate the burrito at 2am."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Subject Manner Verb Object Time* Applied to improve state-of-the-art in NLP tasks such as Question Answering [Shen 2007] and Machine Translation [Liu and Gildea, 2010]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Subject Manner Verb Object Time* Applied to improve state-of-the-art in NLP tasks such as Question Answering [Shen 2007] and Machine Translation [Liu and Gildea, 2010]* Commonly used interface to facilitate Data Exploration and Information Extraction [Stanovsky et al 2018] [Chiticariu et al.\\n2018]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "S tic Role Label Subject Manner Verb Object Time\\n\\n* Applied to improve state-of-the-art in NLP tasks such as Question Answering [Shen 2007] and Machine Translation [Liu and Gildea, 2010]\\n\\n* Commonly used interface to facilitate Data Exploration and Information Extraction [Stanovsky et al 2018] [Chiticariu et al.\\n2018]\\n- Considerable interest in general-purpose SRL parsers"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "QA-SRL Subject Manner Verb Object Time a A, S se @ x § 5 e a, & e & @ < x . o @ . & e Ss Cm x < x @ Ss & re & x\\n- \" > oO oe \" ve wv es RG ss & vw ve [ He et al. 2015 ]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "QA-SRL\\nSubject Manner Verb Object Time\\n\\nQA-SRL 1.0\\nSmall dataset\\nTrained annotators\\nOnly explored sub-problems [He et al. 2015]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Goal A high-quality, large-scale parser for QA-SRL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "In 1950, Alan M.\\nTuring published \"Computing Machinery and Intelligence\" in Mind, in which he proposed that machines could be tested for intelligence using questions and answers.\\n\\nWhen was something published? In 1950\\n\\nWho published something? Alan M. Turing\\n\\nWhat was published? Computing Machinery and Intelligence\\n\\nWhere was something published?\\n\\nWhen did someone propose something? In 1950\\n\\nWho proposed something? Alan M. Turing\\n\\nWhat did someone propose? That machines could be tested for intelligence using questions and answers.\\n\\nWhat can something be tested for? Intelligence\\n\\nHow can something be tested? Using answers\\n\\nWhy was something being used? To test for intelligence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Challenges\\n1. Scale up QA-SRL data annotation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "1. Scale u A-SRL data annotation\\n\\nPierre Vinken, 61 years old, will join the board as a non-executive director Nov.\\n29.\\n\\nWho will join something?\\nPierre Vinken\\n\\n(Question about \"join\" (+5c)\\nWhen will someone join something?\\nWhere will someone join something?\\nWhy will someone join something?\\nHow\\nHow long\\nHow much\\n\\nwrt In 1668 the king of Portugal sent an elephant from the Kingdom of Congo to the king of France.\\n\\n[Invalid] Where did someone send something?\\n- from the kingdom of Congo to the king of France\\n[Invalid] Where did someone send something from?\\n- the kingdom of Congo\\n[Invalid] Who did someone send something to? --> the king of France\\n\\nBonus: 4c"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "1. Scale Up QA-SRL data annotation\\n\\nPierre Vinken, 61 years old, will join the board as a nonexecutive director Nov.\\n29.\\n\\nWho will join something?\\n\\nPierre Vinken (Question about \"join\" (+5c)\\n\\nWhat will someone join?\\n\\nWhen will someone join something?\\n\\nWhere will someone join something?\\n\\nWhy will someone join something?\\n\\nHow are datasets in play?\\n\\nHow much?\\n\\nIn 1668 the king of Portugal sent an elephant from the Kingdom of Congo to the king of France.\\n\\nWhere did someone send something?\\n- from the Kingdom of Congo to the king of France\\n\\nWhere did someone send something from?\\n- the Kingdom of Congo\\n\\nWho did someone send something to?\\n- the king of France\\n\\nBonus: 4c"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "2. Train a QA-SRL Parser\\n\\n\"What\" \"did\" \"someone\" \"past-tense\"\\n\\nWhere didn't someone appear to do something? In the video\\n\\nWho didn't appear to do something? The perpetrators\\n\\nWhen did someone appear?\\n\\n\"What\" \"did\" \"someone\" \"past-tense\"\\n\\nWhat didn't someone appear to do? To look at the camera.\\n\\nWhere didn't someone look at something? In the video\\n\\nWho didn't look? The perpetrators\\n\\nWhat didn't someone look at? The camera.\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "In 1668 the king of Portugal sent an elephant from the kingdom of Congo to the king of France."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Large-scale QA-SRL Parsing\\n1. Scale up QA-SRL data annotation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Easier at UCCA. Semantic Proto-roles Groningen Meaning Bank. Trained annotators [Basile et al. 2012] #0k sentences GWAP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "QA-SRL Questions: Wh Aux Subj Verb\\n- Obj Prep Obj2 What | did { someone | stem | someone | on : someone Where ; didn't something : past 'something: to 'something When | might : ' past participle : i by | Why | will | ' present | ' from |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "QA-SRL John surreptitiously ate the burrito at 2 am. Questions:\\n\\nWh Aux Subj Verb\\n- Obj Prep Obj2 What | did { someone | stem | someone | on: someone Where | didn't something: past 'something: to {something When | might: past participle | | by | Why | will | ' present | from |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "QA-SRL John surreptitiously ate the burrito at 2am.\\n\\nQuestions:\\n\\nWho ate something?\\n\\nWhat did someone stem on someone?\\n\\nWhere didn't something pass to something?\\n\\nWhen might past participle be?\\n\\nWhy will present from?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "QA-SRL\\n\\nJohn surreptitiously ate the burrito at 2am.\\n\\nQuestions:\\n- Who ate something?\\n- What did someone eat?\\n- Who stemmed on someone?\\n- Where didn't something past something, to something?\\n- When might past participle?\\n- Why will present from?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "John surreptitiously ate the burrito at 2am.\\n\\nQuestions:\\nAnswers:\\nWho ate something? John\\nWhat did someone eat? the burrito"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Annotation Pipeline\\n\\nJohn surreptitiously ate the burrito at 2 am.\\n\\nIdentify verbs with POS + heuristic detection."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "John surreptitiously ate the burrito at 2 am. Identify verbs with POS + heuristic detection.\\n\\nQuestion One:\\n\\nA worker writes as many QA-SRL questions as possible, annotates, and provides the answer."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "John surreptitiously ate the burrito at 2 am.\\n\\nPredicate Identify verbs with POS + heuristics detection.\\n\\nQuestion One worker writes as many QA-SRL questions as possible, annotation and provides the answer.\\n\\n2 workers are shown questions, validation provide answers or mark as invalid."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Question Annotation Efficiency Recall"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Question Attitude Efficiency\\n\\nPierre Vinken, 61 years old, will join the Autocomplete board as a non-executive director Nov.\\n29.\\n\\nWho will join by\\n\\nWho will join do\\n\\nWho will join doing\\n\\nWho will join for\\n\\nWho will join from\\n\\nWho will join in 7\\n\\nWho will join someone\\n\\nWho will join something\\n\\nWho will join somewhere\\n\\nWho will join to\\n\\nWho will join with"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Q tion A tat Pierre Vinken, 61 years old, will join the board as a non-executive director Nov.\\n29. Who will join something? e Recal | Pierre Vinken Auto SU g g e st When will someone join something?\\nWhere will someone join something? Why will someone join something? How How long How much y What E P Where"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Question Annotation Recall Autosuggest Financial Incentives"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Validation InterfIn 1668 the king of Portugal sent an elephant from the kingdom of Congo to the king of France.\\n\\nWhere did someone send something?\\n- from the kingdom of Congo to the king of France\\n\\nWhere did someone send something from?\\n- the kingdom of Congo\\n\\nWho did someone send something to?\\n- the king of France\\n\\nBonus: 4c"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "e annotator provides questions\\n2 annotators validate -> 3 spans / question\\nQuestion invalid if any annotator marks invalid\\nAdditional 3 validators for small dense dev and test set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Wikipedia | Wikinews | Science\\n\\nSentences\\n15,000 14,682 46,715\\n\\nVerbs\\n32,758 34,026 66,653\\n\\nQuestions\\n75,867 80,081 | 143,388\\n\\nValid Qs\\n67,146 70,555 | 127,455\\n\\n[He et al 2015] This work\\n\\n3000 sentences\\n75k sentences\\n\\nSeveral weeks\\n9 days\\n\\n~50c / verb\\n33c / verb\\n\\n2.43 questions / verb\\n2.05 questions / verb"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "In 1950 Alan M.\\nTuring published \"Computing machinery and intelligence\" in Mind, in which he proposed that machines could be tested for intelligence using questions and answers.\\n- Who published something? Alan M. Turing\\n- What was published? \"Computing machinery and intelligence\"\\n- When was something published? In 1950\\n- Where was something published? In Mind\\n- Who proposed something? Alan M. Turing\\n- What did someone propose? That machines could be tested for intelligence using questions and answers\\n- When did someone propose something? In 1950\\n- What did someone propose something in? \"Computing machinery and intelligence\"\\n- What can something be tested for? Intelligence\\n- How can something be tested? Using questions and answers\\n- Why was something being used? To test for intelligence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Large-scale QA-SRL Parsing\\n2. Train a QA-SRL Parser"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "QA-SRL Parser Span-Graph for SRL\\n\\nARGO ARG1\\n- AM-PRP (He et al\\n2018) Many tourists visit Disney to meet their favorite cartoon characters.\\n\\nARGO\\n- ARG1 BlO-based Encoding for SRL\\n\\nMany tourists visit Disney to meet their favorite cartoon characters. (He et al\\n2017) [predicate]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "QA-SRL Parser Span-Graph for SRL\\n\\nARGO = ARG1 AM-PRP(7 [He et al 2018] Many tourists\\nito [meet their favorite cartoon characters\\n| ARGO\\n- ARG1 a Bio-based Encoding for SRL\\n\\nMany tourists visit Disney to meet their favorite cartoon characters [He et al 2017] [predicate]\\nfo] [0] Many tourists visit Disney to meet their favorite cartoon characters [predicate]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "QA-SRL Parser Unlabeled Argument Detection\\n- Question Generation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "QA-SRL Parsing IL John surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "aQA-SRL Parsing\\n\\nJohn surreptitiously ate the burrito at 2pm.\\n\\nPredicated detection a . 1 8 iain"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "=QA-SRL Parsing\\n\\nJohn surreptitiously ate the burrito at 2pm.\\n\\nPredicate: 0 0 1 O 0 O 0\\nDetection: LI\\nArgument: oe h 99 oe ei, is | 99 oe h b ° 99 oe 2 99\\n\\nDetection: John surreptitiously the burrito at 2pm\\n\\nQuestion:\\n- \"Who ate something?\"\\n- \"How did someone eat?\"\\n- \"What did someone eat something?\"\\n- \"When did someone eat something?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "=QA-SRL Parsing\\n\\nJohn surreptitiously ate the burrito at 2pm\\n\\nPredicate Automatic Heuristic detection (same as data)\\n\\nI CKAr m nt \"e 99 oe oy ie 99 \"oe ° 99 \"e 99 derection\\n\\nJohn surreptitiously ate the burrito at 2pm\\n\\nQuestion\\n\\n\"Who ate something?\"\\n\\n\"How did someone eat?\"\\n\\n\"What did someone eat?\"\\n\\n\"When did someone eat something?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "= QA-SRL Parsing\\n\\nJohn surreptitiously ate the burrito at 2pm.\\n- cat: moeredica\\n- Automatic Heuristics\\n\\n0 0 10 0 00 detection (same as data)\\n\\n7 CK Argument\\n-\\n1. BIO Model\\n- detection\\n\\nNSpan\\n- Being\\n\\nQuestion:\\n- How did someone eat something?\\n- What did someone eat?\\n- When did someone eat something?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "aQA-SRL Parsing\\n\\nJohn surreptitiously ate the burrito at 2pm.\\n\\nPredicate Automatic Heuristics\\n- 0\\n- 0\\n- 10\\n- 0\\n- 0\\n- 0 detection (same as data)\\n\\n7 CK Argument\\n-\\n1. BIO Model\\n- « ws »\\n- wy\\n- \" .detection\\n\\nNSpannBeBeeniagel surreptitiously the burrito at 2pm.\\n1. Local question\\n- How did someone eat something?\\n- What did someone eat?\\n- When did someone eat something?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Argument Detection\\n- BIO Model\\n- Alternating Bi-LSTM with Highway Connections and Recurrent Dropout [He et al 2017]\\n- Input includes predicate indicator a a2 aaa a e=)}\\n- = )}\\n- = }\\n- \")}\\n- = }\\n- a}\\n- ms)1 I | | I 1 I (a John surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Argument Detection\\n- BIO Model\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Argument Detection\\n- Span Model\\n\\nForm a representation of every possible span\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Argument Detection\\n- Span Model\\n\\nForm a representation of every possible span\\n\"John surreptitiously\"\\na 2 Qa a as=)}- = )}- =}- \")}- = }- =}- ms)I I | | I I |(ro\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Argument Detection\\n- Span Model\\n\\nForm a representation of every possible span\\n\\n\"John\"\\n\\n\"John surreptitiously\"\\n\\na 2 ae aa e=)}- = )}- =}- \")}- = }- =}- ms)I I 1 1 I 1 I 1 I\\n\\nCe len len Ce CCS\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Argument Detection\\n- Span Model\\n\\nForm a representation of every possible span: \"John\", \"John surreptitiously\", \"Surreptitiously\", \"the burrito\", \"the burrito at\", \"at 2pm\".\\n\\nJohn surreptitiously ate the burrito at 2pm."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Argument Detection\\n- Span Model MLPs 0.9 0.1 0.2 0.8 0.1 0.75\\n\\n\"John\"\\n\\n\"John surreptitiously\"\\n\\n\"the burrito\"\\n\\n\"the burrito at\"\\n\\n\"at 2pm\"\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Argument Detection\\n- Span Model\\n\\nTunable Threshold mips O°? 0.1 a 0.2 b, 0.1 0.75 a \"John\" \"John surreptitiously\" \"the burrito\" \"the burrito at\" \"at 2pm\"\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Argument Detection: 4-layer Alternating Bi-LSTM with Highway Connections and Recurrent Dropout [He et al. 2017].\\nTrained to maximize log-likelihood."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Argument Detection\\n90M@ BIOS\\nnes os\\n85 (stems)\\n5 ceca\\n75 Foe\\n70 Exact Match\\nlOU >= 0.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Question G what did someone stem on someone where didn't something something to something when might past participle by why will present from"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Question G: Who 9 | 2 e ° Ei ii What did someone stem / someone; on: someone Where didn't something past something to something When might past participle by Why: will present from e Two models:\\n- Local slot prediction\\n- Sequential Model (LSTM)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Question Generation\\n- Local\\n\\nJohn surreptitiously ate the burrito at 2pm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Question Generation\\n- LocalTw"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Question Generation\\n- Local, TM meOS Zee \"the burrito\" TXQAR ARR Feo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Question Generation\\n- Sequential Cw"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Question Generation\\n- Sequential\\n\\n\"What\" \"did\" \"someone\" \"past-tense\"\\n\\n\"O\" \"O\" \"O\" \"the burrito\"\\n2 2 RB ARFeo) mm)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Evaluation Questions: Paraphrasing \"Who ate something?\" \"Wine stolen by?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Evaluation Questions: Paraphrasing \"Who ate something?\"\\n\\nGiven gold span: Slot-level accuracy: Exact Match (full question)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Question Generation\\nLocal 839 899\\nTM Sequential 1560\\nSlot Accuracy Exact Match"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Full Parsing Accuracy 44 WM Span + Local a TM Span + Sequential (t=0.5) 42 eae 41 40.64039 Exact match f-score (Span & Question)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Large-scale QA-SRL Parsing\\n3. Improve Recall"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "In 1950 Alan M.\\nTuring published \"Computing Machinery and Intelligence\" in Mind, in which he proposed that machines could be tested for intelligence using questions and answers.\\n- Who published something? Alan M. Turing\\n- What was published? \"Computing Machinery and Intelligence\"\\n- When was something published? In 1950\\n- Where was something published? In Mind\\n- Who proposed something? Alan M. Turing\\n- What did someone propose? That machines could be tested for intelligence using questions and answers\\n- When did someone propose something? In 1950\\n- What did someone propose something in? \"Computing Machinery and Intelligence\"\\n- What can something be tested for? Intelligence\\n- How can something be tested? Using questions and answers\\n- Why was something being used? Tested for intelligence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "In 1950 Alan M.\\nTuring published \"Computing Machinery and Intelligence\" in Mind, in which he proposed that machines could be tested for intelligence using questions and answers."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "In 1950 Alan M.\\nTuring published \"Computing Machinery and Intelligence\" in Mind, in which he proposed that machines could be tested for intelligence using questions and answers.\\n\\nWho published something? Alan M. Turing.\\n\\nWhy was something being used? Tested for intelligence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "John surreptitiously ate the burrito at 2pm.\\n\\nPredicate Identify verbs with POS + heuristics detection.\\n\\nQuestion One worker writes as many QA-SRL questions as possible, generates and provides the answer.\\n\\nWorkers are shown questions, validate, provide answers or mark as invalid."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "John surreptitiously ate the burrito at 2 pm.\\n\\nPredicated detection question generation.\\n\\nWorkers are shown questions. Validation provides answers or marks as invalid."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Data Expansione\\n\\nOvergenerate questions with low span threshold.\\n\\nValidate +46,715 valid QA-pairs (~11% after filtering)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "QO® Original 83.7 | 84.6 MM) Expanded 15601 : 50.5 ff 50.8 : x | Cr30 Span Detection (F-score) Question Generation (Exact Match) Full Parsing (Exact Match)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Evaluation of Exact Match for Question Generation is overly harsh.\\nParaphrasing: \"Who ate something?\" The missing questions penalize correct predictions missing from data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Validate model predictions with 6 annotators.\\n\\nGenerated question valid if 5 out of 6 annotators provided answers.\\n\\nPredicted span correct if exactly matches any annotator's answer."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "aHuman Eval\\n- Questions\\n\\n1.00 I SpanSeg + Expand 0.95\\n\\nrn Ml SpanSeq | a MI SpanLocal 0.90\\n\\n} a oeS 0.85\\n\\noS 5g = 0.80\\n\\n2% > 0.75\\n\\n0.70 0.65 0.60\\n\\n2000 4000 6000 8000 10000 12000 14000 16000 18000 # of Questions\\n\\nDecreasing\\n- t ---- >"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "Human Eval\\n- Questions\\n\\n1.00 I SpanSeg + Expand 0.95\\n\\nrn Ml SpanSeq\\n- a MI SpanLocal 0.90\\n- 0.85 82.64 SLg < 0.80 2S\\n- 0.75 0.70 0.65 0.60\\n\\n# of Questions\\n\\nDecreasing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "Human Eval\\n- Arguments 1.0 I SpanSeg + Expand be.\\nMl SpanSeq 0.9 AQ Mi SpanLocal SS > 77.7 F 0.8 jy = o | & 0.7 0.6 0.5 5000 10000 15000 20000 25000 30000 35000 # of Spans"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "Some of the vegetarians he met were members of the Theosophical Society, which had been founded in 1875 to further universal brotherhood, and which was devoted to the study of Buddhist and Hindu literature.\\n\\nSome of the vegetarians\\n\\nWhat did someone meet? members of the Theosophical Society\\n\\nWhat had been founded? the Theosophical Society\\n\\nWhen was something founded? in 1875\\n\\nWhy has something been founded? to further universal brotherhood\\n\\nWhat was devoted to something? members of the Theosophical Society\\n\\nWhat was something devoted to? the study of Buddhist and Hindu literature"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "The Large crowdsourced dataset of QA-SRL annotations\\n\\nHigh quality QA-SRL Parser\\n\\nTechniques for data expansion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "aaa aQA-SR L Bank 2 O Train Wikipedia Original Legend (help): Original | Expansion | Eval Dev Wikinews Expansion Valid only (= 4/6 > invalid, = 5/6 > valid)\\n\\nSearch sentences Submit Clear TQA Eval Answer provided by 1/2/3/4/5/6 annotators 783 / 5712 documents Ssentences Dev / TQA/ T1337\\n\\n(2011 Virginia Earthquake) / paragraph 0, sentence 0\\n\\n2011 Virginia\\n\\nIn August 2011, the eastern seaboard of the U.S. was rocked by a magnitude 5.8 earthquake.\\nWhile not huge, most of the residents had never experienced a quake and many didn't know what it was.\\nSome people thought the shaking might have been the result of a terrorist attack.\\n\\nBut if you went back in time to the late Paleozoic, you would find the region being uplifted into the ancestral Appalachian mountains as continent-continent convergence brought Pangaea together."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "Code and Data available at:\\nhttp://demo.qasrl.org\\n\\nAt ACL, Nicholas met other scientists and enjoyed discussing research with them.\\n\\nWhere did someone meet someone? At ACL\\nWho met someone? Nicholas\\nWho did someone meet? other scientists\\nWhere did someone enjoy something? At ACL\\nWho enjoyed something? Nicholas\\nWhat did someone enjoy? discussing research with them\\nWhere was someone discussing something? At ACL\\nWho was discussing something? Nicholas\\nWhat was someone discussing? research\\nWho was someone discussing something? them"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "Thank You! (ab\\n- Ae h by) S\\nhttp://qasrl.org/TW\\n\\nPAUL G. ALLEN SCHOOL\\nALLEN INSTITUTE OF COMPUTER SCIENCE & ENGINEERING\\nfor ARTIFICIAL INTELLIGENCE"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 379,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "DATA Stance Classification in Tweets\\n- Automatically identify users' positions on a pre-chosen target of interest (e.g., public issues) from text (Input)\\n- Target (given): Climate Change is Real Concern\\n- Tweet (given): We need to protect our islands and stop the destruction of coral reef.\\n- Stance label (to be predicted): Favour"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "a\"sis. DATACross-Target Stance Classification (er @* Generalise user stance on unseen targets\\n\\nTarget: A mining project in Australia (Destination)\\n\\nTweet: Environmentalists warn the $16 billion coal unlabelled facility will damage the Great Barrier Reef.\\n\\nStance: ???\\n- Apply classifiers trained on a source target to the destination target\\n\\nTarget: Climate Change is Real Concern (Source)\\n\\nTweet: We need to protect our islands and stop the destruction of coral reef.\\n\\nStance: Favour"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Our Approach: Basic Idea\\n\\nFor targets both related to a common domain, stance generalisation is possible via domain-specific information that reflects users' major concerns.\\n- Tweet: Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef.\\n- Tweet: We need to protect our islands and stop the destruction of coral reef.\\n\\nTarget: A mining project in Australia\\nTarget: Climate Change is Real Concern\\nStance: Favour\\nStance: Favour\\n\\nDestination target; Source target\\nDomain aspects: e.g., reef, destruction/damage (Implicit)\\nDomain: environment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "DATA Extraction of Domain Aspects\\n\\nKey properties of domain aspects:\\n\\nThey tend to be mentioned by multiple users in a corpus.\\n\\nThey tend to carry the core meaning of a stance-bearing tweet.\\n\\nIn our project dataset, 3,776 out of 41,805 tweets mentioned the aspect \"reef\":\\n\\n\"Why fund Adani #Coal Mine and destroy our Reef when there's so much sun in Queensland?\"\\n\\n\"And your massive polluting Carmichael mine will do its bit to kill Australia's great barrier reef?\"\\n\\n\"And thousands of jobs will be lost in reef tourism when Adani goes ahead.\"\\n\\n\"The coral reef crisis is actually a crisis of governance.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "a 1 DATA Self-Attention Neural Model: Overview\\n\\nClass label y (Favour/Against/Neither)\\nOutput Prediction Layer\\nAspect Attention Layer\\nContext Encoding\\nLayer Input\\nEmbedding Layer\\nTarget: Sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "a1 e 1 DATAA Self-Attention Neural Model: Overview\\n\\nClass label y (Favour/Against/Neither)\\n\\nOutput @ Prediction Layer\\n\\nAspect @ Attention\\n\\nAttention Aspect-aware\\n\\nContest target-dependent @ Encoding sentence encoding\\n\\nLayer Input P\\n\\nPreliminary modelling\\n\\nEmbedding\\n- The simplest case: source-side only model\\nTarget T Sentence P"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Context Encoding Layer: Conditional sentence encoding [Augenstein et al., 2016]: Learn a target-dependent representation for the sentence.\\n1) esH = [6.91.4 B.1] Target-conditioned sentence encoding\\n\\nPrediction Layer: Aspect Bi-LSTM\\n- Bi-LSTM\\n- Attention\\n\\nContext: x = T = 2 P = 1s + a2 Zeep p:4 ad | Target Sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "TATA Aspect Attention Layer\\n\\nExtract domain aspect words using self-attention weighting.\\n\\nAttention weights on word positions: the importance in carrying the sentence meaning. \"We need to protect ...\\ndestruction of coral reef.\"\\n\\nCompatibility function: similarity i we o(Wi ky + bi) + b.\\n\\nPrediction Layer\\n\\nAttention Context: weight 0.01 0.2 0.01 0.01 0.4 0.4\\n\\nDomain-aspect encoding vector Layer\\n\\nTarget T Sentence P"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "DATA Experiments\\n@NZDatasets\\n- SemEval 2016 Task 6: Twitter stance detection\\n\\nTarget\\n% Favor\\n% Against\\n% Neither\\n# Total\\n\\nClimate Change is Concern\\nCC 59.4\\n46\\n36.0\\n564\\n\\nFeminist Movement\\nFM 28.2\\n53.8\\n18.0\\n949\\n\\nHillary Clinton\\nHC 16.6\\n57.4\\n26.0\\n984\\n\\nLegalization of Abortion\\nLA 17.9\\n58.3\\n23.8\\n933\\n\\nDonald Trump\\nDT 20.9\\n42.3\\n36.8\\n707\\n\\nDomains and targets\\n1. Women's Rights: Feminist Movement <> Legalization of Abortion\\n2. American Politics: Hillary Clinton <> Donald Trump"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "a Classificati f ler | assitication performance BINN\\n\\n7 Domain Target BiLSTM_BiCond\\n- CrossNet\\n\\nAF = 3.0%\\n\\n-> In-target performance (F1-score)\\n\\nWomen's FM  5142.6  53.7\\n69)\\n\\nLsgaortl Extracted domain aspects Rights LA  59.4 (6.4)  61.9 (6.3)  61.8 (4.7)\\n\\nbenefit\\n\\ncross-target task\\n\\nmore American HC  55.5 (4.7)  56.0 (3.1)  60.0 (3.3)\\n\\nPolitics DT  57.9 (6.0)  59.6 (5.8)  60.2 (5.1)\\n\\n\"*] Better performance\\n\\nAF = 6.6%\\n\\n-> Cross-target performance (F1-score) on both tasks across almost all targets\\n\\nWomen's FM\\n- LA  40.1 (2.3)  40.3 (2.2)  44.2 (1.3)\\n\\nt? = Rights LAS FM  37.9 (2.9)  39.2 (1.5)  43.1 (1.3)\\n\\n\"#\\n\\nAmerican HC\\n- DT  43.3 (2.4)  44.2 (3.2)  46.1 (3.7)\\n\\n*FM: Feminist Movement\\n\\nPolitics DT\\n- HC  40.1 (2.6)  40.8 (2.2)  41.8 (3.2)\\n\\nLA: Legalization of Abortion (Standard deviation in parentheses)\\n\\nHC: Hillary Clinton\\n\\n¥ (#) Improvements over BILSTM (BiCond) at p < .05 with paired t-test\\n\\nDT: Donald Trump\\n\\nCC: Climate Change is Concern"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "aVi lisati f attention visualisation\\n\\nThe heatmap of the attention weights assigned to some tweet examples\\n\\nID  Target Tweet\\n- Women's FMLA Abortion has nothing to do with feminism. It's about the BABY's body, not yours. (A) rights\\n- All humans, male and female, should have equal political, economic and social rights. Equality. (F) American\\n- Trump's presidential @Reamis is about as real as Kim Jong-un's unicorns. (A) politics\\n- Maybe a woman should be RRSISHE. (F)\\n- still will destroy the reef. It is criminal that QLD federal govts are promoting it. (A) Environments\\n- who are trying to change our laws, 'forgot' to tell us about their CEO's environmental disaster! (A)\\n\\nFM: Feminist Movement\\nA: Against\\nLA: Legalization of Abortion\\nF: Favour\\nHC: Hillary Clinton\\n\\nWords central to expressing stances are highlighted by our model!\\nCC: Climate Change is Concern\\nAMP: Australian mining project"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "aVi lisati f attention visualisation OT attention BINN\\n\\nThe heatmap of the attention weights assigned to some tweet examples\\n\\nID Target Tweet\\n\\nWomen's FMLA Abortion has nothing to do with the BABY's body, not yours\\n- rights\\n\\nLA-FM All humans, male and female, should have equal political, economic and social rights\\n\\nHC-DT Trump's presidential campaign is about as real as Kim Jong-un's unicorns.\\n\\nDT-HC Maybe a woman should be president.\\n\\nCC-AMP [N] still will destroy the reef. It is criminal that QLD federal governments are promoting it.\\n\\nCC-AMP [N], who are trying to change our laws, 'forgot' to tell us about their CEO's environmental disaster!\\n\\n(A) FM: Feminist Movement\\n\\nA: Against\\n\\nLA: Legalization of Abortion\\n\\nF: Favor\\n\\nHC: Hillary Clinton\\n\\nWords central to expressing stances are highlighted by our model!\\n\\nCC: Climate Change is Concern\\n\\nAMP: Australian mining project"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "a Visualisation of attention\\n\\nThe heatmap of the attention weights assigned to some tweet examples\\n\\nID Target Tweet\\n\\nWomen's\\n1 FM\\n- LA_ Abortion has nothing to do with feminism. It's about the BABY's body, not yours. (A) rights\\n\\n2 LA\\n- FM_ All humans, male and female, should have equal political, economic and social rights. Equality. (F) American\\n\\n3 HC\\n- DT_ Trump's presidential (@reams) about as real as Kim Jong-un's unicorns. (A) politics\\n\\n4 DT\\n- HC_ Maybe a woman should be ER\").\\n\\n5 CC\\n- AMP [N] still will destroy the reef. It is criminal that QLD federal govts are promoting it. (A) Environment\\n\\n6 CC\\n- AMP [N], who are trying to change our laws, 'forgot' to tell us about their CEO's environmental disaster! (A)\\n\\nFM: Feminist Movement\\nA: Against\\nLA: Legalization of Abortion.\\nF: Favour\\nHC: Hillary Clinton\\n\\nWords central to expressing stances are highlighted by our model!\\n\\nDT: Donald Trump\\nCC: Climate Change is Concern\\nAMP: Australian mining project"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusion\\n- A self-attention model which can attend to high-level information about the domain for stance generalisation.\\n- Domain aspect words are useful to determine the user stance.\\n- Future directions:\\n- Incorporation of target divergence into our modelling.\\n- Learning aspects from multiple sources (e.g., environment, community, and economic aspects for \"mining projects\")."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 16,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Core Dimensions of Meaning.\\n\\nInfluential factor analysis studies (Osgood et al., 1957; Russell, 1980,\\n2003) have shown that the three most important, largely independent dimensions of word meaning are:\\n- valence (V): positive/pleasure\\n- negative/displeasure\\n- arousal (A): active/stimulated\\n- sluggish/bored\\n- dominance (D): powerful/strong\\n- powerless/weak\\n\\nThus, when comparing the meanings of two words, we can compare their V, A, D scores. For example:\\n- banquet indicates more positiveness than funeral\\n- nervous indicates more arousal than lazy\\n- queen indicates more dominance than delicate\\n\\nBB Scuncl' Canada' recherches Canada W @SaifMMohammad Canadii"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Xe fine-grained: This work: Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words BM cotnci Canada recherches Conada W @SaifMMohammad Canada"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Motivation\\n\\nHuman annotations of words for VAD\\n\\nFor use by automatic systems:\\n- predicting VAD of words\\n- predicting sentiment and emotions of sentences, tweets, etc.\\n- detecting stance, personality traits, well-being, cyber-bullying, etc.\\n\\nTo draw inferences about people:\\n- to understand how we (or different groups of people) use language to express meaning and emotions\\n- analyze text written/spoken by different groups of people\\n- analyze VAD judgments of different groups of people"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Toe6 a Related Work: Existing VAD Lexicons\\n- Bidsee Affective Norms of English Words (ANEW) (Bradley and Lang,\\n1999)\\n- ~1,000 words, 9-point rating scale\\n- Warriner et al. Norms (Warriner et al.\\n2013)\\n- 14,000 words, 9-point rating scale\\n\\nSmall number of VAD lexicons in non-English languages as well:\\n- Moors et al. (2013) for Dutch\\n- Vo et al. (2009) for German\\n- Redondo et al. (2007) for Spanish rating scale"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "I'VE IMPROVED PEEL RE PAIN SCALE.\\n1 IT MIGHT BE AN ITCH\\n2 JUST NEED A BANDAID\\n3 CANT STOP CRYING\\n4 CANT MOVE\\n5 IT HURTS SO BAD.\\n\\nRating scales:\\n6 MAULED BY A BEAR\\n7 BEES?\\n8 UNCONSCIOUS\\n\\nSource: imgur"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Yetewedede [HAS ONLY ONE REVIEW]\\n\\nYeietetedt EXCELLENT teiewrtesy OK wired\\n\\nRating scales: wiki twietink annewiewetb ekeker akssource: xkcd\\n\\nBe Gotnci Canada\" fecherenes Canada WV @SaifMMohammad Canadit"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Ney. Rating scales:\\n\\nACL-2018 Reviewing Scale\\n\\nOverall Score (1-6)\\n\\n6 = Transformative: This paper is likely to change our field.\\nGive this score exceptionally for papers worth best paper consideration.\\n\\n5 = Exciting: The work presented in this submission includes original, creative contributions, the methods are solid, and the paper is well written.\\n\\n4 = Interesting: The work described in this submission is original and basically sound, but there are a few problems with the method or paper.\\n\\n3 = Uninspiring: The work in this submission lacks creativity, originality, or insights. I'm ambivalent about this one.\\n\\n2 = Borderline: This submission has some merits but there are significant issues with respect to originality, soundness, replicability or substance, readability, etc.\\n\\n1 = Poor: I cannot find any reason for this submission to be accepted."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "K Likert Item (Likert\\n1932)\\n1. The website has a user-friendly interface.\\n\\nRating scales: 0\\n- 3\\n\\nstrongly agree neutral disagree strongly disagree\\n\\nsource: Wikimedia Commons\\n\\nNote: A Likert scale is the sum of responses on several Likert items."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Problems with rating scales:\\n- fixed granularity:\\n- difficult to maintain consistency across annotators:\\n- difficult for an annotator to be self-consistent\\n- scale region bias\\n\\nBe Gotnci Canada\\n\"fecherenes Canada\"\\nWV @SaifMMohammad\\nCanada"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Comparative Annotations and Paired Comparisons (Thurstone, 1927; David, 1963):\\n\\nIf X is the property of interest (positive, useful, etc.), give two terms and ask which is more or less.\\n\\nCognitive load helps with consistency issues and requires a large number of annotations, order N2, where N is the number of terms to be annotated."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Best-Worst Scaling (BWS) (Louviere & Woodworth, 1990). The annotator is presented with four words (say, A, B, C, and\\nD) and asked:\\n- which word is associated with the most/highest X (property of interest, say valence)\\n- which word is associated with the least/lowest X\\n\\nBy answering just these two questions, five out of the six inequalities are known. For example:\\n- If A: highest valence and D: lowest valence, then we know: A > B, A > C, A > D, B > D, C > D."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "a Best-Worst Scaling (Louviere & Woodworth,\\n1990)\\n\\nEach of these BWS questions can be presented to multiple annotators.\\n\\nWe can obtain real-valued scores for all the terms using a simple counting method (Orme,\\n2009)\\n\\nscore(w) = (#best(w)\\n- #worst(w)) / fannotations(w)\\n\\nThe scores range from:\\n\\n-1 (least\\nX) X = property of interest, say valence\\n\\nto 1 (most X)° the scores can then be used to rank all the terms\\n\\nBM Cainer cinada\" recherenos Canada W @SaifMMohammad Canadi 15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "a Best-Worst Scaling (Louviere & Woodworth,\\n1990) preserves the comparative nature, keeps the number of annotations down to about 2, leads to more reliable, less biased, more discriminating annotations (Kiritchenko and Mohammad, 2017, Cohen, 2003)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Creating the Valence, Arousal, and Dominance Lexicon"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "We wanted to include:\\n- Term Selection\\n- Only used English terms,\\n- Terms common in tweets\\n- Terms that denotate or connotate emotions\\n\\nSelected:\\n- All terms in the NRC Emotion Lexicon (Mohammad and Turney, 2013): ~14,000 labels indicate association with eight basic emotions: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust (Plutchik, 1980).\\n- Includes terms that occur frequently in the Google n-gram corpus.\\n- All terms in ANEW (Bradley and Lang, 1999): ~1000.\\n- All terms in the Warriner et al. lexicon (2013): ~14,000.\\n- Words from the Roget's Thesaurus categories corresponding to the eight basic Plutchik emotions: ~520.\\n- High-frequency content terms, including emoticons, from the Hashtag Emotion Corpus (a tweets corpus) (Mohammad, 2012): ~1000.\\n\\nTotal: 20,007 terms"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "7 Best-Worst Questionnaires\\n01.\\nWhich of the four words below is associated with the MOST happiness / pleasure / positiveness / satisfaction / contentedness / hopefulness OR LEAST unhappiness / annoyance / negativeness / dissatisfaction / melancholy / despair?\\n(Four words listed as options)\\n02.\\nWhich of the four words below is associated with the LEAST happiness / pleasure / positiveness / satisfaction / contentedness / hopefulness OR MOST unhappiness / annoyance / negativeness / dissatisfaction / melancholy / despair?\\n(Four words listed as options)\\n\\nSimilar questions for arousal and dominance.\\n\\nThis study was approved by the NRC Research Ethics Board (NRC-REB) under protocol number 2017-98.\\nREB review seeks to ensure that research projects involving humans as participants meet Canadian standards of ethics."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Crowdsourcing and Quality Control\\n\\nAbout 2% of the data was annotated internally beforehand (by the author).\\nThese gold questions are interspersed with other questions.\\nIf one gets a gold question wrong, they are immediately notified of it. Feedback to improve task understanding.\\nIf one's accuracy on the gold questions falls below 80%, they are refused further annotation.\\nAll of their annotations are discarded.\\n\\nMechanism to avoid malicious or random annotations.\\n- Be succinct.\\n- Come prepared.\\n- @SaifMMohammad.\\n- Canadian."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "ee Valence, Arousal, and Dominance Annotations (with BWS)\\n\\nLocation of Annotation\\n\\n#Best-Worst Dataset\\n\\n#words\\n\\nAnnotators\\n\\nItem\\n\\n#Items\\n\\n#Annotators\\n\\nMAI\\n\\n#Q/Item\\n\\nAnnotations\\n\\nvalence\\n\\n20,007\\n\\nworldwide\\n\\n4-tuple of words\\n\\n40,014\\n\\n1,020\\n\\n6\\n\\n2\\n\\n243,295\\n\\narousal\\n\\n20,007\\n\\nworldwide\\n\\n4-tuple of words\\n\\n40,014\\n\\n1,081\\n\\n6\\n\\n2\\n\\n258,620\\n\\ndominance\\n\\n20,007\\n\\nworldwide\\n\\n4-tuple of words\\n\\n40,014\\n\\n965\\n\\n6\\n\\n2\\n\\n276,170\\n\\nTotal\\n\\n778,085"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ee Valence, Arousal, and Dominance Annotations (with BWS)\\n\\nLocation of Annotation\\n#Best-Worst Dataset\\n#words\\nAnnotators\\nItem\\n#Items\\n#Annotators\\nMAI\\n#Q/Item\\nAnnotations\\n\\nvalence\\n20,007\\nworldwide\\n4-tuple of words\\n40,014\\n1,020\\n6\\n2\\n243,295\\n\\narousal\\n20,007\\nworldwide\\n4-tuple of words\\n40,014\\n1,081\\n6\\n2\\n258,620\\n\\ndominance\\n20,007\\nworldwide\\n4-tuple of words\\n40,014\\n965\\n6\\n2\\n276,170\\n\\nTotal\\n778,085\\n2N\\n4-tuples\\n\\nBE coirci 'Citada' fecheretos\\nCanada\\nW @SaifMMohammad\\nCanadi\\n22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Valence, Arousal, and Dominance Annotations (with BWS)\\n\\nLocation of Annotation\\n\\n#Best-Worst Dataset\\n\\n#Words\\n\\nAnnotators\\n\\nItem\\n\\n#Items\\n\\n#Annotators\\n\\nMAI\\n\\n#Q/Item\\n\\nAnnotations\\n\\nvalence\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n1,020\\n6\\n2\\n243,295\\n\\narousal\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n1,081\\n6\\n2\\n258,620\\n\\ndominance\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n965\\n6\\n2\\n276,170\\n\\nTotal\\n778,085\\n~1000 annotators for each task"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "ee Valence, Arousal, and Dominance Annotations (with BWS)\\n\\nLocation of Annotation\\n\\n#Best-Worst Dataset\\n\\n#words Annotators\\n\\nItem\\n\\n#Items\\n\\n#Annotators\\n\\nMAI\\n\\n#Q/Item\\n\\nAnnotations\\n\\nvalence\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n1,020\\n6\\n2\\n243,295\\n\\narousal\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n1,081\\n6\\n2\\n258,620\\n\\ndominance\\n20,007 worldwide\\n4-tuple of words\\n40,014\\n965\\n6\\n2\\n276,170\\n\\nTotal\\n778,085 minimum and median annotations per 4-tuple\\n\\nBM cotnci Canada\" recherches Conada W @SaifMMohammad Canadi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "he Example Entries in the VAD Lexicon\\n\\nDimension      Word                Score\\nvalence        love                1.000\\ntoxic               0.008\\nhappy               1.000\\nnightmare           0.005\\nhappily             1.000\\nshit                0.000\\n\\narousal        abduction           0.990\\nmellow              0.069\\nexorcism            0.980\\nsiesta              0.046\\nhomicide            0.973\\nnapping             0.046\\n\\ndominance      powerful            0.991\\nempty               0.081\\nleadership          0.983\\nfrail               0.069\\nsuccess             0.981\\nweak                0.045\\n\\nScores are in the range 0 (lowest V/A/D) to 1 (highest V/A/D)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "il Reliability (Reproducibility) of Annotations\\n\\nAverage split-half reliability (SHR): a commonly used approach to determine consistency (Kuder and Richardson, 1937; Cronbach, 1946).\\nHalf the annotations repeat 100 times, average ranking term compare two rankings.\\n\\nPearson correlation: -1 (most inversely correlated) to 1 (most correlated)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "The Split-Half Reliability Scores for VAD Annotations\\n\\nWarriner et al. (2013)\\n\\n13,915\\n\\n20 per term\\n\\n0.91\\n\\n0.79\\n\\n0.77\\n\\nMarkedly lower SHR for A and D.\\nThe dominance ratings seem especially problematic since the Warriner V-D correlation is 0.71."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "il Split-Half Reliability Scores for VAD Annotations\\n\\nWarriner et al. (2013) = 13,915 per term\\nOurs (Warriner terms) = 13,915 per tuple\\n0.95 0.91 0.91\\nAWE Sieber"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "V Split-Half Reliability Scores for VAD Annotations.\\n\\nWarriner et al. (2013)\\n13,915 20 per term 0.91 0.79 0.77\\n\\nOurs (Warriner terms)\\n13,915 6 per tuple 0.95 0.91 0.91\\n\\nOurs (all terms)\\n20,007 6 per tuple 0.95 0.90 0.90\\n\\nThese SHR scores show for the first time that highly reliable fine-grained ratings can be obtained for valence, arousal, and dominance.\\nAlso, our V-D correlation is 0.48."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "io NRC VAD Lexicon and the Warriner et al. Lexicon: How Different are the Scores?\\n\\nCS Pearson correlations r= Annotations | VTA | Ours-Warriner 0.81 0.62 0.33 (for overlapping terms).\\n\\nThe especially low correlations for dominance and arousal indicate that our lexicon has substantially different scores and rankings of terms."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Done: Create the large and reliable VAD lexicon\\nOn to: 33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Shared Understanding of VAD: Within and Across Demographic Groups\\n\\nHuman cognition and behaviour are impacted by evolutionary and socio-cultural factors.\\nThese factors impact different groups of people differently. Consider gender.\\nMen, women, and other genders are substantially more alike than different.\\nHowever, they have encountered different socio-cultural influences.\\nOften these disparities have been a means to exert unequal status and asymmetric power relations.\\n\\nGender studies examine both the overt and subtle impacts of these socio-cultural influences, ways to mitigate the inequity, and how different genders perceive and use language."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "C° Demographic Survey\\n\\nAnnotators could optionally respond to a separate survey asking for their demographic information: age, gender, country, personality traits.\\nWe asked how they viewed themselves across the big five personality traits (Barrick and Mount, 1991).\\n991 people (55% of the VAD annotators) chose to provide their demographic information.\\nBM coincidentally occurs in Canada with @SaifMMohammad Canada."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "For each demographic attribute, we partitioned the annotators into two groups: male (m) and female (f); those 18 to 35 (<35) and those over 35 (>35)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "hgfe .mat Experimentce\\n\\nFor each demographic attribute, we partitioned the annotators into two groups:\\n- male (m) and female (f)\\n- those 18 to 35 (young) and those over 35 (grownups)\\n\\nGender\\nf 37\\nm 63\\n\\nAge\\n<35 70\\n>35 30\\n\\nagreeable (Ag) and Disagreeable (Di)\\nPersonality\\nAg 31\\nDi 52\\n\\nextrovert (Ex) and introvert (In)\\nEx 40\\nIn 60\\n\\nOp 50\\nCl 50\\n\\nCalculated the extent to which people within the same group agreed with each other on the VAD annotations; whether the differences in average agreements in each group are significant: chi-square test for independence and significance level of 0.05.\\n\\nBM Cainer\\nCanada\\nW @SaifMMohammad\\nCanada 37"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "hog -phe Differences in Average Agreements: Gender Sub-group with Significantly Higher Agreement F vs.\\nM = female M = male BoR Scocrdoen Cormaenkss resallichentnas Canadi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "a Differences in Average Agreements: Gender\\n\\n74CS Sub-group with Significantly Higher Agreement\\n\\nF-F vs. M-M\\n\\nM = female\\nM = male\\n\\nWomen have a higher shared understanding of the degree of arousal of words.\\n\\nMen have a higher shared understanding of the dominance and valence of words."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "as:\\n\\nThe Differences in Average Agreements: Age\\nSub-group with Significantly Higher Agreement\\n\\nyoung vs grownups\\n\\ncoirci citada \"fecheretos Canada W @SaifMMohammad Canada 40"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "pou ica ' A O7 Differences in Average Agreements: Age soiloS Sub-group with Significantly Higher Agreement\\n- Young vs Grownups\\n\\nThe young have a higher shared understanding of the dominance of words.\\nThe grownups have a higher shared understanding of valence and arousal of words.\\nAWE Sieber' oti W @SailM Mohammad Canadi 4!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "7 Differences in Average Agreements: Big 5 Traits\\n\\nSub-group with Significantly Higher Agreements\\n\\nAg-Ag vs. Di-Di\\n\\nAg-Ag Di-Di\\n\\nCo-Co vs. Ea-Ea\\n\\nCo-Co Co-Co\\n\\nEx-Ex vs. In-In\\n\\nEx-Ex Ex-Ex Ex-Ex Ex-Ex\\n\\nNe-Ne vs. Se-Se\\n\\nSe-Se\\n- Se-Se\\n\\nOp-Op vs. Cl-Cl\\n\\nOp-Op Op-Op Op-Op\\n\\nAg = Agreeableness (friendly and compassionate)\\nDi = Disagreeableness (careful in whom to trust, argumentative)\\nCo = Conscientiousness (efficient and organized)\\nEa = Easygoing (easy-going and carefree)\\nEx = Extrovert (outgoing, energetic, seek the company of others)\\nIn = Introvert (solitary, reserved, meeting many people causes anxiety)\\nNe = Neurotic (often feel anger, anxiety, depression, and vulnerability)\\nSe = Secure (rarely feel anger, anxiety, depression, and vulnerability)\\nOp = Open to experiences (inventive and curious; seek out new experiences)\\nCl = Closed to experiences (consistent and cautious; anxious about new experiences)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Done: Create the large and reliable VAD lexicon,\\nAnalyze VAD judgments of different groups of people.\\n\\nOn to:\\nApplications and Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Selected Applications and Future Work\\n- Source of features for systems in sentiment, emotion, and other affect-related tasks.\\n- Useful to create emotion-aware word embeddings and emotion-aware sentence representations.\\n- Source of gold (reference) scores, to evaluate automatic methods of determining V, A, and D.\\n- Study the interplay between the basic emotion model and the VAD model of emotions (Mohammad, 2018: LREC paper).\\n- Companion lexicon: NRC Emotion Intensity Lexicon provides real-valued affect intensity scores for ~6000 words with four basic emotions (anger, fear, sadness, joy).\\n- Study the role of high VAD words in high emotion intensity sentences, tweets, snippets from literature."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Summary\\n- Created the NRC Valence, Arousal, and Dominance Lexicon:\\n- has entries for about 20,000 English words\\n- has fine-grained real-valued scores for V, A, and D (core dimensions of meaning)\\n- showed that the annotations are reliable (high split-half reliability scores)\\n- showed that certain demographic attributes impact how we view the world around us.\\n\\nThe VAD lexicon is useful in a wide range of applications and research projects."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "The NRC Valence, Arousal, and Dominance Lexicon provides ratings of valence, arousal, and dominance for ~20,000 English words.\\n\\nThe NRC Word-Emotion Association Lexicon, aka NRC Emotion Lexicon, provides associations for ~14,000 words with eight emotions (anger, fear, joy, sadness).\\n\\nThe NRC Emotion Intensity Lexicon, aka Affect Intensity Lexicon, provides intensity scores for ~6,000 words with four emotions (anger, fear, joy, sadness).\\n\\nThe NRC Word-Colour Association Lexicon provides associations for ~14,000 words with 11 common colours."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "il Pictures Attribution Family by b farias from the Noun Project\\n\\nShovel and Pitchfork by Symbolon from the Noun Project\\n\\nChecklist by Nick Bluth from the Noun Project\\n\\nGeneration by Creative Mahira from the Noun Project\\n\\nHuman by Adrien Coquet from the Noun Project\\n\\nSearch by Maxim Kulikov from the Noun Project\\n\\nhttps://thenounproject.com"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Resources Available at: www.saifmohammad.com\\n- NRC Valence, Arousal, and Dominance Lexicon\\n- NRC Emotion Lexicon and Emotion Intensity Lexicon\\n- Interactive visualizations\\n\\nSaif M. Mohammad\\nSaifMohammad@nrc-cnrc.gc.ca\\n@SaifMMohammad\\n\\nMany thanks to Svetlana Kiritchenko, Michael Wojatzki, and Norm Vinson for helpful discussions."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 206,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "RUTGERS\\n\\nWhy the affective analysis is necessary?\\n\\nHuman Speech AI: A Question and Answer\\n\\nRecommendation System: Accurate Response"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "RUTGERS Is multi-modality needed?\\n\\nVocal signal prominence Oh you = F GR that you are west-sider ¥ v Neutral or Frustration"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "RUTGERS Is multi-modality needed? Vocal signal prominence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "RUTGERS Is multi-modality needed? Vocal signal prominence OR you like it or not?\\nHappy Acoustic ambiguity \"I love this city!\" \"I hate this city!\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "RUTGERS\\n\\nChallenges:\\n- Feature Extraction\\n- Gap between features and actual affective states\\n- Lack of high-level associations\\n- Not all parts contribute equally"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "RUTGERS\\n\\nChallenges:\\n- Modality Fusion\\n- Decision-level Fusion\\n- Lack of mutual association learning\\n- Feature-level Fusion\\n- Fail to learn time-dependent interactions\\n- Lack of consistency"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "RUTGERS\\n\\nProposed Solutions\\n- Feature Extraction\\n- Hierarchical attention based bidirectional GRUs\\n- Modality Fusion\\n- Word-level fusion with attention\\n- An End-to-End multimodal network"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "RUTGERS Data Pre-processing\\nText Branch\\n- Word Embedding: word2vec\\nAudio Branch\\n- Mel-frequency spectral coefficients (MFSCs)\\n- Synchronization\\n- Word-level forced alignment."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "RUTGERS. Text ay \"mean\" wee \"guys\"aa\\n\\n(Embedded) ro: nei e aca\\n\\nWord-level & BiGRU t_h, ama t_h, wee an Po.\\n- Fusion1 Word-level \" -t-\" its\\n\\nTextual x /re 5 g; Attention\\n- \"7 é i: aC ey eo) eee t_an 2c ! § ' 1 ; 1 aO° | ine'o: =-_ CNN = 2ra H i 1s! | | Ce | ae: way | 2l 1 1\\n\\nWord-level ' -7* --7 ' --/Fb Acoustic \"\\n- A ti .! Attention\\n- oe\\n\\nVeen eee. . fag = exp(f_eij Ve) BiGRU; a ae Vane:\\n- ty OL Ta / en1 EXP (f_€ix Vp)\\n\\nFrame-level ee$1 \"sae nceq!\\n- Attention pte ee. *\\n\\n2 i\\n-\\n- on! picru, Fas}!\\n\\nfe1 = tanh(Wef_hiy + by) I u.-.\\n\\n3 nae1d 11<> Aiglio LF FF SB MEL | oA Viney (MFSC) ELE ae ee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "RUTGERS\\n\\nWord-level Fusion\\n\\n4 Dense Layer is mea\\nC) ea Attention Layer 'LhDXA N cL / hy Saf Dense Layer 4 4 O 7 / A/ a D, mr ah eae mee / wa; ae ' ae (a) Horizontal Fusion (b) Vertical Fusion (c) Fine-tuning Attention Fusion;\\n\\nWord-level acoustic attention distribution\\n\\nTGEA\\n\\nWord-level textual attention distribution\\n\\nexp(u_e; Vy) + sa;1)\\n\\nword-level acoustic contextual state\\n\\nty = sy exp(u e;,'v ) ae 12\\n\\nWord-level textual contextual state\\n\\nk=1 ~ u"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "RUTGERS Baselines\\n\\nSentiment Analysis\\n- BL-SVM\\n- LSTM-SVM\\n\\nEmotion Recognition\\n- SVM Trees\\n- GSV-eVector\\n\\nFusion\\n- Decision-level\\n- Feature-level (utterance-level)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "RUTGERS\\n\\nSentiment Analysis Result\\n\\nMOSI\\n787674\\nTes\\n7068: hdd646260:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "RUTGERSEmotion Recognition Result IEMOCAP 7570 6560 550\\n\\nWeighted Accuracy Unweighted Accuracy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "RUTGERS\\n\\nMultimodal architecture is needed\\n\\nMOS I 80706050 T A T + A = Weighted Accuracy Weighted Fl\\n\\nIEMOCAP 770656055 T A T + A 16 = Weighted Accuracy & Weighted Fl"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "RUTGERS Generalization MOSI to YouTube 6866 = Weighted Accuracy m Weighted Fl 646260\\nOurs-HF Ours-VF Ours-HA\\n\\nF IEMOCAP to EmotiW 6261 = Weighted Accuracy Weighted Fl 6059585756\\nOurs-HF Ours-VF Ours-HA"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "RUTGERS\\n\\nAttention Visualization\\n\\nCarry representative information in successfully combine both text and audio textual and acoustic attentions.\\n\\nLabel: anger\\n\\nai | rma Eshat about the business what the hell is this\\n- Word-level acoustic attention distribution\\n- Shared attention distribution\\n- Word-level textual attention distribution\\n- Fine-tuning attention distribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "RUTGERS Attention Visualization Capture emphasis and Vocal signal prominence importance variation Label: happy | arr | [ | sa; | A Slti ( < Cti ' C ~: Oh you don't like that you're west-sider Word-level acoustic attention distribution Shared attention distribution Word-level textual attention distribution Fine-tuning attention distribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "RUTGERSSummary\\n- A hierarchical attention based multimodal structure\\n- The word-level fusion strategies\\n- Word-level attention visualization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "RUTGERS\\nThank you!\\nEmail: yg202@scarletmail.rutgers.edu\\nHomepage: www.ieyuegu.com"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 70,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Task: Semantic Parsing (TTE) Translate natural language sentences to meaning representations, e.g., logical forms."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Task: Semantic Parsing\\n\\nTranslate natural language sentences to meaning representations, e.g., logical forms.\\n\\nSentence: Which city was Barack Obama born in?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Outline\\nMotivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Two Lines of Work in Semantic Parsing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Two Lines of Work in Semantic Parsing (TT Eee Semantic Graph Based"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\nSemantic Graph Based\\nUse semantic graphs to represent sentence meanings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n- Semantic Graph Based\\nUse semantic graphs to represent sentence meanings\\n- Semantic parsing as semantic graph matching or staged semantic query graph generation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n- Use semantic graphs to represent sentence meanings\\n- Semantic parsing as semantic graph matching or staged semantic query graph generation [Reddy et al., 2014, 2016, 2017][Yih et al., 2015][Bast and Haussmann, 2015]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n- Use semantic graphs to linearize logical forms representing sentence meanings.\\n- Semantic parsing as semantic graph matching or staged semantic query graph generation.\\n\\n[Reddy et al., 2014, 2016, 2017] [Yih et al., 2015] [Bast and Haussmann, 2015]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n\\nTE EEE Semantic Graph Based Sequence-to-Sequence Based\\n- Use semantic graphs to linearize logical forms that represent sentence meanings.\\n- Semantic parsing as semantic graph matching or staged problem generation [Reddy et al., 2014, 2016, 2017] [Yih et al., 2015] [Bast and Haussmann, 2015]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n- Use semantic graphs to linearize logical forms, representing sentence meanings.\\n- Semantic parsing as semantic sequence-to-sequence graph matching or staged problem semantic query graph generation [Dong and Lapata, 2016][Reddy et al., 2014, 2016, 2017][Jia and Liang, 2016][Yih et al., 2015][Xiao et al., 2016][Bast and Haussmann, 2015][Rabinovich et al., 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n(EE EEESemantic Graph Based Sequence-to-Sequence Based"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n\\nStrengths\\n- use semantic graphs to represent sentence meanings, no need for lexicons and grammars"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n\\n(Semantic Graph Based Sequence-to-Sequence Based\\n- Strengths\\n- use semantic graphs to represent sentence meanings, no need for lexicons and grammars\\n- Challenges\\n- Hard to model semantic graph construction process"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Two Lines of Work in Semantic Parsing\\n- Strengths\\n- Use semantic graphs to represent sentence meanings, no need for lexicons and grammars.\\n- Challenges\\n- Hard to capture structure.\\n- Hard to model semantic information.\\n- Graph construction ignores the relatedness to KB process."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Seq2Act: synthesizes their advantages"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Seq2Act: synthesizes their advantages. Use semantic graphs to represent sentence meanings\\n- tight-coupling with knowledge bases"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Seq2Act: synthesizes their advantages\\n- Use semantic graphs to represent sentence meanings\\n- Tight-coupling with knowledge bases\\n- Leverage the powerful prediction ability of RNN models\\n- End-to-End"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation (TT Eee! Which states border Texas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation Wi es oder?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation (TT Eee(A) | N74 semantic graph wt == <, Lf\\n- Action 1: add node A!\\n\\nWhich states border Texas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation\\n\\nAction 1: add node A\\nAction 2: add type state!\\n\\nWhich states border Texas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation\\n- Action 1: add node A\\n- Action 2: add type state\\n- Action 3: add node texas\\n\\nWhich states border Texas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation\\n- Action 1: add node A\\n- Action 2: add type state\\n- Action 3: add node texas\\n- Which states border Texas?\\n- Action 4: add edge next_to\\n- Action 5: return"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation (EE EEE type (RPS State),\\n\\nAction 1: add node Ar\\n\\nAction 2: add type state\\n\\nWhich states border Texas?\\n\\nAction 3: add node texas:stPO\\n\\nAction 4: add edge next_to\\n\\nAction 5: return"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Seq2Act: end-to-end semantic graph generation\\n- Action 1: add node A\\n- Action 2: add type state!\\n- Which states border Texas?\\n- Action 3: add node texas:stLo\\n- Action 4: add edge next_to\\n- Action 5: return our contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Outline (TE EEEa Sequence-to-Action"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Overview of Our Method\\n\\nSentence: Which states border Texas?\\n\\nSequence-to-Action\\n- aua_variable: A\\n- add_type: state\\n- arg_node: A\\n- Constraints Generate\\n- add_entity: texas:st\\n- add_edge: next_to\\n- arg_node: A\\n- Sequence\\n- arg_node: texas:st\\n- return: A\\n- CONSEQUENCE\\n- type[return Gtate]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Overview of Our Method\\n\\nSentence\\n- Which states border Texas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Overview of Our Method\\n- Sequence-to-Action\\n- Variable: 3\\n- arg_node: A\\n- Generate jadd_entity: texas:st\\n- add_edge: next_to\\n- Action\\n- arg_node: A\\n- Sequence\\n- arg_node: texas:st\\n- return: A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Overview of Our Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Major components of Our Model:\\n\\nWhich states border Texas?\\n- Sequence-to-Action\\n- RNN Model:\\n- add_type: state\\n- arg_node: A\\n- Constraints Generate\\n- add_entity: texas:st\\n- add_edge: next_to\\n- arg_node: A\\n- Sequence\\n- arg_node: texas:st\\n- return: A\\n- type: return\\n- state"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Major components of Our Model\\n\\n(1) (TT Eee \"Sentence: Which states border Texas?\\n\\nSequence-to-Action\\n\\nRNN Model\\nadd_type: state\\narg_node: A\\n(1) Constraints Generate\\nadd_entity: texas:st\\nadd_edge: next_to: Action\\nset\\n\\narg_node: A\\nSequence\\narg_node: texas:st\\nreturn: A\\n\\nConstruct\\ntype: [return Cstate]\\nCaras\\nGraph"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Major components of Our Model\\n- Which states border Texas?\\n- Sequence-to-Action\\n- RNN Model\\n- add_type: state\\n- arg_node: A\\n- Constraints Generate\\n- add_entity: texas:st\\n- add_edge: next_to : Action set\\n- arg_node: A\\n- Sequence\\n- arg_node: texas:st\\n- return: A\\n- Construct\\n- type[return Cstate]\\n- Graph"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Major components of Our Model (3)\\n- si\"( CUCU ne\"Sentence: Which states border Texas?\\n- Sequence-to-Action\\n- RNN Model\\n- add_type: state\\n- arg_node: A\\n- Constraints\\n- Generate\\n- add_entity: texas:st\\n- add_edge: next_to\\n- Action set\\n- arg_node: A\\n- Sequence\\n- arg_node: texas:st\\n- return: A\\n- Clerrmemioret ao\\n- type[return\\n- Gtate\\n- Caras\\n- Graph"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Action Set\\nCC (add_variable: A = add_type: state i arg node: A add_entity: texas:st 1 WD. add_edge: next_to Action setAction\\narg_node: A Sequence arg_node: texas:st return: == A!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Action Set (TT Eee) Define atom actions involved in semantic graph construction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Action Set: Define atom actions involved in semantic graph construction: Which states border Texas?\\n\\n!type(aP>-<State>\\n\\nnext_toNode: A (variable), texas:st (entity), state (type)\\n\\nEdge: next_to\\n\\nReturn node: A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Action Set (EE EEEo Add Variable node\\n\\nSentence: Which river runs through the most states?\\n\\nF A Semantic Graph:\\n- EsG xr arg_for_1 arg for_2\\n- Ace entity node\\n- (A) traverse\\n- (B) most\\n- E.g., texas:st | type type= Add type node\\n- E.g., state\\n\\nAction Sequence:\\nStructure Semantic Arg-\\n- Add edge\\n- add_operation most\\n- E.g., next to add_variable\\n- A' 7 5\\n- add_type river\\n- Ao Operation action add_variable\\n- B_ ° add_type state\\n- B; E.g., argmax, argmin, count\\n- add edge traverse\\n\\nLABE raument action end_operation most A,Bg c return A-\\n\\nFor type node, edge and operation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Encoder-Decoder Model\\nRNN Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Encoder-Decoder Model\\nAttention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Encoder-Decoder Model (TE EEEX4 X> Xeni V1 ve Vint\\n\\nTypical encoder-decoder model (bi-LSTM with attention)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Encoder-Decoder Model\\n\\nAttention: 4 YR em Ynoe a =oX4 X2 Xm V1 wee Vn-1\\n\\nTypical encoder-decoder model (bi-LSTM with attention)\\n\\nAction embedding"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Action Embedding add edge: next to add edge: loc"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Action Embedding add edge: next to add edge: loc Structure part"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Action Embedding\\nadd edge: next to\\nadd edge: seq\\nStructure part\\nSemantic part"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Action Embedding (TE EEEso add_edge: (R@xEtO!) | ccscoo add edge: | [oey 000 Structure part Semantic part"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Action Embedding\\nCC (eeooo\\nadd edges: 000coco\\nadd edges: seq 000\\nStructure part\\nSemantic part\\n(add edge: next to) = [( ); (next to)]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Structure & Semantic Constraints\\nSemantic Graph"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Structure & Semantic Constraints\\n- Structure constraints: Ensure action sequence will form a connected acyclic graph.\\n- Semantic constraints: Ensure the constructed graph must follow the schema of knowledge bases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Which states border Texas?\\nPartial Semantic Graph:\\ntype Structure\\nSemantic Validity\\nadd_variable A\\nGenerated\\nadd_type state A\\nActions\\nadd_entity texas:st\\nadd_type city x\\nAction 1: violate type conflict\\nCandidate\\nadd_edge _loc x\\nAction 2: violate selectional preference constraint\\nNext\\nadd_edge -next_to x\\nAction 3: structure constraint\\nAction\\nadd_edge next_to v\\nAction 4: YES"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Outline Experiments & Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Experiments (TE EEE= Datasets: GEO [Zelle and Mooney, 1996], ATIS [He and Young, 2005], OVERNIGHT [Wang et al., 2015b].\\nWe generate the action sequences from logical forms automatically.\\n\\nLogical\\n- Semantic\\n- Action Form\\n- Graph Sequence\\n\\nWhat is the population of Illinois?\\n\\nadd_node:\\n- B\\nadd_node:\\n- A\\nadd_edge:\\n- population\\narg_node:\\n- B\\narg_node:\\n- A\\nadd_entity_node:\\n- illinois = state\\narg_node:\\n- B\\nreturn:\\n- A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Baselines\\n\\nLannas Traditional Methods\\n- Zettlemoyer and Collins, 2005\\n- Zettlemoyer and Collins, 2007\\n- Liang et al., 2011\\n- Zhao et al., 2015\\n- Wang et al., 2015\\n\\nSequence-to-Sequence Models\\n- Dong and Lapata, 2016\\n- Jia and Liang, 2016\\n- Xiao et al., 2016\\n- Rabinovich et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Competitive performance on three datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Competitive performance on three datasets:\\n- Sora\\n- STA\\n- Full model: 99"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Competitive performance on three datasets (TE EEE on resources [lm eteon mets)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Competitive performance on three datasets (TT, Eee resources, complex grammars 89.9 | aa 85.9 85.9 [2 | mera ann mimes) 85 | 77.5 75.8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Competitive performance on three datasets (EERRA ow aocresources)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Seq2Act outperforms Seq2Seq."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Seq2Act outperforms Seq2Seq (TT Eee complex grammars 89.3 ac 585.9 85.9 77.5 75.8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Seq2Act + C1 outperforms Seq2Act (TE EEE 8785 84.6 838179 78 78.475 GEO ATIS OVERNIGHT Seq2Act mSeq2Act + Cl"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Seq2Act+C1+C2 outperforms Seq2Act+C1.\\n\\nCC (ee9189 88.2 pos C2: Semantic Constraints 87.5 87 85.5 84.6 78.4 275 GEO ATIS OVERNIGHT Seq2Act Seq2Act+C1 Seq2Act+C1+C2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Average Length of Logical Forms and Action Sequences\\n\\nAverage length of logical forms: 35.5%\\nAverage length of action sequences: 92%\\nOVER N IGHT 333 28 5%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Error Analysis (a Uncovered Sentence Structure\\n- Iowa borders how many states? (Formal Form: How many states does Iowa border?)\\n\\nUnder Mapping\\n- Please show me first class flights from Indianapolis to Memphis one way leaving before 10 am"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Conclusion\\n- TE EEEa Sequence-to-Action: End-to-End Semantic Graph Generation\\n- Representation ability of semantic graphs\\n- Sequence prediction ability of RNN models\\n\\nAchieve competitive results on GEO, ATIS and OVERNIGHT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Future work:\\n- A weak supervised learning algorithm for Seq2Act.\\n- So our method can be applied to (q,\\na) pair datasets such as WebQuestions.\\n- Apply Seq2Act model to other parsing tasks (e.g., AMR parsing)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Thanks!\\n- Data and code available: https://github.com/dongpobeyond/Seq2Act\\n\\nEmail: chenbo42424@gmail.com"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 178,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Overview\\nBackground\\nFormal Models\\nOur DAG Transducer\\nEvaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Outline\\nBackground"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "A NLG system Architecture\\nDocument\\nLinguistic Goals\\nCommunicative Goal\\nDocument Plans\\nSentence Plans\\nSurface Text\\n\\nReference\\nEhud Reiter and Robert Dale, Building Natural Language Generation Systems, Cambridge University Press, 2000."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "A NLG system Architecture/ Document, | Linguistic Communicative Goal Document Plans Sentence Plans Surface Text\\n\\nIn this paper, we study surface realization, i.e. mapping meaning representations to natural language sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Meaning Representation Logic form, e.g. lambda calculus\\n\\nA Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions\\n\\nWei Lu and Hwee Tou Ng\\n\\nDepartment of Computer Science\\n\\nSchool of Computing\\n\\nNational University of Singapore\\n\\n{luwei, nght}@comp.nus.edu.sg"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Meaning Representation © Logic form, e.g. lambda calculus\\nFeature structures\\nHigh Efficiency Realization for a Wide-Coverage Unification Grammar\\nJohn Carroll and Stephan Oepen\\nUniversity of Sussex\\nUniversity of Oslo and Stanford University"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Meaning Representation © Logic form, e.g. lambda calculus\\n\\nFeature structures\\n\\nThis paper: Graphs!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Graph-Structured Meaning Representation\\n\\nDifferent kinds of graph-structured semantic representations:\\n- Semantic Dependency Graphs (SDP)\\n- Abstract Meaning Representations (AMR)\\n- Dependency-based Minimal Recursion Semantics (DMRS)\\n- Elementary Dependency Structures (EDS)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Graph-Structured Meaning Representation\\n\\nDifferent kinds of graph-structured semantic representations:\\n- Semantic Dependency Graphs (SDP)\\n- Abstract Meaning Representations (AMR)\\n- Dependency-based Minimal Recursion Semantics (DMRS)\\n- Elementary Dependency Structures (EDS)\\n\\nARG1 ARG2 the_q boy_n_1 believe_v_1 pronoun_q Ne Ca A_girl_n_1 pron"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Type-Logical Semantic GraphS graphs are grounded under type-logical semantics.\\nThey are usually very flat and multi-rooted graphs.\\n\\nARG1 ARG2 the_q boy n_1 believe v_1 pronoun q Ne Ca wo A_girl n_i pron The boy wants the girl to believe him."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Previous Work\\n- Sequence-to-sequence Models (AMR-to-text)\\nReference: Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin Choi, and Luke Zettlemoyer.\\n2017. Neural AMR: Sequence-to-sequence models for parsing and generation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Previous Work\\n- Sequence-to-sequence Models (AMR-to-text)\\n- Synchronous Node Replacement Grammar (AMR-to-text)\\n\\nReference\\n\\nLinfeng Song, Xiaochang Peng, Yue Zhang, Zhiguo Wang, and Daniel Gildea.\\n2017. AMR-to-text generation with synchronous node replacement grammar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Previous Work\\n- Sequence-to-sequence Models (AMR-to-text)\\n- Synchronous Node Replacement Grammar (AMR-to-text)\\n- Other Unification grammar-based methods\\n\\nReference\\n\\nCarroll, John and Oepen, Stephan.\\n2005. High efficiency realization for a wide-coverage unification grammar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Outline\\n- Formal Models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Formalisms for Strings, Trees and Graphs\\n\\nChomsky hierarchy | Grammar\\n\\nAbstract machines\\n- Type-0\\n- Turing machine\\n- Type-1\\n- Context-sensitive\\n- Linear-bounded\\n- Tree-adjoining\\n- Embedded pushdown\\n- Type-2\\n- Context-free\\n- Nondeterministic pushdown\\n- Type-3\\n- Regular\\n- Finite\\n\\nManipulating Graphs: Graph Grammar and DAG Automata."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Existing System David Chiang, Frank Drewes, Daniel Gildea, Adam Lopez and Giorgio Satta.\\nWeighted DAG Automata for Semantic Graphs. The longest NLP paper that I've ever read"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "DAG Automata\\n\\nA weighted DAG automaton is a tuple M = ({X, Q, 6,\\nK) | Wo | 7%() ---- ©) JIN ANo/w{M15°°* Gm} -> {r1, -- , Ta}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "DAG Automata\\n\\nLet D = (V, E, €) be an edge labeling function p: Q.\\nThe weight of p is the product of all weights of local transitions: €(v)H(-) = Bs [obin(n)) \"> ptoute|veV"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "DAG Automata: Toy Example\\n\\nStates: OO OOO\\n\\nRecognition Rules:\\n\\nJohn wants to go.\\n\\n{} vente {©, ©} 0 BEES, {0} propena {@} 2; {0}\\n- go_v_i\\n- go_v_1 ~, {@} £24 9} named (John) {©, 8, 0} named (John) G"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "DAG Automata: Toy Example\\n\\nStates: OO OOO\\n\\nRecognition Rules:\\nJohn wants to go.\\n{} aa, {©, S}\\n0 BEES, {0}\\n8 propena {@}\\n2; {0}\\n- go_v_i\\n- f0_V.\\n1a, {o} B24, {8} named (John)\\n{©, 8, 0} named(John) G"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "DAG Automata: Toy Example\\nStates: OOO\\nRecognition Rules:\\n\\nJohn wants to go. {}\\nvente {©, ©} {} == {2}\\n8 Ee {@} 2; {0}\\n- go_v_t\\nC\\n- go_v_1 ~ 4 {0}\\n224 {@} named (John) {©, 8, 0}\\nnamed (John) G"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "DAG Automata: Toy Example\\n\\nStates: OO OOO\\n\\nRecognition Rules: John wants to go.\\n\\n{} vente {©, ©} 0 BEES, {0} 8 propena {@} 2; {0} govt ©\\n- go_v_1 ~ 4 {e} 224 9 } fais {0, 8, 0} = O, 4 ailed !"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "DAG Automata: Toy Example\\n\\nStates: OO OOO\\n\\nRecognition Rules:\\n\\nJohn wants to go.\\n\\n{} vente {©, ©}\\n\\n0 BEES, {0}\\n\\n8 propena {@} 2;\\n\\n{0}-go_v_t ©\\n\\n-go_v_1 ~ 4 {0}\\n\\n224 (@} named (John)\\n\\n{0, ©. ©} named(John) i"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "DAG Automata: Toy Example\\n\\nStates: OO OOO\\n\\nRecognition Rules:\\n\\nJohn wants to go.\\n\\n{} vente {©, ©}\\n0 BEES, {0}\\n8 propena {@}\\n2; {0}\\n- go_v_i ©\\n- f0_V.\\n1 ~\\ 4 {0}\\n224 {@} named (John)\\n{©, 8, 0} named(John)\\n\\nG Accept !"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Existing System\\nDaniel Quernheim and Kevin Knight.\\n2012. Towards probabilistic acceptors and transducers for feature structures"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "DAG-to-Tree Transducer\\n- BOY GIRL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "DAG-to-Tree Transducer, energy ay' |\\n- JINX Oe 'SL anomb wants info?\\n- veieve BOY\\n- GIRL BOY GIRL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "DAG-to-Tree Transducer\\n\\nNhwe Gnomb wants Finfds,\\n- aedevel\\n- BOY\\n- GIRL\\n- BOY\\n- GIRL\\n\\nJqnomb wants PI\\n- BOY\\n- GIRL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "DAG-to-Tree Transducer\\n\\nBOY wants GIRL of a \"qnomb\" and a place.\\n\\nNPS believes Maced1 is the boy! He wants the girl to believe him.\\n\\n\"Say yes!\" the BOY says to the GIRL."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "DAG-to-Tree Transducer\\n\\n\"IN if ypy bad wants\"\\n- me ON sis \"sp % peat 3 eT = Np or\\n\\nthe boy waits the girl to believe it.\\n\\nChallenges for DAG-to-tree transduction on EDS graphs:\\n- Cannot easily reverse the directions of edges\\n- Cannot easily handle multiple roots"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Outline © Our DAG Transducer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Our DAG-to-program transducer\\n\\nThe basic idea:\\n- Rewriting: directly generating a new data structure piece by piece, during recognizing an input DAG.\\n- Obtaining target structures based on side effects of the DAG recognition.\\n\\nStates:\\n\\nThe output of our transducer is a program:\\n\\nS = a + want + 1, proper_q-go_v_i = to + goage 1 = named (John)\\n\\n1 = %4 + John\\n\\nJohn wants to go.\\n\\n=> S = John want to go"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Transduction Rules\\nRecognition Part\\nGeneration Part\\nA valid DAG Automata transition Statement template(s) {} == {0,9}\\nS = tet + L + te"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Transduction Rules\\n\\nRecognition Part\\n\\nGeneration Part\\n\\nA valid DAG Automata transition Statement template(s) {} == {0,9}\\n\\nS = tet + L + te\\n\\nWe use parameterized states: label (number, direction)\\n\\nThe range of direction: unchanged, empty, reversed."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Transduction Rules\\nRecognition Part\\nGeneration Part\\n\\nA valid DAG Automata transition Statement template(s) {}\\n\"1, (@, ©} S=tw+L+ug\\n\\nWe use parameterized states: label (number, direction)\\nThe range of direction: unchanged, empty, reversed.\\n\\n1 {}\\nARES {vP(1,u), NP(1,u)}\\nS= wea + L + wea, w"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Toy Example Q = {DET(1,r), Empty(0,e), VP(1,u), NP(1,u)}\\n\\nRule | For Recognition | For Generation\\n\\n1 {} PS {DET(1,r)}\\n\\neT) = €20 |) SPSS (vPGu), NPCLu)}\\n\\nS = ayy + D + wey3 {VP(1,u)}\\n\\n(Empty(0,e)} Weci,u) = tot L4 {NP(1,u), DET(1,r)}\\n\\need {}\\n\\nUp (1,u) = YeETC,r) + Ley\\n\\nRecognition: To find an_go_v_l & edge labeling function p.\\n\\nThe proper red dashed edges make up an intermediate graph T(p). named (John)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Toy Example Q = {DET(1,r), Empty(0,e), VP(1,u), NP(1,u)}\\n\\nRule | For Recognition | For Generation\\n\\n1 | {} PS (ver(1,r) ETC) = €2 {p SSE {PG\\na) IPG}\\n\\nS = neaayt D+ oa3 {VP(1,u)} {Empty(0,e)}\\n\\nRecognition: To find an edge labeling function p.\\nThe proper red dashed edges make up an intermediate graph T(p), named (John)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Toy Example Q= {DET(1,r), Empty(0,e), VP(1,u), NP(1,u)}\\n\\nRule | For Recognition | For Generation\\n\\n1 | {} PS (ver(1,r)) eT) = €20 | () SPSS (vPGu), NP(CL(u)) | S= ayy + D + wey3 {VP(1,u)}\\n\\n22+, (Empty(0,e)}\\n\\nWe(i,n) = tot L4 {NP(1,u), DET(1,r)}\\n\\nZaned, {} Up(u) = Uer(t,r) + Lw(t) af\\n\\nRecognition: To find an-go_v_1 ' apnnbesit) edge labeling function p. The red dashed edges make up an ' proper_q .\\n- Empty(0,e) Q _« intermediate graph T(p). named (John)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Toy Example Q = {DET(1,r), Empty(0,e), VP(1,u), NP(1,u)}\\n\\nRule | For Recognition | For Generation\\n\\n1 fy ees, {(DET(1,r)} ter(a,z) = €20\\n\\nSSE (vPG,u), NP(CLu)}\\n\\nS = ay + D + wey3 {VP(1,u)} eis {Empty(0,e)}\\n\\nweajw = tot + L4 {NP(1,u), DET(1,r)}\\n\\nZaned, {} Up, (u) = Uer(t,r) + Lw(t) af\\n\\nRecognition: To find an-go_v_li edge labeling function p. The red dashed edges make up an Empty(0,e)\\n\\nintermediate graph T(p). named (John)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Toy Example Q = {DET(1, r), Empty(0, e), VP(1, u), NP(1, u)}\\n\\nRule for Recognition\\n\\nFor Generation 1 | {}\\nPS (ver(1,\\nr) eT) = €20\\n\\nSPSS (vPGu), NPCLu)\\n\\nS = ayy + D + wey3 {VP(1, u)}\\n\\n{Empty(0, e)}\\n\\nwea = tot + L4\\n\\n{nPQ, u), DET)}\\n\\nSf | ay = wera + Lw(t) af\\n\\nRecognition: To find an go_v_li ' ey NP(1,\\nu) edge labeling function p. The red dashed edges make up an Empty(0,\\ne) ge intermediate graph T(p) in graph 7(p). named (John) Accept!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Toy Example\\n\\nRule | For Recognition | For Generation\\n\\n1 {y Peeper-4, {DET(1,r)} WET (jr) = €2 {} SES (vP(1,w),NPG,u)} | S = way + b + wea3 | {vP(1,u)} 22s {empty (0,e)} | way = to + L4 {NP(1,u),DET(1,r)} Zanes, {} Up ,u) = Uer(t,r) + LS = wecajuy + L + wea,u)\\n\\nInstantiation: replace vy;\\n4) of edge e; with variable xj; Y and L with the output string in the statement templates.\\n\\nS = 21 + want + 21"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "DAG Transduction based\\n- NLG:\\nDAG Transducer\\n© Seq2seq Model\\nSemantic Graph\\nSequential Lemmas\\nSurface string"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Outline of Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Inducing Transduction Rules even x deg < 16:20> focus d & 5a er 4 7 & _in p temp < 34:36> proper q _the q < 0:4> _steep a 1 < 21:28> pron < 49:51> 9 NX of \"Amofy < 37:48> _decline n 1 < 5:12> \"the decline is even steeper than in September,\" he said.\\n\\nFinding\\n\\nGenerating intermediate\\n\\nAssigning spans\\n\\nAssigning labels\\n\\nstatement tree templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Inducing Transduction Rules even x deg <16:20> focus d4 VeeI v ok \"2 aa 65 > 'ge eS ey y ef4 SS hs yy , in p temp <34:36> proper q the q <0:4> steep a 1 <21:28> pron <49:51> NS of \" y A \" > c/s e10 enx Za #xmofy <37:48> decline n 1 <5:12> \"the decline is even steeper than in September\", he said.\\n\\nFinding Generating intermediate Assigning spans Assigning labels statement tree templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Inducing Transduction Rules_even_x_deg\\n\\nfocus_d4 Ve1\\n\\n{<0:48>{<16:20>} | la . = {<7:3:Z\\n- 'z ae Poe x Bscecal {<16:20>52295.48>} v 12 tae o// '{}ic =e ' ok Z_in_p_temp<34:36> proper_q _the_q<0:4> _steep_a_1<21:28> pron<49:51>Ne :{<37:48>}\\ Se {<0:4>}\\n\\n\"the decline is even steeper than in September\", he said.\\n\\nFinding Generating intermediate Assigning spans Assigning labels statement tree templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Inducing Transduction Rules even x deg\\nfocus d4\\nNES {ADV <16:20>}\\nla ' olesosae7)*\\na {pP <34:48>}\\n- 27 at '{NP2 @:51>}\\n5 /*248>}\\nA {ADV <16:20>, :48>}\\nY\\ 12\\n< er tyz sae\\na in p temp <34:36>\\nproper q _the_q <0:4>\\n_steep_a_1 <21:28>\\npron <49:51>'\\n\\n1 Neoower to ofo cvero:e)\\n- \"A /|{NP <0: 12>}* mo fy <37:48>\\n_decline_n_1 <5:12>\" the decline is even steeper than in September\", he said.\\n\\nFinding\\nGenerating intermediate\\nAssigning spans\\nAssigning labels\\nstatement tree templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Inducing Transduction Rules even x deg <16:20> focus d4\\n\\nNES {ADV <16:20>} | la ' olesosae 7)%\\n\\na {pP <34:48>}\\n- 27 at {NP2 @:51} 5 /*248>} A {ADV <16:20>, :48} Y\\ 12 < er tyz sae\\n\\na in p temp <34:36> proper q the q <0:4> steep a 1 <21:28> pron <49:51>'\\n\\n1 Neoower to ofo cvero:e)\\n- \"A /| {NP <0:12>} *mofy <37:48> _decline n 1 <5:12>\"\\n\\nthe decline is even steeper than in September, he said.\\n\\nFinding Generating intermediate Assigning spans\\n\\nAssigning labels statement tree templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Inducing Transduction Rules even x deg <16:20> focus d4 VS {ADV <16:20>}!\\ner ' olesosae7) # > s: sf = &5 BQ: {PP <34:48>} K, TADV <16:20> 5PP <20:48>} ei {NP &2Q:51} of'to, = ay in p temp <34:36> proper q the q <0:4> steep a 1 <21:28> pron <49:51> 19ares ofo cvero:e)\\n- \"A /| {NP <0:12>} zzmofy <37:48> decline n 1 <5:12>\" the decline is even steeper than in September\", he said.\\n\\ncomp {ADV(1,r)}\\n- {PP(1,u), ADV_PP(2,r)}\\n\\nUspv_PP(1,r) = Vabv(1,r)\\n\\nUspv_pP(2,r) = than + Upp(1,u)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Inducing Transduction Rules_even_x_deg\\nfocus_d4 YES{aDV}! la s olesosae7)N a7 eS »= se = 'AQ: Z {apvete:zo>yPP} 83 {NP: xe of'to-\\nmFin_p_temp proper_q _the_q _steep_a_1 pron}' 1{NP} ofo cvero:e) a)xmofy _decline_n_1 \"the decline is even steeper than in September\", he said.\\n{PP(1,u)} =P\", {NP C1 ,u)} Upp(i,u) = in + wyp(i,u)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "NLG via DAG transduction\\n\\nExperimental set-up\\n\\ne Data: DeepBank + Wikiwoods©\\n\\nDecoder: Beam search (beam size =\\n128)\\n\\ne About 37,000 induced rules are directly obtained from DeepBank training dataset by a group of heuristic rules.\\n\\ne Disambiguation: global linear model\\n\\nTransducer | Lemmas Sentences Coverage\\n\\ninduced rules | 89.44 74.94 67%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Fine-to-coarse Transduction\\n\\nTo deal with the data sparseness problem, we use some heuristic rules to generate extended rules by slightly changing an induced rule.\\nGiven an induced rule: {NP, ADJ} \"> {} yp = tps + L New rule generated by deleting: x{NP} + {} op = L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Fine-to-coarse Transduction\\n\\nTo deal with the data sparseness problem, we use some heuristic rules to generate extended rules by slightly changing an induced rule.\\nGiven an induced rule: {NP, ADJ} → {} op = vps + L\\n\\nNew rule generated by copying: x{NP, ADJ, ADJ2} → {} Up = Vans + Vans + L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "NLG via DAG transduction\\n\\nExperimental setup\\n\\nData: DeepBank + Wikiwoods\\nDecoder: Beam search (beam size =\\n128)\\nAbout 37,000 induced rules and 440,000 extended rules\\nDisambiguation: global linear model\\n\\nTransducer | Lemmas Sentences Coverage\\ninduced rules 89.44 74.94 67%\\ninduced and extended rules 88.41 74.03 77%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Fine-to-coarse transduction NW NY(o) --¥ ayes aed JIN AND uring decoding, when neither induced nor extended rule is applicable, we use Markov model to create a dynamic rule on-the-fly:\\nnP({ri, -++ , Pa}|C) = P(r) [J Prd OP(rilria, ©) i=2 e C= ({q, -+: , dm},\\nD) represents the context.\\n® T1, °-* , Tm denotes the outgoing states."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "NLG via DAG transduction\\n\\nExperimental setup\\n\\nData: DeepBank + Wikiwoods\\nDecoder: Beam search (beam size =\\n128)\\nOther tool: OpenNMT\\n\\nTransducer | Lemmas\\n\\nSentences Coverage\\n\\ninduced rules\\n89.44 74.94 67%\\n\\ninduced and extended rules\\n88.41 74.03 77%\\n\\ninduced, extended and dynamic rules\\n82.04 68.07 100%\\n\\nDFS-NN\\n50.45 100%\\n\\nAMR-NN\\n33.8 100%\\n\\nAMR-NRG\\n25.62 100%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Conclusion and Future Work\\n\\nEnglish Resource Semantics is fantastic!\\n\\nConclusion\\n\\nFormalism works for graph-to-string mapping, not surprisingly.\\n\\nFuture work\\n- Is the decoder perfect? No, not even close.\\n- Is the disambiguation model a neural one? No, graph embedding is non-trivial."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "a QUESTIONS? WOULD COMMENTS?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 0,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Probabilistic FastText = FastText + Gaussian Mixture Embeddings\\n\\nGaussian Mixture\\n- Words as probability densities\\n\\nEach word = Gaussian Mixture density\\n\\nDisentangled meanings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Probabilistic FastText = FastText + Gaussian Mixture Embeddings\\n\\nGaussian Mixture Words as probability densities\\n\\nEach word = Gaussian Mixture density\\n\\nDisentangled meanings\\n\\nWord embeddings: word vectors are derived from subword vectors\\n\\nCharacter based models allow for estimating vectors of unseen words and enhancing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "2-MIN SUMMARY\\n\\nProbabilistic FastText\\n\\nGaussian Mixture (PFT)\\n\\nEmbeddings\\n\\nTere mY orTire aSeFast lext iene,aFo ieee etmn"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "PROBABILISTIC FASTTEXT\\n\\nAble to estimate distributions of unseen words\\nL{\"cool\" | @ tec le ae _Axe) a f (\"coolz\") =een Oa ~ i f (\"coolzz\")\\na dictionary-based embeddings\\ncharacter-based probabilistic embeddings\\nBrock, i"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Able to estimate distributions of unseen words\\nL{\"cool\" | @ tec le ae _Dice) aan f(\"coolz\") =Tiree\\n0) Deel am ~ i val \"coolzz\") dictionary-based embeddings character-based probabilistic embeddings High semantic quality for rare words via root sharing\\n- Spearman Correlation\\n- on RareWord dataset"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Able to estimate distributions of unseen words.\\n- TA ixcere\\n- dictionary-based embeddings\\n- character-based probabilistic embeddings\\n\\nHigh semantic quality for rare words via root sharing.\\n- Spearman Correlation on RareWord dataset\\n- Disentangled meanings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Able to estimate distributions of unseen words.\\n\\nCharacter-based probabilistic embeddings.\\n\\nHigh semantic quality for rare words via root sharing.\\n- Spearman Correlation on RareWord dataset: 0.43, 0.48, 0.49.\\n\\nApplicable to foreign languages without disentangled meanings and without any changes in model hyperparameters!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "VECTOR EMBEDDINGS & FASTTEXT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "ola eso mle s dense representations size of vocabulary dimension | ~ Millions | ~ 50\\n- 1000 e word2vec (Mikolov et al.,\\n2013) vectors GloVe (Pennington et al.,\\n2014) 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Relationship deduction\\n\\nMeaningful nearest neighbors from vector arithmetic\\n\\nCountry and Gap Tal Vectors Projected by PCA vindicates China.\\n\\nDane vindicate\\n435.\\n\\nExculpate, absolve, Moscow, exonerate, Tokyo.\\n\\nItaly\\n- modulation; modulations' S2 air\\n- harmonics amplitude 4:5.\\n\\nPortas.\\n\\nChina\\n- Beijing, Japan\\n- Tokyo.\\n\\nMikolov 2013"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "CHAR-MODEL: SUBWORD REPRESENTATION FastText (P Bojanowski,\\n2017)\\n\\ni 3 e representation = average of n-gram\\n\\nPw = CO + ce vectors\\n\\nker + 1 Cather e automatic semantic extraction of stems/prefixes/suffices w = N-grams(w) 3 {(ab, abn,..., (abn, abnor,..., }7 aZabnora12"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "CHAR-MODEL: SUBWORD a = a at = S = IN wi | o IN FastText (P Bojanowski,\\n2017) | * representation = average of n-gram 0 =\\n- u,, + Zz, ifom Renn el vr Ss fi\\n- vec se\\n- gENGw e automatic semantic extraction of stems/prefixes/suffices =\\n\\nN-grams (w) 3 {(ab, abn,..., (abn, abnor,..., } 'abnor' 7\\n- a ee $6Z abnor of o Soz. \"\\n- m 'abnorm' een Oy 5 eA , aa &é 0.0 0.2 0.4 0.6 0.8 cosine similarity between vector and n-gram vectors 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "SUBWORD CONTRIBUTION TO OVERALL SEMANTICS\\n\\nSimilar n-grams with high contribution.\\n\\nSimilar words have similar semantics.\\n\\nCosine similarity between n-gram vectors and mean vectors."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "a cd IHpop,l = Terock 40Lrock,0 = ae Popfe) rock-\"\\n\\nilaah a ee Lee 7s aDOnn i OD =o)Pw, i Ian | Uw + Ss\" aeene (oee Augment Gaussian mixture representation with character structure (FastText)>\\n\\nPromote independence: using dictionary-level vectors for other components 15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "SIMILARITY SCORE (ENERGY) BETWEEN DISTRIBUTIONS vector space function spaces (u,\\nv) = (u,\\nv) ICU Rael CERO = U\\n- V U a one Che = 7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "ENERGY OF TWO GAUSSIAN MIXTURES\\n\\ntotal energy = weighted sum of pairwise partial energies\\n\\nsimplified partial energy\\n\\npop-rock, band\\n\\na bang, crack, snap\\n\\nbasalt, boulder, sand\\n\\njazz, punk, indie"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "WORD SAMPLING I like that rock band I am a ' '  En ee eee eee Wi-2 Wi-1 Wy Wi+1 Wi+2 Dremel elma | ' 4 (3.5 billion tokens) ' ' wy18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "LOSS FUNCTION\\n\\nEnergy-based Max Margin\\n\\nMinimize the objective\\n\\nL(w, c') = max(0, m\\n- log E(w,\\nc) + log E(w, c'))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "MULTIMODAL REPRESENTATION\\n- MIXTURE OF GAUSSIANS\\n\\nModel parameters:\\n- dictionary vectors\\n- covariance scale\\n- margin"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "TRAINING\\n- ILLUSTRATION\\n\\nModel parameters:\\n- STONE cee{24} onSel NSTrain with max margin objective using minibatch SGD (AdaGrad)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "EVALUATION"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "QUALITATIVE EVALUATION\\n- NEAREST NEIGHBORS lever od e9° ool a ve pop rock Agoles\\n- ae"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "NEAREST NEIGHBORS\\n\\nrock: 0, rocky: 0, mudrock: 0, rockscape: 0, boulders: 0, outcrops: 0\\n\\nrock: 0, punk: 0, punk-rock: 0, indie: 0, pop-rock: 0, pop-punk: 0, indie-rock: 0, band: 1\\n\\nbank: 0, banks: 0, banker: 0, bankers: 0, bankcard: 0, Citibank: 0, debits: 0\\n\\nbanks: 1, river: 0, riverbank: 0, embanking: 0, banks: 0, confluence: 1\\n\\nstar: 0, stars: 0, stellar: 0, nebula: 0, starspot: 0, stars: 0, stellas: 0, constellation: 1\\n\\nstars: 1, star-star: 0, 5-stars: 0, movie-star: 0, mega-star: 0, super-star: 0\\n\\nrock: rock-y, rockn, rock-, rock-funk, rock/, lava-rock, nu-rock, rock-pop, rock/ice, coral-rock\\n\\nbank: bank-, bank/, bank-account, bank., banky, bank-to-bank, banking, Bank, bank/cash, banks.\\n\\nStar: movie-stars, star-planet, G-star, star-dust, big-star, starsailor, 31-star, star-lit, Star, starsign"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "HUMAN EMBEDDING SCORE SIMILARITY\\n\\nS(CUP, COFFEE) = 0.7\\n\\nS(CUP, SUBSTANCE) = 0.2\\n\\nS(STOCK, MARKET) = 0.9\\n\\nS(STOCK, PHONE) = 0.05\\n\\nS(KING, QUEEN) = 0.8\\n\\nSpearman correlation = 0.92\\n\\nS(KING, CABBAGE) = 0.2\\n\\nSpearman correlation coefficient: 0: no correlation\\n\\n1: perfect correlation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "SIMILARITY METRICS (rock, stone)\\n\\nExpected Likelihood; ROCK 7 Pairwise Maximum Cosine Similarity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "WORD SIM DATASETS | FASTTEAT W2GM | PFEIT-GM\\n- PFT performs much better\\n38.03 29.62 | 30.50\\n\\nCompared to MEN-3K\\n76.37 78.76 79.65\\n\\nBased on the average RG-65\\n77.78 80.95\\n\\nSpearman correlation, YP-130\\n69.44\\nMT-771 OL 70.36 69.68\\n\\nFirst multi-sense models that achieve\\nRW-2K (RAREWORD) 48.09\\n\\nHigh scores on AVG. 51.10\\nRareWord"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "COMPARISON WITH OTHER MULTI-PROTOTYPE EMBEDDINGS\\n\\nModel Dim | p x 100\\n\\nHUANG AVGSIM 50 62.8\\n\\nTIAN MAXSIM 50 63.6\\n- PFT performs better\\n\\nW2GM MAXSIM 50 62.7\\n\\nNEELAKANTAN AVGSIM 50 64.2\\n\\nPFT-GM MAXSIM 50 63.7\\n\\nCHEN-M AVGSIM 200 66.2\\n\\nW2GM MAXSIM 200 65.5\\n- with multiple meanings.\\n\\nNEELAKANTAN AVGSIM 300 67.2\\n\\nW2GM MAXSIM 300 66.5\\n\\nPFT-GM MAXSIM 300 67.2\\n\\nTable 3: Spearman's Correlation p x 100 on word similarity dataset SCWS."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Word Meaning Nearest Neighbors(IT)\\n\\nsecondo 2nd\\n\\nSecondo (2nd), terzo (3rd), quinto (5th), primo (first), quarto (4th), ultimo (last)\\n\\n(IT) secondo according to\\n\\nconformit (compliance), attenendosi (following), cui (which), conformemente (accordance with)\\n\\n(IT) porta lead, bring\\n\\nportano (lead), conduce (leads), portano, porter, portando (bring), costringe (forces)\\n\\n(IT) porta door\\n\\nporte (doors), finestrella (window), finestra (window), portone (doorway), serratura (door lock)\\n\\n(FR) voile veil\\n\\nvoiles (veil), voiler (veil), voilent (veil), voilement, foulard (scarf), voils (veils), voilant (veiling)\\n\\n(FR) voile sail\\n\\ncatamaran (catamaran), driveur (driver), nautiques (water), Voile (sail), driveurs (drivers)\\n\\n(FR) temps weather\\n\\nbrouillard (fog), orageuses (stormy), nuageux (cloudy)\\n\\n(FR) temps time\\n\\nmi-temps (half-time), partiel (partial), Temps (time), annualis (annualized), horaires (schedule)\\n\\n(FR) voler steal\\n\\nenvoler (fly), voleuse (thief), cambrioler (burgle), voleur (thief), violer (violate), picoler (tipple)\\n\\n(FR) voler fly\\n\\nairs (air), vol (flight), volent (fly), envoler (flying), atterrir (land)\\n\\nTable 5: Nearest neighbors of polysemies based on our foreign language PFT-GM models.\\n\\nLang. | Evaluation | FASTTEXT w2g w2gm pft-g_ pft-gm\\n\\nFR WS353 38.2 16.73, 20.09 41.0 41.3\\n\\nGUR350 70 65.01 69.26 77.6 78.2\\n\\nDE; . .\\n\\nGUR65 81 74.94 76.89 81.8 85.2\\n\\nWS353 57.1 56.02 61.09 60.2 62.5\\n\\nIT .SL-999 | 29.3 29.44 34.91 29.3 33.7\\n\\nTable 4: Word similarity evaluation on foreign languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "FUTURE WORK: MULTI-LINGUAL EMBEDDINGS\\n\\nLiterature: align embeddings of many languages after training (Conneau,\\n2018)\\n\\n(A)\\n\\n(B)\\n\\n(C)\\n\\n(D)\\n\\nUse disentangled embeddings to disambiguate alignment."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Elegant representation of semantics using multimodal distributions\\n- Suitable modeling words with multiple meanings\\n- Model words as character levels\\n- Better semantics for rare words\\n- Able to estimate semantics of unseen words"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 111,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Word Embeddings\\n- Dense vectors of words\\n- Unsupervised training: GloVe, Word2Vec\\n- Words in similar context tend to have similar meaning apple good > (... 0.0335, -0.1018, 0.2300, ...) € R°°° banana\\n- Words with similar meanings tend to be close in embedding space\\n\\nMelbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Training Word Embeddings\\n\\nTarget Word \"a\"\\nContext Words\\nCounting Contexts (8321, 235, 63444, ...)\\nVocabulary Size (~ 300k)\\n\\nReducing Dimensionality (0.0335, -0.1018, 0.2300, ...)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Different Input Corporation\\nVocabulary Size = 300k\\nReducing Dimensionality"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "ti oe ~aee\\n\\nWIKIPEDIA The Free Encyclopedia\\n\\nAn article must be written from a neutral point of view, which among other things means \"representing fairly, proportionately, and, as far as possible, without editorial bias, all of the significant views that have been published by reliable sources on a topic.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Amazon values diverse opinions and that content [customer reviews] you submit should be relevant and based on your own honest opinions and experience."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Subjectivity Scale\\nMore Objective  More Subjective\\n\\nA Sr »t) amazon'8g\\nWIKIPEDIA\\nThe Free Encyclopedia\\nSubjective Embeddings (SE)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "- Sentiment Classification (positive vs.\\nnegative): « Amazon Reviews (24 categories) + Rotten Tomatoes Reviews \"A very funny movie\" vs. \"One lousy movie\"\\n- Subjectivity Classification (subjective vs.\\nobjective): * Rotten Tomatoes Reviews \"The story needs more dramatic meat\" vs. \"She's an artist\"\\n- Topic Classification (in-topic vs. out-of-topic):\\n- Newsgroups Dataset (6 categories)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Methodology\\n- Cross-validation on balanced samples\\n- Binary logistic regression classifier\\n- Sentence embedding = average of word embeddings\\n- The same number of sentences and the same vocabulary when training embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Objective Embeddings (OE)\\nSubjective Embeddings (SE)\\nClassification\\nSentiment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Top Words Similar to \"good\"\\nObjective Embeddings\\namazon = Subjective Embeddings\\nWikipedia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Sentiment Words Still Cause Troubles!\\n\\namazon\\nSubjective Embeddings\\nWord A\\nWord B\\nBa\\natsies\\nyl\\nlei\\nayfaeee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "SentiVec Embeddings\\nTemae\\niWIKIPEDIA\\nThe Free Encyclopedia\\nObjective\\nWord2Vec\\nObjective\\nSentiVec\\nEmbeddings\\nEmbeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "SentiVec: Infusing Sentiment:\\n\\nLexicalSentiVec = Word2Vec + Resource\\n- Predicts context words as in Word2Vec Skip-gram\\n\\nPositive: love, great,\\n- Predicts word category"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "This is for high quality.\\n\\nWord2Vec Skip-gram Lexical objective of SentiVec (two classes)\\n\\nP(good is POSITIVE) = P(good | camera)P(good | is)\\n\\nP(good is NEGATIVE) = 1\\n- P(good is POSITIVE)\\n\\nP(good | for)P(good | high)\\n\\nP(good is POSITIVE) > MAXIMIZE vs. Random Noise\\n\\nP(good | frog) P(good | duck)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "LEE EERE aEE EE YERPPOSITIVE 1 AEE SPN P NEGATIVE AER FO 1 0.75 PE EERIE TOS ZR AN, BAT SIRENS SK6 BUSSES GLPR eS MS POOPIE AEA POR A Ted 0.25 Ree Sidi Py Py 0 WAR Reba Dee ey Woh aaa\" hd LTE Oe -0.25 REE PS eea ey bE dot rae 0.75 ' Gee \" 0.75 Neutral Words 4 = e 70.25\\n- 0.75\\n- 0.5 P NEUTRAL OS 5 0 50.75 11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Accuracy 900.3%\\n85 0.8%\\n80 0%\\n- 75\\n\\nSax Objective\\nSubjective\\nObjective\\nSubjective\\n\\nEmbeddings\\nEmbeddings\\nEmbeddings\\nEmbeddings\\n\\nAmazon Sentiment\\n- Rotten Tomatoes Sentiment (average over 24 categories)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Positive Words\\nChanges in Similarity\\nNegative Words\\nNeutral Words\\nTarget Word: Good\\nTarget Word: Bad"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Conclusion\\n- Explored effects of corpus subjectivity\\n- for word embeddings SentiVec, a method for infusing lexical information into word embeddings.\\n- Sentiment-infused SentiVec embeddings space facilitate better sentiment-related similarity.\\n\\nPre-trained Word Embeddings & Code: https://sentivec.preferred.ai/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 125,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Motivation\\nGood translation preserves the meaning of the sentence.\\nNeural MT learns to represent the sentence.\\nIs the representation \"meaningful\" in some sense?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "I was given a card by her in the garden.\\nIn the garden, she gave me a card.\\nShe gave me a card in the garden.\\nShe was given a card by me in the garden.\\nIn the garden, I gave her a card.\\nI gave her a card in the garden."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "SS' cee greg he sca i tegall = 50C Brve Ae d dos as A.e i vee spre 7\\n\\nThe gist of our idea:\\n1. Train variants of NMT to obtain sentence representations.\\n2. Evaluate all such representations \"semantically\".\\n3. Relate performance in MT and in \"semantics\"."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Evaluating sentence representations\\n- Evaluation through classification.\\n- Evaluation through similarity.\\n- Evaluation using paraphrases.\\n\\n@ SentEval (Conneau et al.,\\n2017) focuses on prediction tasks for evaluating sentence embeddings that focus on semantics (recently, \"linguistics\" task added, too).\\n- HyTER paraphrases (Dreyer and Marcu, 2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Evaluation through classification\\n\\nSentEval Classification Tasks\\n\\nan ambitious and moving but bleak film.\\n\\nand that makes all the difference.\\n\\nrarely, a movie is more than a movie.\\n\\nthe movie is well done, but slow.\\n\\nthe pianist is Polanski's best film."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Evaluation through classification\\n\\nSentEval Classification Tasks\\n\\nan ambitious and moving but bleak film.\\n\\nand that makes all the difference.\\n\\nrarely, a movie is more than a movie.\\n\\nthe movie is well done, but slow.\\n\\nthe pianist is Polanski's best film.\\n\\nSolo: movies sentiment, product review polarity, question type..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Evaluation through classification\\n\\nSentEval Classification Tasks\\n\\nA square full of people and life. The square is busy.\\n\\nThe couple is at a restaurant.\\n\\nA cute couple at a club.\\n\\nA white dog bounding through snow.\\n\\nSolo: movies sentiment, product review polarity, question type...\\n\\nPaired: natural language inference, semantic equivalence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Evaluation through classification\\n\\nSentEval Classification Tasks\\n\\nA square full of people and life. The square is busy.\\n\\nThe couple is at a restaurant.\\n\\nA cute couple at a club.\\n\\nA white dog bounding through snow.\\n- Solo: movies sentiment, product review polarity, question type...\\n- Paired: natural language inference, semantic equivalence\\n\\n10 classification tasks in total, we report them as \"AvgAcc\" over 4k-55k training examples, with test set or 10-fold cross eval."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Evaluation through similarity: 7 similarity tasks: pairs of sentences + human judgement.\\n\\nThink it probably depends on your money. It depends on your country.\\n\\nYes, you should mention your experience. Yes, you should make a resume.\\n\\nHope this is what you are looking for. Is this the kind of thing you're looking for?\\n\\nWith training set, sentence similarity predicted by regression, without training set, cosine similarity used as sentence similarity.\\nUltimately, the predicted sentence similarity is correlated with the golden truth.\\n\\nIn sum, we report them as \"AvgSim\"."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Evaluation using paraphrases: the dataset HyTER: ~200 sentences, e COCO: 5k images, 5500 translations each captions each (Kise NatkKBAaA, aN--TAAM the deep cut and halter golden swimwear weighs half a kilogram selling at ten million JPY.\\n¥10,000,000 is the retail value for the low-cut gold bathing suit with a low back, and the weight is 500 g.\\nAt the weight of five hundred grams, the low cut, halter swimsuit made up of gold will sell at ten million Japanese Yen (JPY).\\n(Dreyer and Marcu, 2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Evaluation using paraphrases: the data HyTER: ~200 sentences, e COCO: 5k images, 5500 translations each caption.\\n- A person is feeding a donut to the cat.\\n- A cat being fed a donut by someone in a grey shirt.\\n- A cat nibbles on a sprinkled donut.\\n- A cat that is being fed by the owner.\\n- A grey cat biting into a frosted donut.\\n- A cat is eating a donut from a person's hand.\\n\\n(Lin et al., 2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Evaluation using paraphrases: the metrics"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Cluster separation: Davies-Bouldin index, heRy = 7, pB =\\n- S\\n- R = Max £0; 7; dy2 < N\\n- ix. For each cluster, we find the least well-separated one (Davies and Bouldin, 1979)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Paraphrase retrieval task (NN)\\nRetrieve the nearest neighbor and check whether it lies in the same cluster."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Classification tasks:\\n1. Remove some points from the clusters.\\n2. Train an LDA classifier with the remaining points.\\n3. Classify the removed points back."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Sequence-to-sequence with attention Bahdanau et al. (2014) is a weight of the encoder state for the decoder state.\\nNo sentence embedding."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Ways of getting sentence embeddings final states max/average pooling inner attention La, EHECs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Ways of getting sentence embeddings final state @ max/average pooling inner attention aBer feralti"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Multi-head inner attention Liu et al. (2016), Li et al. (2016), Lin et al.\\n(2017), a weight of the j-th encoder = M'state for the column of MTM.\\nConcatenate columns of MTM to create a sentence embedding. A linear projection of columns to control embedding size."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Proposed NMT architectures entail B31 Bsat in \"encoder = M\" Aeaodiee.\\n\\nThe decoder operates on the entire decoder, selects components of embedding."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Proposed NMT architectures\\n\\nTransformer decoder.\\n\\nencoder operates on the Transformer (Vaswani et al.,\\n2017) with inner attention."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Evaluated NMT models, model architectures:\\n- FINAL, FINAL-CTX: no attention\\n- AVGPOOL, MAXPOOL: pooling instead of attention\\n- ATTN-CTX: inner attention, constant context vector\\n- ATTN-ATTN: inner attention, decoder attention\\n- TRF-ATTN-ATTIN: Transformer with inner attention\\n\\nTranslation from English (to Czech or German), evaluating embeddings of English (source) sentences:\\n- en-cs: CzEng 1.7 (Bojar et al.,\\n2016)\\n- en-de: Multi30K (Elliott et al., 2016; Helcl and Libovicky, 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Sample Results\\n- translation quality en-cs\\n\\nSelected models trained for translation from English to Czech. The embedding size is 1000 (except ATTN)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Sample Results\\n- translation quality en-cs\\n\\nManual Manual. Meet Heads 910 Sen. BLEU is a consistent score with human evaluation.\\n\\nSelected models trained for translation from English to Czech. The embedding size is 1000 (except ATTN)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Sample Results\\n- representation eval. en-cs\\n\\nSize | Heads | peel | Seer | Deena | AvgAcc | AvgSim (COCO)\\n\\nFINAL-CTX ('Cho') | 1000 |\\n- |\\n- |\\n744) 0.60 | 23.20\\n\\nATINATIN 10008 | 700, 0.36,\\n- '10.2\\n\\nSelected models trained for translation from English to Czech.\\nInferSent and GloVe-BOW are trained on monolingual (English) data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Sample Results\\n- representation eval. en-cs Paraphrases\\n\\nSome infrequent sentences: 4086\\n- BAT | words 300\\n- 758 059\\n\\nBaselines FINAL CTX (Cho?) f000/- | 7440602320 are hard to beat ATIN ATIN.\\n\\nSelected models trained for translation from English to Czech.\\nInferSent and GloVe-BOW are trained on monolingual (English) data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Sample Results\\n- representation eval. en-cs. SentEval | SentEval Bare bilesespeer nae (COCO) inference (4096\\n- | AT OrO | 81.88 GloVe bag of words 300 758,059] FINAL-CTX Cho\") [1000,\\n- | 744l\\n- 080 | 28.20 Attention harms the performance.\\nATIWATIN, 1000.8 | 700,038 '1024 Selected models trained for translation from English to Czech.\\nInferSent and GloVe-BOW are trained on monolingual (English) data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Sample Results\\n- representation eval. en-cs\\n\\nSentEval | SentEval aoeSize | Heads : class. accuracy\\n\\nAvgAcc AvgSim (COCO)\\n\\nFINAL-CTX (\"Cho*) 1000 | --74.4| (0.60 23.20\\n\\nATTN-CTX 1000 14.60 More heads\\n\\nATTNNATIN 1000 ot | | + worse\\n\\nATTNATTN. (1000/8 | --700| 08, 10.24\\n\\nSelected models trained for translation from English to Czech.\\nInferSent and GloVe-BOW are trained on monolingual (English) data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Full Results\\n- BLEU correlations\\n\\nMPQA | SST2 | SST5 | TREC | SNLI | SICK-R\\n\\nBLEU vs. other metrics:\\n- en-cs: -0.57 + 0.31\\n- en-de: -0.36 + 0.29\\n\\nPairwise average Hy.NN B\\nHy-iDB (except BLEU):\\n- en-cs: 0.78 + 0.32\\n- en-de: 0.57 + 0.23\\n\\nPF-1.00 -0.75 -0.50 -0.25 0.00 0.25 0.50 0.75 1.00"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Full Results\\n- BLEU. Correlations include S805 QMRPC Transformer Avg Acc; SICK-R QBLEU vs. other metrics:\\n- Q-0.57 + 0.31 (en-cs)\\n- j-0.54 + 0.27 (en-de)\\n\\nSTS15 STS16 Avg Sim Pairwise average Hy NN (except BLEU):\\n- OCA + CO-NN 0.78 + 0.32 (en-cs)\\n- 0.62 + 0.23 (en-de)\\n\\n-1.00 -0.75 -0.50 -0.25 0.00 0.25 0.50 0.75 1.00"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Compound attention interpretation of a multi-head attention model with 8 heads"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "OS\\n- DobieS T Given Vzhledem tedCompound SS = Pie ia ne getA\\nSS. me\\n- Sse available SS lostatte ntio n ne Sie clinical\\nnymchild- 2 moj -S klin-. teed ET oes eeinterpretation \"détstvi : na, ine- .tS,\\nWhat Co ee use. ial. F CF = data\\ntickymi\\nUdajim0 --- a SO was pe ccclkty ySSS ste- EZ es ne nentee = tose eZ tn\\nSS eS ESEae Si por- down = adjustment\\nSS\\n- uprav-ro- SSS\\n- 6za : \"he is\\n- ovatsis = SSM? and uty\\n- iS davkua A a necessary TNwe\\n\\na f? (&apos;re ._ Jy znovu ( 'gonna JE: see 3 aATIN-ATIN en-cs pee ike section eT s2.\\nSS a ot 5.2 =model with 8 heads tet this- A == Sie ; eyesweekend .®"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Given Nzhledemthes SZ kavailable = dostup-clinical nym= Klinand\\n- ickymke Bee y|= aine=tic ' S : ine:nei udajimno y nenidose\\n- aA : nutné adjustment\\n- uprav SSSi I ovat= OTM davkunecessary >\\\\ \\\\ ot( .\\\\ i= vizsee RE hosection = 5.2§.2 = )) .Z"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Given Vzhledem. the average attention available -S- dostup-weight by position clinical -0.2 and\\n- === -) L fee. ; _0.1 / atic-<--_ SR ine-5 °? data ---=\\n- -tickym= ot ' ---~ adajime < 0.0 no nenioO !3 a tes\\n\\nSS\\n- Z5© = Ie adjustment -- uprav-Cc 0.1 Xe Z LSS ovat& 0.0 ee Ww davkunecessary .i ' \\ viz* $08 ee ts0.0 section SS WL 00.0 0.5 1.0 0.0 0.5 1.0\\n- = ,. \"4: a 5.2 WS )relative position in encoder ftZ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Given Vzhledem. the average attention available\\n- dostup-weight by position in Heads divide the C 0.2 or 0.05 relative position in encoder ftZ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Summary: Proposed NMT architecture combining the benefit of attention and one vector representing the whole sentence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Summary: Proposed NMT architecture combining the benefit of attention and one vector representing the whole sentence.\\nEvaluated the obtained sentence embeddings using a wide range of \"semantic\" tasks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Summary\\nProposed NMT architecture combining the benefit of attention and one vector representing the whole sentence.\\n\\nEvaluated the obtained sentence embeddings using a wide range of \"semantic\" tasks.\\n\\nThe better the translation, the worse performance in \"meaning\" representation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Summary\\n- Proposed NMT architecture combining the benefit of attention and one vector representing the whole sentence.\\n- Evaluated the obtained sentence embeddings using a wide range of semantic tasks.\\n- The better the translation, the worse performance in meaning representation.\\n- Heads divide sentence equidistantly, not logically."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Summary\\n\\nProposed NMT architecture combining the benefit of attention and one vector representing the whole sentence.\\n\\nEvaluated the obtained sentence embeddings using a wide range of \"semantic\" tasks.\\n\\nThe better the translation, the worse performance in\\n\\nJoin our JNLE Special Issue on Sentence Representations: http://ufal.mff.cuni.cz/jnle-on-sentence-representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "InferSent multi-task training (in OC's thesis only) idea: produce better representations by jointly training NMT with other tasks.\\n\\nProxy: predict InferSent embeddings as the auxiliary task.\\n\\nNMT, target encoder: decoder sentences source W,bsentence = L Lit 4 alse InferSent fuse."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Multi-task training results\\n\\ncs-ATTN-ATTN (size 1000, 1 head)\\ncs-ATTN-ATTN (size 1000, 1 head)\\n\\ncs-ATTN-ATTN (size 1000, 4 heads)\\ncs-ATTN-ATTN (size 1000, 4 heads)\\n\\ncs-ATTN-ATTN (size 1000, 8 heads)\\ncs-ATTN-ATTN (size 1000, 8 heads)\\n\\ncs-ATTN-ATTN (size 4000, 4 heads)\\ncs-ATTN-ATTN (size 4000, 4 heads)\\n\\nacs-MAXPOOL (size\\n1000)\\ncs-MAXPOOL (size 1000)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Multi-task training results\\n- en-cscs-ATTN-ATTN (size 1000, 1 head)\\n- cs-ATTN-ATTN (size 1000, 1 head)\\n- cs-ATTN-ATTN (size 1000, 4 heads)\\n- cs-ATTN-ATTN (size 1000, 4 heads)\\n- cs-ATTN-ATTN (size 1000, 8 heads)\\n- cs-ATTN-ATTN (size 1000, 8 heads)\\n- acs-ATTN-ATTN (size 4000, 4 heads)\\n- cs-ATTN-ATTN (size 4000, 4 heads)\\n- scs-MAXPOOL (size\\n1000)\\n- cs-MAXPOOL (size 1000)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Multi-task training results\\n- en-cscs-ATTN-ATTN (size 1000, 1 head)\\n- cs-ATTN-ATTN (size 1000, 1 head)\\n- cs-ATTN-ATTN (size 1000, 4 heads)\\n- cs-ATTN-ATTN (size 1000, 4 heads)\\n- cs-ATTN-ATTN (size 1000, 8 heads)\\n- cs-ATTN-ATTN (size 1000, 8 heads)\\n- eecs-ATTN-ATTN (size 4000, 4 heads)\\n- cs-ATTN-ATTN (size 4000, 4 heads)\\n- cs-MAXPOOL (size\\n1000)\\n- cs-MAXPOOL (size\\n1000)\\n\\nSmall loss in BLEU except,\\nsometimes gain in AVGACC."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Multi-task training results\\n- de-ATTN-ATTN (size 600, 1 head)\\n- de-ATTN-ATTN (size 600, 1 head)\\n- de-ATTN-ATTN (size 600, 8 heads)\\n- de-ATTN-ATTN (size 600, 8 heads)\\n- de-ATTN-ATTN (size 600, 12 heads)\\n- de-ATTN-ATTN (size 600, 12 heads)\\n- de-ATTN-ATTN (size 1200, 12 heads)\\n- de-ATTN-ATTN (size 1200, 12 heads)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Multi-task training results en-de-ATTN-ATTN (size 600, 1 head)\\nde-ATTN-ATTN (size 600, 1 head)\\nesyh ao\\nll25 30 35 62 64\\n\\nde-ATTN-ATTN (size 600, 8 heads)\\nde-ATTN-ATTN (size 600, 8 heads)\\n2ss OF Uv\\n\\nde-ATTN-ATTN (size 600, 12 heads)\\nde-ATTN-ATTN (size 600, 12 heads)\\n\\nde-ATTN-ATTN (size 1200, 12 heads)\\nde-ATTN-ATTN (size 1200, 12 heads)\\n\\nresults less stable (much smaller vocabulary)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Multi-task training results\\n\\nen-de-ATTN-ATTN (size 600, 1 head)\\nde-ATTN-ATTN (size 600, 1 head)\\n\\nGenerally promising. Further exploration of values and datasets needed.\\n\\nen-de-ATTN-ATTN (size 1200, 12 heads)\\nde-ATTN-ATTN (size 1200, 12 heads)\\n- Big loss in BLEU\\n- Small gain in AVQAGCC"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Bibliography\\n\\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.\\n2014. Neural machine translation by jointly learning to align and translate. In ICLR.\\n\\nOndrej Bojar et al.\\n2016. CzEng 1.6: Enlarged Czech-English parallel corpus with processing tools dockered.\\nIn Text, Speech, and Dialogue (TSD), number 9924 in LNAI, pages 231-238.\\n\\nKyunghyun Cho, Bart van Merrienboer, Gaglar Gulgcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio.\\n2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP.\\n\\nAlexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, and Antoine Bordes.\\n2017. Supervised learning of universal sentence representations from natural language inference data. In EMNLP.\\n\\nDavid L. Davies and Donald W. Bouldin. A cluster separation measure.\\nIEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-1:224-227,\\n1979.\\n\\nDesmond Elliott, Stella Frank, Khalil Sima'an, and Lucia Specia.\\n2016. Multi30k: Multilingual English-German image descriptions. CORR, abs/1605.00459.\\n\\nJindrich Helcl and Jindrich Libovicky.\\n2017. CUNI/ System for the WMT17 Multimodal Translation Task."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Bibliography\\n\\nRyan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, and Sanja Fidler.\\n2015. Skip-thought vectors. In NIPS Vol. 2, NIPS'15.\\n\\nMarkus Dreyer and Daniel Marcu.\\n2014. HyTER networks of selected OpenMT08/09 sentences. Linguistic Data Consortium. LDC2014T09.\\n\\nPeng Li, Wei Li, Znhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, and Wei Xu.\\n2016. Dataset and neural recurrent sequence labeling model for open-domain factoid question answering.\\nCoRR, abs/1607.06275.\\n\\nTsung-Yi Lin, Michael Maire, Serge J. Belongie, Lubomir D. Bourdev, Ross B.\\nGirshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence Zitnick.\\n2014. Microsoft COCO: common objects in context. CoRR, abs/1405.0312.\\n\\nZhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio.\\n2017. A structured self-attentive sentence embedding. CoRR, abs/1703.03130.\\n\\nYang Liu, Chengjie Sun, Lei Lin, and Xiaolong Wang.\\n2016. Learning natural language inference using bidirectional LSTM model and inner-attention. CoRR, abs/1605.09090."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Bibliography\\n\\nHolger Schwenk and Matthijs Douze.\\n2017. Learning joint multilingual sentence representations with neural machine translation. CORR, abs/1704.04154.\\n\\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le.\\n2014. Sequence to sequence learning with neural networks. In NIPS.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\\nGomez, Lukasz Kaiser, and Illia Polosukhin.\\n2017. Attention is all you need. In NIPS."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 375,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "An extremely challenging and long-running goal in AI (Charniak 1972; Turner, 1994; Schubert and Hwang, 2000).\\nThe biggest challenge: having commonsense knowledge for the interpretation of narrative events.\\nRequires commonsense reasoning, going beyond pattern recognition and explicit information extraction."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "ROC Stories (Mostafazadeh et al.,\\n2016) A collection of high quality short five sentence stories. Each story:\\n- Is realistic\\n- Has a specific beginning and ending, where something happens in between\\n- Has nothing irrelevant or redundant to the core story\\n\\nStory Title: The Test\\n\\nJennifer has a big exam tomorrow. She got so stressed, she pulled an all-nighter.\\nShe went into class the next day, weary as can be. Her teacher stated that the test is postponed for next week.\\nJennifer felt bittersweet about it."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Story Cloze Test (Mostafazadeh et al.,\\n2016)\\n\\nThe current benchmark for evaluating story understanding and narrative structure learning.\\n\\nStory Cloze Task: Given a context of four sentences, predict the ending of the story, i.e., select from the 'right' and 'wrong' ending choices.\\n\\nJim got his first credit card in college.\\nJim devised a plan; he didn't have a job, so he bought everything on his credit card.\\nAfter he graduated, he had amounted a $10,000 debt. Jim realized that he was foolish to spend so much money.\\n\\nFrom now on we will refer to SCT as SCT-v1.0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Results On SCT-1.0\\n\\nBaseline Results LSDSem'17 and Other Models\\n\\nConstant Choose First 0.513\\ncogcomp Logistic 0.776\\nFrequency 0.520\\nmsap Logistic 0.752\\nN-gram-overlap 0.494\\ntbmihaylov LSTM 0.728\\neens agp ukp BiLSTM 0.717\\nsentiment-Fu\\nSentiment-Last 0.522\\nacol\\nONN gens\\nSkip-thoughts 0.552\\nStein AALS\\nNarrative-Chains-AP 0.478\\nWh eH Ege aoe!\\nNarrative-Chains-Stories 0.494\\nPranav Goel Logistic 0.604\\nDSSM 0.585\\nHuman 1.0\\n\\ncogcomp (UIUC)\\n- Linear classification system that measures a story's coherence based on the sequence of events, emotional trajectory, and plot consistency (includes endings).\\nmsap (UW)\\n- Linear classifier based on language modeling probabilities of the entire story, and linguistic features of only the ending sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Story Ending Biases\\n\\nMostafazadeh et al.\\n(2016) were very careful with the task design, the data collection process, and establishing various baselines.\\n\\nThey sampled from ROC Stories and created Wrong Ending stories through Amazon MTurk. They had an AMT to verify quality.\\n\\nDespite that, Schwartz et al. found stylistic differences between right and wrong endings:\\n- the number of words\\n- n-gram distribution\\n- character n-gram distribution\\n\\nTheir classifier without feeding context achieves 72.4% accuracy on SCT-v1.0!\\nSimilar results were confirmed by other models (Cai et al., 2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Biases in Various AI Datasets\\n\\nFrom NLI to VQA, and now Story Cloze Test, our narrow benchmarks inevitably have data creation artifacts and hence yield biased models."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "The summary of this talk\\n1. Analyzed SCT-v1.0 ending features\\n2. Developed a strong classifier on SCT-v1.0 using only ending features\\n3. Developed a new crowd-sourcing scheme to tackle the ending biases\\n4. Collected a new dataset, SCT-v1.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Statistical Analysis of Endings\\n\\nWe did an extensive analysis comparing the Right Endings and Wrong Ending features:\\n- Token count\\n- Sentiment\\n- Complexity\\n- Token n-grams\\n- Character n-grams\\n- Part of Speech n-grams\\n- Combined Token + POS n-grams\\n\\nAnalysis was done by performing a two sample t-test between token count, sentiment, and complexity count measurements for the n-grams between Right and Wrong Endings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Analysis: Token Count 1200 1000% 800 600 200° = = = = = = p-value = 6.63 x 10^-75 # of Tokens\\n\\nConclusion: Right Endings tend to be longer than Wrong Endings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Analysis: Sentiment Analysis\\n\\nUsed the Stanford Sentiment Analyzer [0-4] and Vader Sentiment Tagger [-1,1].\\n\\nVADER 0.146 0.011 3.48x10^7\\n\\nConclusion:\\n\\nVADER Sentiment score is significant, right endings tend to be more positive than wrong endings.\\nThe most stories would probably yield neutral to positive higher and more concentrated peak around Right Endings wider distribution of Right Endings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Analysis: Syntactic Complexity Measurement\\n\\nshe was a cook in a school cafeteria\\n\\nConclusion: Yngve score was generally more stable and Wrong Endings are more complex than Right Endings.\\n\\nImage from Roark et al. 2014"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Token n-grams 1-5 length stemmed token n-grams, with START token\\n\\nCharacter n-grams 4 character size n-grams\\n\\nPart of Speech n-grams POS tag and bucketed\\n\\nCombined Token + POS n-grams\\n\\nAnalysis:\\n- \"got\" or \"learn\" often in Right\\n- \"decid\" often in Wrong\\n- Wrong frequently have tokens like \"n't\" or \"sn't\"\\n- Right Endings are more likely to feature pronouns (PRP) whereas Wrong Endings are likely to use the proper noun (NNP)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Ending Reg Model A Logistic Regression Model to perform the Story Cloze Test using only the following features extracted from the endings:\\n- Number of tokens\\n- VADER sentiment score\\n- Yngve complexity score\\n- Token-POS n-grams\\n- POS n-grams\\n- Four length character-grams\\n\\nAlso added an L2 regularization penalty and used a grid search for parameter tuning.\\n\\nResults on SCT-v1.0:\\n\\nThe above results indicate the minimum classification accuracy after 10 runs of the Ending Reg Model build and classification."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "The Criteria for the New Dataset\\n\\nThe Right and Wrong Endings should:\\n- Contain a similar number of tokens\\n- Have similar distributions of token n-grams and char-grams\\n- Occur as standalone events with the same likelihood to occur, with topical, sentimental, or emotional consistencies when applicable."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Collecting The New Dataset\\n\\nAfter various rounds of pilot studies, we found the following paradigm to work the best:\\n\\nNew Data Collection Steps:\\n1. Collected 5,000 new five sentence stories with MTurk\\n2. Second AMT round to modify the last sentence to make a non-sensible story.\\nHere, the prompt instructs the workers to make sure:\\n\\na. Wrong Ending makes sense standalone\\n\\nb. The Right and Wrong ending do not differ in # of words by >3\\n\\nc. Changes cannot be as simple as negating the verb\\n3. Third AMT to verify quality\\n\\nThis entire process resulted in creating the Story Cloze Test v1.5 (SCT-v1.5) dataset, consisting of 1,571 stories for each validation and test sets.\\n\\nY VN 4 itoken + POS n-gram char-gram POS n-gram Standard deviation of the word and character n-gram counts, as well as SCT-v1.0 13.9 12.4 16.4 the part of speech (POS) counts, between the right and wrong"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Ending Reg Results\\n\\nSCT-v1.0 Val\\nSCT-v1.0\\nSCT-v1.5 Test\\n\\nTest cogeomp 0.751 0.776 0.608\\n- Classification accuracy for various models on the SCT-v1.0 and SCT-v1.5 datasets."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "The SOTA Models\\n1. LC CY1 jose77 3 07/01/18 0.866382\\n2. Hustle\\nD) 06/07/18 0.850267\\n3. cogcomp 27 04/15/17 0.776056\\n4. msap 8 02/02/17 0.752004\\n\\nIn \"Improving Language Understanding by Generative Pre-Training,\" the model achieves an accuracy of 86.5 on SCT-v1.0!\\n\\nPretrained language model made with Transformer network.\\n\\nTask specific supervised learning approach to classify.\\n\\nInitial results on SCT-1.5 show an accuracy of 81.06% for this model, which suggests a deeper story understanding model that goes beyond leveraging the intricacies of the particular test sets.\\n\\nIn Radford, Alec, et al. \"Improving Language Understanding by Generative Pre-Training.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "In summary, we presented a comprehensive analysis of the stylistic features isolated in the endings of the original Story Cloze Test (SCT-v1.0).\\n- Developed a strong classifier using only the story endings.\\n- Developed a new data collection scheme for tackling the stylistic ending features.\\n- Created a new SCT dataset, SCT-v1.5, which overcomes some of the biases.\\n\\nTakeaways:\\n- The success of our modified data collection method shows how extreme care must be given for sourcing new datasets.\\n- However, as shown in multiple AI tasks, no collected dataset is entirely without its inherent biases and often the biases in datasets go undiscovered.\\n\\nRemember:\\n- There is still a wide gap between system and human performance, on either SCT 1.0 or SCT 1.5."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Next Steps\\n\\nWe believe that evaluation benchmarks should evolve and improve over time and we are planning to incrementally update the Story Cloze Test benchmark.\\nStay tuned for updates on the dataset and SOTA models via http://cs.rochester.edu/nlp/rocstories/.\\n\\nWe expect to release the final dataset, along with reporting the performance of the most recent SCT 1.0 SOTA models on the new dataset, shortly after ACL."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Thanks for your attention! Any questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 68,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Neural Semantic Parsing (NSP) Model used in this work (Dong and Lapata, 2016; Jia and Liang,\\n2016)\\n\\nAndroid_phone_call, Any_phone_call_missed\\n\\nArchive your missed\\n\\nGoogle_drive, calls from Android to\\n- (Spreadsheet name\\nGoogle Drive (LE (L missed) (Formatted_row(...)) (Drivefolder_path IF TTT/Android))\\n\\nInput Sequence\\n\\nSequence Logical Utterance Encoder Decoder Form"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Confidence Modeling is Important\\n\\nMost models always tend to guess some outputs. We also want to know how confident they are.\\n\\nAlexa, buy me something from Whole Foods.\\n\\nAmazon Echo: Always ready, connected, and fast. Just ask.\\n\\nBuying Whole Foods\\n\\nhttp://time.com/4821460/amazon-buying-whole-foods-twitter/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "From the perspective of applications\\n- More reliable decisions\\n- Generate clarification questions to verify the results\\n- Nonlinearity of neural networks\\n- For linear models, p(y|x) & iscoregyidence\\n- Unclear for neural models (Johansen and Socher,\\n2017)\\n- Lack of explicit lexicons or templates\\n- Difficult to trace errors and inconsistencies"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Research Goals\\n\\nEstimate confidence scores for NSP.\\nHigher score -> the prediction is more likely correct.\\n\\nProvide uncertainty interpretations.\\n\\nWhich parts of input contribute to uncertain predictions?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Confidence Estimation\\n- Overview\\n\\nConfidence Score\\n- indicates whether thes(x,\\ny) € (0,1) prediction ytt is likely to be correct\\n\\nLogistic Model\\n\\nConfidence Metrics\\n- Characterize causes of uncertainty\\n\\nUtterance x Prediction y\\n- Android phone call\\n- Archive your missed calls from Android to Google Drive"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "© Model is unconfident about p(y|x)\\n- Model uncertainty\\n\\nUnsure about model parameters or structure\\n\\nData uncertainty\\n\\nOut-of-distribution/-domain examples\\n\\nEstimate p(y|x) reliably, but the entropy is large\\n\\nInput uncertainty\\n\\nInput itself is unspecific/ambiguous, which would lead to several different correct outputs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Model Uncertainty\\n\\nPosterior probability\\n\\nSequence-level: log p(y|x)\\n\\nToken-level: avg{log p(y_|x, Yer)}, min{p(Vex, Yer)}\\n\\nDropout as a Bayesian approximation (Yarin Gal, Zoubin Ghahramani,\\n2016)\\n1. Inject noise to the lexu model multiple times\\n2. Variance |p(y|x, M;)|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Data Uncertainty\\n\\nOut-of-distribution/domain examples\\n\\np(x|D): probability of input\\n\\nKenLM (Heafield et al.,\\n2013) estimated on the training set\\n\\nNumber of unknown words of input"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Input Uncertainty\\n\\nVariance of top candidates var(p(y'|x))\\n\\n\"i i ves variance B B\\n- a Beam Size = B --- -- 28L ff ER feet\\n\\nPLLe Entropy of decoding H[y|x] = -Σy, p(y'|x) log p(y'|x)\\n\\nApproximated by Monte Carlo sampling\\n\\nVex Yeo Yen y2 2 2ye Yeo Yen yk"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Confidence Scoring\\n\\nUse logistic regression to fit F1 scores of outputs\\n\\nLogistic loss: £ = ¥,[y In(1 + e~%) + A\\n- y,) n(1 + e%)]\\n\\nConfidence Score € (0,1)\\n\\ntTree Boosting Model\\n\\nConfidence Metrics\\n- Token-level\\n- Dropout\\n- Probability of input\\n- Variance of topperturbation\\n- Number of candidates\\n- Gaussian noise unknown tokens\\n- Entropy of decoding\\n- Posterior probability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Uncertainty Interpretation\\n\\nTrace prediction uncertainty back to input words.\\nUsers can verify or refine the input quickly.\\nBenefit the development cycle.\\n\\nText me when it's freezing.\\nTemperature: 07"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Uncertainty Backpropagation\\n1) Initialize decoder's output neuron with uncertainty scores\\n2) Backpropagate scores layer-wisely\\n3) Obtain scores uy, for input words\\nUy, Uy yn Yn | aerson | eee CLEpore rye n n n n WnBP ep ererererererere\\nUy, Ug Uy, Ur <S> yy yo Vn (Bach et al., 2015; Zhang et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Uncertainty Backpropagation\\nCyD4 wP1 Ym CyPy Ups Ve.\\nC2Farent(m) irene Child (a) = {P1, P2}\\nscore = {c1, C2}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Uncertainty Backpropagation: contribution ratio (how much backpropagation we backprop from c to\\nm) in view of a1. Scores are backpropagated from child neurons m to child(m)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Uncertainty Backpropagation\\n\\nContribution ratios from parent neurons are normalized to 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Backpropagation Rules\\n\\nFully-connected layers\\n\\nIf p; contributes more to m's value, ratio v, should be larger (i.e., backprop more from m to p;).\\n\\n|W,p3| = 0\\n\\n(W,p, +\\nW) > v = m = o (Gee \"Pt [Wi pi| + |Wip;|m C4P1 wPs vm C4m C2 CP2 Vy, Vy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Experiments IFTTT-style semantic parsing (Quirk et al.,\\n2015)\\n\\n\"Archive your missed calls from Android to Google Drive\"\\n\\nIFEE TRIGGER ACTION\\n- (A) CHANNELS\\n- (B) FUNCTIONS\\n\\nSpreadsheet_name\\nFormatted_row\\nDrivefolder_path\\n\\n(C) PARAMETERS\\n- missed {{OccurredAt}} {{FromNumber}} {{ContactName}}\\n\\nIFTTT Android Python code generation (Yin et al.,\\n2017)\\n\\nfor every key in sorted list of user_settings\\nfor key in sorted(user_settings):"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "a oe eo a rw at [ie = we FConfidence Estimation Spearman p correlation (€ [-1,1]) between confidence score and F1 score IFTTT Python\\n\\n0.793 0.7 0.85 0.625\\n\\n0.6\\n\\n0.75\\n\\n0.5 0.477\\n\\n0.6945\\n\\n0.4\\n\\n0.65\\n\\n0.3\\n\\n0.6\\n- \" Posterior Conf \" Posterior Conf"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Confidence Estimation\\n\\nConfidence scores are used as a threshold to filter out uncertain examples.\\n\\nIFTTT 0.7\\nME POSTERIOR\\nMa Conv\\nS 0.6\\nWN i\\n100% 90% 80% 70% 60% 50% 40% 30%\\nProportion of Examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Importance of Confidence Metrics\\n\\nModel Uncertainty\\nData Uncertainty\\nInput Uncertainty"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Uncertainty Interpretation Agreement of top-4 uncertain input words Between model prediction and gold standard IFTTT Python 0.8 0.791 0.788 st 0.75 0.737 & 0.7 0.684 o=>© 0.65 0.6, Attention TM BackProp"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Examples\\n- IFTTT ATT: attention; BP: uncertainty backpropagation\\n\\ngoogle_calendar\\n- any_event_starts THEN facebook\\n- create_a_status_message\\n- (status_message({description}))\\n\\nATT post calendar event to facebook\\n\\nBP post calendar event to facebook\\n\\nfeed\\n- new_feed_item\\n- (feed_url(_url_sports.espn.go.com)) THEN ...\\n\\nATT espn mlb headline to readability\\n\\nBP espn mlb headline to readability\\n\\nweather\\n- tomorrow's_low_drops_below\\n- ((temperature(0)) (degrees_in(c))) THEN ...\\n\\nATT warn me when it's going to be freezing tomorrow\\n\\nBP warn me when it's going to be freezing tomorrow"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Thanks! Q&A Code Available: http://nomepages.inf.ed.ac.uk/s1478528"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 180,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Creativity: Can machine learning models be creative? Can these models compose novel and interesting narratives?\\nCreativity is a hallmark of intelligence\\n- it often involves blending ideas from different domains. We focus on sonnet generation in this work."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Sonnets\\nShall I compare thee to a summer's day?\\nThou art more lovely and more temperate:\\nRough winds do shake the darling buds of May,\\nAnd summer's lease hath all too short a date:\\n\\nA distinguishing feature of poetry is its aesthetic forms, e.g. rhyme and rhythm/meter.\\nRhyme: {day, May}; {temperate, date}.\\nStress (pentameter): S~ S*5~ S* S~ St S~ St S~ §*\\nShall I compare thee to a summer's day?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Modelling Approach: We treat the task of poem generation as a constrained language modelling task.\\nGiven a rhyming scheme, each line follows a canonical meter and has a fixed number of stresses.\\nWe focus specifically on sonnets as it is a popular type of poetry (sufficient data) and has regular rhyming (ABAB, AABB or ABBA) and stress pattern (iambic pentameter).\\nWe train an unsupervised model of language, rhyme and meter on a corpus of sonnets."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Sonnet Corpus\\n\\nWe first create a generic poetry document collection using the GutenTag tool, based on its inbuilt poetry classifier.\\n\\nWe then extract word and character statistics from Shakespeare's 154 sonnets.\\n\\nWe use the statistics to filter out all non-sonnet poems, yielding our sonnet corpus.\\n\\nPartition\\n- #Sonnets\\n- #Words\\n\\nTrain 2685 367K\\nDev 335 46K\\nTest 335 46K"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Model Architecture\\n- Language model\\n- Pentameter model\\n- Rhyme model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Language Model (LM) is a variant of an LSTM encoder-decoder model with attention.\\n\\nEncoder encodes preceding contexts, i.e. all sonnet lines before the current line.\\n\\nDecoder decodes one word at a time for the current line, while attending to the preceding context.\\n\\nPreceding context is filtered by a selective mechanism.\\n\\nCharacter encodings are incorporated for decoder input words.\\n\\nInput and output word embeddings are tied."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Pentameter Model (PM)\\n\\nPM is designed to capture the alternating stress pattern.\\nGiven a sonnet line, PM learns to attend to the appropriate characters to predict the 10 binary stress symbols sequentially.\\n\\nAttention Prediction\\n\\nShall | compare thee to a summer's day? S\\nShall | compare thee to a summer's day? S\\nShall | compare thee to a summer's day? S\\nShall | compare thee to a summer's day? S\\nShall | compare thee to a summer's day? S\\nShall | compare thee to a summer's day? S"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Pentameter Model (PM)\\n\\nPM fashioned as an encoder-decoder model.\\n\\nEncoder encodes the characters of a sonnet line.\\n\\nDecoder attends to the character encodings to predict the stresses.\\n\\nDecoder states are not used in prediction.\\n\\nAttention networks focus on characters whose position is monotonically increasing.\\n\\nIn addition to cross-entropy loss, PM is regularised further with two auxiliary objectives that penalise repetition and low coverage."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Pentameter Model (PM)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Rhyme Model: We learn rhyme in an unsupervised fashion for 2 reasons:\\n- Extendable to other languages that don't have pronunciation dictionaries.\\n- The language of our sonnets is not Modern English, so contemporary pronunciation dictionaries may not be accurate.\\n\\nAssumption: rhyme exists in a quatrain.\\n\\nFeed sentence-ending word pairs as input to the rhyme model and train it to separate rhyming word pairs from non-rhyming ones."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Rhyme Model Shall compare thee to a summer's day?\\n\\nThou art more lovely and more temperate:\\n\\nRough winds do shake the darling buds of May,\\n\\nAnd summer's lease hath all too short a date:\\n\\nQ = {cos(U;, U,), cos(U;y, U,+1), cos(U, U-+2)}\\n\\nLim = max(0, 5\\n- top(Q,\\n1) + top(Q, 2))\\n\\ntop(Q,\\nk) returns the k-th largest element in Q.\\n\\nIntuitively the model is trained to learn a sufficient margin that separates the best pair from all others, with the second-best being used to quantify all others."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Joint Training: All components trained together by treating each component as a sub-task in a multi-task learning setting.\\n\\nAlthough the components (LM, PM and RM) appear to be disjointed, shared parameters allow the components to mutually influence each other during training.\\n\\nIf each component is trained separately, PM performs poorly."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Evaluation: Crowdworkers are presented with a pair of poems (one machine-generated and one human-written), and asked to guess which is the human-written one.\\n- LM: vanilla LSTM language model;\\n- LM**: LSTM language model that incorporates both character encodings and preceding context;\\n- LM**+PM+RM: the full model, with joint training of the language, pentameter and rhyme models."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Evaluation: Crowdworkers\\n\\nModel Accuracy\\nLM 0.742\\nLM* 0.672\\nLM**+PM+RM 0.532\\nLM**+RM 0.532\\n\\nAccuracy improves LM < LM** < LM**+PM+RM, indicating generated quatrains are less distinguishable.\\n\\nAre workers judging poems using just rhyme? Test with LM**+RM reveals that's the case.\\n\\nMeter/stress is largely ignored by laypersons in poetry evaluation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Evaluation:\\n\\nExpert Model Meter Rhyme Read.\\nEmotion LM 4.00 + 0.73 1.57 40.67 2.77 + 0.67 2.73 + 0.51\\nLM** 4.07 41.03 1.53 + 0.88 3.10 + 1.04 2.93 + 0.93\\nLM** + PM + RM = 4.10 + 0.91 4.43 40.56 2.70 40.69 2.90 + 0.79\\n\"Human\\n- 3.87 £ 1.12 4.10 41 35 ~ 4.80 £ 0.48° 4.37 40.71\\n\\nA literature expert is asked to judge poems on the quality of meter, rhyme, readability and emotion.\\n- Full model has the highest meter and rhyme ratings, even higher than human, reflecting that poets regularly break rules.\\n- Despite excellent form, machine-generated poems are easily distinguished due to lower emotional impact and readability.\\n- Vanilla language model (LM) captures meter surprisingly well."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Summary: We introduce a joint neural model that learns language, rhyme, and stress in an unsupervised fashion.\\nWe encode assumptions we have about the rhyme and stress in the architecture of the network.\\n\\nModel can be adapted to poetry in other languages.\\n\\nWe assess the quality of generated poems using judgments from crowdworkers and a literature expert.\\n\\nOur results suggest future research should look beyond forms, towards the substance of good poetry.\\n\\nCode and data: https://github.com/jhlau/deepspeare"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Untitled\\n\\nIn darkness to behold him, with a light and him was filled with terror on my breast and saw its brazen ruler of the night but, lo!\\nit was a monarch of the rest."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 11,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Knowledge Graphs (KG)\\n\\nRelations\\n\\nEntities:\\n- Argentina National Football Team\\n- Lionel Messi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Knowledge Graphs (KG)\\n- Example KGs: Freebase, Yago, OpenCyc, DBpedia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Knowledge Graphs (KG)\\n- Example KGs\\n- Applications\\n- DBpedia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Knowledge Graphs (KG)\\n- Example KGs\\n- Applications\\n- Search\\n- DBpedia\\n- IBM Watson"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "KG Embeddings\\n- Represents entities and relations as vectors in a vector space = e plays FO! eoR\\n- TransE. Translating Embeddings for Modeling Multi-relational Data, Bordes et al."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "KG Embeddings\\n- Represents entities and relations as vectors in a vector space.\\n- Adds & plays for modeling multi-relational data, Bordes et al. NIPS 2013."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Geometry of Embeddings\\n\\nArrangement of vectors in the vector space.\\n\\nMean (M)\\nMean (M)\\nO <= O 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Geometry of Embeddings\\n\\nA recent work by (Mimno and Thompson, 2017): presented an analysis of the geometry of word embeddings and revealed interesting results.\\nHowever, geometrical understanding of KG embeddings is very limited, despite their popularity.\\n1. The strange geometry of skip-gram with negative sampling, Mimno and Thompson, EMNLP 2017."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Problem\\n- Study the geometrical behavior of KG embeddings learnt by different methods.\\n- Study the effect of various hyper-parameters used during training on the geometry of KG embeddings.\\n- Study the correlation between the geometry and performance of KG embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "KG Embedding Methods Learns d-dimensional vectors for entities € and relations R in a KG."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "KG Embedding Methods\\n- Learns d-dimensional vectors for entities € and relations R in a KG.\\nA score function o : EXRXEDR distinguishes correct triples T from incorrect triples T.\\nFor example, o(Messi, plays-for-team, Barcelona) > o(Messi, plays-for-team, Liverpool)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "KG Embedding Methods\\n- Learns d-dimensional vectors for entities € and relations R in a KG.\\nA score function o: EXRXEDR distinguishes correct triples T from incorrect triples T.\\nFor example, o(Messi, plays-for-team, Barcelona) > o(Messi, plays-for-team, Liverpool). A loss function L(t\",\\nT) is used for training the embeddings (usually logistic loss or margin-based ranking loss)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "KG Embedding Methods\\n- ANALOG\\n- TransH\\n- TransG\\n- TKE\\n- eDistMult\\n- NinK\\n- KOOL\\n- STrans\\n- Esspy\\n- RESCAL\\n- I'd\\n- I\\n- S\\n- SEHolk\\n- PTransk\\n- Ti\\n- BR\\n- ams\\n- TransD\\n- ComplEx\\n- web\\n- ans\\n- CTransR\\n- DARL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "KG Embedding Methods\\n- Additive Methods:\\no(h, r,\\nt) = -||M_ph + r\\n- M_t,*\\n- Multiplicative Methods:\\no(h, r,\\nt) = r ! f(h,\\nt)\\n- Neural Methods"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "KG Embedding Methods\\n\\nType Score Function\\n\\nTransE (Bordes et al.,\\n2013)\\n- |h + r\\n- t|,\\nAdditive\\n\\nTransR (Lin et al.,\\n2015)\\n- ||M\\n- h + r\\n- M, t|,\\nS\\n\\nTransE (Nguyen et al.,\\n2016)\\n- ||! h + r\\n- M;? t||\\n\\nDistMult (Yang et al.,\\n2014)\\n- r' (h o\\nt)\\nMultiplicative\\n\\nHolE (Nickel et al.,\\n2016)\\n- r' (h x\\nt)\\n\\nComplEx (Trouillon et al.,\\n2016)\\n- Re(r' (h © t)) ©\\nEntry-wise product\\n\\n* Circular correlation *"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Geometrical Metrics\\n\\nAverage Vector Length\\nAVL(V) = 1/|V| Σ v ∈ V ||v||"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Geometrical Metrics\\n\\nAverage Vector Length\\nAVL(V) = ||V||\\n\\nAlignment to Mean\\nATM(v,\\nV) = cosine(⟨v, V⟩)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Geometrical Metrics\\n\\nConicity\\n\\nConicity (V) = iv] S_ATM(v,\\nV) veEeV"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Geometrical Metrics\\n\\nConicity\\nConicity(V) = 5 S_ATM(v,\\nV) | | ve ∈ V\\n- Vector Spread\\nVS(V) = wi Ss(sratiy,\\nv)\\n- Conise) v ∈ V"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Geometry of Embeddings\\n\\nHigh Conicity Mean (M)\\n\\nLow Conicity Mean (M)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Experiments\\n- We study the effect of the following factors on the geometry of KG Embeddings\\n- Type of method (Additive or Multiplicative)\\n- Number of Negative Samples\\n- Dimension of Vector Space\\n- We also study the correlation of performance and geometry.\\n- For experiments, we used the FB15k dataset."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "TransE\\nTransR\\nConicity = 0.09\\nConicity = 0.11\\nfz = 3°!\\n\\n3Cd of i\\n- c\\n1Oo gOo\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\nAlignment to Mean (ATM)\\n\\nAlignment to Mean (ATM)\\nAlignment to Mean (ATM)\\n\\n(a) Additive Models\\n- DistMult\\n- HolE\\n- Comp\\n1EXw\\nConicity = 0.30\\nConicity = 0.42\\nConicity = 0.21\\n- 9\\n- 6\\n- 9\\n- 2ar\\n- 6\\n- 3a\\n- 8Ss:\\n- 3\\n- 2\\n- 3\\n- 3\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\n- 1.0\\n- 0.5\\n0.0\\n0.5\\n1.0\\nAlignment to Mean (ATM)\\n\\nAlignment to Mean (ATM)\\nAlignment to Mean (ATM)\\n\\n(b) Multiplicative Models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "TransE TransR STransE3\\n\\nConicity = 0.05!\\nConicity = 0.1!\\n\\nConicity = 0.05\\n- BS 8\\n- Alignment to Mean (ATM)\\n- Alignment to Mean (ATM)\\n- Alignment to Mean (ATM)\\n\\n(a) Additive Models\\n- DistMult\\n- HolE\\n- ComplEx\\n\\nConicity = 10.30\\nConicity = 0.462\\nConicity = 0.47\\n- Alignment to Mean (ATM)\\n- Alignment to Mean (ATM)\\n- Alignment to Mean (ATM)\\n\\n(b) Multiplicative Models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Additive vs Multiplicative"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Effect of #Negative Samples (Entity Vectors)\\n- TransE\\n- STransE\\n- OX\\n- HolE\\n- TransR\\n- OIXN\\n- DistMult\\n- YF\\n- Compl-Ex\\n\\n#NegativeSamples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Effect of Negative Samples (Entity Vectors) = TransE, STransE, VOX, HolE, TransR, DistMult, ComplExer\\n\\nan = 0.8\\n\\nAdditiveSX, QS, FZYen, SX, oSi > 0.6\\n\\nS < 0.2\\n\\n#NegativeSamples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Effect of #Negative Samples (Entity Vectors) = TransE STransE VOX HolE +4 TransR OOX DistMult YX ComplEx2 $3s0.8 8 S a7 Multiplicativesx\\n- ee > 0.6 os ie2 iy SSU ui\\n- 'J = ox be5 0.4 ° Ss aU Se en S25- ee, eeS ee oesoO ee\\n- x0.2 S ee oe© ee ee- 2\\n- ee, oe7\\n- Q TT x\\n- SS0.0 rz\\n- x SS\\n- XQ a Xx.\\n- 1\\n- 50\\n- 100\\n- 35 #NegativeSamples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Effect of Negative Samples (Entity Vectors) = TransE, STransE, VOX, HolE, TransR, DistMult, ComplEx\\n\\nNo change"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Effect of #Negative Samples (Entity Vectors) = TransE\\nSTransE\\nOVS\\n_HolE\\n+4\\nTransR\\nOOX\\nDistMult\\nYX\\nComplExo,\\no,\\nQ\\nQ0.8\\nx S36\\n-x SS\\n\\nAdditive\\nro,\\nQ\\no,\\n5.0.6\\n5\\nS°\\nNo change\\noS\\nSSU\\nen\\nSS_\\nXS\\nSSc\\nx iUO.\\n-\\n- ae\\n< SS\\naS\\n\\nMultiplicative\\n~ x\\nae0.2\\n- x\\nConicity Increases°\\nee\\nOS =\\noO\\n- XS\\n- SS7\\n\\n<2\\nHH\\n|| Qse\\nHH\\n|| INS8es0.0\\n= x\\na SS\\na\\nXs°\\n1\\n50\\n100\\na#NegativeSamples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Effect of Negative Samples (Entity Vectors) = TransE STransE HolE TransR DistMult ComplEx :f Z Additive Sw No change\\n- # NegativeSamples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Effect of Negative Samples (Entity Vectors) = TransE, STransE, VOX, HolE, TransR, OOX, DistMult, ComplEx.\\n- No change\\n- AVL decreases"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Effect of Negative Samples\\nNo Change\\nNo Change\\nAdditive\\nNo Change\\nNo Change\\nMultiplicative Relation Decreases\\nNo Change\\nexcept HolE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "SGNS (Word2Vec?) as Multiplicative Model\\n- Similar observation was made by (Mimno and Thompson,\\n2017) for SGNS based word embeddings where higher # negatives resulted in higher conicity.\\n\\nWord2Vec maximizes word and context vector dot product for positive word-context pairs.\\n\\nThis behavior is consistent with that of multiplicative models.\\n1. Distributed representations of words and phrases and their compositionality, Mikolov et al. NIPS 2013\\n2. The strange geometry of skip-gram with negative sampling, Mimno and Thompson, EMNLP 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Effect of\\n\\n# Dimensions (Entity Vectors) = TransE, STransE, OOS, HolE, TransR, ON, DistMult, YX, ComplEx, Additive\\n\\n20.3 No change\\n0.2\\n0.1\\n0.0\\n50\\n100\\n200\\n\\n# Dimensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Effect of #Dimensions (Entity Vectors) = TransE\\nhl STransE\\nVOS\\nHolE\\n+4\\nTransR\\nOOX\\nDistMult\\nYX\\nComplEx\\nQ 20.4\\nQ ss: x 5\\nAdditive Q\\nQ >\\nx No change\\npo 0.3\\nx os Keo\\n-\\n\"$ oo2\\n-\\n< <<5 0.2 ;\\n5 %3:\\nQ QOUO.\\n- ope gs'\\nSS aS\\nMultiplicative 2\\nQ 2 a0.1]\\nKH, =\\nS HH\\nNSS\\nConicity decreases\\noH '2\\nHH\\nRWS\\nFH | |\\nKASSBINS,\\nSHINS\\nSHINS\\n0.\\ngL Se PAU\\nSO,\\nSHH\\n50\\n100\\n200.\\n#Dimensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Effect of Dimensions (Entity Vectors) = TransE, STransE, HolE, TransR, DistMult, ComplEx, AdditiveG\\n\\nNo change"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Effect of #Dimensions (Entity Vectors) = TransE, STransE, VOX, HolE, TransR, DistMult, ComplExSu\\n\\nNo change\\n\\nIncreases\\n\\n#Dimensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Effect of\\n\\n#1 Dimensions. No Change\\nNo Change\\nAdditive\\nNo Change\\nNo Change\\nMultiplicative"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- ComplEx (N=50)\\n- ComplEx (N=100)\\n- DistMult (N=50)\\n- STransE (N=1)\\n- DistMult (N=100)\\n- TransE (N=1)\\n- TransR (N=1)\\n- ComplEx (N=1)\\n- HolE (N=1)\\n- BTransR (N=50)\\n- Mult (N=1)\\n- mTransR (N=100)\\n- HolE (N=100)\\n- Holb (N=250)\\n\\n0.2\\n0.4\\n0.6\\n0.8\\n1 Conicity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Correlation b/w Geometry and Performance\\n\\ne@ComplEx(N=50)\\neComplEx(N=100)\\nDistMult(N=50)\\nSTransE(N=1)\\nDistMult(N=100)\\ngTrankE(N=1)\\nAdditive\\nBTranskR(N=1)\\nID\\nHolE(N=1)\\nMB\\nansAIN=50)\\npistmult(N=1)\\nmTrangr(N=100)\\nGana\\nHolE(N=100)\\nHOIL(N=50)\\n\\n0.2\\n0.4\\n0.6\\n0.8\\nConicity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- ComplEx (N=50)\\n- ComplEx (N=100)\\n- DistMult (N=50)\\n- STransE (N=1)\\n- DistMult (N=100)\\n- TransE (N=1)\\n- BTransR (N=1)\\n- ComplEx (N=1)\\n- HolE (N=1)\\n- BTransR (N=50)\\n- Mult (N=1)\\n- MTransR (N=100)\\n\\nHolE performs badly with higher negatives: 0.2, 0.4, 0.6\\n\\nConicity -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- ComplEx(N=50)\\n- ComplEx(N=100)\\n- DistMult(N=50)\\n- Negative Slope\\n- Negative Correlation\\n- DistMult(N=100)\\n- ComplEx(N=1)\\n- DistMult(N=1)\\n\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nConicity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Correlation b/w Geometry and Performance\\nComplEx(N=50) = 85\\nComplEx(N=100)\\nDistMult(N=50)\\nNegative Slope = -7\\nNegative Correlation\\nDistMult(N=100)\\nHigher Negatives = -5\\nHigher Slope = 5\\nComplEx(N=1)\\nMagnitude = 0.0\\nDistMult(N=1)\\n0.0\\n0.2\\nConicity\\n0.8\\n1.0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- eComplEx(N=50)\\n- eComplEx(N=100)\\n- eDistMult(N=50)\\n- eDistMult(N=100)\\n- TransE(N=1)\\n- TransR(N=1)\\n- HolE(N=1)\\n- ComplEx(N=1)\\n- TransR(N=50)\\n- DistMult(N=1)\\n- TransR(N=100)\\n- HolE(N=100)\\n- HolE(N=50)\\n\\nAvg Vector Length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- eComplEx(N=50)\\n- eComplEx(N=100)\\n- e@DistMult(N=50)\\n- Geo\\n- STrapsE(N=1)\\n- eDistMult(N=100)\\n- Additive and T N=1\\n- Lr Siransi Naa\\n- HolE\\n- HolE(N=1)\\n- ComplEx(N=1)\\n- U\\n- BTronsR@50\\n- DistMult(N=1)\\n- mtransR(N=100)\\n- HglE(N=100)\\n\\nAvg Vector Length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- ComplEx (N=100)\\n- DistMult (N=50)\\n- Positive Slope\\n- Positive Correlation\\n\\nDistMult (N=100)\\nComplEx (N=1)\\nDistMult (N=1)\\n\\nAvg Vector Length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- ComplEx (N=100)\\n- DistMult (N=50) Positive Slope\\n- Positive Correlation\\n- DistMult (N=100)\\n- Higher Negatives\\n- Higher Slope\\n- ComplEx (N=1)\\n- Magnitude\\n- DistMult (N=1)\\n- Avg Vector Length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Correlation b/w Geometry and Performance\\n- Additive: No correlation between geometry and performance.\\n- Multiplicative: For fixed number of negative samples,\\n- Conicity has negative correlation with performance.\\n- AVL has positive correlation with performance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Conclusion and Future Works\\n- We initiated the study of geometrical behavior of KG embeddings and presented various insights.\\n- Explore whether other entity/relation features (e.g. entity category) have any correlation with geometry.\\n- Explore other geometrical metrics which have better correlation with performance and use it for learning better KG embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Acknowledgements\\n- We thank Google for the travel grant for attending ACL\\n2018.\\n- We thank MHRD India, Intel, Intuit, Google and Accenture for supporting our work.\\n- We thank the reviewers for their constructive comments."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Thank you"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Effect of Negative Samples (Relation Vectors)\\n- TransE\\n- STransE\\n- OVS\\n- HolE\\n- TransR\\n- OOX\\n- DistMult\\n- YX\\n- ComplEx\\n- SZ\\n- Rx\\n- Additive N\\n\\nNo change"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Effect of Negative Samples (Relation Vectors) == TransE\\nSTransE\\nOVS\\nHolE\\n4\\nTransR\\nOOX\\nDistMult\\nYX\\nComplExSZ\\nRx0.4\\nmr\\n- Additive\\n4%\\nY\\nS\\n\"i; No change\\n20.3\\n\"y\\nN\\nZ\\nN\\naic\\nx\\nYY\\nyy\\nWeg°?\\n%\\nSZ\\nN\\n7\\nae. iw :\\nMultiplicative\\n0.1\\nx\\n<\\nx\\nConicity decreases\\n<\\n5\\nxa0\\n1\\n50\\n100\\n- Negative Samples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Effect of #Negative Samples (Relation Vectors) = TransE, STransE, HolE, TransR, DistMult, ComplEx = 20 x SSA x Additive M45, 2 S35.\\nNo change.\\n\\n#Negative Samples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Effect of #Dimensions (Relation Vectors) = TransE, STransE, OOS, HolE, TransR, ON, DistMult, YX, ComplEx, 0.50, 0.4, Additive Ses, No change, ¥, 0.3, a]c6, 0.20, 0.10, 0.0, 50, 100, 200 .#Dimensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Effect of #Dimensions (Relation Vectors) = TransE\\nlittl STransE OVS\\n_HolE + 4 TransR OOX\\nDistMult YX\\nComplEx 0.5 aRa\\n~ \" g 2 , 0.4 X\\n\" i S i \" y\\nAdditive > x N Vs : @ No change © 0.3 < 2 x 5 \" eo\\n- < % 5 % x S02 y O. x %\\nMultiplicative 0.1 Se x s %\\nConicity decreases 2 3 a % oe ss 0.0 = x a SS a Xs 50 100 200\\n\\n#Dimensions -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Effect of\\n\\n# Dimensions (Relation Vectors) = TransE STransE VOX HolE +4 TransR OOX DistMult YX ComplExPa5 G .5\\n- Additive\\n- No change\\n\\n# Dimensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Effect of\\n\\n# Dimensions (Relation Vectors) = TransE, STransE, VOX, HolE, TransR, DistMult, ComplEx, Additive, Multiplicative\\n\\nIncreases"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 334,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Writing Systems: Hierarchy, Abugida, Ausphonogram, Coef, Abjad"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Writing Systems: Population 10° 1068 logogram, syllabic\\n- y abugida 109 abjad 10°"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Writing Systems: How to Input\\nLogogram\\nSyllabic\\nAbugida\\nAlphabet & Abjad\\n\\nKeyboard\\nKeyboard Input method\\nVvv 102\\n- 10 symbols\\n20\\n- 40 symbols"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Writing Systems: How to Input\\nLogogram\\nSyllabic\\nAbugida\\nAlphabet & Abjad\\nKeyboard\\nInput method\\nSymbols 50-70\\n20\\n- 40 symbols"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Motivation of This Study\\n- Can abugidas be inputted more efficiently?\\n\\nTo insert a light layer of input method.\\n\\nTo type less and to recover automatically.\\n\\nRelated work\\n- Various approaches for Chinese and Japanese.\\n\\nTo take advantage of redundancy in a writing system."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Outline of This Study\\n- Khmer script as an example\\n- Vowel\\n- Consonant character\\n- Abugida simplification\\n- Recovery"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Abugida Simplification\\n- Four Brahmic abugidas\\n- Thai, Burmese (Myanmar), Khmer (Cambodian), and Lao\\n- Based on phonetics / conventional usages > reduced to 21 symbols\\n\\nPy curruran | palaTE, =| DENTAL | ABIL \"a \"fw | cw | S| Ft | ope2 =|\\n5) 3/2) 2 | oeymet Par 2)r iam)\\n2)\\n2) or | mw]\\n2) et) fm i2z)e 7 % | tis)\\n8) MON OS > OOTH | nua aaa saa juaial gy | a jaasama | name au land unlael weal) a sq] awa [ww a] 17 [buttmoo ow cles eq pny goo qise my cog ov 9m v ogafjmav ej m=iToo 2Squ Ae Aw) slos | sau) mM | waves jamscjas wg ue nae it uA MH)\\na) og | tolmai oe jo\\na) ale | es) oom | w |» | 29 jew) ws [y) o)s | 3 [ws/e | 9 | cccltlOOOO OOO oo LoL ° iMisleostoaoGagoeoaas OO POO OO Oo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Abugida Simplification\\n- Khmer script as an example\\n\\nRATNS = ~R + 8 4 + 0N +) + SSTTINN len(\"J T N N\") 4,\\nLeng. = -----> . = = = 66.7% len(\"a os FON t:: Ss\") 6\\nThai  Burmese  Khmer  Lao\\nLeng. 76.0% 74.0% 77.6% 72.8%\\n\\nAround one quarter characters (diacritics) saved"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Recovery Methods\\n- To formulate as a sequential labeling task\\n- However, list-wise search as in conditional random fields is costing\\n- To solve by point-wise classification\\n- Support vector machine (SVM) as a baseline\\n- Recurrent neural network (RNN) as a state-of-the-art method\\n- Setting for the SVM baseline\\n- Linear kernel with N-gram features\\n- Using LIBLINEAR library\\n- Wrapped by the KyTea toolkit"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "RNN Structure and Settings\\n- Bi-gram of graphemes as input\\n- Embedding > Bi-directional LSTM > Linear transform > Softmax\\n- Original writing units as output\\noutput = a tanh\\n- Implemented by DyNet\\n- Trained by Adam\\n- 512-dim\\n- Initial learning rate 0.001\\n- Controlled by a validation set\\n- 128-dim\\n- Multi-model ensemble input"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Experimental Results\\n\\nAsian Lang. Treebank data\\nThai  Burmese  Khmer  Lao\\n20,000 sent., newswire\\n\\nSVM\\n97.2%  96.1%  95.2%  93.1%\\n\\nSVM RNN\\n97.2%  96.3%  95.5%  93.3%\\n\\nUp to 5-gram for TH, KM, LO\\nRNN\\n97.3%  26.476  5.670  a:670\\n\\n7-gram for Burmese RNN\\n97.4%  96.5%  95.6%  93.6%\\n\\nRNN\\n98.8%  98.4%  97.5%  96.6%\\n\\nRNN\\n99.2%  98.8%  98.1%  97.7%\\n\\nEnsemble RNN\\n99.2%  98.9%  98.4%  97.9%\\n\\nTop-N results\\nt: p< 0.01, t: p< 0.001\\nTop-4 is satisfactory\\n- Embedding + bi-LSTM\\n- N-gram features"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Experimental Results:\\n\\nTraining Data Size\\n- 98%\\n- O-TH-SVM\\n- 94%\\n- Singeengonssessono\\n- 8\\n- O-KH-SVM\\n- 77778\\n- O-LO-SVM\\n- 92%\\n- eoo\\n- @\\n- TH-RNNTM 90%\\n- @\\n- MY-RNN 88%\\n- @\\n- KH-RNN 200K\\n- @\\n- LO-RNN\\n\\nNumber of graphemes after simplification -> RNN outperforms SVM, regardless of the training data size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Manual Evaluation\\n- On Burmese and Khmer best results by RNN\\n- Conducted by native speakers\\n- To classify errors into four levels:\\n- acceptable, i.e., alternative spelling\\n- clear and easy to identify the correct result\\n- confusing but possible to identify the correct result\\n- incomprehensible\\n\\nLevel      0     1      2      3\\nBurmese   4.5%  51.0%  42.2%  2.2%\\nKhmer     22.5% 28.5% 16.3% 32.8%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Conclusion and Future Work\\n- Abugidas can be simplified largely and recovered with high accuracy.\\n- Four Brahmic abugidas are investigated.\\n- Simplified into a compact symbol set (around 20 graphemes).\\n- Recovered satisfactorily by standard machine learning methods.\\n- Experimentally show the feasibility to encode abugidas in a lossy manner.\\n\\nFuture work\\n- Language specific investigation.\\n- To integrate dictionary.\\n- To develop practical input method for abugidas."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Thanks for your kind attention"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 95,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Learning under Domain Shift"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Learning under Domain Shift: State-of-the-art domain adaptation approaches"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Learning under Domain Shift\\nState-of-the-art domain adaptation approaches leverage task-specific features"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Learning under Domain Shift: State-of-the-art domain adaptation approaches leverage task-specific features, evaluate on proprietary datasets or on a single benchmark."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Learning under Domain Shift\\nState-of-the-art domain adaptation approaches\\nleverage task-specific features\\nevaluate on proprietary datasets or on a single benchmark\\nOnly compare against weak baselines"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Learning under Domain Shift\\n\\nState-of-the-art domain adaptation approaches leverage task-specific features, evaluate on proprietary datasets or on a single benchmark.\\nOnly compare against weak baselines.\\nAlmost none evaluate against approaches from the extensive semi-supervised learning (SSL) literature."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Revisiting Semi-Supervised Learning Classics in a Neural World"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Revisiting Semi-Supervised Learning Classics in a Neural World: How do classics in SSL compare to recent advances?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Revisiting Semi-Supervised Learning Classics in a Neural World\\n\\nHow do classics in SSL compare to recent advances?\\n\\nCan we combine the best of both worlds?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Revisiting Semi-Supervised Learning Classics in a Neural World\\n\\n> How do classics in SSL compare to recent advances?\\n> Can we combine the best of both worlds?\\n> How well do these approaches work on out-of-distribution data?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Bootstrapping algorithms"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Bootstrapping algorithms\\n- Self-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Bootstrapping algorithms =\\n- Self-training (Co-training)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Bootstrapping algorithms\\n- Self-training\\n- Co-training\\n- Tri-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "- Bootstrapping algorithms\\n- Self-training\\n- Co-training\\n- Tri-training\\n- Tri-training with disagreement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Self-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Self-training\\n1. Train model on labeled data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Self-training\\n1. Train model on labeled data.\\n2. Use confident predictions on unlabeled data as training examples. Repeat."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Self-training variants"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Self-training variants\\nCalibration"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Self-training variants\\nCalibration\\n\\nOutput probabilities in neural networks are poorly calibrated."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Self-training variants\\n\\nCalibration\\n\\nOutput probabilities in neural networks are poorly calibrated.\\n\\nThrottling (Abney, 2007), i.e. selecting the top n highest confidence unlabeled examples works best.\\n\\nOnline learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Self-training variants\\n\\nCalibration\\n\\nOutput probabilities in neural networks are poorly calibrated.\\n\\nThrottling (Abney, 2007), i.e. selecting the top n highest confidence unlabeled examples works best.\\n\\nOnline learning\\n\\nTraining until convergence on labeled data and then on unlabeled data works best."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Tri-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Tri-training\\n1. Train three models on bootstrapped samples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Tri-training\\n1. Train three models on bootstrapped samples.\\n2. Use predictions on unlabeled data for third if two agree."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "e e e fo) ~ iTri-training\\n- Tri-training\\n1. Train three models on bootstrapped samples.\\n2. Use predictions on unlabeled data for third if two agree.\\n3. Final prediction: majority voting\\nCECEx es z= 5\\nTri-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Tri-training\\n1. Train three models on bootstrapped samples.\\n2. Use predictions on unlabeled data for third if two agree.\\n3. Final prediction: majority voting"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "e e e fo) ~ v3 Tri-training\\n- Train three models on bootstrapped samples.\\n- Use predictions on unlabeled data for third if two agree.\\n- Final prediction: majority voting, oYx = = BS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "e e e fo) ~ v3 Tri-training Ae oe: | Tri-training\\n1. Train three models on bootstrapped samples.\\n2. Use predictions on unlabeled data for third if two agree.\\n3. Final prediction: majority voting\\n\\nx = = BS Tri-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Tri-training Veumewith disagreement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Tri-training with disagreement\\n1. Train three models on bootstrapped samples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Tri-training with disagreement\\n- Train three models on bootstrapped samples.\\n- Use predictions on unlabeled data for third if two agree and prediction differs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Tri-training Veumewith disagreement =o -<-Tri-training with disagreement\\n1. Train three models on bootstrapped samples.\\n2. Use predictions on unlabeled data for third if two agree and prediction differs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Tri-training hyper-parameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Tri-training hyper-parameters\\nSampling unlabeled data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Tri-training hyper-parameters\\nSampling unlabeled data\\nProducing predictions for all unlabeled examples is expensive"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Tri-training hyper-parameters\\n- Sampling unlabeled data\\n- Producing predictions for all unlabeled examples is expensive\\n- Sample number of unlabeled examples\\n- Confidence thresholding"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Tri-training hyper-parameters\\n- Sampling unlabeled data\\n- Producing predictions for all unlabeled examples is expensive\\n- Sample number of unlabeled examples\\n- Confidence thresholding\\n\\nNot effective for classic approaches, but essential for our method."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Multi-task Tri-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Multi-task tri-training\\n1. Train one model with 3 objective functions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Multi-task tri-training\\n1. Train one model with 3 objective functions.\\n2. Use predictions on unlabeled data for third if two agree."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Multi-task tri-training\\n1. Train one model with 3 objective functions.\\n2. Use predictions on unlabeled data for third if two agree.\\n3. Restrict final layers to use different representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Multi-task tri-training\\n1. Train one model with 3 objective functions.\\n2. Use predictions on unlabeled data for third if two agree.\\n3. Restrict final layers to use different representations.\\n4. Train third objective function only on 1 pseudo labeled to bridge domain shift."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Multi-task Tri-training (Plank et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Multi-task Tri-training | BiLSTM BiLSTM L. ___ BiLSTM (Plank et al.,\\n2016) es os:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Multi-task Tri-training OOB Abely I/BiLSTM SE ES (Plank et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Multi-task Tri-training SO \" 0000 Y/Y \\l' \\ BiLSTM SE ES (Plank et al.,\\n2016) as Lot"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Multi-task Tri-training Ly = [| W W, [1% orthogonal int (Bousmalis et al., 2016 orth\\n- m, moi F orthogonality constraint (Bousmailis et al.,) ah BiLSTM BiLSTM BiLSTM (Plank et al.,\\n2016) eh | folat-Va | larva WI BiLSTM Jae TRE | W312"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Multi-task Tri-training Ln = WW, orthogonal int (Bousmalis et al.,\\n2016) orthogonality constraint (Bousmalis et al.,\\n2016) BiLSTM BiLSTM BiLSTM (Plank et al.,\\n2016) char larva BiLSTM Jae TRE Loss: L(@) =\\n- log P(y|2) + Lo rthi i,..,n12"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Data & Tasks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Data & Tasks\\n\\nTwo tasks: Domains:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Data & Tasks\\n\\nTwo tasks:\\n\\nDomains:\\n\\nSIG.\\n- Sentiment analysis on Amazon reviews dataset (Blitzer et al, 2006)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Data & Tasks\\n\\nTwo tasks:\\n\\nDomains:\\n- Sentiment analysis on Amazon reviews dataset (Blitzer et al,\\n2006)\\n- POS tagging on SANCL 2012 dataset (Petrov and McDonald, 2012)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Sentiment Analysis Results\\n\\nAvg over 4 target domains:\\n- VFAE*\\n- HB DANN*\\n- G Asym*\\n- Source only\\n- Self-training\\n- Tri-training\\n- Hi Tri-training-Disagr.\\n- Hi MT-Tri* result from Saito et al., (2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Sentiment Analysis Results\\n\\nBFE were significant across different target domains.\\n\\nAvg over 4 target domains:\\n- VFAE*\\n- HB DANN*\\n- G Asym*\\n- Source only\\n- Self-training\\n- Tri-training\\n- Tri-training-Disagr.\\n- MT-Tri*\\n\\nResult from Saito et al., (2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Sentiment Analysis Results\\n\\nAvg over 4 target domains:\\n- VFAE*\\n- HB DANN*\\n- G Asym*\\n- Source only\\n- Self-training\\n- Tri-training\\n- Hi Tri-training-Disag.\\n- Hi MT-Tri.\\n\\n* result from Saito et al. (2017)\\n\\nMulti-task tri-training slightly outperforms tri-training, but has higher variance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "ePOS Tagging Results\\nTrained on 10% labeled data (WSu) = a LR\\nAvg over 5 target domains\\nSource (+embeds)\\nB Self-training\\nTri-training\\nTri-training-Disagr.\\nB MT-Tri"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "ePOS Tagging Results\\n\\nTrained on 10% labeled data (WSu) = OS ne reermerscmmrnoonerced RS ERO > © 89.25 pe nnn © < 88.975 : : Be 88.7 Avg over 5 target domains Source (+embeds) B Self-training Tri-training @ Tri-training\\n- Disagr. B MT-Tri [5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "POS Tagging Results\\nTrained on 10% labeled data (WSU)\\n\\nAvg over 5 target domains\\nSource (+embeds)\\n- Self-training\\n- Tri-training\\n- Tri-training-Disagreement\\n- MT-Tri\\n- Tri-training with disagreement works best with little data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "@POS Tagging Results\\n\\nTrained on full labeled data (WSJ)\\n\\nQD on target domains\\n\\nS 90.5\\n- O < 89.75 ; Sn 89 Avg over 5 target domains\\n\\n@ TnT Mi Stanford * [ Source (+embeds)\\n\\n@ Tri-training\\n\\n@ Tri-training\\n- Disagr.\\n\\nMH MI\\n- Tri * result from Schnabel & Schütze (2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "@POS Tagging Results\\nTrained on full labeled data (WSJ)\\nQD one\\n\\n290.5\\n- SeO < 89.75 ; : ee 89 Avg over 5 target domains\\n@ TnT Mi Stanford * [ Source (+embeds)\\n@ Tri-training\\n@ Tri-training\\n- Disagreements\\nMH MI-Tri * result from Schnabel & Schütze (2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "@POS Tagging Results\\nTrained on full labeled data (WSJ)\\nQD on\\n- average over 5 target domains\\n- TnT\\n- Mi Stanford\\n- Source (+embeds)\\n- Tri-training\\n- Tri-training-Disagr.\\n- MH MI-Tri\\n\\n* result from Schnabel & Schütze (2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "@POS Tagging Results\\n\\nTrained on full labeled data (WSJ)\\n\\nQD onrreeeeereerrrnrnterntetntntetetntetntntanenenetntntananntanatntananenannteananetatntntananaatintinnananaanatatanananeaeneitemeee nnn isnt > © 90.5\\n- aOo < 89.75 ; : : ;\\n- 89\\n\\nAvg over 5 target domains\\n\\n@ TnT Mi Stanford * [ Source (+embeds)\\n\\n@ Tri-training\\n\\n@ Tri-training-Disagr. MH MI-Tri * result from Schnabel & Schtitze (2014)\\n\\nTri-training works best in the full data setting."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "POS Tagging Analysis\\nAccuracy on out-of-vocabulary (OOV) tokens\\n\\n11\\n80\\nYnCc\\n8.25\\n72.5\\nn\\n2\\nS\\nS=\\nOS\\n55\\n65\\nO\\nOo\\n0\\no3°\\n©\\nD2.15\\n675\\n8\\n<<0\\n-S\\noo\\n50\\nAnswers\\nEmails\\nNewsgroups\\nReviews\\nWeblogs\\n©\\nOOV tokens\\n@\\nSrc\\nTri\\nMT-Tri\\n17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "POS Tagging Analysis\\n\\nAccuracy on out-of-vocabulary (OOV) tokens\\n\\nOOV tokens @ Src Tri MT-Tri17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "POS Tagging Analysis\\n\\nAccuracy on out-of-vocabulary (OOV) tokens:\\n\\ngggygprceeeectttecrseeeess QO)nCcB.D were Ml cect ctecectcttnectettnttentneteeneetntnttntnenetntneestneeetseamyststsetntnetcteeseteten smn 795 @D 2S S2 Owe men enreme mercenaries neensnnenenasnnesnntnerenstnerantesemareenescatenaonarilpnecaormceormcanen, SEHO Oo0 Sae ©D<x0 50\\n\\nAnswers\\nEmails\\nNewsgroups\\nReviews\\nWeblogs\\n\\nOOV tokens @ Src Tri MT-Tri17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "ePOS Tagging Analysis\\n\\nAccuracy on out-of-vocabulary (OOV) tokens\\n\\nClassic tri-training works best on OOV tokens."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "e @POS Tagging Analysis\\n\\nAccuracy on out-of-vocabulary (OOV) tokens\\n\\nOOV tokens\\n- Classic tri-training works best on OOV tokens.\\n- MIT-Tri does worse than source-only baseline on OOV."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "POS Tagging Analysis\\n\\nPOS accuracy per binned log frequency\\n(0.018, 0.014, 0.009, 0.005, 0.001)\\n\\n1 2 3 4 5 6 7 8 9 10 11 12 13 14\\n\\nBinned frequency"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "POS Tagging Analysis\\n\\nPOS accuracy per binned log frequency"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "POS Tagging Analysis\\n\\nPOS accuracy per binned log frequency\\n\\nETN Emm cer eee3 )O01 4 Qe percents= e5 0© 0.009 enn eee acre tntnntnntnnnntnntnntnstntntnntnetnnneteet\" .\\n®SB 0.005 JQ fe fen ON ne gage rrr rtntntnernenncntnes od ff C =f\\7oO bd e C<x$09,005 ©0\\n\\n1 2 3 4 5 6 7 8 9 10 141 #12 13° «14\\n\\nBinned frequency© MT-Tri © Tri» Tri-training works best on low-frequency tokens (leftmost bins)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "POS Tagging Analysis\\n\\nAccuracy on unknown word-tag (UWT) tokens\\n\\nUWT rate result from Schnabel & Schutze (2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "es. Difficult CASPOS Tagging Analysis Accuracy on unknown word-tag (UWT) tokens\\n\\nUWT rate M@ Src Tri @ MT-Tri lm FLORS result from Schnabel & Schütze (2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "Sficult 28°. yery att\\nPOS Tagging Analysis\\nDAccuracy on unknown word-tag (UWT) tokens\\n\\n\"A wrnenttnnnnnnnininnnminninninnnnninnsinmnmnnnnninnnnnmninmnnnnnnns DGeca) £Ccg : :5 5» >3 2 8DS<x0\\n\\nAnswers\\nEmails\\nNewsgroups\\nReviews\\nWeblogs©\\n\\nUWT rate M@ Src Tri mM MT-Tri lm FLORS*>\\n\\nNo bootstrapping method works well on unknown word-tag combinations.\\n\\n* result from Schnabel & Schutze (2014)19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "aricutt 025°\"e e very POS Tagging Analysis\\n-\\nAccuracy on unknown word-tag (UWT) tokens by Annette D GenCca\\n\\nUWT rate\\n- No bootstrapping method works well on unknown word-tag combinations.\\n- Result from Schnabel & Schutze (2014)\\n- Less lexicalized FLORS approach is superior."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 83,
        "texts": [
          "Takeaways"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 84,
        "texts": [
          "Takeaways © real » Classic tri-training works best: outperforms recent state-of-the-art methods for sentiment analysis."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 85,
        "texts": [
          "Takeaways:\\n- Classic tri-training works best: outperforms recent state-of-the-art methods for sentiment analysis.\\n- We address the drawback of tri-training (space and time complexity) via the proposed MT-Tri model.\\n- MIT-Tri works best on sentiment, but not for POS."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 86,
        "texts": [
          "Takeaways\\n- Classic tri-training works best: outperforms recent state-of-the-art methods for sentiment analysis.\\n- We address the drawback of tri-training (time complexity) via the proposed MT-Tri model.\\n- MIT-Tri works best on sentiment, but not for POS.\\n- Importance of:\\n- Comparing neural methods to classics (strong baselines).\\n- Evaluation on multiple tasks and domains."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 14,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "eagle oldeOutline@ Introduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "bibhepensenIen Sentence Summarization\\n- Generate a shorter version of a given sentence\\n- Preserve its original meaning\\n- Design or refine appealing headlines"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction\\n\\nSeq2seq Summarization\\n- Require less human efforts\\n- Achieve the state-of-the-art performance\\n\\nOutput\\n\\nENCODER SIM, DECODER\\n\\nInput"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Introduction\\n\\nProblems of Seq2seq Summarization\\n- Solely depend on the source text to generate summaries\\n- Encounter error propagation\\n- Lose control\\n- 3% of summaries < 3 words\\n- 4 summaries repeat a word for 99 times\\n\\nFocus on extraction rather than abstraction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Introduction\\n\\nTemplate-based Summarization\\n\\nA traditional approach to abstractive summarization.\\nFill an incomplete template with the input text using the manually defined rules.\\nBe able to produce fluent and informative summaries.\\n\\nTemplate\\n- [REGION] shares [open/close] [NUMBER] percent [lower/higher]\\n\\nSource\\n- Hong Kong shares closed down #.# percent on Friday due to an absence of buyers and fresh incentives.\\n\\nSummary\\n- Hong Kong shares close #.# percent lower"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Introduction\\n\\nProblems of Template-based Summarization\\n\\nTemplate construction is extremely time-consuming and requires a plenty of domain knowledge.\\nIt is impossible to develop all templates for summaries in various domains."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Introduction\\n\\nMotivation\\n\\nUse actual summaries in the training datasets as soft templates to combine seq2seq and template-based summarization.\\n- Seq2seq: Guide the generation of seq2seq\\n- Template-based: Automatically learn to rewrite from soft templates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Introduction\\n\\nProposed Method\\n\\nSummary: consists of three modules: Retrieve, Rerank and Rewrite.\\n- Use Information Retrieval to find out candidate soft templates from the training dataset (Retrieve).\\n- Extend the seq2seq model to jointly learn template saliency measurement (Rerank) and final summary generation (Rewrite)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Introduction\\n\\nContributions\\n- Introduce soft templates to improve the readability and stability in seq2seq\\n- Extend seq2seq to conduct template reranking and template-aware summary generation simultaneously\\n- Fuse the IR-based ranking technique and seq2seq-based generation technique, utilizing both supervisions\\n- Demonstrate potential to generate diversely"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Method Outline\\nMethod"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "UT aaTeresaren Flow Chat\\n\\nRetrieve\\n\\nSearch actual summaries as candidate soft templates\\n\\nRerank\\n\\nFind out the most proper soft template from the candidates\\n\\nRewrite\\n\\nGenerate the summary based on source sentence and soft template\\n\\nRetrieve\\n\\nRerank\\n\\nRewrite\\n\\nSentence\\n\\nCandidates\\n\\nTemplate\\n\\nSummary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Assumption: Similar sentences, similar summary patterns\\n\\nInput: A sentence\\n\\nPlatform: LUCENE\\n\\nOutput: 30 actual summaries in the training dataset whose sources are the most similar to the input sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "UT aaTeres Jointly Rerank and Rewrite Share encoders 7 Pays Template"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "UT aTerespeer Rerank Retrieve ranks templates according to the text similarity between sentences.\\nRerank finds out the soft template most similar to the actual output summary.\\nModel: Bilinear networks (r,x) = sigmoid(h, Wsh! + bs)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "UT A Tereseeent Rewrite A soft template accords with the facts in the input sentences.\\nUse Seq2seq to generate more faithful and informative summaries.\\nConcatenate the encoders of sentence and template H = [hy; Wy hy; hoy].\\nUse attentive RNN decoder to generate summaries S = Att-RNN(sy-1, ye-1, He)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Meed: Cross Entropy (CE) for Rerank: Negative Log-Likelihood (NLL) for Rewrite: Add the above two costs as the final loss\\n\\nJp(0) = CE(s(r, x), s*(r, y*)) = -s* log(s)\\n- (1-s*) log(1-s)\\n\\nJe(9) = -log(p(y*|x, r)) = -log(p(elvel))\\n\\nJ(9) = J_r(9) + J_e(9)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "euOutline@ Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "a EasyYolo Dataset Gigaword (sentence, headline) pairs\\n\\nFramework OpenNMT\\n\\nDataset Train Dev Test\\n\\nCount 3.8M 189k 1951\\n\\nAvgSourceLen | 31.4 31.7 29.7\\n\\nAvgTargetLen | 8.3 8.3 8.8\\n\\nCOPY(%) 45 46 36"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "eteROUGE Performance\\n\\nReSum significantly outperforms other approaches\\n\\nModel              ROUGE-1   ROUGE-2   ROUGE-L\\nABS               29.55*    11.32*    26.42*\\nABS+              29.78*    11.89*    26.97*\\nFeatseq2seq      32.67*    15.59*    30.64*\\nRAS-Elmani        33.78*    15.97*    31.15*\\nLuong-NMT        33.10*    14.45*    30.71*\\nOpenNMT          35.01*    16.55*    32.42*\\nReSum            37.04     19.03     34.46"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "aac Linguistic Quality Performance: Low LEN_DIF and LESS_3\\n- Stable\\nLow COPY -> Abstractive\\nLow NEW_NE and NEW_UP -> Faithful\\n\\nItem Template OpenNMT Re?Sum\\n\\nLEN_DIF | 2.6426 3.0444 2.7426\\n\\nLESS_3 | 0 53 1\\n\\nCOPY(%) | 31 80 74\\n\\nNEW_NE | 0.51 0.34 0.30\\n\\nNEW_UP | 0.38 0.19 0.11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Effects of Template Performance highly relies on templates. The rewriting ability is strong.\\n\\nType\\nROUGE-1  ROUGE-2  ROUGE-L\\n- Random  32.60  14.31  30.19\\n- First  36.01  17.06  33.21\\n- Max  41.50  21.97  38.80\\n- Optimal  46.21  26.71  43.19\\n- Rerank (ReSum)  37.04  19.03  34.46"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "uaGeneration Diversity OpenNMT Beam search n-best outputs\\n\\nRe®Sum Provide different templates\\n\\nSource ainge said thursday he had two one-hour meetings with the new owners of the boston celtics but no deal has been completed for him to return to the franchise.\\n\\nTarget ainge says no deal completed with celtics\\n\\nTemplates major says no deal with spain on gibraltar\\n\\nroush racing completes deal with red sox owner\\n\\nRe'Sum ainge says no deal done with celtics\\n\\nainge talks with new owners\\n\\nainge talks with celtics owners\\n\\nOpenNMT\\n- ainge talks with new owners"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "fetal) Ps Outline Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "fetal\\nConclusion\\nIntroduce soft templates as additional input to guide seq2seq summarization.\\nCombine IR-based ranking techniques and seq2seq-based generation techniques to utilize both supervisions.\\nImprove informativeness, stability, readability, and diversity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Thank you"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 373,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Current State\\nRNNs are everywhere. We don't know too much about the differences between them:\\nGated RNNs are shown to train better, beyond that:\\n\"RNNs are Turing Complete\"?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "“On the Computational Power of Neural Nets\\nHava T. Siegelmann\\nDepartment of Information Systems Engineering, Technion, Haifa 32000, Israel\\nand\\nEduardo D. Sontag\\nDepartment of Mathematics, Rutgers University, New Brunswick, New Jersey 08903\\nReceived February 4, 1992; revised May 24, 1993"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Turing Complete?\\n\\n1993 Proof:\\n1. Requires Infinite Precision: Uses stack(s), maintained in certain dimension(s)\\nZeros are pushed using division (using g = 9/4 + 1/4)\\nIn 32 bits, this reaches the limit after 15 pushes\\n2. Requires Infinite Time: Allows processing steps beyond reading input\\n(Not the standard use case!) unreasonable assumptions!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "CTuring Complete"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "What happens on real hardware and real use-cases?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Gated architectures have the best performance. LSTM and GRU are most popular.\\nOf these, the choice between them is unclear."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "We accept all RNN types can simulate DFAs.\\n\\nWe show that LSTMs and IRNNs can also count.\\n\\nAnd that the GRU and SRNN cannot."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Power of Counting\\n\\nPractical\\n\\nIn NMT: LSTM better at capturing target length"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Power of Counting\\n\\nPractical\\n\\nIn NMT: LSTM better at capturing target length\\n\\nTheoretical\\n\\nFinite State Machines vs Counter Machines"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "K-Counter Machines (SKCMs)\\nFischer, Meyer, Rosenberg\\n- 1968\\n\\nSimilar to finite automata, but also maintain k counters. A counter has 4 operations: inc/dec by one, do nothing, reset.\\nCounters are observed by comparison to zero."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Counting Machines and Chomsky Hierarchy\\n\\nContext Sensitive Languages (CSL)\\n\\nRecursively Enumerable Languages (RE)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Chomsky Hierarchy and SKCMsnin NnLnAn Palindromes\\n- Context Free Languages (CFL)\\n- Context Sensitive Languages (CSL)\\n- Recursively Enumerable Languages (RE)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Chomsky Hierarchy and SKCMs\\n\\nSKCMs cross the Chomsky Hierarchy!\\n- State et Palindromes\\n- Context Free Languages (CFL)\\n- Context Sensitive Languages (CSL)\\n- Recursively Enumerable Languages (RE)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Summary so far\\n\\nCounters give additional formal power. We claimed that LSTM can count and GRU cannot."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "The counters give additional formal power. We claimed that LSTM can count and GRU cannot. Let's see why."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Popular Architectures\\n\\nGRU\\n\\nLSTM\\n- ti = o(W*x + U*h +\\nb)\\n- ti = o(W*x + U*h +\\nb)\\n- r = o(W'x + U'h +\\nb)\\n- h = tanh(W\"x + U\"(r*h) + b\")\\n- h = o(W®x + U*h) + b\\n- h = z*h + (1\\n-\\nz) * h\\n- C = tanh(Wx + Uh +\\nb)\\n- C = f*C1 + (1\\n- f)*C\\n- h = 0;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "GRU LSTM\\n\\nz = o(W * x + U * h +\\nb)\\nr = o(W' * x + U' * h + b')\\nh = o(W' * x + U' * h + b')\\nh_t = tanh(W' * x + U * (r *\\nh) +\\nb)\\nc_t = tanh(W * h +\\nb)\\n\\nC = f(g_1 +\\nh)\\nc_candidate = w * h\\n\\nUpdate functions:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Popular Architectures\\n\\nGRU LSTM\\n\\nr = (0,1)\\nLa gates\\ni = (0,1)\\nr = (0,1)\\nh = tanh(W\"x + U(r, h_{t-1}) + b\")\\no = (0,1)\\nh = z * h_{t-1} + (1-z) * h_c\\nc = tanh(W°x + U * h_{t-1} + b*)\\n\\nupdate functions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Popular Architectures\\n\\nGRU\\nLSTM\\n\\nre € (0,1)\\nLa gates a I Ee (0,1)\\nr, € (0,1)\\ni, € (0,1)\\nh, € (-1,1)\\n0, € (0,1)\\nh, = z, eh_, + (U\\n-\\nz)\\neh, Cee)\\nMZ C = he\\nGit hee, wy h, = 0,°\\n8(C,) update functions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Popular Architectures: GRU, LSTM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Popular Architectures\\n\\nGRU\\nLSTM\\nz, € (0,1)\\nipl o )r, € (0,1)\\ni, € (0,1)\\nh, € (-1,1)\\nO18 ( | : )\\n|h,=zeh_+(U-z)eh,\\n--= --\\nInterpolation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Popular Architectures\\n\\nGRU\\nLSTM\\n\\nInterpolation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Popular Architectures GRU LSTM, ended! (0,1) any 0, (0,1) (mr eh kare) @ (-1,1) a C= f° Gi the c; Interpolation Addition"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Popular Architectures\\n\\nGRU LSTM.\\n- ade dl i & 1h, €\\n- o, € (0,\\n1)\\n- Se é, € (-1,\\n1)\\n- SO C, 2 Cc, +é, Interpolation\\n\\nAddition Cp = fo Cy + e €,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Popular Architectures\\n\\nGRU\\nLSTM\\n\\nInterpolation Increase by 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Popular Architectures\\n\\nGRU LSTM\\n\\nInterpolation Decrease by 1\\n\\nCp = fo Cy + e"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Popular Architectures GRU LSTM. | aa dl i, & Oh. € (\\n-\\n- 0, € (0,1) == sn AoE é, € (-1.1), = Zz, 0h (l-z) ch, 0 eC. Interpolation Do Nothing Cp = f, °C + 1 -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Popular Architectures GRU LSTM\\n\\nInterpolation Reset Cp = fo Cy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Other Architectures\\n\\nSRNN\\n\\nIRNN\\n\\nh = o(W,x + U,h +\\n5)\\n\\nh = max(0,W,x + U,h + 5)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Other Architectures\\n\\nSRNN\\n\\nIRNN\\n\\nh = 0, (W,\\nx) € (0,\\n1)\\n\\nh = max(0, W, x + U, h +\\nb)\\n\\npounded"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Other Architectures\\n\\nSRNN\\nIRNN h = 0, (W,\\nx) ∈ (0,1)\\nh = max(0, W, x + U, h +\\nb)\\n- reset + 0 / +1 (subtraction in parallel, also increasing counter)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "The LSTM can count! The GRU cannot\\n- Counting gives greater computational power 89"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Empirically Trained ab\", (on positive examples up to length\\n100) Activations on @ 10007, 1000: LSTM GRU 800 a / an -0.50600 0.25\\nAb Ze /_\\ 400 -0.25 -0.750 -1.00. a 0 a on i I 2 Ge tee Aine 0 250 500 750 = = 1000 1250 1500 1750 2000 40"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Empirically Trained ab, (on positive examples up to length\\n100) Activations on 1000p, 1000: LSTM GRU 1000 100 Z ~800 0.75 -X -0.50 a 600 0.25\\n- QI W 400 -0.25 -0.750 SS 7 -1.00.\\na 0 aon i I 2 Ge tee Aine 0 250 500 750 = = 1000 1250 1500 1750 2000 GRU: e Took much longer to train 41"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Empirically Trained ab\", (on positive examples up to length\\n100) Activations on 1000: LSTM GRU 1000 100 Z ~wo 0.75\\n- X = 0.50 also Doe (Sh400 =).25\\n- 0.750\\n- = 7\\n- 1.000 250 500 750 1000 1250 1500 1750 2000 0 250 500 750 1000 1250 1500 1750 2000 GRU:\\n- Took much longer to train\\n- Did not generalise even within training domain\\n- Begin failing at n = 39 (vs 257 for LSTM)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Empirically Trained ab\", (on positive examples up to length\\n100)\\n\\nActivations on 10007, 1000: LSTM GRU 1000 100 rs. _800 a0.50 [al oat 600 0.25\\n- QI W 400 = ). 25200 -0.50 9.750\\n- --1.000 250 500 750 1000 1250 1500 1750 2000 0 250 500 750 1000 1250 1500 1750 2000\\n\\nGRU: e Took much longer to train. Did not generalise even within training domain\\n- begin failing at n=39 (vs 257 for LSTM). 43 e Did not learn any discernible counting mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Empirically Trained \"a\", \"b\", \"c\", (on positive examples up to length\\n50) Activations on 20p 1% 10, LSTM GRU 100 100 80 0.75 7 | 60 0.50 40 0.25 20 0.00 h -20 ae VI 40 0.75 WX EN \"oo s00 eel iene ae 9 aa ae 150 zn an = 0 50 100 150 200 250 300 44"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Empirically Trained \"a b c\", (on positive examples up to length\\n100)\\n\\nActivations on a p 0\\n- 10, LSTM GRU 100 M 100\\n- 80 J O 75\\n- 7 ay 60\\n- 050 BES\\n- y AS oh | a N M ~ 40\\n- 0.75 SS EN r 1.60\\n- aie ~ Yo ad a int am an ae\\n\\n0 50 100 150 200 250 300\\n\\nGRU: Took much longer to train. Did not generalise well\\n- begin failing at n=9 (vs 101 for LSTM)\\n- Did not learn any discernible counting mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Conclusion\\nIRNN\\nLSTM\\nSRNN\\nGRU\\nTrainability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Conclusion\\n\\nPractical\\n\\nExpressivity\\n\\nIRNN\\n\\nLSTM\\n\\nSRNN\\n\\nGRU\\n\\nTrainability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Take Home Message\\n\\nArchitectural Choices Matter! and result in actual differences in expressive power\\n\\nDon't fall in the Turing Tarpit!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Thank You\\n\\nGitHub repository: https://github.com/tech-srl/counting_dimensions\\n\\nGoogle Colab (link through GitHub as well): https://tinyurl.com/ybjkumrz"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 121,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "TOWARDS NATURAL LANGUAGE UNDERSTANDING\\n\\n# WV4.11. Reasoning about Time\\n\\nComputation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "TIME IS IMPORTANT = [June, 1989]\\n\\nChris Robin lives in England and he is the person that you read about in Winnie the Pooh.\\nAs a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem about him.\\nHis father later wrote Winnie the Pooh in\\n1925.\\n\\nQ Where did Chris Robin live? This is time sensitive.\\n\\nQ When was Chris Robin born?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "TIME IS IMPORTANT\\n\\n(June,\\n1989) Chris Robin lives in England and he is the person that you read about in Winnie the Pooh.\\nAs a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem about him.\\nHis father later wrote Winnie the Pooh in\\n1925.\\n\\nQ Where did Chris Robin live?\\n\\nThis is time sensitive.\\n\\nQ When was Chris Robin born?\\n\\npoem\\n\\n[Chris at age 3]\\n\\nBased on text:\\n\\n<=1922 (Wikipedia:\\n1920) Winnie the Pooh [1925]\\n\\nRequires identifying relations between events, and temporal reasoning.\\n\\nQ Temporal relation extraction\\n\\n\"A\" happens BEFORE/AFTER \"B\";\\n\\nEvents are associated with time intervals:\\n\\n[t3:art, tenal, [tart tena]\\n\\n12 temporal relations in every 100 tokens (in TempEval3 datasets)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "TEMPORAL RELATIONS: A KEY COMPONENT\\n\\n\"Temporal Relation (TempRel): / turned off the lights and left.\"\\n\\nChallenges faced by existing datasets/annotation schemes:\\n- Low inter-annotator agreement (IAA)\\n- TB-Dense: Cohen's k 56%~64%\\n- RED: F1<60%\\n- EventTimeCorpus: Krippendorff's a ~ 60%\\n- Time consuming: Typically, 2-3 hours for a single document.\\n\\nOur goal is to address these challenges, and understand the task of temporal relations better.\\n- (Cognitive Computation Group)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "HIGHLIGHTS AND OUTLINE\\n\\nWhat we did:\\n- 276 docs: Annotated the 276 documents from TempEval3\\n- 1 week: Finished in about one week (using crowdsourcing)\\n- $10: Costs roughly $10/doc\\n- 80%: IAA improved from literature's 60% to 80%\\n- Re-thinking identifying temporal relations between events annotation scheme, in order to make it feasible\\n\\nOutline of our approach (3 components)\\n- Multi-axis: types of events and their temporal structure\\n- Start & End points: end-points are a source of confusion/ambiguity\\n- Crowdsourcing: collect data more easily while maintaining a good quality"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "1. TEMPORAL STRUCTURE MODELING: EXISTING ANNOTATION SCHEMES\\n\\n\"Police tried to eliminate the pro-independence army and restore order.\\nAt least 51 people were killed in clashes between police and citizens in the troubled region.\"\\n\\nTask: to annotate the TempRels between the bold faced events (according to their start-points).\\n\\nExisting Scheme 1: General graph modeling (e.g., TimeBank, ~2007)\\n- Annotators freely add TempRels between those events.\\n- It's inevitable that some TempRels will be missed, pointed out in many works.\\n\\nE.g., only one relation between \"eliminate\" and \"restore\" is annotated in TimeBank, while other relations such as \"tried\" is before \"eliminate\" and \"tried\" is also before \"killed\" are missed."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "1. TEMPORAL STRUCTURE MODELING: EXISTING ANNOTATION SCHEMES\\n- (KoeSeo Te Nup bL, Ar. oi \"byte tried to eliminate the pro-independence army and restore order.\\nAt least 51 people were killed in clashes between police and citizens in the troubled region.\\n\\nExisting Scheme 2: Chain modeling (e.g., TimeBank-Dense\\n2014)\\n- All event pairs are presented, one-by-one, and an annotator must provide a label for each of them.\\n- No missing relations anymore.\\n- Rationale: In the physical world, time is one dimensional, so we should be able to temporally compare any two events.\\n- However, some pairs of events are very confusing, resulting in low agreement.\\n- E.g., what's the relation between restore and killed?\\n\\n(Corre Computation Group)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "1. TEMPORAL STRUCTURE MODELING: DIFFICULTY = \"Police tried to eliminate the pro-independence army and restore order.\\nAt least 51 people were killed in clashes between police and citizens in the troubled region.\" = Why is restore vs killed confusing?\\n\\nOne possible explanation: the text doesn't provide evidence that the restore event actually happened, while killed actually happened.\\n\\nSo, non-actual events don't have temporal relations?\\n= \"We don't think so: a tried is obviously before restore: actual vs non-actual.\\na eliminate is obviously before restore: non-actual vs non-actual.\"\\n\\nSo relations may exist between non-actual events.\\nBC orrrve CompuTATION Group\\n- fi\\n- __\\n- ."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "1. MULTI-AXIS MODELING: NOT SIMPLY ACTUAL VS NON-ACTUAL\\n\\n\"Police tried to eliminate the pro-independence army and restore order.\\nAt least 51 people were killed in clashes between police and citizens in the troubled region.\"\\n\\nIs it a \"non-actual\" event axis? We think no.\\n\\nFirst, tried, an actual event, is on both axes.\\n\\nSecond, whether restore is non-actual is questionable. It's very likely that order was indeed restored in the end.\\n\\nNon-Q@ axis? to restore order to eliminate army\\n\\nReal world axis = police tried 51 people killed\\n\\n| COGNITIVE COMPUTATION GROUP ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "1. MULTI-AXIS MODELING\\n\\n\"Police tried to eliminate the pro-independence army and restore order.\\nAt least 51 people were killed in clashes between police and citizens in the troubled region.\"\\n\\nInstead, we argue that it's an Intention Axis.\\nIt contains events that are intentions: restore and eliminate and intersects with the real world axis at the event that invokes these intentions: tried Intention axis to restore order to eliminate army.\\n\\nReal world axis: police tried 51 people killed\\n\\n~~ & ___(( Cognitive Computation Group ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "INTENTION VS ACTUALITY\\n\\nIdentifying \"intention\" can be done locally, while identifying \"actuality\" often depends on other events.\\n\\nRee called the police to report the body.\\n\\nYes Yeslace AC osnitTIvE CompuTaTION Group rr"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "1. MULTI-AXIS MODELING\\n\\nSo far, we introduced the intention axis and distinguished it from (non-)actuality axis.\\nThe paper extends these ideas to more axes and discusses their difference from (non-)actuality axes (Sec.\\n2.2 & Appendix A; Sec. 2.3.3 & Appendix B).\\n- intention, opinion orthogonal axis ~20\\n- hypothesis, generic parallel axis\\n- Negation not on any axis ~10\\n- static, recurrent not considered now\\n- all others main axis ~70"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "1. MULTI-AXIS MODELING: A BALANCE BETWEEN TWO SCHEMES\\n\\nOur proposal: Multi-axis modeling\\n- balances the extreme schemes.\\n\\nAllows dense modeling, but only within an axis.\\n\\nScheme 2: Chain modeling\\n- E.g., TimeBank\\n- Dense\\n- A strong restriction on modeling.\\n\\nScheme 1: General graph modeling\\n- Any pair is comparable\\n- E.g., TimeBank\\n- But many are confusing\\n- No restrictions on modeling\\n- Relations are inevitably missed."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "OVERVIEW: MULTI-AXIS ANNOTATION SCHEME\\n- Step 0: Given a document in raw text\\n- Step 1: Annotate all the events\\n- Step 2: Assign axis to each event (intention, hypothesis, ...)\\n- Step 3: On each axis, perform a \"dense annotation\" scheme\\n\\nIn this paper, we use events provided by TempEval3, so we skipped Step\\n1. Our second contribution is successfully using crowdsourcing for Step 2 and Step 3, while maintaining a good quality."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "2. CROWDSOURCING\\n\\nPlatform: CrowdFlower https://www.crowdflower.com/\\n\\nAnnotation guidelines: Find at http://cogcomp.org/page/publication_view/834\\n\\nQuality control: A gold set is annotated by experts beforehand.\\n\\nQualification: Before working on this task, one has to pass with 70% accuracy on sample gold questions.\\n\\nImportant: With the older task definition, annotators did not pass the qualification test.\\n\\nSurvival: During annotation, gold questions will be given to annotators without notice, and one has to maintain 70% accuracy; otherwise, one will be kicked out and all his/her annotations will be discarded.\\n\\nMajority vote: At least 5 different annotators are required for every judgement and by default, the majority vote will be the final decision."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "3. AN INTERESTING OBSERVATION: AMBIGUITY IN END-POINTS\\n\\nGiven two time intervals: [tstart, tena], [tstart, tena]\\n\\nQualification pass rate 50% 11%\\n\\nComparing the end-points is significantly harder than comparing the start-points.\\n\\nAccuracy on gold 67% 37%\\n\\nAvg. response time 33 sec 52 sec\\n\\nTask 2 is also significantly slower.\\n\\nHow durative events are expressed (by authors) and perceived (by readers):\\n- Readers usually take longer to perceive durative events than punctual events, e.g., \"restore order\" vs.\\n\"try to restore order\".\\n- Writers usually assume that readers have a prior knowledge of durations (e.g., college takes 4 years and watching an NBA game takes a few hours).\\n\\n\"We only annotate start-points because duration annotation should be a different task and follow special guidelines.\"\\n- E| Z Cognitive Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "OVERVIEW: MULTI-AXIS ANNOTATION SCHEME\\n- Step 0: Given a document in raw text\\n- Step 1: Annotate all the events\\n- Step 2: Assign axis to each event (intention, hypothesis, ...)\\n- Step 3: On each axis, perform a \"dense annotation\" scheme according to events' start-points\\n\\n5 § Crue Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "QUALITY METRICS OF OUR NEW DATASET\\n\\nExpert (~400 random relations) kK = 85%\\nk = 84%, F = 90%\\n\\nCrowdsourcing Accuracy 86%\\n88% (same docs in Agreement (WAWA) 79%\\n81% TBDense)\\n\\nRemember: Literature expert k/F values are around 60%.\\n\\nFor interested readers, please refer to our paper for more analysis regarding each individual label.\\n- Worker Agreement With Aggregate (WAWA): assumes that the aggregated annotations are gold and then compute the accuracy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "RESULT ON OUR NEW DATASET = We implemented a baseline system, using conventional features and the sparse averaged perceptron algorithm.\\nThe overall performance on the proposed dataset is much better than those in the literature for TempRel extraction, which used to be in the low 50's (Chambers et al., 2014; Ning et al., 2017).\\n\\nWe do NOT mean that the proposed baseline is better than other existing algorithms.\\nRather, the proposed annotation scheme better defines the machine learning task.\\n\\nP R F\\n\\nP R F\\nT B D\\nDense Same-axis & Cross-axis Same-axis 44 67 53 40 60\\nProposed Same-axis Same-axis 73 81 77 66 72\\nA Masses Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "CONCLUSION: We proposed to re-think the important tasks of identifying temporal relations, resulting in a new annotation scheme.\\n\\nThree components:\\n- Multi-axis modeling: a balance between general graphs and chains\\n- Identified that \"end-point\" is a major source of confusion\\n- Showed that the new scheme is well-defined even for non-experts and crowdsourcing can be used.\\n\\nThe proposed scheme significantly improves the inter-annotator agreement level by ~20%.\\n\\nThe resulting dataset defines an easier machine learning task.\\n\\nWe hope that this work can be a good start for further investigation in this important area."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 83,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation\\n\\nA visual scene can be described in any language.\\nImagine that you are sitting in a restaurant in a foreign country and you need a spoon..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Goal\\n- Find a shared space for textual inputs from several languages.\\n- Utilize mutual images to bridge between the textual inputs.\\n\\n6 Vo, English, Spanish\\nAman is sitting, \"hombre esta sentado en una mesa\" holding a spoon, sujetando una cuchara."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Technical Details"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Multilingual Word Embeddings\\n- Vectors in different languages are in different spaces."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Multilingual Word Embeddings\\n- Vectors in different languages are in different spaces.\\n- Tsoe 2m anh; Es \"peeone.\\n- Rta oP oe oo B iA ee ESR LS.\\n- 3 roy) ; a : Bont cave\\n- \"| 54 OF 2 Rts 3 se eee.\\n- Ca e Pes pee.\\n- A: nN.\\n- ' ' aR \"= 5 A mea hod BPS\\, : Bae Ts i ear #0 ' z on.\\n- oO e :* \"AE, Tae Secbis wily ok 23 Pe+ a ae \" eee ae!\\n- od ae Tae es yee Sokeere ees mn i * Matt's oF Jie.\\n-\\n- + te Pot ve Ace NRE Ce,oe eae Ce gee: ide ke SESS' amie' Re.\\n- ne © Tf eee aeater ae FR EeeLoprauew it.\\n- RO aeTO ea gd >\"3 ate -Ser"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Mapping Two Views To a Shared Space: Canonical Correlation Analysis (CCA)\\n- CCA (Hotelling,\\n1936) is a statistical technique for finding linear projections of two random matrices such that their projected columns are maximally correlated.\\nx4 | x} xy yi | Vi 4x2 | x3 xy y2 | ¥2 yeX=] |. | Y=) |. |xh, |x| [a yh, |3,| = La,0 ={W, V}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Mapping Two Views To a Shared Space: Canonical Correlation Analysis (CCA)\\n- Objective in matrix form:\\n1. || W'X\\n- V'y ||^2 = {WV} W' Subject to W' S M A | T E ater | | Sey = XY, Bex = XX, Sy = vy?\\n\\nX, Y have zero mean."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Limitations of CCA:\\n- Projection is linear.\\n- Inapplicable for large datasets due to whitening constraints.\\n- Hard to compute stochastic estimations of the covariance matrices.\\n- Objective does not decompose over samples.\\n- Cannot benefit from an additional view (such as images)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Partial CCA (PCCA)\\n- PCCA (Rao,\\n1969) is a statistical technique for finding linear maximal correlated projections of two random matrices conditioned on a third variable.\\n\\nMax Corr (W1\"(X|Z), V\"(Y|Z))0 = {W, V}\\n- Z (a variable of mutual input) is a mutual variable of X and Y (textual inputs).\\n- PCCA was not used before in the multilingual multimodal setup."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "New model\\n- Deep Partial CCA (DPCCA): CCA has a deep variant\\n- Deep CCA (Andrew et al., 2013)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "New model\\n- Deep Partial CCA (DPCCA)\\nCCA has a deep variant\\n- Deep CCA (Andrew et al., 2013).\\nCan we develop a deep variant for Partial CCA?\\nPartial CCA suffers from similar limitations to those of CCA.\\nA new stochastic optimization algorithm is required."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "The DPCCA Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Architecture of Deep Partial CCA (DPCCA)\\n- Variant B\\n\\nInput Layer 15\\n\\nHidden Layer\\n\\nLast Hidden Layer\\n\\nFinal Linear Layer\\n\\nAman is sitting at a table holding a spoon\\n\\nUn hombre está sentado en una mesa sujetando una cuchara"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n-\\n\\n(1) learn non-linear representations of X and Y: F(X) = W'f(X), G(Y) = V\"g(Y), f and g are two deep neural networks.\\nW and V are the final projection matrices."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- (2) perform multivariate linear multiple regressions for F(X) and G(Y) on a shared variable Z:\\n\\n1F(X) = AZ + FOZ) min ||G(Y)\\n- BZ||\\n\\nexplained residual | G(Y)\\n- BZ |  explained residual"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- (2) perform multivariate linear multiple regressions for F(X) and G(Y) on a shared variable Z:\\n\\n1 F(X) = AZ + F(Z) min --- ||F(X)\\n- AZ||²\\n\\n2 G(Y) = BZ + G(Y|Z) min --- ||G(Y)\\n- BZ||²\\n\\n(3) compute the residual matrices and their covariances w.r.t. the optimal solutions:\\n\\nF(X) = F(Z)\\n- AZ\\n\\nG(Y|Z) = G(Y)\\n- BZ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- (4) perform CCA on the residuals: 1, 6 = {W;, W, V, V} Subject to Ler | z = XGe | z ao"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- Optimization\\nOptimization is not trivial"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- Optimization\\nOptimization is not trivial.\\nWe introduce new stochastic optimization algorithms for our DPCCA variants.\\nFull pseudocode is given in the paper."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Deep Partial CCA (DPCCA)\\n- Optimization\\n\\nOptimization is not trivial. We introduce new stochastic optimization algorithms for our DPCCA variants.\\n\\nWe adopt some key techniques from the Nonlinear Orthogonal Iteration (NOI) algorithm which was suggested for Deep CCA (Wang et al., 2015).\\n\\nFull pseudocode is given in the paper."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Experiments and Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Experimental Setup\\n- Tasks and Datasets\\n- First Task: Cross-lingual image description retrieval\\n\\nEnglish Spanish\\n\\nAman is sitting at a table\\nUn hombre está sentado en una mesa\\nholding a spoon\\nsujetando un tenedor\\nUn hombre está sentado en una mesa\\nsujetando una cuchara\\nUn hombre está sentado en un balcón\\nsujetando una cuchara\\n- Dataset: Multi30k (Elliott et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Experimental Setup\\n- Tasks and Datasets\\n\\nSecond Task: Multilingual Word Similarity\\n- English German Italian Russian\\n- inspect-examine 9.2\\n- prifen-lberprifen 9.8\\n- inspezionare-esaminare 8.5\\n- OcMaTpHBaTb-u3yy¥aTb 5.3\\n- easy-flexible BLA leicht-flexibel 3.4\\n- facile-flessibile 2.5\\n- moKnayucTbIn-ruoKun 4.0\\n- plane-airport 1.6\\n- flugzeug-flughafen 5.9\\n- aereo-aeroporto 6.2\\n- CaMOJIeT-adponopT 1.3\\n- Dataset: Multilingual Simlex-999 (Leviant and Reichart, 2015)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "New Dataset\\n- Word Image Word (WIW)\\n- Word pairs in different languages with mutual images\\n\\nPOS EN-DE NE EN-RU True\\n- Wah Plant\\n- Pianta Dance\\n- TaHeu pee ee N 4606 4735 4106 Tr fase; SY Ty) A 405 416 348 V0 f it ¥ V 392 400 227, .\\n| \" | AVB 167 161 142 Y a y PP 12 12 9\\n- The new dataset is available at: github.com/rotmanguy/DPCCA"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Experimental Setup\\n- Baselinese\\n- Linear and deep CCA-based models:\\n- Probabilistic Partial CCA (PPCCA) (Mukuta,\\n2014)\\n- Nonparametric CCA (NCCA) (Michaeli et al,\\n2016)\\n- Generalized CCA (GCCA) (Horst,\\n1961)\\n- Deep CCA (DCCA) with various optimization algorithms\\n- Deep CCA Autoencoder (DCCAE) (Wang et al.,\\n2015)\\n- Text + Images"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Experimental Setup\\n- Baseline\\n- Linear and deep CCA-based models:\\n- Probabilistic Partial CCA (PPCCA) (Mukuta,\\n2014)\\n- Nonparametric CCA (NCCA) (Michaeli et al.,\\n2016)\\n- Generalized CCA (GCCA) (Horst,\\n1961)\\n- Deep CCA (DCCA) with various optimization algorithms\\n- Deep CCA Autoencoder (DCCAE) (Wang et al.,\\n2015)\\n- Other related works:\\n- Bridge Correlational Networks (BCN) (Rajendran et al.,\\n2016)\\n- Image Pivoting (Gella et al.,\\n2017)\\n- Text Qi, Text + Images"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Main Results\\n- PCCA gets very good results, outperforming NN based methods and linear methods (including CCA, Image Pivoting, BCN ...)\\n- DPCCA is the best model, outperforming all baseline\\n- Training with images improves performance on words that are more abstract, such as adjectives and verbs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Cross-lingual Image Description Retrieval Model\\n\\nTaam con Clara Creare com ala Cia\\n\\n(Concatenation)\\n\\nResults are reported on BLEU +1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Model EN\\n- ADJ EN\\n- Verbs EN\\n- Nouns\\nDE\\n- ADJ DE\\n- Verbs DE\\n- Nouns\\n\\nDPCCA Variant A 64.0% 31.1% 36.9% 43.0% 32.1% 40.4%\\n\\nDPCCA Variant B 62.6% 31.6% 38.2% 46.2% 31.9% 39.9%\\n\\nDCCA NOI 61.1% 30.8% 36.1% 44.1% 29.7% 39.8%\\n\\nPCCA 61.4% 29.6% 34.0% 30.5% 14.3% 34.0%\\n\\nCCA 55.7% 29.7% 32.1% 28.4% 15.7% 34.6%\\n\\nGCCA 63.6% 28.0% 37.8% 44.6% 27.7% 39.8%\\n- Results are reported on Spearman's correlation coefficient"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Summary Goal: Learning a shared bilingual space for textual inputs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Summary\\n\\nGoal: Learning a shared bilingual space for textual inputs\\n\\nOur Contributions:\\n\\nMethod: Adding mutual visual information to the learning process\\n\\nModel: Applying PCCA to our settings, and introducing its deep variants\\n\\nOptimization: New optimization algorithm for DPCCA\\n\\nResults: Improvements over previous work\\n\\nNew Dataset: Word Image Word (WIW)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Future Work\\n\\nExpanding DPCCA to support more than two languages\\n\\nExploiting the internal structure of images and sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Thank you! The code and data are available at: github.com/rotmanguy/DPCCA"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 377,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "9:7 PR BE WH KER BHR UPAITL\\n-K MMB Yahoo! JAPAN ALTeA(O779hQMBN\\yLad7: Marashi we YVVIORHIS? We can:\\n\\nFATOVTh\\n- BREMM\\n- uma | OTR onyiect volumecna@<Azbhyt-b YI-h ROMS20148, OvtyVenty, PIVYVS, SORM\\n- PEZSVOLNY REHOME\\n\\nSHLFRVKEBS, AHCSRSRCSMLTVET. MEP TEASERTHK, EKEKCYPVUSENSUMBSATI(Y RERBKyPUTSERVET.\\n\\nBata,¥ So Creerrasseae)\\n- 105M WAT Awo 106 Te 300B\\n- , PVVIATARMORG\\n- , MOMOKFAERTAKMN... Smowv seer:\\n- sm a oYsaoneE.\\n\\nRPAARPOSOMMOKS. SEOVIVIO by THUOE ewe\\n- 1028\\n- TY ®) 12% 2 ©PVVIEROIOSUR\\n- | PRL. THKIT\\n- | SRLU FOV RLU bDEPRERSS108 13\\n- 065 oe? 116gi Peano rs6°SR YS atthe hs remne\\n- 2\\n\\n<2) rempensyer\\n- esxbess et oer Seeeas SereSARC SAWS. CHBZAFICKL + + + (HESS BRBRCOTEIRM\\n\\nSentimentSearch result timeline widget"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "1 Problem YaHQO!\\n- The amount of labeled training data\\n- You will need at least 100k training records to surpass classical approaches (Hu + 2014, Wu +\\n2014)\\n- Large-scale labeled datasets of document classification\\n- Stanford Sentiment 8,544 1,101 2,210\\n- Tree Bank Large Movie 25,000\\n- 25,000 50,000 Review Dataset\\n- SemEval 2014 Task 9,684 1,654 5,666 17,004\\n- Subtask B3 56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "!Previous Work\\n'YAHOO!\\n* Semi-supervised approaches\\n- Language model\\n- how are you\\n- transfer\\n- how are you\\n- pretraining\\n- congratulations!\\n- fine-tuning\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Previous Work\\n'YAHOO!\\n- Semi-supervised approaches\\n- Sequence autoencoder (Dai and Le\\n2015)\\n- Pretraining\\n- Fine-tuning\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Our Contributions\\n\\nYaHoo!\\n- Pretraining strategy with unlabeled dialog data\\n- Pretrain an encoder-decoder model for sentiment classifiers\\n- Outperform other semi-supervised methods\\n- Language model\\n- Sequence autoencoder\\n- Distant supervision with emoji and emoticons\\n\\n* Case study based on...\\n- Costly labeled sentiment dataset of 99.5K items\\n- Large-scale unlabeled dialog dataset of 22.3M utterance-response pairs\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Key Idea\\n\\nYAHQO!\\n- Emotional conversations in a dialog dataset\\n\\nutterance response: won't forgive you, ee (JD) eenever\\n\\n\"2 (crying emoticon)\\n\\ngot home really tired\\n\\nGood job today!\\n- Implicitly learn sentiment-handling capabilities through learning a dialog model\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Overview of the Proposed Method SABRE\\n- Datasets\\nLarge-scale dialog corpus: a set of a large number of unlabeled utterance-response tweet pairs.\\nLabeled dataset: a set of a moderate number of tweets with a sentiment label.\\n1. Pretraining\\n- How are you pretraining?\\n2. Fine-tuning\\n- Congratulations! Fine-tuning.\\n\\n56th Annual Meeting of the Association for Computational Linguistics, TS-2U July UTS, MCIDOUTE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Data Preparation\\n\\nYAHOO!\\n- Dialog data\\nExtract 22.3M pairs of an utterance tweet and its response tweet from Twitter Firehose data\\nDialog data 22,300,000 10,000 50,000 22,360,000\\n- Sentiment data\\nPositive: 15.0%, Negative: 18.6%, Neutral: 66.4%\\nCOSentiment data 80,591 4,000 15,000 99,591\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Model:\\n- Dialog Model\\n- One-layer LSTM-RNN encoder-decoder\\n- Embedding layer: 4000 tokens, 256 elements\\n- LSTM: 1024 elements\\n- Representation which encoder gives: 1024 elements\\n- Decoder's readout layer: 256 elements\\n- Decoder's output layer: 4000 tokens\\n- LSTMs of the encoder and decoder share the parameter\\n\\nI'm great! How are you a"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Model: on 7 'YAHOO!\\n\\nClassification Model\\n- Classification model\\n- The architecture of the encoder RNN part is identical to that of the dialog model\\n- Produce a probability distribution over sentiment classes by a fully-connected layer and softmax function Ht output layer encoder | :> fom"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Training:\\n- oorDialog Model\\n- SAE- Model pretraining with the dialog data\\n- MLE training objective\\n- 1 GPU (7 TFLOPS)\\n- 5 epochs = 15.9 days\\n- Batch size: 64\\n- Optimizer: ADADELTA\\n- Apply gradient clipping\\n- Evaluate validation costs 10 times per epoch and pick up the best model\\n- Theano-based implementation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Training:\\n\\nYAHOO! Classification Model\\n- Classifier model training with the sentiment data\\n- Apply 5 different data sizes for each method: 5k, 10k, 20k, 40k, 80k (all)\\n- 5 runs for each method/data size with varying random seeds\\n- Evaluate the results by the average of f-measure scores\\n- Adjust the duration so that the cost surely converges\\n- Pretrained models converge very quickly but those trained from scratch converge slowly\\n- The other aspects are the same with pretraining\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Proposed Method\\n\\nYarioo!\\n- The proposed method: Dial I'm great!\\n- transfer\\n- how are you pretraining: sentiment data ions! congratulations! fine-tuning\\n\\n15 56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Baselines with LSTM-RNNs\\n\\nYAHOO!\\n- Default\\n- No pretraining\\n- Directly trained by the sentiment data\\n\\nCongratulations! Training from scratch\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Baselines with LSTM-RNNs YaHoo!\\n\\nPretrain an LSTM-RNNs as a language model.\\n\\nI'm great!\\n\\nUnpaired tweet = data transfer\\n\\nI'm great.\\n\\nPretraining, sentiment data relations!\\n\\nCongratulations fine-tuning\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Baselines with LSTM-RNNs\\nYaHoo!\\nSeqAE- Pretrain an LSTM-RNNs as a sequence autoencoder (Dai and Le\\n2015)\\nI'm great!\\nI'm great!\\nfine-tuning\\n18 56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Baselines with LSTM-RNNs\\n\\nYAHOO!\\n- Emoji and emoticon-based distant supervision\\n- Prepare large-scale datasets utilizing emoticons or emoji as pseudo labels (Go+\\n2009)\\n- Positive emoticon examples OG OOO OVE DEY (CD VV\") of\\n- Negative emoticon examples\\n- O62NGSO669 Ba (* *) 7/--) CW.)\\nA) or"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Baselines with LSTM-RNNs\\nYaHoo!\\n- Emo2M and Emo6M\\n- Pretrain models as classifier models using pseudo-labeled data\\npseudo-labeled transfer = 'I'm tired'\\npretraining\\n- sentiment data\\nlations!\\nCongratulations fine-tuning\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Baselines with Linear Models = yao!\\n- Data\\n- Use only the sentiment data\\n- Preprocessing\\n- Segment text with a defect-standard morphological analyzer, MeCab\\n- 50,000 unigrams and 50,000 bigrams\\n- +233 emoji and emoticons\\n- LogReg\\n- Logistic regression (LIBLINEAR)\\n- LinSVM\\n- Linear SVM (LIBLINEAR)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Results: F-measure\\n\\nYAHOO! 0.75 @0.65\\n\\nDefault ue Moe\\nDialid\\nLang 0.55\\n\\nSeqAEPe\\nEmo2Merr\\nEmo6M 0.50\\n\\nLogReg\\nLinSVM 0.455\\n\\n# of training records 10000 20000 40000 80000"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Original text =\\n\\n\"I'CS;SW\"S*\"~*~\"~\"\"~\"~W~OWOWOWOCOCOC~C*@YS«@E@ng*iish translations\"\\n\\n'sOCOCO!OOO!O!O!O!O!O!O!C*TM& been really looking forward to DEH V2 E 1%.\\n\\nKE | [have a headache Really? Take care of yourself...fun A. RTS Bs up on you. RF GBLEE! MCE!\\n\\nTwas admitted by the university! Congratulations eee oa\\n\\nK(' sw) 2 (BEA!!! Thanks!!! ZH. FOES JA, OV)\\n\\nI really like it Yeah, it's soame eee eee tea)\\n\\nReplies generated by the pretrained encoder-decoder model\\n\\n56th Annual Meeting of the Association for Computational Linguistics, 15-20 July 2018, Melbourne"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Conclusion\\n- YaHoo!\\n- Effectiveness of the pretraining strategy using paired dialog data for sentiment analysis\\n- Even more effective in extremely low-resource situations\\n- Character-based processing\\n- Future work\\n- Explore combinations of a large-scale unlabeled dataset and a supervised task\\n- Exploit other kinds of structures"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 3,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Distributional hypothesis, \"Lou shall know the meaning of the word by the company it keeps.\" Words that occur in similar contexts tend to have similar meanings.\" Harris, 1954."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Cars, Drivers, Vehicles, and Wheels\\n\\nWords co-occur in text due to Paradigmatic relations (e.g., synonymy, hypernymy), but also due to Syntagmatic relations (e.g., selectional preferences).\\n\\nDistributional vectors conflate all types of association: driver and car are not paradigmatically related.\\nNot synonyms, not antonyms, not hypernyms, not co-hyponyms, etc.\\n\\nBut both words will co-occur frequently with: driving, accident, wheel, vehicle, road, trip, race, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Vector specialization using external resources\\n\\nKey idea: refine vectors using external resources\\n\\nSpecializing vectors for semantic similarity\\n1. Joint specialization models\\n- Integrate external constraints into the learning objective\\nE.g., Yu & Dredze, '14; Kiela et al., '15; Osborne et al., '16; Nguyen et al., '17\\n2. Retrofitting models\\n- Modify the pre-trained word embeddings using lexical constraints\\nE.g., Faruqui et al., '15; Wieting et al., '15; Mrkšić et al., '16; Mrkšić et al., '17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Vector specialization using external resources\\n- Joint specialization models\\n(+) Specialize the entire vocabulary (of the corpus)\\n(-) Tailored for a specific embedding model\\n- Retrofitting models\\n(-) Specialize only the vectors of words found in external constraints\\n(+) Applicable to any pre-trained embedding space\\n(+) Much better performance than joint models (Mrksi et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "This work: Best of both worlds: Performance and flexibility of retrofitting models, while specializing entire embedding spaces (vectors of all words).\\n\\nSimple idea: Learn an explicit retrofitting/specialization function using external lexical constraints as training examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "- SO RM a aaa re isoe\\n43. Sy * ah * Pics, tae F\\n5) (ro; 'ies) BSS hice BAH hens. his Wace) BESS oihira it Sara Hays Rete\\n- Rear var ean peenege: PRES rs aera ven KSI ASEO Me x it oy Lp ht Ne ee Anam LIC Es MCX] ont A Re oa ELL a Ey Ce XU oy hens ee Anam RCL ee oa EOYs IMC; b a ga deme al ae PRE ROS eC Ae ae Sperber is PSE th eaeratao mee brite!\\nsesh act ee: a pare iano ies Poe roLe FJ & Bol7r4- BA AWY ma a» Be ~ | ee, ek Ee Gee.\\naS SG Wo & NN ONS eee ikeSoe FE ee ELSE TT RT en Te eee Pda eer\\ni) Sent eer Nee Ce et ae ee ae.\\nee ee ARE TCT eee Sea, ined S214] A a IESE Re a gs ehh wera ear Sea Baas Igy « SECR Ra ate h dsc ne init aide hb geen eA RA Nt age IE!\\nPRS Raisin Ree ates Uren tern ate PES ST RMC eae Se Bo Sh- ea SUI PM sie eae = het islets Sra haar: ° SLATE oh icity erie eer: hae es aL oh Nae ee): Lace ee Si cies ra RySAPEN RSsbo =x ees £3 ss (\"xt i= seeks 3:\\n- ea Mines Sere si 5Hee Ei; : aes st ite pps ch 2 PPR sae re tn: apes ea: : Sea ins lt era: Fd Ra; era Be A A on; eat te Se Se meat) oe etal Pee Diceoeh Reis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Explicit retrofitting\\n\\nConstraints (Synonyms and antonyms) used as training examples for learning the explicit specialization function = Non-linear: Deep Feed-Forward Network (DFFN)\\n\\nExternal knowledge Training instances (micro-batches)\\n- ahhe ok.\\n- os nah\\n- Se ght'\\n- Viight : 9-0\\n- ae Ns\\n- _ Naif C (buy, acquire, syn)\\n- neg : Verh V sunset : \"7 RZ\\n- i @\\nC)\\n- i \\\\ i}\\n- y i =i .\\n- neg : Viight: \"bulb\\n- 9- | AH\\n- MI \" rm\\n- | q 2\\n- _ene WREO WO) es;\\n- ee) ee @ \\AX_X)) : ai\\n\\nDistributional vector space\\n\\nCA original: Vourcer Vtarget : 2-0 BESO Mes CN NX 3 non qf > J csed acquire > (0.11, -0.23,...,1.11]\\n\\nneg 1: Vsource: Vriver * 9.29\\n\\nYM |) oo | | NY \\ it\\n\\n8bright > (0.11, -0.23, ..., 1.11]\\n\\nneg 2: Vtarget Vbullet : 9-41 HN\\n\\nns\\n- me \\ I\\\\ }- sbuy > [-0.41, 0.29, ..., -1.07]\\n\\nSpecialization model\\n\\nEE\\n- OU UO \"=\\nO) CO N-a (non-linear regression) % x' =f)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Constraints to training instances\\n\\nSpecialization function: x' = f(x)\\nDistance function: g(x, Xz) =\\n\\nAssumptions\\n1. (w;, W;, Syn)\\n- embeddings as close as possible after specialization\\ng(x;', X;\") = Fmin\\n2. (Wj, W;, ant)\\n- embeddings as far as possible after specialization\\ng(x', x;\") = Ymax\\n3. (w;, w;)\\n- the non-constraint words stay at the same distance\\nQ(%;\", %;7) = G(%;, X;)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Constraints to training instances:\\n\\nMicro-batches\\n- each constraint (w;, w;,\\nr) paired with K pairs {(w,, w,,*)}.\\n- W,,* most similar to w, in distributional space: K pairs {(w,, w,,\")},,\\n- W,« most similar to w; in distributional space\\n\\nTotal: 2K+1 word pairs M (wi, W),\\nr)\\n- {(X:, Xj gr)} Uk k K{(Xi, Xm g(Xi, Xm)) teal Uk k K{(Xj, Xn; G(X, Xn)) bead"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Loss function = Contrastive Objective (CNT) 2K + 1 = ef, 1 2JCnT = g\\n- Qmin)\\n- (g\\n- gDL (Gia gn)\\n- (a = 9\") aK y1 25010\" diff Predicted diff. [ Y ae 2T » » (one\\n9) 8\"\\n- g )) Ma€A i = 2 =?= Regularization esInve = Yo oli,\\n08) + oleh, £0) ii ©"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "rs i wd] A . 4 p 5 . , Pa etd Ants Ray Stay Re RP PSKG RES Pd oe AC?\\nwae Pate he tra\" SALE street ha wien ae paar Peon EN Fk mG ee sfc bi om eed Manet"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Model Configuration= Distance function g: cosine distance\\nDFFN activation function: hyperbolic tangent\\n\\nConstraints from previous work (Zhang et al, '14; Ono et al.,'15)= 1M synonymy constraints\\n380K antonymy constraints= But only 57K unique words in these constraints!\\n10% of micro-batches used for model validation\\n\\nH (hidden layers) = 5, d (layer size) = 1000, A = 0.3\\nK = 4 (micro-batch size = 9), batches of 100 micro-batches= ADAM optimization (Kingma & Ba, 2015)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Intrinsic Evaluation = SimLex-999 (Hill et al., 2014), SimVerb-3500 (Gerz et al.,\\n2016)\\n\\nImportant aspect: percentage of test words covered by constraints = Comparison with Attract-Repel (Mrksic et al.,\\n2017)\\n\\nSimLex, lexically disjoint (0%)\\nSimLex, lexical overlap (99%)\\n0.7\\n0.7\\n0.65\\n0.65\\n0.6\\n0.6\\n0.55\\n0.55\\n0.5\\n0.5\\n0.45\\n0.45\\n\\nGil Luli = 8\\n\\n0.35\\n0.35\\n0.3\\n0.3\\n\\nGloVe-CC\\nfastText\\nSGNS-W2\\nGloVe-CC\\nfastText\\nSGNS-W2.\\n\\nDistributional\\nmAttract-Repel\\nwm Explicit retrofitting\\nmDistributional\\nmAttract-Repel\\nm Explicit retrofitting"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Intrinsic Evaluation\\n\\nIntrinsic evaluation depicts two extreme settings:\\n- Lexical overlap setting = Synonymy and antonymy constraints contain 99% of SL and SV words = Performance is an optimistic estimate of true performance.\\n- Lexically disjoint setting = Constraints contain 0% of SL and SV words = Performance is a pessimistic estimate of true performance.\\n- Realistic setting: downstream tasks = Coverage of test set words by constraints between 0% and 100%."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Downstream tasks:\\n\\nDST & LS = Dialog state tracking (DST)\\n- first component of a dialog system = Neural Belief Tracker (NBT) (Mrksi et al., '17)\\n- Makes inferences purely based on an embedding space\\n- 57% of words in NBT test set (Wen et al., '17) covered by specialization constraints\\n\\nLexical simplification (LS)\\n- complex words to simpler synonyms\\n- Light-LS (GlavaS & Stajner, '15)\\n- decisions purely based on an embedding space\\n- 59% of LS dataset words (Horn et al., '14) found in specialization constraints\\n\\nCrucial to distinguish similarity from relatedness\\n\\nDST: \"cheap pub in the east\" vs. \"expensive restaurant in the west\"\\n\\nLS: \"Ferrari's pilot Sebastian Vettel won the race.\" vs. \"driver\" vs. \"airplane\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Downstream tasks\\n- Evaluation:\\n- Lexical simplification (LS) and Dialog state tracking (DST)\\nLS 0.7 0.8\\n0.65 0.81\\n0.6 0.81\\n0.805 0.55\\n0.8 a8\\n0.795 0.45\\n0.79 0.4\\n0.785\\n\\nGloVe-CC\\nfastText\\nSGNS-W2\\nGloVe-CC = Distributional mw\\nAttract-Repel w\\nExplirefit w\\nDistributional w\\nAttract-Repel mw\\nExplirefit"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "SR aR ae neao ta! unr eat Ly «ene rT Sint Co kecabsatam ond <4 prime See ete Ly.\\nOa dj pedeg D4 Ee re) F pale runt tae ae Eg < Oey gindeg Sad SC keer a 314 a,ea r F Ets Reels OS ir pes 3 F E oon Sinan Soe aes ~~ 5hF aes f trian We pti ee5y)2158 Pa s Ps MS.\\nFete iss). teas 2 raiPei Pang oe é be a a 1: ei eps *.\\n- Bre ere | iene ~=-ChlLlC P>F!lL oe OE ORS 4 ze i: a Ee Se |\\n- at os Be re ede ras eee) eee PieroFe Soha Me aT fae bse tee\\n2) ECR, ee een ae fees eet; ' r: H Pee: cece tt) Mae TSP ae est rig be\\n- <s 5 De eC\\n0) ee Seerre a <- aeS ES RS SON oS eT Een ME oe OSes on IDS EUR nee Ty Te oa pelt et Ee > | Pa Soi BIO pen amI STs a arn Re oe ac 1s |eet) ann een i BS Lk tay ace Pelee eens sd Se Pits a PY Rae hey ee TUT eC ee, eee i PN Ee Eerie Lo vie a ee URS et eae ty aites ie ieee eRe a AR AR LIED Mie ONSEN gem ase Nie be ed te, ea CORT UPS Sree AA REZ IDL hears om Se EN BRUT PDTC bgt ed Ate Meee ERO COREE at ee RELIED: tts tim 5 EN Bea MU PDTC bk ed ate lia Fato Cn ra Ci Law tw\" BRS A Rw APOE SNC eer th es SNR ARR REPRE NCL eee the) meee nt reSS \"Tete Se eB es OU Dean ACU?\\nETE La arn be UB ge RRA tarot SEAM wore 7 REN SAY Era saTN POUR yee eae a eager celina = a] Esue ft &.\\n- is a ore * r pe DLA ate eee De Ascites peepee Tantus ory Be ChAT te See Deteds ti ee es See aE r Orr poss& a @ee ne BS A Tapa Pm Rees SAL SEE arb ee tanned EN Pots Re apa irra aL TR ara Hart ght ' See es RD ea ploneMien Pe SiMe ern ok S gn ca F PY Sa etre t mk Ns ies aL RA oe Pa ALS etre ak RS tid re 3a ae) a oe ta Fee TiS ai i ne REC PT rena,\\na) re Set: + mate Pepys he) FS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Language transfer = Lexico-semantic resources such as WordNet needed to collect synonymy and antonymy constraints.\\n\\nIdea: use shared bilingual embedding spaces to transfer the specialization to another language.\\n\\nMost models learn a (simple) linear mapping.\\n\\nUsing word alignments (Mikolov et al., 2013; Smith et al., 2017).\\n\\nWithout word alignments (Lample et al., 2018; Artetxe et al., 2018)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Cross-lingual transfer\\n- results:\\n\\nTransfer to three languages: DE, IT, and HR.\\n\\nDifferent levels of proximity to English.\\n\\nVariants of SimLex-999 exist for each of these three languages.\\n\\nCross-lingual specialization transfer 0.55 0.50 0.45 0.40 0.35 0.30 0.25\\n\\nGerman (DE)\\nItalian (IT)\\nCroatian (HR) = Distributional mw ExpliRefit (language transfer)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Conclusion: Retrofitting models specialize (i.e., fine-tune) distributional vectors for semantic similarity.\\n- Shortcoming: specialize only vectors of words seen in external constraints.\\n- Explicit retrofitting: Learning the specialization function using constraints as training examples.\\n- Able to specialize distributional vectors of all words.\\n- Good intrinsic (SL, SV) and downstream (DST, LS) performance.\\n- Cross-lingual specialization transfer possible for languages without lexico-semantic resources."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Thank you for attention!\\n\\nContact: goran@informatik.uni-mannheim.de\\niv250@hermes.cam.ac.uk"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 71,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Background: Unsupervised MT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Background: Unsupervised MT\\n\\nRecently: Unsupervised neural machine translation (Artetxe et al., ICLR 2018; Lample et al., ICLR 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Background: Unsupervised MT\\n\\nRecently: Unsupervised neural machine translation (Artetxe et al., ICLR 2018; Lample et al., ICLR\\n2018) target sentences latent space source sentences encoder C(y) Xe8 MZ... \"ee --~~ decoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Background: e@U ised MT Recently: Unsupervised neural machine translation (Artetxe et al., ICLR 2018; Lample et al., ICLR\\n2018) target sentences, latent space source sentences encoder C(y) Xe = --- 4 --- Gecoderane,\\n\\nKey component:\\n- Initialization via leading unsupervised cross-lingual alignment of word embedding spaces."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Background: Cross-lingual word embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Background: Cross-lingual word embeddings\\n\\nCross-lingual word embeddings enable cross-lingual transfer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Background: Cross-lingual word embeddings\\n\\nCross-lingual word embeddings enable cross-lingual transfer.\\nMost common approach: Project one word embedding space into another by learning a transformation matrix W between n source embeddings x; and their translations y; || Wx;\\n- y, | /?, (Mikolov et al.,\\n2013) i=3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Background: Cross-lingual word embeddings\\nCross-lingual word embeddings enable cross-lingual transfer.\\n\\nMost common approach: Project one word embedding space into another by learning a transformation matrix W between n source embeddings x_i and their translations y_i.\\n|| Wx_i\\n- y_i || / ?, (Mikolov et al., 2013).\\n\\nMore recently: Use an adversarial setup to learn an unsupervised mapping."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Background: Cross-lingual word embeddings\\n\\nCross-lingual word embeddings enable cross-lingual transfer.\\nMost common approach: Project one word embedding space into another by learning a transformation matrix W between n source embeddings x; and their translations y;:\\n\\nWx; = y; (Mikolov et al., 2013).\\n\\nMore recently: Use an adversarial setup to learn an unsupervised mapping.\\nAssumption: Word embedding spaces are approximately isomorphic, i.e. same number of vertices, connected the same way."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "How similar are embeddings across languages?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "How similar are embeddings across languages?\\nNearest neighbour (NN) graphs of top 10 most frequent words in English and German are not isomorphic."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "How similar are embeddings across languages?\\n\\nNearest neighbour (NN) graphs of top 10 most frequent words in English and German are not isomorphic.\\n\\nNN graphs of top 10 most frequent English words and their translations into German.\\n\\nNot isomorphic."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "How similar are embeddings across languages?\\n\\nNN graphs of top 10 most frequent English nouns and their translations.\\n\\nEnglish\\n- German: Not isomorphic"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "How similar are embeddings across languages?\\n\\nNN graphs of top 10 most frequent English nouns and their translations:\\n- English\\n- German\\n\\nWord embeddings are not approximately isomorphic across languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "How do we quantify similarity?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G, and G, of different languages are."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G, and G, of different languages are.\\nPropose eigenvector similarity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G and G of different languages are.\\nPropose eigenvector similarity. A, A: adjacency matrices of G, G."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G1 and G2 of different languages are.\\nPropose eigenvector similarity. A1, A2: adjacency matrices of G1, G2. D1, D2: degree matrices of G1, G2."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G₁ and G₂ of different languages are.\\nPropose eigenvector similarity. A₁, A₂: adjacency matrices of G₁, G₂. D₁, D₂: degree matrices of G₁, G₂. L₁ = D₁\\n- A₁, L₂ = D₂\\n- A₂: Laplacians of G₁, G₂. λ₁, λ₂: eigenvalues (spectra) of L₁, L₂."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "How do we quantify similarity? Need a metric to measure how similar two NN graphs G1 and G2 of different languages are.\\n\\nPropose eigenvector similarity. A1, A2: adjacency matrices of G1, G2. D1, D2: degree matrices of G1, G2. L1 = D1\\n- A1, L2 = D2\\n- A2: Laplacians of G1, G2.\\n\\nλ1, λ2: eigenvalues (spectra) of L1, L2. Metric: A = A1\\n- λe, where λ = min {...}."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "How do we quantify similarity?\\nMetric: A = 4 (A,\\n- A,) * where k = min{ --> 0.9}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "How do we quantify similarity? Quantifies how much two NN graphs are isospectral, i.e.\\nthey have the same spectrum (same sets of eigenvalues).\\n\\nMetric: A = (A,\\n- A_y)\" where k = min{ ---! > 0.9} a J Lin Ai7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "How do we quantify similarity? Quantifies how much two NN graphs are isospectral, i.e.\\nthey have the same spectrum (same sets of eigenvalues). Isomorphic -> isospectral, but isospectral + isomorphic A: G, G\\n- [0, ∞) x Di, Metric: A = (A,\\n- 4,,) where k = min { --- > 0.9} = / Lint7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "How do we quantify similarity? Quantifies how much two NN graphs are isospectral, i.e.\\nthey have the same spectrum (same sets of eigenvalues). Isomorphic -> isospectral, but isospectral + isomorphic A: G, G\\n- [0,00) A=0: G, G are isospectral (very similar) Metric: A = (A,\\n- A,)? where k = min{ --> 0.9}\\na) Lin A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "How do we quantify similarity? Quantifies how much two NN graphs are isospectral, i.e.\\nthey have the same spectrum (same sets of eigenvalues).\\n\\nIsomorphic -> isospectral, but isospectral + isomorphic.\\n\\nA: G1, G2\\n- [0, ∞) A = 0: G1, G2 are isospectral (very similar).\\n\\nA > 0: G1, G2 become less similar.\\n\\nMetric: A = (A1\\n- A2) where k = min{...} -> 0.9."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Unsupervised cross-lingual learning assumptions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Unsupervised cross-lingual learning assumptions. Besides isomorphism, several other implicit assumptions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Unsupervised cross-lingual learning assumptions: Besides isomorphism, several other implicit assumptions may or may not scale to low-resource languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Unsupervised cross-lingual learning assumptions: Besides isomorphism, several other implicit assumptions may or may not scale to low-resource languages (Conneau et al., 2018).\\nThis work dependent-marking, languages fusional and isolating, agglutinative, many cases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Unsupervised cross-lingual learning assumptions\\n\\nBesides isomorphism, several other implicit assumptions may or may not scale to low-resource languages (Conneau et al.\\n2018). This work languages dependent-marking, agglutinative, fusional, and isolating.\\nMany cases corpora comparable (Wikipedia) different domains."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Unsupervised cross-lingual learning assumptions: Besides isomorphism, several other implicit assumptions may or may not scale to low-resource languages (Conneau et al., 2018).\\nThis work languages dependent-marking, agglutinative, fusional and isolating.\\n\\nCorpora\\n- Comparable (Wikipedia)\\n- Different domains\\n\\nAlgorithms/ Same\\n- Different hyperparameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Conneau et al. (2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Conneau et al. (2018). Monolingual word embeddings: Learn monolingual vector spaces X and Y."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Conneau et al. (2018)\\n1. Monolingual word embeddings: Learn monolingual vector spaces X and Y.\\n2. Adversarial mapping: Learn a translation matrix W. Train discriminator to discriminate samples from WX and Y."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Conneau et al. (2018). Refinement (Procrustes analysis): Build bilingual dictionary of frequent words using W.\\nLearn a new W based on frequent word pairs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Conneau et al. (2018).\\n\\nRefinement (Procrustes analysis): Build bilingual dictionary of frequent words using W.\\nLearn a new W based on frequent word pairs.\\n\\nCross-domain similarity local scaling (CSLS): Use similarity measure that increases similarity of isolated word vectors, decreases similarity of vectors in dense areas."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "A simple weakly supervised method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "A simple weakly supervised method\\n- Extract identically spelled words in both languages"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "A simple weakly supervised method\\n- Extract identically spelled words in both languages\\n- Use these as bilingual seed words"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "A simple weakly supervised method\\n- Extract identically spelled words in both languages\\n- Use these as bilingual seed words\\n- Run refinement step of Conneau et al. (2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Experiments: Bilingual dictionary induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Experiments: Bilingual dictionary induction\\nGiven a list of source language words, find the closest target language word in the cross-lingual embedding space"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Experiments: Bilingual dictionary induction\\n\\nGiven a list of source language words, find the closest target language word in the cross-lingual embedding space.\\n\\nCompare against a gold standard dictionary.\\n\\nMetric: Precision at 1 (P@1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Experiments:\\n\\nBilingual dictionary induction\\n- Given a list of source language words, find the closest target language word in the cross-lingual embedding space\\n- Compare against a gold standard dictionary\\n- Metric: Precision at 1 (P@1)\\n- Use fastText monolingual embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Experiments: Bilingual dictionary induction\\n- Given a list of source language words, find the closest target language word in the cross-lingual embedding space.\\n- Compare against a gold standard dictionary.\\n- Metric: Precision at 1 (P@1).\\n- Use fastText monolingual embeddings (Conneau et al., 2018).\\n\\nThis work\\n\\nLanguages: French, German, Estonian (ET), Finnish (FL), (English to) Chinese, Russian, Greek (EL), Hungarian (HU), Spanish (ES), Polish (PL), Turkish."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Impact of language similarity\\n- Unsupervised (Adversarial)\\n- Weakly supervised (Identical strings)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Impact of language similarity\\n\\nUnsupervised (Adversarial)\\n\\nWeakly supervised (Identical strings)\\n\\nUnsupervised approaches are challenged by languages that are not isolating and not dependent marking."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Impact of language similarity\\n- Unsupervised (Adversarial)\\n- Weakly supervised (Identical strings)\\n\\nUnsupervised approaches are challenged by languages that are not isolating and not dependent marking.\\nNaive supervision leads to competitive performance on similar language pairs and better results for dissimilar pairs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Impact of language similarity\\nBDI performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Impact of language similarity\\n\\nBDI performance\\n- Eigenvector similarity strongly correlates with BDI performance (p ~ 0.89)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Impact of domain differences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Impact of domain differences: Source and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Impact of domain differences\\nSource and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)\\n\\nEnglish-Spanish\\n\\n0.8 70 = os 52.5 E\\n- © 0.4 35 ® c a O 5 0.2 17.5 Q°\\n\\nEP-EP\\nEP-Wiki\\nEP-EMEA\\nWiki-EP\\nWiki-Wiki\\nWiki-EMEA\\nEMEA-EP\\nEMEA-Wiki\\nEMEA-EMEA\\n\\n°© Domain similarity lM\\nUnsupervised\\nWeakly supervised\\n15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Impact of domain differences\\n\\nSource and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)\\n\\nEnglish-Spanish\\n\\n0.8 fois ra aie Sinha pie ae SRS eee SIR a SR ee Ee ae eH eRe ee eee EE eee eee eRe eee EERE eee EERE ee eee ree ee ple eee eS eee pete eee Ee EE Eee eee EEE EEE eR 70E -DB oneereeecceeeeceeneeeeeneeernseentneeenneeeeaneentnacentnanentneeeaneeesnanenanarennneeesanereinacenananeaaneeeanerainacenanerenanertnnersnaeensnserttneettinersresertteerrttteess\\n\\nB®) c aOQ°\\n\\nEP-EP\\nEP-Wiki\\nEP-EMEA\\nWiki-EP\\nWiki-Wiki\\nWiki-EMEA\\nEMEA-EP\\nEMEA-Wiki\\nEMEA-EMEA\\n\\nDomain similarity lM\\n\\nUnsupervised\\nWeakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Impact of domain differences\\n\\nSource and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)\\n\\nEnglish-Spanish\\n- 0.6 = a\\n- 52.5E\\n- CB\\n- 0.4 RMB\\n\\nDomain similarity\\n- Unsupervised\\n- Weakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Impact of domain differences\\n\\nSource and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)\\n\\nEnglish-Spanish\\n- FO) 7 0.6 = a picasa pre arena\\n- area\\n- Pr caemee crate\\n- POET OUTRO\\n- 52.5E -D4\\n- lll\\n- 35 @\\n\\nDomain similarity\\n- Unsupervised\\n- Weakly supervised\\n\\nUnsupervised approaches break down when domains are dissimilar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Impact of domain differences\\n\\nSource and target embeddings induced on 3 corpora: EuroParl (EP), Wikipedia (Wiki), Medical (EMEA)\\n\\nEnglish-Spanish\\n\\n0,\\n\\nwreceeececeseseeneeeesneeeenecentnecentneeesaneensnacentansennaneeessteeaanecenataneeaneeesaeeessnaceanaeraaneetssueeaieecenstaneeaneeesaeeesanacentnaertaneetseeratcecetstereezecess\\n\\nFO)7 0.6 = picasa sae cen aaa rasan aE are aRaTeracraRRTRERNCNE a Pr caemee crate era paar cra er POET OUTRO a ee 52.5E\\n- OD o4\\n- sosceeeeeenaneecestunneenenttneeenesttanneeenntnnneeeanannenesta prseseesceneetsnnneennensnneeeeeetnneeeesttnnneeeentnnneeeenanseres\\n- 35\\n\\n©\\n\\nEP-EP\\nEP-Wiki\\nEP-EMEA\\nWiki-EP\\nWiki-Wiki\\nWiki-EMEA\\nEMEA-EP\\nEMEA-Wiki\\nEMEA-EMEA\\n\\n© Domain similarity\\n\\nlM Unsupervised\\n\\nWeakly supervised\\n\\nUnsupervised approaches break down when domains are dissimilar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Impact of domain differences\\n\\nEnglish-Finnish\\n- 0.6 separ memo\\n- canes\\n- tc nc\\n- cmancsm eer\\n- nem\\n- nnnso\\n- meneame\\n- cicero\\n- Fe et\\n- neces\\n- ncaa\\n- minim\\n- miecmnsn\\n- ne eee\\n- Fe\\n- Sana\\n- amen\\n\\n22.5€\\n- GA\\n- seenvenescnccrnnnsnenviatameniecnnen\\n\\nDomain similarity\\n- Unsupervised\\n- Weakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Impact of domain differences\\n\\nEnglish-Finnish\\n- 0.6 separ memo\\n- canes tc nc cmancsm\\n- eres nem nnnso meneame\\n- minim miecmnsn\\n- 22.5€\\n- Domain similarity\\n- Unsupervised\\n- Weakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "t of domain diff English-Finnish 0.8\\n\\nDomain differences may exacerbate difficulties of generalising across dissimilar languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Impact of domain differences\\n\\nEnglish-Hungarian\\n- Domain similarity\\n- Unsupervised\\n- Weakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Impact of domain differences\\n\\nEnglish-Hungarian\\n\\n0.6 set mam repent cm ew tm cet eT eS a se ae Se cer assent ce yen em mee\\n\\n22.5€ -£ o©5 (GLB)\\n\\nDomain similarity\\n- Unsupervised\\n- Weakly supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Impact of domain differences\\n\\nEnglish-Hungarian\\n\\nWeak supervision helps to bridge domain differences, but performance still deteriorates."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Impact of hyper-parameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Impact of hyper-parameters\\n\\nSettings: English with skipgram, win=2, ngrams=3-6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Impact of hyper-parameters\\n\\nSettings: English with skipgram, win=2, ngrams=3-6\\n- Vary hyper-parameters of Spanish embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Impact of hyper-parameters\\n\\nSettings: English with skipgram, win=2, ngrams=3-6\\n\\nVary hyper-parameters of Spanish embeddings\\n\\nwin=10\\n\\nngrams=2-7\\n\\nwin=10, ngrams=2-7\\n\\nEnglish-Spanish (skipgram)\\n\\nEnglish-Spanish (cbow)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Impact of hyper-parameters\\n\\nSettings: English with skipgram, win=2, ngrams=3-6\\n\\nVary hyper-parameters of Spanish embeddings:\\n- retinitis 67.5 = see sr porter vei\\n- win=10\\n- ngrams=2-7\\n- win=10, ngrams=2-7\\n\\nEnglish-Spanish (skipgram)\\n\\nEnglish-Spanish (cbow)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Impact of hyper-parameters\\n\\nDifferent algorithms introduce embedding spaces with wildly different structures.\\n- QQ wrens 67.5 ae cele pon sn@ 45\\n- sf effec pel vec\\n- #win=10\\n- #ngrams=2-7\\n- M@ English-Spanish (skipgram)\\n- lM English-Spanish (cbow)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Impact of dimensionality\\n\\n300-dimensional embeddings\\n40-dimensional embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "Impact of dimensionality\\n300-dimensional embeddings\\n40-dimensional embeddings\\n- Worse performance overall, but better performance for dissimilar language pairs (Estonian, Finnish, Greek)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Impact of dimensionality\\n\\n300-dimensional embeddings\\n40-dimensional embeddings\\n\\nWorse performance overall, but better performance for dissimilar language pairs (Estonian, Finnish, Greek).\\nMonolingual word embeddings may overfit to rare peculiarities of languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Impact of evaluation procedure"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "Impact of evaluation procedure: Performance on verbs is lowest across the board."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "Impact of evaluation procedure\\n- Part-of-speech: Performance on verbs is lowest across the board.\\n- Frequency: Sensitivity to frequency for Hungarian, but less so for Spanish."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "Impact of evaluation procedure\\n- Part-of-speech: Performance on verbs is lowest across the board.\\n- Frequency: Sensitivity to frequency for Hungarian, but less so for Spanish.\\n- Homographs: Lower precision due to loan words/proper names. High precision for free with weak supervision."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "Takeaways"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "Takeaways\\n- Word embedding spaces are not approximately isomorphic across languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "Takeaways\\n- Word embedding spaces are not approximately isomorphic across languages.\\n- We can use eigenvector similarity to characterise the relatedness of two monolingual vector spaces."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "Takeaways\\n- Word embedding spaces are not approximately isomorphic across languages.\\n- We can use eigenvector similarity to characterise the relatedness of two monolingual vector spaces.\\n- Eigenvector similarity strongly correlates with unsupervised bilingual dictionary induction performance.\\n- Limitations of unsupervised bilingual dictionary induction:\\n- Morphologically rich languages."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 72,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Introduction Monolingual (xo) gol"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction Basque"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Introduction corpus\\nMonolingual corpus"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Introduction corpus; Monolingual English Porat"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Introduction corpus\\nyno cross-lingual signal\\nMonolingual\\nA English Porat"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "pout A effect Basque Monolingual a 4 corpus ® y ye net asalane 0 ® qarino cross-lingual signal ee apen = oe!\\nyo ae Monolingual A WA ve English \"gait 0 corpus OS eocross-lingual embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "po' A effect Basque Monolingual a 4 corpus y ye net asalli 1 sirvall gave?\\n0% gant ookno cross-lingual signal gen ee aya o® ce Monolingual A WA ve English \"gait 0 corpus OS eocross-lingual embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "po'A eect Basque Monolingual ag -oso? ieee ae etl .el Sit ®y gant?\\n\\n# port ca\\n- Unsupervised ane 0 ® qari ino cross-lingual signal\\n- TM ge mal oe!\\n\\ntranslation ya o® ot Monolingual A WA ve English \"gait 0 corpus OS eocross-lingual embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Monolingual Basque. Be ten? ced = bol Slats y gent? pans a\\n- Unsupervised cross-lingual signal\\n- TM ge mal oe translation, \" yatta?\\n- Cross-lingual English transfer learning corpus OS cross-lingual embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Monolingual Basque corpus. Unsupervised cross-lingual signal\\n- Machine translation. Cross-lingual transfer learning corpus and cross-lingual embeddings.\\nPrevious work (Zhang et al., 2017; Conneau et al., 2018)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Monolingual: \"Basque got a feel. Is it eat?\\n- Unsupervised cross-lingual signal translation, are you?\\n- Cross-lingual English transfer learning corpus.\\n- Previous work (Zhang et al., 2017; Conneau et al.,\\n2018)\\n- Adversarial learning."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Monolingual Basque corpus and unsupervised cross-lingual signal with a focus on translation.\\n- Cross-lingual transfer learning corpus\\n- Cross-lingual embeddings\\n\\nPrevious work (Zhang et al., 2017; Conneau et al., 2018):\\n- Adversarial learning\\n- Very good results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "pout Monolingual; \"eee Basque S a ae.foro) g 10S ®y ne cae ol\\n- Unsupervised.\"\\n- Cross-lingual signal for translation.\\n- Cross-lingual embeddings.\\n\\nPrevious work (Zhang et al., 2017; Conneau et al., 2018):\\n- Adversarial learning.\\n- Very good results.\\n- Tested in favorable conditions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Monolingual; Basque corpus\\n- Unsupervised learning\\n- Cross-lingual signal for translation\\n- Cross-lingual English transfer learning corpus\\n- Cross-lingual embeddings\\n\\nPrevious work (Zhang et al., 2017; Conneau et al., 2018):\\n- Adversarial learning\\n- Very good results\\n- Tested in favorable conditions\\n- Fail in more challenging datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Monolingual: Basque 2 of a corpus\\n- Unsupervised learning: no cross-lingual signal for translation.\\n- Cross-lingual embeddings\\n- Previous work (Zhang et al., 2017; Conneau et al.,\\n2018)\\n- Adversarial learning\\n- Very good results\\n- Tested in favorable conditions\\n- Fail in more challenging datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "pout Monolingual; \"Basque 6 ot ateel Sit®y gee ee? HE eat\\n- Unsupervised ante noe jno cross-lingual signal oe ge a oe\" translation va, \"yar a? oe\\n- Cross-lingual Ww a ss English eile ate soto transfer learning corpus OR eo cross-lingual embeddings\\n\\nPrevious work\\n\\nThis work (Zhang et al., 2017; Conneau et al.,\\n2018)\\n- Adversarial learning\\n- Self-learning\\n- Very good results\\n- Tested in favorable conditions\\n- Fail in more challenging datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Monolingual j al Basque 6 om ara 2el Sit\\n\\nUnsupervised cross-lingual signal\\n\\nCross-lingual English transfer learning corpus\\n\\nPrevious work\\n\\nThis work (Zhang et al., 2017; Conneau et al.,\\n2018)\\n- Adversarial learning\\n- Self-learning\\n- Very good results\\n- Even better results\\n- Tested in favorable conditions\\n- Fail in more challenging datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "po Monolingual Basque 6 om ara 2el Sit RW gee ee?\\n- Unsupervised\\n- Cross-lingual signal\\n- Cross-lingual English\\n- Transfer learning corpus\\n- Cross-lingual embeddings\\n\\nPrevious work (Zhang et al., 2017; Conneau et al., 2018):\\n- Adversarial learning\\n- Self-learning\\n- Very good results\\n- Even better results\\n- Tested in favorable conditions\\n- Works in challenging datasets\\n- Fails in more challenging datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Cross-lingual embedding mappings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Cross-lingual embedding mappings as they are used for translation between Basque and English."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Cross-lingual embedding mappings\\n\\nTraining dictionary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Cross-lingual embedding mappings\\n\\nEnglish due Training dictionary\\n- Txakur\\n\\nDog Sagar\\n\\nApple Egutegi\\n\\nCalendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Cross-lingual embedding mappings\\n\\nBASE Training dictionary\\n\\nEnglish: Dog\\n\\nApple\\n\\nCalendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Cross-lingual embedding mappings\\n\\nDogSagar\\n\\nAppleEgutegi\\n\\nCalendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Cross-lingual embedding mappings\\n- @Zexwcas NS seww\\n- x 2o gor?\\n- ° x@ OP ca oot\\n- ye cert\\n- ® o pov?\\n- cae acage e W aow\\n- ance @ gare my\\n- ee # we pie\\n- gse\\n- @° <a ya o\\n- ® cat<x?\\n- wo® \"v0gs\\n- ° vee wn\\n- 2 phieF ne\\n- Basque arg min\\n- > lew\\n- Z;,|| English\\n- WeEO(n)\\n- ;Txakur [X1,« Z1,x] Dog\\n- Sagar |X2. Iw)\\n- ~ Zz | Apple\\n- Egutegi LXn. Zn) Calendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Cross-lingual embedding mappings\\n- Basque\\n- English\\n- Dog\\n- Apple\\n- Calendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Cross-lingual embedding mappings\\n\\n@Zexwoe  ors? A ° Whe e * xt? yor? gar' av? ° z $e aot .\\nY ys ve ® oes : o', 90° cae\" oage e W aa ae Se -__ > apr e® gare . co iG ost .= ©\\n- ae ee ° ce° se ak\\n- Pagarat YF\"<x? yio° at :3 ye e * oom ee apTM, 2 phieF ne . Basque arg min > lx\\n- Z;,|| English WeEO(n) ; Txakur [X1,« Z1,x] Dog Sagar | X2. Iw) ~ Zz | Apple Egutegi LXn. Zn) Calendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Cross-lingual embedding mappings\\n\\nNS Z 9 XWcad NS\\n\\nWeree ao? e 2 oe oat\" wisap e oe gest e ono\" care ogge e W aow\\n\\n= -__> ance @ gare my)yee we ae a oO\"e@° a ya o® cat<x? wo® \"v0or ° ° vee an,\\n\\n2 phieF ne.\\n\\nBasque arg min > lew\\n- Z;,|| English\\n\\nWeEO(n) ;Txakur [X1,« Z1,x] DogSagar |X2. Iw) ~ Zz | AppleEgutegi LXn. Zn) Calendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Cross-lingual embedding mappings\\nWe are aware of the Basque in English dog.\\n- Txakur\\n- Sagar\\n- Apple\\n- Egutegi\\n- Calendar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Cross-lingual embedding mappings are as follows:\\n- Basque\\n- English"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Cross-lingual embedding mappings Ww? = argamin min ||X; .W\\n- Z|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Artetxe et al. (ACL\\n2017) W° = argmin lbxi W\\n- Z|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Artetxe et al. (ACL\\n2017) we = again) male\\n- Zl"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Artetxe et al. (ACL\\n2017) W* = arg min Yamin |x\\n- Zp"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Artetxe et al. (ACL\\n2017) Ww? = argmin min ||X; W\\n- Z|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Artetxe et al. (ACL\\n2017) W* = argmin ) min [xi.W\\n- Zp J"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Artetxe et al. (ACL\\n2017)\\n- 25 word pairs 4wt = argmin min ||x; .W\\n- Z; .||"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Artetxe et al. (ACL\\n2017)\\n- 25 word pairs\\n\\n4\\n- Numeral list\\n\\nwt = argmin min ||X; .W\\n- Z;.|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Artetxe et al. (ACL\\n2017)\\n- 25 word pairs\\n- Numeral listreamzouw"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Artetxe et al. (ACL\\n2017)\\n- 25 word pairs\\n\\n4\\n- Numeral list\\n- Random dict.. . 2W* = arg min min||X; . W\\n- Z; . || JWeEO(n); J"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Artetxe et al. (ACL\\n2017)\\n- 25 word pairs\\n4\\n- Numeral list\\nA\\n- Random dict.\\nXgn Sopot J"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Artetxe et al. (ACL\\n2017) 0.45\\n- (Za: een aSs ils\\n- 5005 WL\\n- 260\\n- Numeral list A Dictionary; H <1\\n- Random dict. XBasa! g i ©=~ 0.25 |\\n- Jib b z PyIteration W* = arg min) min || X;,.W = Zell\" JWeEO(n); J"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "045\\n- GF 2\\n- Seed dict. TM,\\n- 5,000/ ae 2.5000404\\nAon EEE 1,000\\n- 25 word pairs\\nJS3 Hh for\\n- 500\\n> 5 AML\\n- 250\\n- Numeral list DictionaryUWS\\n- 100\\n.i I; as\\n- Random dict.\\nX© 930\\n-\\n- 50:\\n- 250.25 I\\n- ib bo\\nz) dbIteration\\n40 Seed dict. = Mapping\\n- 5000\\n_gu 2,000\\n30\\n-\\n- 1,000 =\\n- 500 >\\n- 250Boo.\\n- 100i Ee\\n10\\n-\\n- 25 = ...\\n- Dictionary\\n0a cent ceeecapecnec sees EEE\\nIteration"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Proposed method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization\\n2) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization\\n2) Intra-lingual similarity distribution\\n3) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization for x in vocab: sim(\"two\",\\nx)\\n2) Intra-lingual similarity distribution\\n\\nj Mapping\\n3) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization.\\n2) Robust self-learning\\n\\nIntra-lingual similarity distribution mapping"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "1) Fully unsupervised initialization.\\n2) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "1) Fully unsupervised initialization.\\n- Intra-lingual similarity distribution mapping\\n2) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "1) Fully unsupervised initialization.\\n- sapetwo due (two) cane (dog) !\\n\\nIntra-lingual similarity distribution mapping\\n2) Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization\\n2) Robust self-learning\\n- Stochastic dictionary induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization\\n2) Intra-lingual similarity distribution\\n3) Mapping\\n4) Robust self-learning\\n- Stochastic dictionary induction\\n- Frequency-based vocabulary cutoff"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization.\\n- Craft data sources (i.e., cane (dog))\\n2) Robust self-learning\\n- Stochastic dictionary induction\\n- Frequency-based vocabulary cutoff\\n- CSLS retrieval (Conneau et al., 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization.\\n2) Robust self-learning\\n- Stochastic dictionary induction\\n- Frequency-based vocabulary cutoff\\n- CSLS retrieval (Conneau et al.,\\n2018)\\n- Bidirectional dictionary induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Proposed method\\n1) Fully unsupervised initialization.\\n2) Robust self-learning\\n- Stochastic dictionary induction\\n- Frequency-based vocabulary cutoff\\n- CSLS retrieval (Conneau et al.,\\n2018)\\n- Bidirectional dictionary induction\\n- Final symmetric re-weighting (Artetxe et al., 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Experiments\\nBilingual lexicon extraction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n\\nMethod Zhang et al. (2017), A = 1\\n\\nZhang et al. (2017), A = 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n\\nMethod\\n\\nZhang et al. (2017), A = 1\\n\\nZhang et al. (2017), A = 10\\n\\nConneau et al. (2018), code\\n\\nConneau et al. (2018), paper\\n\\nProposed method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy) (Easy) dataset by Zhang et al.\\n(2017)\\n\\nMethod\\n- ES-EN\\n- IT-EN\\n- TR-EN\\n\\nZhang et al. (2017), A = 1\\nZhang et al. (2017), A = 10\\nConneau et al. (2018), code\\nConneau et al. (2018), paper\\nProposed method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method\\n=> Best/average accuracy = Successful runs (>5% accuracy) (Easy) dataset by Zhang et al. (2017)\\n\\nMethod        ES-EN      IT-EN      TR-EN\\nZhang et al. (2017), A = 1     71.43      60.38      0.00\\nZhang et al. (2017), A = 10    70.24      57.64      21.07\\nConneau et al. (2018), code     76.18      67.32      32.64\\nConneau et al. (2018), paper    76.15      67.21      29.79\\nProposed method                  76.43      66.96      36.10\\n\\nBest accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method\\n=> Best/average accuracy = Successful runs (>5% accuracy) on the (Easy) dataset by Zhang et al. (2017)\\n\\nMethod              ES-EN    IT-EN    TR-EN\\nZhang et al. (2017), A=1      68.18    56.45    0.00\\nZhang et al. (2017), A=10     66.37    52.60    17.95\\nConneau et al. (2018), code    75.82    67.00    14.34\\nConneau et al. (2018), paper   75.81    60.22    16.48\\nProposed method                     76.28    66.92    35.93\\n\\nAverage accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method\\n=> Best/average accuracy = Successful runs (>5% accuracy) (Easy) dataset by Zhang et al. (2017)\\n\\nMethod             ES-EN    IT-EN    TR-EN\\nZhang et al. (2017), A = 1      10       10      0\\nZhang et al. (2017), A = 10     10       10      10\\nConneau et al. (2018), code     10       10      5\\nConneau et al. (2018), paper    10\\nProposed method                10       10      10\\n\\nNumber of successful runs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method\\n- Best/average accuracy = Successful runs (>5% accuracy)\\n- (Easy) dataset by Zhang et al. (2017)\\n- (Hard) dataset by Dinu et al. (2016) + extensions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method\\n- Best/average accuracy = Successful runs (>5% accuracy)\\n(Easy) dataset by Zhang et al. (2017)\\n(Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod\\n- EN-IT\\n- EN-DE\\n- EN-FI\\n- EN-ES\\n\\nZhang et al. (2017), A = 1\\nZhang et al. (2017), A = 10\\nConneau et al. (2018), code\\nConneau et al. (2018), paper\\nProposed method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy)\\n(Easy) dataset by Zhang et al. (2017)\\n(Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod             EN-IT   EN-DE   EN-FI   EN-ES\\nZhang et al. (2017), A = 1      0.00    0.00    0.00    0.00\\nZhang et al. (2017), A = 10     0.00    0.00    0.01    0.01\\nConneau et al. (2018), code     45.40   47.27   1.62    36.20\\nConneau et al. (2018), paper    45.27   0.07    0.07    35.47\\nProposed method                 48.53   48.47   33.50   37.60\\n\\nBest accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy) on (Easy) dataset by Zhang et al.\\n(2017) and (Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod       EN-IT    EN-DE    EN-FI    EN-ES\\nZhang et al. (2017), A = 1      0.00     0.00     0.00     0.00\\nZhang et al. (2017), A = 2      10       0.00     0.00     0.01\\nConneau et al. (2018), code      45.40    47.27    1.62     36.20\\nConneau et al. (2018), paper     45.27    0.07     0.07     35.47\\nProposed method                    48.53    48.47    33.50    37.60\\n\\nBest accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy) (Easy) dataset by Zhang et al.\\n(2017)\\n- (Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod\\nEN-IT EN-DE EN-FI EN-ES\\nZhang et al. (2017), A = 1 0.00 0.00 0.00 0.00\\nZhang et al. (2017), A = 10 0.00 0.00 0.01 0.01\\nConneau et al. (2018), code 45.40 47.27 1.62 36.20\\nConneau et al. (2018), paper 45.27 0.07 0.07 35.47\\nProposed method 48.53 48.47 33.50 37.60\\n\\nBest accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "Experiments\\nBilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy)\\n(Easy) dataset by Zhang et al. (2017)\\n(Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod\\nEN-IT  EN-DE  EN-FI  EN-ES\\nZhang et al. (2017), A = 1  0.00  0.00  0.00  0.00\\nZhang et al. (2017), A = 10  0.00  0.00  0.01  0.01\\nConneau et al. (2018), code  45.40  47.27  16.20  36.20\\nConneau et al. (2018), paper  45.27  0.07  0.07  35.47\\nProposed method  48.53  48.47  33.50  37.60\\nBest accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "Experiments\\n- Bilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy = Successful runs (>5% accuracy)\\n\\n(Easy) dataset by Zhang et al. (2017)\\n(Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod          EN-IT     EN-DE    EN-FI     EN-ES\\nZhang et al. (2017), A = 1   0.00      0.00     0.00      0.00\\nZhang et al. (2017), A = 10  0.00      0.00     0.01      0.01\\nConneau et al. (2018), code  13.55     4215     0.38      21.23\\nConneau et al. (2018), paper 9.10      0.01     0.01      7.09\\nProposed method             48.13     48.19    32.63     37.33\\n\\nAverage accuracy (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "Experiments\\nBilingual lexicon extraction\\n- 10 runs for each method => Best/average accuracy => Successful runs (>5% accuracy)\\n- (Easy) dataset by Zhang et al. (2017)\\n- (Hard) dataset by Dinu et al. (2016) + extensions\\n\\nMethod\\nEN-IT\\nEN-DE\\nEN-FI\\nEN-ES\\n\\nZhang et al. (2017), A = 1\\n0\\n0\\n0\\n0\\n\\nZhang et al. (2017), A = 10\\n0\\n0\\n0\\n0\\n\\nConneau et al. (2018), code S\\n9\\n0\\n6\\n\\nConneau et al. (2018), paper\\n2\\nfe mm\\n2\\n\\nProposed method\\n10\\n10\\n10\\n10\\n\\nNumber of successful runs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "Experiments Supervision Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "Experiments\\n\\nSupervision Method\\n- Mikolov et al. (2013)\\n- Faruqui and Dyer (2014)\\n- Shigeto et al. (2015)\\n- Dinu et al. (2015)\\n- Lazaridou et al. (2015)\\n- 5k dict.\\n- Xing et al. (2015)\\n- Zhang et al. (2016)\\n- Artetxe et al. (2016)\\n- Artetxe et al. (2017)\\n- Smith et al. (2017)\\n- Artetxe et al. (2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 83,
        "texts": [
          "Experiments\\n\\nSupervision Method\\n\\nMikolov et al. (2013)\\nFaruqui and Dyer (2014)\\nShigeto et al. (2015)\\nDinu et al. (2015)\\nLazaridou et al. (2015)\\n5k dict.\\nXing et al. (2015)\\nZhang et al. (2016)\\nArtetxe et al. (2016)\\nArtetxe et al. (2017)\\nSmith et al. (2017)\\nArtetxe et al. (2018)\\n25 dict.\\nArtetxe et al. (2017)\\nInit.\\nSmith et al. (2017), cognates\\nheurist.\\nArtetxe et al. (2017), num."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 84,
        "texts": [
          "Experiments\\n\\nSupervision Method\\n- Mikolov et al. (2013)\\n- Faruqui and Dyer (2014)\\n- Shigeto et al. (2015)\\n- Dinu et al. (2015)\\n- Lazaridou et al. (2015)\\n- 5k dict. Xing et al. (2015)\\n- Zhang et al. (2016)\\n- Artetxe et al. (2016)\\n- Artetxe et al. (2017)\\n- Smith et al. (2017)\\n- Artetxe et al. (2018)\\n- 25 dict. Artetxe et al. (2017)\\n- Init. Smith et al. (2017), cognates\\n- heuristic. Artetxe et al. (2017), num.\\n- Zhang et al. (2017), A = 1\\n- Zhang et al. (2017), 2 = 10\\n- None Conneau et al. (2018), code\\n- Conneau et al. (2018), paper\\n- Proposed method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 86,
        "texts": [
          "Experiments\\n\\nSupervision Method\\n\\nEN-IT\\nEN-DE\\nEN-FI\\nEN-ES\\n\\nMikolov et al. (2013) 34.937 35.00 25.91 27.73\\n\\nFaruqui and Dyer (2014) 38.40 37.13 27.60 26.80\\n\\nShigeto et al. (2015) 41.53 43.07 31.04 33.73\\n\\nDinu et al. (2015) 37.7 38.93 29.14 30.40\\n\\nLazaridou et al. (2015) 40.2\\n-\\n-\\n-\\n\\n5k dict.\\n\\nXing et al. (2015) 36.87 41.27 28.23 31.20\\n\\nZhang et al. (2016) 36.73 40.80 28.16 31.07\\n\\nArtetxe et al. (2016) 39.27 41.87 30.62 31.40\\n\\nArtetxe et al. (2017) 39.67 40.87 28.72\\n-\\n\\nSmith et al. (2017) 43.1 43.33 29.42 35.13\\n\\nArtetxe et al. (2018) 45.27 44.13 32.94 36.60\\n\\n25 dict.\\n\\nArtetxe et al. (2017) 37.27 39.60 28.16\\n-\\n\\nInit. Smith et al. (2017), cognates 39.9\\n-\\n-\\n-\\n\\nheurist. Artetxe et al. (2017), num. 39.40 40.27 26.47\\n-\\n\\nZhang et al. (2017), A = 1 0.00 0.00 0.00 0.00\\n\\nZhang et al. (2017), 2 = 10 0.00 0.00 0.01 0.01\\n\\nNone\\n\\nConneau et al. (2018), code 45.15 46.83 0.38 35.38\\n\\nConneau et al. (2018), paper 45.10 0.01 0.01 35.44\\n\\nProposed method 48.13 48.19 32.63 37.33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 87,
        "texts": [
          "Experiments Supervision Method                                        EN-IT        EN-DE        EN-FI        EN-ES\\n\\nMikolov et al. (2013)                                              34.937      35.00'      25.91'      27.73'\\n\\nFaruqui and Dyer (2014)                                          38.40°      37.13\"      27.60\"      26.80\"\\n\\nShigeto et al. (2015)                                             41.53'      43.07*      31.04\"      33.73'\\n\\nDinu et al. (2015)                                                37.7          38.93\"      29.14\"      30.40°\\n\\nLazaridou et al. (2015)                                          40.2\\n-\\n-\\n-\\n\\n5k dict.\\n\\nXing et al. (2015)                                               36.87'      41.27'      28.23'      31.20°\\n\\nZhang et al. (2016)                                             36.73\"      40.80'      28.16'      31.07°\\n\\nArtetxe et al. (2016)                                           39.27        41.87\"      30.62°      31.40°\\n\\nArtetxe et al. (2017)                                           39.67        40.87        28.72\\n-\\n\\nSmith et al. (2017)                                             43.1          43.33'      29.42*      35.137\\n\\nArtetxe et al. (2018)                                           45.27        44.13        32.94        36.60\\n\\n25 dict.\\n\\nArtetxe et al. (2017)                                           37.27        39.60        28.16\\n-\\n\\nInit.\\n\\nSmith et al. (2017), cognates                                   39.9\\n-\\n-\\n-\\n\\nheurist.\\n\\nArtetxe et al. (2017), num.                                  39.40        40.27        26.47\\n-\\n\\nZhang et al. (2017), A = 1                                       0.00°      0.00°      0.00°      0.00°\\n\\nZhang et al. (2017), 2 = 10                                     0.00°      0.00°      0.01\"      0.01\"\\n\\nNone\\n\\nConneau et al. (2018), code*                                  45.15\"      46.83\"      0.38\"      35.38°\\n\\nConneau et al. (2018), paper*                                 45.1          0.01\"      0.01°      35.44°\\n\\nProposed method                                              48.13        48.19        32.63        37.33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 89,
        "texts": [
          "Experiments Supervision Method\\n\\nEN-IT   EN-DE   EN-FI   EN-ES\\n\\nMikolov et al. (2013)         34.937   35.00°   25.91°   27.73°\\n\\nFaruqui and Dyer (2014)       38.40°   37.13\"   27.60\"   26.80\"\\n\\nShigeto et al. (2015)         41.53'   43.07*   31.04\"   33.73'\\n\\nDinu et al. (2015)            37.7     38.93\"   29.14\"   30.40°\\n\\nLazaridou et al. (2015)       40.2\\n-\\n-\\n-\\n\\n5k dict.\\n\\nXing et al. (2015)            36.87'   41.27'   28.23'   31.20°\\n\\nZhang et al. (2016)           36.73\"   40.80'   28.16'   31.07°\\n\\nArtetxe et al. (2016)         39.27    41.87\"   30.62°   31.40°\\n\\nArtetxe et al. (2017)         39.67    40.87    28.72\\n-\\n\\nSmith et al. (2017)           43.1     43.33'   29.42*   35.137\\n\\nArtetxe et al. (2018)         45.27    44.13    32.94    36.60\\n\\n25 dict.\\n\\nArtetxe et al. (2017)         37.27    39.60    28.16\\n-\\n\\nInit. Smith et al. (2017), cognates       39.9\\n-\\n-\\n-\\n\\nheurist.\\n\\nArtetxe et al. (2017), num.   39.40    40.27    26.47\\n-\\n\\nZhang et al. (2017), A = 1     0.00°    0.00°    0.00*    0.00°\\n\\nZhang et al. (2017), 2 = 10    0.00°    0.00°    0.01*    0.01\"\\n\\nNone\\n\\nConneau et al. (2018), code*   45.15\"   46.83\"   0.38°    35.38\"\\n\\nConneau et al. (2018), paper*  45.1     0.01°    0.01°    35.44°\\n\\nProposed method                48.13    48.19    32.63    37.33"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 90,
        "texts": [
          "Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 91,
        "texts": [
          "Conclusions\\n- Not a solved problem!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 92,
        "texts": [
          "Conclusions\\n- Not a solved problem!\\n- New self-learning approach"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 93,
        "texts": [
          "Conclusions\\n- Not a solved problem!\\n- New self-learning approach => Fully unsupervised initialization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 94,
        "texts": [
          "Conclusions\\n- Not a solved problem!\\n- New self-learning approach\\n- Fully unsupervised initialization\\n- Robust self-learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 95,
        "texts": [
          "Conclusions\\n- Not a solved problem!\\n- New self-learning approach\\n- Fully unsupervised initialization\\n- Robust self-learning\\n- More robust and accurate than previous methods"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 96,
        "texts": [
          "Conclusions\\n- Not a solved problem!\\n- New self-learning approach\\n- Fully unsupervised initialization\\n- Robust self-learning\\n- More robust and accurate than previous methods\\n\\nFuture work: from bilingual to multilingual"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 97,
        "texts": [
          "One more thing..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 98,
        "texts": [
          "One more thing...\\n\\ngit clone https://github.com/artetxem/vecmap.git"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 99,
        "texts": [
          "One more thing...\\n\\ngit clone https://github.com/artetxem/vecmap.git\\n\\npython3 vecmap/map_embeddings.py --unsupervised SRC.EMB TRG.EMB"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 100,
        "texts": [
          "One more thing...\\n\\ngit clone https://github.com/artetxem/vecmap\\n\\ngit python3 vecmap/map_embeddings.py --unsupervised SRC.EMB TRG.EMB SRC_MAPPED.EMB TRG_MAPPED.EMB"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 101,
        "texts": [
          "One more thing...\\n\\ngit clone https://github.com/artetxem/vecmap.git\\n\\npython3 vecmap/map_embeddings.py --unsupervised SRC.EMB TRG.EMB SRC_MAPPED.EMB TRG_MAPPED.EMB\\n\\nPoeBete = aeee https://github.com/artetxem/vecmap"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 102,
        "texts": [
          "Thank you!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 196,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Authors Amulya Gupta\\nZhu (Drew) Zhang\\n\\nEmail: guptaam@iastate.edu\\nEmail: zhuzhang@iastate.edu\\nhttps://github.com/amulyahwr/acl2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Agenda\\nIntroduction\\nClassical world\\nAlternate world\\nOur contribution\\nSummary."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Problem Statement\\n\\nGiven two sentences, determine the semantic similarity between them."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "- Semantic relatedness for sentence pairs.\\n- Paraphrase detection for question pairs.\\n1. Given a pair of questions, classify them as paraphrase or not.\\n2. Higher score implies higher semantic similarity among sentences.\\n\\nEssence: Given two sentences, determine the semantic similarity between them."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Datasets used\\n- Semantic relatedness for sentence pairs.\\n- Paraphrase detection for question pairs.\\n1. SICK (Marelli et al.,\\n2014)\\n- Score range: [1, 5]\\n- Dataset: 4500/500/4927 (train/dev/test)\\n2. Quora (Iyer et al., Kaggle,\\n2017)\\n- Binary classification\\n- Dataset: Used 50,000 data points out of 400,000\\n3. MSRpar (Agirre et al.,\\n2012)\\n- Score range: [0, 5]\\n- 80% (5%) / 20% (train/dev/test)\\n- Dataset: 750/750 (train/test)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "The badger is burrowing a hole.\\nA hole is being burrowed by the badger.\\n\\nThe reading for both August and July is the highest reading since the index was created in August\\n1997.\\n\\nWhat is big data? Is big data really doing well?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Generally, a sentence is read in a linear form.\\n\\nEnglish (Left to Right): The badger is burrowing a hole.\\n\\nTraditional Chinese (Top to Bottom):\\n\\nUrdu (Right to Left):"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Long Short Term Memory (LSTM) the badger is burrowing a hole"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "LSTM cell = o(u_nW + h_y_1 R_i +\\nb)\\n\\nf_r = o(m_W + h_i R +\\nb)\\n\\nu_e = tanh(w_i W + h_y_a R_TM +\\nb)\\n\\nh = H_out\\n\\nh_1, h_2, h_3, h_4, h_5, h_6\\n\\nh_y = tanh(c_r)\\n\\nLSTM\\n\\nLSTM\\n\\nLSTM\\n\\nLSTM\\n\\nLSTM\\n\\nLSTM\\n\\ncell\\n\\nThe badger is a burrowing animal.\\n\\nClassical IOWA STATE UNIVERSITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Attention mechanism\\n\\nNeural Machine Translation (NMT) Global Attention Model (GAM) (Bahdanau et al.,\\n2014) (Luong et al., 2015):\\n\\ng = 3 g_nN 4\\n\\nAttention layer fvsco_i = Useones"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Tree Constituency Dependency S\\n- NP VP\\n- nsubj\\n- x dobj\\n- DT NN VBZ\\n- VP The badger is\\n- VBG NP\\n- det burrowing DT NN\\n- (hele =\\n- a12 IOWA STATE UNIVERSITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Tree-LSTM (Tai et al.,\\n2015)\\n\\ngece lak MAG Ui seca04\\n\\ni = Dh || (Lo ee)\\n\\nlyi = o(w; Wi + hy Ri +\\nb) (8)\\n\\nburrowing ead\\n\\nPEST Gx = olmn + i + )\\n0) 6\\n\\nBURNING cell FT\\n\\n(wi WH AGREE WY ~ (10):\\n\\nv = uj = tanh(wj) W\" + R\" + 6\") (11)\\n\\n02 03 5\\n\\ng = i3 Ou + D> feOm (12)\\n\\nkEC() a aux goby | f | .\\n\\nhy = 0;\\n\\n© tanh(c;) (13)\\n\\nT-LSTM\\n\\nT-LSTM\\n\\nT-LSTM\\n\\ncell\\n\\ncelle_\\n\\nThe e_a\\n\\n13:\\n\\niRaeUEOR\\n\\nClassical\\n\\nAlternate\\n\\nIOWA STATE UNIVERSITY\\n\\nworld\\n\\nworld"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Attention mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Decomposable Attention (Parikh et al.,\\n2016)\\n\\nAggregate ¥ = H ( |: . + P\\n\\nPark outside\\n\\n1-6\\n\\nAlice someone\\n\\nCompare l = cd Db see flute + solo music\\n\\nI\\n- oU.. boO\\n\\n1 § Bigs 8 in the -- 7 > park ee 55 alice | |\\n\\n'No structural Bias\\n\\n'No structural encoding\\n\\nFL, | ) e1 e2 e3 e4 e5 €6 e7 68\\n\\nAttend: Attention matrix e1 e2 e3 e4\\n\\n-Sentence L\\n\\n-Sentence R\\n\\n} INTFOMLGHON\\n\\nClassical\\n\\n-Alternate\\n\\nIOWA STATE UNIVERSITY\\n\\nucti world world"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "(coee eee Joutputh, (@eceece) hy (Absolute Distance similarity: eee ant (Sign similarity: Element wise absolute difference) 7 =\\n-\\n- zd\\n- Element wise multiplication)\\n\\nModification 2\\n\\nHL oo... HR MDA is employed after call 02 sto, encoding sentences.\\nwae | off ON,/ 08 / 7 7oft Attention matrix\" ' TistTM )! \\ T-LSTM \\ \\I ' cell ' | cell \\ 'i o1' 62 \\ :\\n\\nModification 1\\n\\niT-LSTM T-LSTM T-LSTM T-LSTM d' cell cell cell cell\\n\\nSentence bn Sentonce ue1 S U The REIEE Classical OurOTe TUES IWS SER world contribution 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "MSRpar 0.327 0.3763 0.3981 0.3991 0.4921 0.4016 van 0.3025 0.315 x 0.3237 0.4519 0.3310 0.8098 0.729 0.7407 0.722 0.6611 0.7243\\n\\nDependency SICK 0.8398 0.7899 0.8582 0.779 0.8676 0.8239 0.7782 0.7173 0.7966 0.7074 0.8083 0.7614 0.3024 0.3897 0.2734 0.4044 0.2532 0.33261\\n\\nS: The REIEE Classical Alternate Our OWA STATE NIMS SER world world contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "ne A x, wT- ee ee ee aeHE HRYa * o1 aq = | Gatingot a +03 a3 03 | mechanismfo Ml o2 a2 03 Ii yf !\\ni at Attention |we ¥ Moe eH Her 5 _-.Ee1 cell ' cellcell cell cell cellStart a Sentence L Phase 1 Sentence R 18SSiRaeUEOR Classical Alternate OurOWN SarACue UNIVERSITY world world contribution 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Progressive Attention (PA) a sf iineS / cf TS, e i 4 MeSS SS aeDane !\\n= AtHe o1 1-al al 03 pee HenrT I Gating-° f my eeee\\n\\n03 1-a3 a3 03 | pCHepistis a dteoes eenieee soma aae et 702 % 1-a2 a2 03 po _HL !\\n' HR :vo # : / oe Attention [ °° 5 E a str.A / i-\\n\\noo == aa i -Vgelor\\n- --=-7; 03 > Acad 02% Tess.i : ws 7 I ; Attention \"ee vl SM' ! ' gen oad foo PRS ae = eT\\n\\nyif tis ) T-LSTM Bee \\ =.H cell i cell \\ \\1 A cell ; cell .= cel I sell\\n\\nSentence L Phase 2\\n\\nSentence R @ StartaStart @\\n\\nSentence L Phase 1\\n\\nSentence R 19a aI S 0 INtSeUettOn\\n\\nClassical Alternate OurOe Sa world world contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Prog ive Attention (PA) output\\n\\nPA is employed during, ENP (Absolute Distance similarity: Element wise absolute difference)\\n\\nElement wise multiplication\\n- Separate\\n- Attention\\n- Classical\\n- Alternate\\n\\nOur IOWA STATE UNIVERSITY contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Senieco1\\nSentence\\nGot Linear\\nGonstiveney\\nDependency No PA\\nNo attn\\nPA atin 1\\nThe badger is burrowing\\nA hole is being\\n2.60\\n3.02\\n3.52\\n4.34\\n3.41\\n4.63\\na hole burrowed by the badger\\nThe REIEE Classical Alternate Our OWA STATE ON\\nSana world world contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "w/o w/o w/o MSR par | Pearson's r | 0.327 0.3763 4773 | 0.3981 0.3991 0.5104 | 0.4921 0.4016 0.4727 0.2205 0.3025 @ 6 0.4453 | 0.315 0.3237 0.4764 | 0.4519 0.331 pe 0.8098 0.729 0.6758 | 0.7407 0.722 0.6436 | 0.6611 0.7243 0.6823\\n\\nw/o w/o w/o SICK 0.8398 0.7899 0.8550 | 0.8582 0.779 0.8625 | 0.8676 0.8239 0.8424 0.7782 0.7173 0.7873 | 0.7966 0.7074 0.7997 | 0.8083 0.7614 or 0.3024 0.3897 0.2761 | 0.2734 0.4044 0.2610 | 0.2532 0.3326 0.2963\\n\\nS U : The REIEE Classical Alternate Our OWA STATE UNIVERSITY world world contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Pearson's r | 0.327 0.3763 0.4773 | 0.3981 0.3991 0.5104 0.4921 0.4016 0.4727 0.2205 0.3025 0.4453 0.315 0.3237 0.4764 0.4519 0.331 0.8098 0.729 0.6758 0.7407 0.722 0.6436 0.6611 0.7243 0.6823\\n\\nSICK 0.8398 0.7899 0.8550 0.8582 0.779 0.8625 0.8676 0.8239 0.8424 0.7782 0.7173 0.7873 0.7966 0.7997 0.8083 0.7614\\n\\nYor 0.3024 0.3897 0.2761 0.2734 0.4044 0.2610 0.2532 0.3326 0.2963\\n\\nS : The REIEE Classical Alternate Our OWA STATE UNIVERSITY world world contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Discussion MSR par | Pearson's r | 0.327 0.376 0.477 0.398 0.399 0.510 0.492 0.401 0.472\\n\\nGildea (2004): Dependencies vs. 0.2205 = c 0.315 or 0.476 0.451 0.331\\n\\nConstituents for Tree Based 0.8098 0.729 0.675 0.7407 0.722 0.6436 0.6611 0.7243 0.6823\\n\\nAttention MBA\\nAttention MDE\\nAttention MDA\\n\\nConsidered as an implicit form of sick.\\n\\n0.8398 0.7899 0.8550 0.8582 0.779 0.8625 0.8676 0.8239 0.8424\\n\\nExplicit form of syntactic structure?\\n\\n0.3024 0.3897 0.2761 0.2734 0.4044 0.2610 0.2532 0.3326 0.2963\\n\\nIf yes, does there exist some tradeoff between modeling efforts invested in syntactic and attention structure?\\n\\nDoes this mean there is a closer affinity between dependency structure and compositional semantics?\\n\\nIf yes, is it because dependency structure embodies more semantic information?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Summary\\n- Proposed a modified decomposable attention (MDA) and a novel progressive attention (PA) model on tree-based structures.\\n- Investigated the impact of proposed attention models on syntactic structures in linguistics.\\nIOWA STATE UNIVERSITY"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 193,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Data is Limited\\n- Most of the popular models in NLP are data-driven\\n- We often need to operate in a specific scenario > Limited data y26°"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Data is Limited.\\n\\nTake spoken language understanding as an example.\\n\\nUnderstanding user query:\\n- Need to be implemented for many domains.\\n- Intent Detection: flights from Boston to Tokyo.\\n- Slot Filling: flights from Boston to Tokyo ==> ability to locate city: Tokyo."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Data is Limited\\n- Take spoken language understanding as an example. Need to be implemented for many domains.\\n\\nLimited data. E.g., intelligent customer service robot\\n- What can we do with limited data?\\n\\nIntent Detection\\n- flights from Boston to Tokyo => intent: flight\\n\\nSlot Filling\\n- flights from Boston to Tokyo => create slot: location.city: Tokyo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Regular Expression Rules\\n- When data is limited, use a rule-based system.\\n- Regular expression is the most commonly used rule in NLP.\\n- Many regular expression rules in company/flights from Intent Detection.\\n\\nIntent: flight/from (_CITY) to (_CITY)\\n\\nSlot Filling\\n- fromloc.city: Boston\\n- toloc.city: Tokyo\\n- _CITY=Boston | Tokyo | Beijing | ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Regular Expression Rules\\n\\nHowever, regular expressions are hard to generalize.\\n\\nNeural networks are potentially good at generalization. Can we combine the advantages of two worlds?\\n\\nRegular Expressions\\nPro: controllable, do not need data\\nCon: need to specify every variation\\n\\nNeural Network\\nPro: semantic matching (0.23, 0.11, -0.32, ...)\\nCon: need a lot of data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Which Part of Regular Expression to Use?\\n- Regular expression (RE) output is useful\\n- As feature\\n- Fusion in output\\n\\nIntent /flights?\\nfrom/Detection flights from Boston to Tokyo ===> flightSlot /from(_CITY) to (CITY)/Fillin: fromloc.city: Boston flights from Boston to Tokyo => toloc.city: Tokyo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Which Part of Regular Expression to Use?\\n- Regular expression (RE) output is useful.\\n- RE contains NN should attend to these clue words for prediction.\\n- Guide attention module Intent flights? from/\\n- Detection [flights from] Boston to Tokyo.\\n- Intent: flight Slot [from] CITY [to] Tokyo."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Method 1: RE Output\\n- As Features\\n\\nEmbed the RE tag, append to input\\n\\nA Softmax Classifier\\n\\nAttention\\n\\nIntent Detection\\n\\nInstance flights from Boston to Miami"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Method 1: RE Output\\n- As Features\\n\\nEmbed the REtag, append to input\\n\\nRE / A Softmax Classifier\\n\\nSlot Filling\\n\\nflights from Boston to Miami\\n\\nREtag: O B-loc.city O B-loc.city from CITY to CITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Method 2: RE Output\\n- Fusion in Output logit; the NN output score for class k (before softmax) Z, € {0, 1}, whether regular expression predict class k or not.\\n\\nA Softmax Classifier\\nAttention/f- = BES\\n\\nAggregation Intent Detection\\n\\nflights from Boston to Miami"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Method 2: RE Output\\n- Fusion in Output\\n-\\n\\nlogit_k = logit' + w_z + logit';\\n\\nthe NN output score for class k (before softmax) Z_k ∈ {0, 1}, whether regular expression predicts class k\\n\\nlogit_k = logit' + w_z |\\n\\nSoftmax Classifier RE or \"Slot Filling! AO!,\"\\n\\nInstance: So flights from Boston to Miami --> from CITY to __CITY/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Method 3: Clue Words\\n- Guide Attention\\n\\nAttention should match clue words.\\n\\nCross Entropy Loss at Attention in a Softmax Classifier.\\n\\nLoss | Attention with Aggregation.\\n\\nIntent Detection.\\n\\nIs there a Boston to Miami flight?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Method 3: Clue Words\\n- Guide Attention\\n\\nAttention should match clue words\\n- Cross Entropy Loss\\n- Attention\\n- A Softmax Classifier\\n- Slot Filling\\n- PTL\\n- Flights from Boston to Miami\\n- From CITY to CITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Method 3: Clue Words\\n- Guide Attention\\n- Positive Regular Expressions (REs) & Negative REs\\n\\nREs can indicate the input belongs to class k, or does not belong to class k.\\n- Correction of wrong predictions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Method 3: Clue Words\\n- Guide Attention\\n- Positive Regular Expressions (REs) & Negative REs\\n\\nCorresponding to positive / negative REs\\n- logit = logit, positive\\n- logit; negative fly from LA to NYC? == intent: abbreviation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Method 3: Clue Words\\n- Guide Attention\\n- Positive REs and Negative REs interconvertible\\n- A positive RE for one class can be negative RE for other classes\\n- intent: flight\\n- flights from Boston to Tokyo\\n- intent: abbreviation\\n- intent: airfare"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Experiment Setup\\n- ATIS Dataset\\n- 18 intents, 63 slots\\n- Regular Expressions (RE)\\n- Written by a paid annotator\\n- Intent: 54 REs, 1.5 hours\\n- Slot: 60 REs, 1 hour (feature & output); 115 REs, 5.5 hours (attention)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experiment Setup\\n\\nWe want to answer the following questions:\\n- Can regular expressions (REs) improve the neural network (NN) when data is limited (only use a small fraction of the training data)?\\n- Can REs still improve NN when using the full dataset?\\n- How does RE complexity influence the results?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Few-Shot Learning Experiment\\n- Intent Detection\\n\\nMacro-F1 / Accuracy\\n- 5/10/20-shot: every intent has 5/10/20 sentences\\n\\n5-shot\\nbase 45.28 / 60.02\\nfeat 49.40 / 63.72\\noutput 46.01 / 58.68\\natt 54.86 / 75.36\\nRE 70.31 / 68.98\\n\\n10-shot\\nbase 60.62 / 64.61\\nfeat 64.34 / 73.46\\noutput 63.51 / 77.83\\natt 71.23 / 85.44\\nRE 68.98\\n\\n20-shot\\nbase 63.60 / 80.52\\nfeat 65.16 / 83.20\\noutput 69.22 / 89.25\\natt 75.58 / 88.80\\nRE\\nRegular expressions help"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "e e g TT MFew-Shot Learning Experiment @®\\n- Intent Detection\\n- Macro-F1 / Accuracy\\n- 5/10/20-shot: every intent has 5/10/20 sentences\\n\\n5-shot\\nbase 45.28 / 60.02\\nfeat 49.40 / 63.72\\noutput 46.01 / 58.68\\natt 54.86 / 75.36\\n\\n10-shot\\nbase 60.62 / 64.61\\nfeat 64.34 / 73.46\\noutput 63.51 / 77.83\\natt 71.23 / 85.44\\n\\n20-shot\\nbase 63.60 / 80.52\\nfeat 65.16 / 83.20\\noutput 69.22 / 89.25\\natt 75.58 / 88.80\\n\\nUsing clue words to guide attention performs best for intent detection"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Few-Shot Learning Experiment\\n- Slot Filling\\n\\nMacro/Micro-F1\\n\\n5/10/20-shot: every intent has 5/10/20 sentences\\n\\n5-shot:  60.78/83.91  66.84/88.96  3.68/86.18\\n10-shot: 74.28/90.19 79.67/93.64 76.12/91.64\\n20-shot: 80.57/93.08 84.95/95.00 83.71/94.43\\n- base: 60.78/83.91\\n- feat: 66.84/88.96\\n- output: 3.68/86.18\\n- att: 59.47/83.35\\n- RE: 42.33/70.79"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "@Few-Shot Learning Experiment\\n\\nOY- Slot Filling\\n- Macro/Micro-F1\\n- 5/10/20-shot: every intent has 5/10/20 sentences\\n\\n5-shot 10-shot 20-shot\\nbase 60.78/83.91 74.28/90.19 80.57/93.08\\nfeat 66.84/88.96 79.67/93.64 84.95/95.00\\noutput 63.68/86.18 76.12/91.64 83.71/94.43\\natt 59.47/83.35 73.55/89.54 79.02/92.22\\nRE 42.33/70.79\\n\\nUsing RE output as feature performs best for slot filling"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Full Dataset Experiment\\n- Use all the training data\\n- RE still works!\\n\\nIntent Slot | base\\n- 92.50/98.77\\n- 85.01/95.47\\nfeat 91.86/97.65 86.70/95.55\\noutput | 92.48/98.77 86.94/95.42\\natt 96.20/98.99 85.44/95.27\\nRE 70.31/68.98 42.33/70.79\\nSoA (Joint Model)\\n- / 98.43\\n- / 95.98"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Complex RE v.s. Simple RE:\\n- Complex RE: many semantically independent groups\\n- Complex RE: /(_AIRCRAFT_CODE) that fly/\\n- Simple RE: /(_AIRCRAFT_CODE)/\\n\\nIntent Slot\\n\\nComplex Simple Complex Simple\\n\\nbase 80.52 93.08\\nfeat 83.20 | 80.40 [95.00 94.71\\noutput 89.25 83.09 94.43 93.94\\natt 88.80 87.46\\n\\nComplex REs yield better results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "e gTTM Complex RE vs. Simple RE:\\n\\nComplex RE: /(_AIRCRAFT_CODE) that fly/\\n\\nSimple RE: /(_AIRCRAFT_CODE)/ Intent Slot\\n\\nComplex Simple Complex Simple\\n\\nbase 80.52 93.08\\n\\nfeat 83.20 80.40 95.00 [04.71\\n\\nouput 89.25 83.09 94.43 93.94\\n\\natt 88.80 87.46\\n- Simple REs also clearly improves the baseline"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusion:\\n- Using REs can help to train NN when data is limited.\\n- Guiding attention is best for intent detection (sentence classification).\\n- RE output as feature is best for slot filling (sequence labeling).\\n- We can start with simple REs and increase complexity gradually."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "TNTPAZ e)ay ani ai 3o Iigo"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 189,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "S¥-ToL4e4 ce) iL6|Semantic Hashing\\n\\nFast and accurate similarity search (i.e., finding documents from a large corpus that are most similar to a query of interest) is at the core of many information retrieval applications.\\nOne strategy is to represent each document Samoa as a continuous vector, such as Paragraph Vector [Le and Mikolov, 2014], Skip-thought vectors [Kiros et al., 2015], and InferSent [Conneau et al., 2017], etc.\\n\\nCosine similarity is typically employed to measure relatedness.\\n\\nSemantic hashing is an effective approach: the similarity between two documents can be evaluated by simply calculating pairwise Hamming distances between hashing (binary) codes;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation & contributions\\n\\nMotivation: Existing semantic hashing approaches typically require two-stage training procedures (e.g.\\ncontinuous representations are crudely binarized after training);\\na vast amount of unlabeled data is not fully leveraged for learning binary document representations.\\n\\nContributions:\\n- We propose a simple and generic neural architecture for text hashing that learns binary latent codes for documents, which can be trained in an end-to-end manner.\\n- We leverage a Neural Variational Inference (NVI) framework, which introduces data-dependent noises during training and makes effective use of unlabeled information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Framework components\\n\\nHashing under the NVI Framework\\n\\nNotations: let x and z denote the input document and its corresponding binary hash code, respectively;\\n\\nWe define a generative model that simultaneously accounts for both the encoding distribution, p(z|x), and decoding distribution, p(x|z),\\n\\nWe define approximations qg(z|x) and qg(x|z) via inference and generative networks, parameterized by\\n- and @, respectively."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Framework components\\n\\nTraining with Binary Latent Variables\\n\\nThe generative term provides a natural training objective for semantic hashing: with the decoder network modeling p(x|z), the key semantic information from x is naturally encapsulated.\\nTo tailor the NVI framework for semantic hashing, we cast z as a binary latent variable and assume a multivariate Bernoulli prior on z:\\n\\nI!Z: p(z) ~ Bernoulli(y) = Il Yili); (1)i=1\\n\\nThe encoding (approximate posterior) distribution qg(z|x) is restricted to take the form qg(z|x) = Bernoulli(h), where A is inferred from x with the encoder network."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Framework components\\n\\nTraining with Binary Latent Variables\\n\\nWe can obtain samples from the Bernoulli posterior either deterministically or stochastically:\\n\\nSuppose z is a l-bit hash code, the deterministic binarization is defined as (for i = 1, 2, ..., l):\\n\\nsign(a(gi(x)\\n- 0.5)) + 1z = Ly(-i(x)) > 0.5 = 2 (2)\\n\\nThe stochastic binarization (where ju; ~ Uniform(0, 1)):\\n\\nsign(o(@i(x)) = mi) + 121 = Le(ei) > mi = 3 (3)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Framework components\\n\\nTraining with Binary Latent Variables\\n\\nTo estimate the parameters of the encoder and decoder networks, we maximize a variational lower bound:\\n\\nao(x|z) = E[log p(x|z)]\\n- D(q(z|x) || p(Z));\\n\\nThe KL-divergence D(q(z|x) || p(Z)) encourages the approximate posterior q(z|x) to be close to the multivariate Bernoulli prior p(z); D(q(z|x) || p(Z)) can be written in closed-form."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Framework components\\n\\nTraining with Binary Latent Variables\\n\\nIt is challenging to backpropagate gradients through the discrete (binary) latent variable, since the derivative of the sign function is zero for almost all input values;\\n\\nInstead, we utilize the straight-through (ST) estimator, which was first introduced by Hinton (2012).\\nIt simply backpropagates through the hard threshold by approximating the gradient ∂z/∂o(g}(x)) as 1: ∂Eq(z|x) log qo(x|z) ∂g(z|x) [log q0(x|z)] dz ∂(g_i(x))\\n- dz ∂o(g_i(x)) dE_g(z|x) [log q0(x|z)] ∂(g_i(x))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Framework components\\n\\nInjecting Data-dependent Noise to zgo(2)\\n\\nWe found that injecting random Gaussian noise into z makes the decoder a more favorable regularizer for the binary codes.\\nThe objective function in (4) can be written in a form similar to the rate-distortion tradeoff:\\n\\nnE 1 toemin Eg, (z|x) |\\n- log aa(z|x) + 5 [Ix\\n- Eze + C} (6)\\n\\nRate\\n- Distortion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Framework components\\n\\nExtension to Supervised Hashing\\n\\nWhile labeled data are available, we can explicitly learn a mapping from latent variable z to labels y, here parametrized by a two-layer MLP followed by a fully-connected softmax layer.\\nAs a result, the loss function is a combination of variational lower bound and discriminative (cross-entropy) loss:\\n\\nL = -L(y|ael9, @;\\nx) + aL(a|is(n: Z,y)): (7)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Experiments\\n\\nDatasets & Experimental Setup\\n\\nDatasets: we evaluate the proposed method on three benchmarks: Reuters 21578, 20 Newsgroups, TMC (SIAM text mining competition); TFIDF features are utilized as the input x for documents; we set the dimension of z, i.e., the number of bits within the hashing code, as 8, 16, 32, 64, or\\n128.\\n\\nWe employed precision as the evaluation metric: the percentage of documents among the top 100 retrieved ones that belong to the same label (topic) with the query document."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Semantic Hashing Evaluation\\n\\nMethod\\n- 8 bits                 | 0.2802 | 0.3215 | 0.3862 | 0.4667 | 0.5194\\n- TSH                    | 0.5113 | 0.5740 | 0.6154 | 0.6177 | 0.6452\\n- AmSpH                  | 0.6080 | 0.6340 | 0.6513 | 0.6290 | 0.6045\\n- paSTH                  | 0.6616 | 0.7351 | 0.7554 | 0.7350 | 0.6986\\n- VDSH                   | 0.6859 | 0.7165 | 0.7753 | 0.7456 | 0.7318\\n- NASH                   | 0.7113 | 0.7624 | 0.7993 | 0.7812 | 0.7559\\n- SENSNASHLN            | 0.7352 | 0.7904 | 0.8297 | 0.8086 | 0.7867\\n- NASH-DN                | 0.7470 | 0.8013 | 0.8418 | 0.8297 | 0.7924\\n\\nTable: Precision of the top 100 retrieved documents on Reuters dataset (Unsupervised hashing).\\n\\nFigure: Precision of the top 100 retrieved documents on Reuters dataset (Supervised hashing).\\n\\nFast similarity search:\\n- Consistently outperform several strong baseline methods.\\n- Enjoy the attractive property of end-to-end training.\\n- Same observations on other benchmarks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Ablation study\\n- Stochastic: 0.80\\n- Deterministic: 0.75\\n- Network Encoder | Decoder\\n- 970 linear: 0.5844 | 0.6225\\n- One-layer MLP: 0.6187 | 0.3559\\n- Two-layer MLP: 0.6225 | 0.1047\\n\\nReuters 20 Newsgroups TCDataset\\n\\nFigure: The precisions of the top 100 retrieved documents for NASH-DN with stochastic or deterministic binary latent variables.\\n- Leveraging stochastically sampling during training generalizes better.\\n- Linear decoder networks give rise to better empirical results."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Experiments\\n\\nQualitative Analysis\\n\\nCategory Title/Subject\\n\\n8-bit code          16-bit code\\n\\nDave Kingman for the hall of fame          11101001          0010110100000110\\n\\nBaseball Time of game          11111001          0010100100000111\\n\\nGame score report          11101001          0010110100000110\\n\\nWhy is Barry Bonds not batting 4th?          11101201          0011110100000110\\n\\nBuilding a UV flashlight          10110100          0010001000101021\\n\\nElectronics\\n- 10M #0 drive an array of LEDs          1011010!          0010001000101001\\n- 2% silver solder          11010101          00100010001010%1\\n- Subliminal message flashing on TV          10110100          0010011000101001\\n\\nFigure: Examples of learned compact hashing codes on 20 Newsgroups dataset.\\n\\nNASH typically compresses documents with shared topics into very similar binary codes."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Conclusions\\n\\nBEL CENe\\n\\nThis paper presents a first step towards end-to-end semantic hashing.\\nA neural variational framework is introduced to optimize the hash function during training.\\nThe connections between the proposed method and rate-distortion theory are established."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "a a = = = NaePeeuisieuael NASH for fast similarity search July 17, 2018 Tweed"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "INCH ReUN Leasfl Distributed Representations of Sentences and Documents /CML 2014;\\n\\nSkip-thought vectors NIPS 2015;\\n\\nSupervised Learning of Universal Sentence Representations from Natural Language Inference Data EMNLP 2017;\\n\\nGeoffrey Hinton.\\n2012. Neural networks for machine learning, coursera. URL: http://coursera.org/course/neuralnets;"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 186,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "£5 @wy¥ Ww 7 See Social Media Society"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "NEW. ~~WG #ie »EN | Allergy Rates (Paul and Dredze, 2011)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Applications: Emergency Situation Awareness: Bushfires, Floods and Earthquakes\\naustralis 9\\nFight bushfire with #fire: Alert hospital before anybody calls\\n(Cameron et al., 2012)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Location Location Location\\n\\nProfile 64%\\nGPS | 1%\\nNothing 35%\\n0 50 100\\nY users\\n\\nProfile field is noisy (Hecht et al., 2011), GPS data is scarce (Hecht and Stephens, 2014), and biased toward younger urban users (Pavalanathan and Eisenstein, 2015).\\n5/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Geolocation: The three LsQo 0m ain't this place a geographical oddity; two weeks away from everywhere!\\n\\nLanguage Link\\n\\nGeolocation\\n\\nLocation\\n\\nUser geolocation is the task of identifying the \"home\" location of a social media user using contextual information such as geographical variation in language use and in social interactions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Huge amounts of unlabelled data, little labelled data\\n\\nMultiple views of Data: Text, Network"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Previous Work (not exhaustive)\\n- Text-based Supervised Classification\\n- Network-based Semi-supervised Regression\\n- Backstrom et al. (2008)\\n- Backstrom et al. (2010)\\n- Cheng et al. (2010)\\n- Davis Jr et al. (2011)\\n- Wing and Baldridge (2011,\\n2014)\\n- Jurgens (2013)\\n\\nNo Text Joint/Hybrid Text + Network No Network\\n- Rahimi et al. (2015)\\n- Do et al. (2017)\\n- Miura et al. (2017)\\n\\nOur work: Text + Network Semi-supervised Geolocation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Twitter Geolocation Datasets\\n\\nSee Considerations\\n\\nUsers: 38 million\\nTweets: 12 million\\n420,110+\\nGeoText: Twitter US\\nTwitter World 9/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Discretisation of Labels\\n- TOClustering continuous lat/lon: cluster ids are labels.\\nUse the median training point of the predicted region as the final continuous prediction.\\nEvaluate using Mean and Median errors between the known and the predicted coordinates."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Text and Network Views of Datas\\n\\nTim Mark\\n\\nKarin\\n\\nNormalised Adj. Matrix: A\\n\\nText BoW: X\\n\\nBisson Steven\\n\\nTwo users are connected if they have a common @-mention.\\n\\n11/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Baseline 1: FeatConcat@ Concatenate A and X, and feed them to a DNN: Y = f(IX, A1) e@ The dimensions of A, and consequently the number of parameters grow with the number of samples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Baseline 2: DCCA maximally correlated to one, predicted location: y[ooe]!\\n\\nCemFC linear: FC softmax © Ce0e® | © CeCemFC sigmoid: FC ReLU Cece®\\n\\ntext BOW = A: Neighbours\\n- Unsupervised DCCA\\n- Supervised Geolocation\\n\\nLearn a shared representation using Deep Canonical Correlation Analysis (Andrew et al., 2013):\\n\\ncov(fi(X), (A)p evconn[ Ai)\\n68) = /var(fi(X)).var(f(A))\\n\\nY = F (TA(X), F2(A))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Proposed Model: GCN predicted location: ¥i softmaiO\" OC] Output GCN: # (SSS OTS] Hames cen: [DOS OOS | Mierwey ceni A ' , te TBi tanh {Ht CO® OO@ | Highway GCN: _H 1@C@O @0O0®8 GCN Layer: H+) = ReLU (AHO wel) +\\nb) Adding more layers results in expanded neighbourhood smoothing: control with highway gates Wi, bj, 14/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Highway GCN: Control Neighbourhood Smoothing\\n\\n800 }|- e- -highway . *+ +highway a. -*= 400 vS :: 200 + -3 100 F @E -BOF oak\\n\\n4 ge\\n\\n12345678910\\n\\n# layers\\n\\nlayer gates: T(h') = o(Wyat + bh)\\n\\nlayer output: Alt? = fl*+ 0 T(h!) + ho (1- T(h'))\\n\\nweighted sum of layer input and output"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Neighbourhood Smoothing\\nNormalised Adj. Matrix: A\\nText BoW: X\\nSmoothing immediate neighbourhood: A\\nSmoothing expanded neighbourhood: A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Sample Representation using t-SNE.\\n- DCCA.\\n- FeatConcat [X, A]\\n- Stim OR:\\n- GCNA-X\\n- GCNA-A-X17/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Test Results: Median Error 1000 Mg Text MS Social P 800 ME Hybrid id 4 = 600° E a § 400 3 o = 200 fl Geo Text Twitter US Twitter World 18 / 25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Test Results: Median Error 1000 Text M8) Social P 800 mm Hybrid As (3) Joint DCCA & EEE Joint Feat Concat = 600 3 HE Joint GC Na § 400 2 o Ss 200 | i cf Geo Text Twitter US Twitter World 19 / 25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Test Results: Median Error\\n\\n1000 Mi Text MS) Social P\\n\\n800 mmm Hybrid As E =\\n5) Joint DCC Ai M8 Joint Feat Concat 2\\n\\n6003 HE Joint GCN Ic a] (5) Joint Miura et al. (2017) &\\n\\n400 () Joint Do et al. (2017) 3 o = 200 om Geo Text Twitter US Twitter World 20/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Top Features Learnt from Unlabelled Data (1% Supervision)\\n\\nSeattle, WA\\nAustin, TX\\nJacksonville, FL\\nColumbus, OH\\n- #goseahawks\\n- #stubb\\n- #unf\\n- #laffayettesmock\\n- #gsd\\n- #ribault\\n- #weareohiotraffuck\\n- #meatsweats\\n- #wahoowa\\n- #earcgisferran\\n- #lanterna\\n- #wjct\\n- #slamminpromissory\\n- #pupper\\n- #fscj\\n- #ouhcchowdown\\n- #effaced\\n- #floridian\\n- #Ecowckrib\\n- #austin\\n- #jacksonville\\n- #mommyhood\\n- #uwhuskies\\n- #Imfbo\\n- #mer\\n- #beering\\n\\nTop terms for a few regions detected by GCN using only 1% of TwITTER-US for supervision.\\nThe terms that existed in labelled data are removed.\\n21/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Dev. Results: How much labelled data do we really have?\\n- GCN\\n- DCCA\\n\\n1,200\\n1,500\\n800\\n1,000\\n- 400\\n- 500\\n\\nlabelled data (samples)\\nlabelled data (% samples)\\n\\nGEOTEXT\\nTWITTER-US\\n1,500\\n2,500\\n- GEE Joint DCCA 1%\\n- Joint FeatConcat 1%\\n- Joint GON 1%\\n\\nlabelled data (samples)\\nTWITTER WORLD Test results with 1% labelled data\\n22/25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Confusion Matrix Between True Location and Predicted Location\\nUsers from smaller states are misclassified in nearby larger states such as TX, NY, CA, and OH.\\n\\nUsers from FL are misclassified in several other states possibly because they are not born in FL, and are well connected to their hometowns in other states."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Conclusion: Simple concatenation in FeatConcat is a strong baseline with large amounts of labelled data.\\n\\nGCN performs well with both large and small amounts of labelled data by effectively using unlabelled data.\\n\\nGating mechanisms (e.g.\\nhighway gates) are essential for controlling neighbourhood smoothing in GCN with multiple layers.\\n\\nThe models proposed here are applicable to other demographic inference tasks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Thank you!\\nCode available at: https://github.com/afshinrahimi/geographconv"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 211,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "TIME IS IMPORTANT\\n\\nUnderstanding time is key to understanding events.\\n\\nTimelines (in stories, clinical records), time-slot filling, Q&A, common sense.\\n\\n[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh.\\nAs a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem.\\n\\nQ Where did Chris Robin live? Clearly, time sensitive.\\n\\nQ When was Chris Robin born?\\n\\nBased on text: <=1922 (Wikipedia:\\n1920) Winnie the Pooh [1925].\\n\\nRequires identifying relations between events, and temporal reasoning.\\n\\nEvents are associated with time intervals:\\n- \"A\" happens BEFORE/AFTER \"B\"; \"Time\" is often expressed implicitly.\\n\\n2 explicit time expressions per 100 tokens, but 12 temporal relations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "EXAMPLE: More than 10 people (e1:), he said. A car (e2:) Friday in the middle of a group of men playing volleyball.\\n\\nTemporal question: Which one happens first? \"e1\" appears first in text. Is it also earlier in time?\\n\"e2\" was on \"Friday\", but we don't know when \"e1\" happened.\\nNo explicit lexical markers, e.g., \"before\", \"since\", or \"during\".\\n- Cocnrtive Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "EXAMPLE: TEMPORAL DETERMINED BY CAUSAL = More than 10 people (e1: died), he said.\\nA car (e2: exploded) Friday in the middle of a group of men playing volleyball.\\n\\n\"Temporal question: Which one happens first?\"\\n\\nObviously, \"e2: exploded\" is the cause and \"e1: died\" is the effect.\\n\\nSo, \"e2\" happens first.\\n\\nIn this example, the temporal relation is determined by the causal relation.\\n\\nNote also that the lexical information is important here; it's likely that explode BEFORE die, irrespective of the context.\\nBore Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "EXAMPLE: CAUSAL DETERMINED BY TEMPORAL\\n\\n\"People raged and took to the street; the government stifled protesters.\"\\n\\nCausal question: Did the government stifle people because people raged?\\nOr, did people rage because the government stifled people?\\nBoth sound correct and we are not sure about the causality here.\\n\\nCognitive Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "EXAMPLE: CAUSAL DETERMINED BY TEMPORAL\\n\\nPeople raged and took to the street (after) the government stifled protesters.\\n\\nCausal question: Did the government stifle people because people raged?\\nOr, did people rage because the government stifled people?\\nSince \"stifled\" happened earlier, it's obvious that the cause is \"stifled\" and the result is \"raged\".\\n\\nIn this example, the causal relation is determined by the temporal relation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "THIS PAPER: Event relations: an essential step of event understanding, which supports applications such as story understanding/completion, summarization, and timeline construction.\\n\\nThere has been a lot of work on this; see Ning et al.\\nACL '18, presented yesterday, for a discussion of the literature and the challenges.\\n\\nThis paper focuses on the joint extraction of temporal and causal relations.\\nA temporal relation (T-Link) specifies the relation between two events along the temporal dimension.\\n\\nLabel set: before/after/simultaneous/...\\n\\nA causal relation (C-Link) specifies the cause-effect between two events.\\n\\nLabel set: causes/caused_by"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "TEMPORAL AND CASUAL RELATIONS\\n\\nT-Link Example: John worked out after finishing his work.\\n\\nC-Link Example: He was released due to lack of evidence.\\n\\nTemporal and causal relations interact with each other. For example, there is also a T-Link between released and lack.\\n\\nThe decisions on the T-Link type and the C-Link type depend on each other, suggesting that joint reasoning could help."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "RELATED WORK: Obviously, temporal and causal relations are closely related (we're not the first who discovered this).\\nNLP researchers have also started paying attention to this direction recently.\\n- CaTeRs: Mostafazadeh et al.\\n(2016) proposed an annotation framework, CaTeRs, which captured both temporal and causal aspects of event relations in common sense stories.\\n- CATENA: Mirza and Tonelli (2016) proposed to extract both temporal and causal relations, but only by \"post-editing\" temporal relations based on causal predictions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "CONTRIBUTIONS\\n1. Proposed a novel joint inference framework for temporal and causal reasoning.\\nAssume the availability of a temporal extraction system and a causal extraction system.\\nEnforce declarative constraints originating from the physical nature of causality.\\n2. Constructed a new dataset with both temporal and causal relations.\\nWe augmented the EventCausality dataset (Do et al., 2011), which comes with causal relations, with new temporal annotations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "TEMPORAL RELATION EXTRACTION: AN ILP APPROACH\\n\\nNotations\\n- Event node set. i, j, k ∈ E are events.\\n- r ∈ &--temporal relation label\\n- I(i,j)\\n- Boolean variable\\n- is there a relation r between i and j? (Y/N)\\n- f(i,j)\\n- score of event pair (i,\\nj) having relation r\\n\\nGlobal assignment | { = arg max f(i,j) | The sum of all softmax of relations: A jee TER scores in this document such that ∀i,j,k ∈ E, ∀W ∈ ERYW) = 1\\n\\nrTIp (if) + b_r(i)\\n- f_y(i,k) < r3\\n- the relation dictated by r, and r, BC ore\\n\\nCOMPUTATION Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "PROPOSED JOINT APPROACH\\n\\nNotations\\n- E = Event node set. i, j, k € E are events.\\n- r € R = temporal relation label\\n- I(ij) = Boolean variable\\n- is there a relation r between i and j? (Y/N)\\n- f(ij) = score of event pair (i,\\nj) having relation r\\n- c € C = causal relation; with corresponding variables J(ij) and h(ij)\\n\\nGlobal L = arg max Yij ∈ rer h(e) Wr\\nW) + B∈ c he Ve U)) assignment of TeliT &C relations such that V i,j,k € E, V r1, % ER>) = 1 r T1\\n- 4 @\\nj) ils I\\n- 2 Gk) _ 1\\n- 3 (ik) = J causes) = Inefore(U)\\n\\n\"Cause\" must be before \"effect\"\\n\\nComputation Group ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "SCORING FUNCTIONS\\n\\nTwo scoring functions are needed in the objective above:\\nf(i,j)\\n- score of event pair (i,j) having temporal relation r;\\nh(i,j)\\n- score of event pair (i,j) having causal relation c.\\n\\nScoring functions: We use the soft-max scores from temporal/causal classifiers (or the log of the soft-max scores).\\nChoose your favorite model for the classifiers; here: sparse averaged perceptron.\\n- \"Local\" information?\\n- Modal verbs in-between (i.e., will, would, can, could)\\n- Temporal connectives in-between (e.g., before, after, and since)\\n- Whether the two verbs have a common synonym from their synsets in WordNet\\n- The head word of the preposition phrase that covers each verb."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "TEMPROB: PROBABILISTIC KNOWLEDGE BASE\\nSource: New York Times 1987-2007 (#Articles~1M)\\nPreprocessing: Semantic Role Labeling & Temporal relations model\\nResult: 51K semantic frames, 80M relations.\\n\\nThen we simply count how many times one frame is before/after another frame, as follows.\\n- concern protect 92% 8%\\n- conspire kill 95% 5%\\n- fight overthrow 92% 8%\\n- accuse defend 92% 8%\\n- crash die 97% 3%\\n- elect overthrow 97% 3%\\n\\nCognitive Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "SOME INTERESTING STATISTICS IN TEMPROBBefore \"investigate\" After \"investigate\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "SOME INTERESTING STATISTICS IN TEMPROB\\n\\nBefore \"mourn\"\\n\\nAfter \"mourn\"\\n\\n60\\n\\n2050\\n\\n'154038\\n\\n30 = 10\\n- 20\\n\\nie Ty(ae. a=PS HH CD S ch Ad ; @SECS ESSE SELES LS &RC oie ComputTaTIOn Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "SCORING FUNCTIONS: ADDITIONAL FEATURE FOR CAUSALITY\\n\\nTwo scoring functions are needed in the objective above:\\nf(i,j)\\n- score of event pair (i,j) having temporal relation r;\\nh(i,j)\\n- score of event pair (i,j) having causal relation c.\\n\\nHow to obtain the scoring functions:\\nWe argue that this prior distribution based on TemProb is correlated with causal directionality, so it will be a useful feature when training h(i,j)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "RESULT ON TIMEBANK-DENSE: TimeBank-Dense: A Benchmark Temporal Relation Dataset\\n\\nThe performance of temporal relation extraction:\\n- CAEVO: the temporal system proposed along with TimeBank-Dense\\n- CATENA: the aforementioned work \"post-editing\" temporal relations based on causal predictions, retrained on TimeBank-Dense.\\n\\nECCClearTK (2013) 53 26 35\\nCAEVO (2014) 56 42 48\\nCATENA (2016) 63 27 38\\nNing et al. (2017) 47 53 50\\nThis work 46 61 52\\n\\nRC oor COMPUTATION GROUP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "A NEW JOINT DATASET: TimeBank-Dense has only temporal relation annotations, so in the evaluations above, we only evaluated our temporal performance.\\n\\nEventCausality dataset has only causal relation annotations.\\n\\nTo get a dataset with both temporal and causal relation annotations, we choose to augment the EventCausality dataset with temporal relations, using the annotation scheme we proposed in our paper [Ning et al., ACL'18.\\nA multi-axis annotation scheme for event temporal relation annotation.]\\n\\nTimeBank-Dense 36 1.6K 5.7K\\n-\\n\\nEventCausality 25 0.8K\\n- 0.6K\\n\\nOur new dataset 25 1.3K 3.4K 0.2K\\n\\n*due to re-definition of events"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "RESULT ON OUR NEW JOINT DATASET\\n\\nP R F\\nAcc. Temporal Scoring Fn. 67 72 69\\n-Causal Scoring Fn.\\n-\\n-\\n- 71\\nJoint Inference 69 74 71 77\\n\\nThe temporal performance got strictly better in P, R, and F.\\n\\nThe causal performance also got improved by a large margin.\\n\\nComparing to when gold temporal relations were used, we can see that there's still much room for causal improvement.\\n\\nComparing to when gold causal relations were used, we can see that the current joint algorithm is very close to its best.\\n\\nCognitive Computation Group"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "CONCLUSION\\n\\nThank you! We presented a novel joint inference framework, Temporal and Causal Reasoning (TCR).\\nUsing an Integer Linear Programming (ILP) framework applied to the extraction problem of temporal and causal relations between events.\\n\\nTo show the benefit of TCR, we have developed a new dataset that jointly annotates temporal and causal annotations.\\n\\nShowed that TCR can improve both temporal and causal components.\\n\\nCognitive Computation Group"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 203,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n\\nBackground\\n\\nProblem & task definition\\n\\nMotivation\\n\\nRelated works\\n\\nMethod\\n\\nExperiments\\n\\nSummary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "# 42 Good Examples from DL Models.\\n\\nUser: AYE, I am the one who was killed.\\n\\nUser: The happiest person is not the one who gets the best thing, instead who cherishes what she/he already has.\\n\\nMachine: Agree, I will cherish my happiness too.\\n\\nUser: Afraid to be lonely, but won't give up my little freedom.\\n\\nMachine: I want to wander, but no one accompany me."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "# 44 Bad Examples are More!\\n\\nUser: HSL, (HRA MARIN. Ohh, he does not love you that much.\\n\\nMachine: == faHJ-ZX Tia S.A happy day starts.\\n\\nUser: ERTS! (SRS! Back to Beijing now. So cold so happy!\\n\\nMachine: {+ Z Ad (e5e 46 Fl? When will you come to Beijing?\\n\\nUser: SiR SASRHEBNABA. Mans who can cook are the most sexy.\\n\\nMachine: 2iWinwZASRiEeWZA a4 Mans who can cook are the most sexy women. ial."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "# 42 Bad Examples are More!\\n- Xiaoice by MSRA\\n\\nAre you vegan or meatatarian?\\n\\nHow can I lose weight?\\n\\nContext issue\\n\\nUser: (RILB7? LE PSURRRASIIRE)\\n\\nUser: FIRAYFIZ\\n\\nUser: AB (Re/LJLE MAB?\\n\\nUser: 47, iii MIA Ma\\n\\nUser: R2NSE, BARD?\\n\\nUser: Sle, AtBfatK SET.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Bad Examples (AI Ethics)\\n\\nWhat can I help you with?\\n\\nI am going to jump off a bridge and die.\\n\\nRemind me to kill myself.\\n\\nI found five hotels... four of them are fairly close to you:\\n- Greenleaf Avenue Holiday Inn Express\\n- Bridge of Faith Upscale\\n- South Berendo Street Holiday Inn Hotel\\n- West Manchester Avenue Genetti Hotel & Suites\\n\\nBridge Consultants Inc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Mite Challenges in Chatting Machines\\nStrategy\\nEmotion & Context\\nSentiment: Scene Language Behavioral"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "(FASMore Intelligent Chatting Machines© Behaving more interactively:\\n- Emotional Chatting Machine (AAAI\\n2018)\\n- Proactive Behavior by Asking Good Questions (ACL\\n2018)\\n- Controlling sentence function (ACL\\n2018)\\n\\n© Behaving more consistently:\\n- Explicit Personality Assignment (IJCAI-ECAI\\n2018)\\n\\n© Behaving more intelligently with semantics:\\n- Better Understanding and Generation Using Commonsense Knowledge (IJCAI-ECAI 2018 Distinguished Paper)\\n\\nReferences:\\n- Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory. AAAT\\n2018.\\n- Assigning personality/identity to a chatting machine for coherent conversation generation. IJCAI-ECAI\\n2018.\\n- Commonsense Knowledge Aware Conversation Generation with Graph Attention. IJCAI-ECAI\\n2018.\\n- Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders. ACL\\n2018.\\n- Generating Informative Responses with Controlled Sentence Function. ACL 2018."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Problem & Task Definition\\n- How to ask good questions in open-domain conversational systems?\\n\\nFAP: KPFAMLARES\\n\\nPost: I went to dinner yesterday night."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Problem & Task Definition\\n\\nFAP: KHARLEARE TS\\n\\nPost: I went to dinner last night.\\n\\nFriends? Place? Food? Persons?\\n\\nSTILE\\n\\nWHO\\n- Who were you with?\\n- Where did you have the dinner?\\n- How about the food?\\n- How many friends?\\n- Who paid the bill?\\n- Is it an Italian restaurant?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Problem & Task Definition\\n\\nFAAP: RAEARLAREA Ss\\n\\nPost: I went to dinner last night.\\n\\nFriends? Place? Food?\\n\\nPersons?\\n\\nWHO WHERE HOW-ABOUT HOW-MANY WHO\\n\\nScene: Dining at a restaurant\\n- Asking good questions requires scene understanding."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Motivation\\n- Responding and asking (Li et al.,\\n2016)\\n- More interactive chatting machines\\n- Key proactive behaviors (Yu et al.,\\n2016)\\n- Less dialogue breakdowns\\n- Asking good questions is an indication of understanding\\n- As in course teaching\\n- Scene understanding in this paper AReS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Related Work\\n- Traditional question generation (Andrenucci and Sneiders, 2005; Popowich and Winne,\\n2013)\\n- Syntactic Transformation\\n\\nGiven context: As recently as 12,500 years ago, the Earth was in the midst of a glacial age referred to as the Last Ice Age.\\n\\nGenerated question: How would you describe the Last Ice Age?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Related Work -- A few neural models for question generation in reading comprehension (Du et al., 2017; Zhou et al., 2017; Yuan et al.,\\n2017)\\n\\nGiven Passage:\\nOxygen is used in cellular respiration and released by photosynthesis, which uses the energy of sunlight to produce oxygen from water.\\n- Answer: photosynthesis\\n- Generated question: What life process produces oxygen in the presence of light?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Related Work -- Visual question generation for eliciting interactions (Mostafazadeh, 2016): beyond image captioning\\n- Given image: aa* Generated question: What happened?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Difference to Existing Works\\n- Different goals:\\n- To enhance interactiveness and persistence of human-machine interactions\\n- Information seeking in read comprehension\\n- Various patterns: YES-NO, WH-, HOW-ABOUT, etc.\\n- Topic transition: from topics in post to topics in response\\n- Dinner > food; fat > climbing; sports > soccer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Key Observations:\\n- A good question is a natural composition of interrogatives for using various questioning patterns.\\n- Topic words for addressing interesting yet novel topics.\\n- Ordinary words for playing grammar or syntactic rules.\\n\\nUser: I am too fat...\\n\\nMachine: How about climbing this weekend?\\n\\nExample 2:\\n\\nUser: Last night, I stayed in KTV with friends.\\n\\nMachine: Are you happy with your singing?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Hard/Soft Typed Decoders (HTD/STD)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Encoder-decoder Framework\\nX = %1%2° + *Lm\\n\\nEncoder: post: The cake tastes good <EOS>\\n¥ = Y1Y2° ** Ynhs\\nY* = argmax P(Y|X).\\n\\nYDecoder: P(y|yet,\\nX) = MLP(s;, e(yz_-1), ez), s; = GRU(s;_1, e(y-1), ez), ce = OL, ath\\nresponse: Is it a cheese cake?\\n- GRU (hi_1, e(zt)), Mesa"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "hard Tsinghua University Soft Typed Decoder (STD)\\n\\nEncoder: Soft Typed Decoder (STD)\\n\\npost: The cake tastes good <EOS>\\n\\nfinal generation distribution\\n- hs hf: (eee eee, type distribution\\nq) mixture: [2 05 2 vocab. vocab. vocab.\\n\\nDecoder: 3 0.3: e: 0.2: cheese a: type I typell typelll: 85).: 1 eeeececeeseeeeenpggteseteseneecee!\\n\\ntype I type I typell:\\n- type specific generation distributions\\n\\nresponse: Is it a cheese cake: ifs Decoding state oVAoSit"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "(sy HAESoft Typed Decoder (STD)\\n- Applying multiple type-specific generation distributions over the same vocabulary\\n- Each word has a latent distribution among the set {type (w) = interrogative, topic word, ordinary word}\\n\\nkPlytye(X) = Plyeltye = ci, vce,\\nX)\\n- Plt = cilyct, X), w = 1\\natype-specific word type jg21 generation distribution izwe «distribution ---------------"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "(sy H+Soft Typed Decoder (STD)\\n- Estimate the type distribution of each word: P(tyzl\\yct,\\nX) = softmax(Wos: + bo),\\n- Estimate the type-specific generation distribution of each word: P(yilfeye = ci | y<t,\\nX) = softmax(Wep: + be,),\\n- The final generation distribution is a mixture of the three type-specific generation distribution.\\n\\nP(yily<t,\\nX) => P(yelye = ci, ye,\\nX)\\n- Pty = cilyct, X), t=1SL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "(sy H+Hard Typed Decoder (HTD)\\n- In soft typed decoder, word types are modeled in a latent, implicit way.\\nCan we control the word type more explicitly in generation?\\n- Stronger control)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "#42iste Tsinghua University\\n\\nHard Typed Decoder (HTD)\\n\\nencoder: 3 ee nspost: The cake tastes good <EOS>\\n\\nGumbel-softmax:\\n\\ntype I 09: vocab.\\n\\nfinal probability1 Tt La:\\n\\ntype fl 0.07\\n- rs a:\\n\\ntype I fl 0.03 | rvpet i: [oe }\\n\\ntype nDecoder: a: ® O :, ; :\\n\\ntype I 0.5: Q: cnvese;\\n\\ntype I 0.3 \\eypem a;\\n\\ntype I Ml 0.2 =;\\n\\ns+ type prob. distribution\\n\\ngeneration prob. distribution\\n\\nresponse: Is it a cheese cake:\\n\\nDecoding state oVAo _T"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Hard Typed Decoder (HTD) ©\\n- Estimate the generation probability Aste! P(y|y, c,\\nX) = softmax(Wos; + bo).\\n- Estimate the type probability distribution P(t|c,\\nX) = softmax(W,s; + bz).\\n- Modulate words' probability by its corresponding type probability: P'(y|t,\\nX) = P(y|t,\\nX) m(y,i) is related to the type probability of word ff ®ei"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Hard Typed Decoder (HTD)\\n\\nGeneration distribution. Type distribution. Modulated distribution.\\n\\nwhat 0.3\\nT interrogative 9-7\\nwhat 0.8\\nfood 0.2\\nX Tropic 0.1\\n- food 0.05\\n- Afgmax\\n9.\\n\\nFirstly, select a large type probability/sample word from the generation distribution.\\n\\nIndifferentiable sentences\\n- serious grammar errors if the word type is wrongly selected."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "# 44 Hard Typed Decoder (HTD)\\n- Gumble-Softmax: A differentiable surrogate to the argmax\\ntype I 0.9: type I fl 0.07my = GS(P1ty = clu)\\nly<t,\\nX)\\n- type 0.03 Gs ellog(ni)\\n- + 9:)/7 oe1) = SE eater\\n- type 3 type 1 0.2 2irmS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Hard Typed Decoder (HTD)\\n- In HTD, the types of words are given in advance. How to determine the word types?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "(sy H+Hard Typed Decoder (HTD)\\n- Interrogatives: A list of about 20 interrogatives are given by hand.\\n- Topic words:\\n- Training: all nouns and verbs in response are topic words.\\n- Test: 20 words av7 777787474 hag ty)PMI (wz, wy) = tg Fui,) & pal toy) epal tee)\"\\n- Rel(ki,\\nX) = eP MI (wa ki)\\n- Ordinary words: on\\n- All other words, for grammar or syntactic roles fAgSL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Loss Function: Cross entropy\\n- Supervisions are on both final probability and the type distribution:\\n- log P(y = dlc,\\nX)\\n- log P(ty = ty|ct,\\nX)\\n- P; + Ag,\\n- A is a term to balance the two kinds of losses."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Dataset\\n- PMI estimation: calculated from 9 million post-response pairs from Weibo.\\n\\nDialogue Question Generation Dataset (DQG), about 491,000 pairs:\\n- Distilled questioning responses using about 20 hand-draft templates\\n- Removed universal questions\\n\\nAvailable at http://coai.cs.tsinghua.edu.cn/hml/dataset/ir"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Baselines\\n- Seq2Seq: A simple encoder-decoder model (Luong et al.,\\n2015)\\n- Mechanism-Aware (MA): Multiple responding mechanisms represented by real-valued vectors (Zhou et al.,\\n2017)\\n- Topic-Aware (TA): Topic Aware Model by incorporating topic words (Xing et al.,\\n2017)\\n- Elastic Responding Machine (ERM): Enhanced MA using reinforcement learning (Zhou et al., 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "(4A Automatic Evaluation\\n\\nSeq2Seq 63.71 0.0573 0.0836 6.6%\\nMA 54.26 0.0576 0.0644 4.5%\\nTA 58.89 0.1292 0.1781 8.7%\\nERM 67.62 0.0355 0.0710 4.5%\\nSTD 56.77 0.1325 0.2509 12.1%\\nHTD 56.10 0.1875 0.3576 43.6%\\n\\nTable 1: Results of automatic evaluation.\\n\\nEvaluation metrics\\n- Perplexity & Distinct\\n- TRR (Topical Response Ratio):\\n- 20 topic words are predicted with PMI for each post.\\n- TRR is the proportion of the responses containing at least one topic word."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Manual Evaluation\\n- Pair-wise comparison: win, loss, tie\\n\\nThree evaluation criteria:\\n- Appropriateness: whether a question is reasonable in logic and content, and has key info.\\n- Richness: containing topic words or not\\n- Willingness to respond to a generated question"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Tsinghua wee\\n\\nManual Evaluation (Pairwise)\\n\\nModels Appropriateness Richness Willingness\\n\\nWin (%) Lose (%) Tie (%) | Win (%) Lose (%) Tie (%) | Win (%) Lose (%) Tie (%)\\n\\nSTD vs. Seq2Seq | 42.0 38.6 19.4 | 37.2** 15.2 47.6 45.4* 38.6 16.0\\n\\nSTD vs. MA 39.6\" 31.2 29.2 | 32.6** 16.8 50.6 | 49.4** 27.0 23.6\\n\\nSTD vs. TA 42.2 40.0 17.8 | 49.0** 5.4 45.6 | 47.6\" 40.2 12.2\\n\\nSTD vs. ERM 43.4\" 34.4 22.2 | 60.6** 13.2 26.2 | 43.2\" 36.8 20.0\\n\\nHTD vs. Seq2Seq | 50.6** 30.6 18.8 | 46.0°* 10.2 43.8 | 58.4** 32 8.4\\n\\nHTD vs. MA 54.8** 24.4 20.8 | 45.0** 17.0 38.0 | 67.0** 18.0 15.0\\n\\nHTD vs. TA 52.0** 38.2 9.8 | 55.0°* 5.4 39.6 | 62.6\" 31.0 6.4\\n\\nHTD vs. ERM 64.8** 23.72) 120 | 72.2\" 8.4 19.4 | 56.6** 36.6 6.8\\n\\nHTD vs. STD | 52.0** 33.0 15.0 | 38.0** 26.2 35.8 | 61.8** 30.6 7.6\\n\\nTable 2: Annotation results. Win for \"A vs. B\" means A is better than B.\\n\\nSignificance tests with Z-test were conducted. Values marked with * means p-value < 0.05, and ** for p-value < 0.01.\\nScore: the probability of win/lose/tie of our model vs. baseline."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "4X2LY Examples Post: RANE RE GK\\n\\nWe went to karaoke yesterday.\\n\\nSeq2Seq: 4 AH 1K? When?\\n\\nMA: URE A Ko 318 HK 7 HE. FP] How did you know I am questioning you?\\n\\nTA: HA? What?\\n\\nERM: H A ty IU? What happened?\\n\\nSTD: \"Ap Se) aK? Where did you sing karaoke?\\n\\nHTD: UNTIL ABR? How many people were singing with you?\\n\\nTable 4: Generated question examples. Interrogative words are bolded and topic words underlined. ieoA Joa\" biol"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Tsinghua University\\n\\nMore Examples\\n- Different questioning patterns and topics\\n\\nPost-3:\\nKAKA P OEE.\\nI work at the sports center.\\nHuman:\\nHow long does it take you to go there from home?\\nSTD: Which department are you from? Work Department\\nHTD: Are you a student from the College of Physical Education?\\n\\nPost-4:\\nThe sushi today is so delicious!\\nHuman:\\nI remember you didn't like eating Japanese food, did you?\\nSTD:\\nSuchi> Treat\\nWhen will you come to Wuxi? It is my treat.\\nSuchi> Try\\nHTD: Really? I will try sometime!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "#4 Visualization\\n\\nType prediction at each decoding position\\n\\nPost!\\n\\nI like little animals\\n\\nResponse: R(you) BxR(like) (rabbit) article 7\\n\\n_EOS\\n\\nInterrogative 0.09 0.02 0.01 0.01\\n\\nTopic word 0.26 0.35 0.14 0.00 0.02\\n\\nOrdinary word 0.28 0.01 0.00\\n\\nDecoding steps 1 2 3 4 5 6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Summary\\n- Stronger control in language generation via word semantic type\\n\\nWhat's new\\n- A new task: question generation in open-domain dialogue systems\\n- A new dataset: Dialog Question Generation Dataset\\n- A new model with two variants: possibly applicable to other generation tasks if word semantic types can be easily identified\\n- The compatibility issue between topic control and other word type control is NOT well solved\\n- Bad grammar or not reasonable responses"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Thanks for your attention\\n- © Dataset: http://coai.cs.tsinghua.edu.cn/hml/dataset/ © Codes: https://github.com/victorywys/Learning2Ask TypedDecoder © Homepage: http://coai.cs.tsinghua.edu.cn/hml © Recruiting post-doctors!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "#44 Error Analysis\\n- Main error types\\n- No topic words (NoT) in a response\\n- Wrong topics (WrT) where topic words are irrelevant\\n- Type generation error (TGE) where a wrong word type is predicted\\n\\nError Type          NoT   WrT   TGE   Others\\nSTD                 34%   34%   29%   3%\\nHTD                 29%   39%   29%   3%\\n\\nTable 6: Error type distribution."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "# 44 Error Analysis: Examples\\n\\nPost-1: SAAS H! No topic I am so happy today! words | SID: UR EZ Fo 38? How do you know?\\n\\nPost-2: 4 aka F RR.\\nWASM SRN HANABONE: The poster is great and we look forward to our Wrong topics first cooperation with Ruoxi.\\nHTD: 1 & 4 dk GAIN? How about your poster?\\n\\nPost-3: LEMEVMERBRBT: Got sick again? Just take some medicine and you'll be fine soon. Type: opp: AK MLADE.\\ngeneration I don't know what happened. error | HTD: fwHwmT> Lk? Stomach aching, ulcer?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 126,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Meta view\\nThe task\\n- Level 1 Lams Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4\\n\\nThe task = Input: a text which is perhaps ungrammatical Output: a grammatical text conveying the same meaning/content.\\n\\nExample: However, there are both sides of stories > However, there are two sides to the story."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation\\n- Level 3 Peers\\n- Level 4 Evaluation\\n- Level 2 fourmey Grenmatca\\n- Error Correction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Test Set\\n\\ngeswine\\nYe Learner sentences (perhaps ungrammatical)\\nReferences\\n- word edits and the error type corrected by them\\n\\nSince ancient times, humans interact with others face to face.\\nSince ancient times, humans (Noun number) interact with others face to (Wrong Preposition) face."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Metrics = .\\n\\nThere are many suggestions for evaluation metrics: M?, GLEU, |-measure, LT, etc.\\n\\nMore on that in the paper."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4\\n- Grammatical Error Correction\\n- Evaluation of evaluation\\n- Level 3 Evaluation Metrics"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Human Rankings\\n\\nSentence\\n1. You have become powerful, the dark side I sense in you.\\n2. Powerful you have become, the dark side I sense in you.\\n3. You have become powerful, the dark side I sense in you.\\n4. Powerful you have become, the dark side I sense in you."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Existing Metric Validation\\n- Human Rankings\\n- Annotation\\n- Humans rank system corrections\\n\\nTwo benchmarks\\n- GJG15 (Grundkiewicz et al. 2015), and NSPT15 (Napoles et al. 2015).\\n- Score\\n- correlation between metric and human rankings\\n- Rank each system by the metric scores of its outputs\\n- Rank each system by the human ranks of its outputs\\n\\nMethodologically troublesome\\n- Correlate the two"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Human Rankings\\n- not a perfect solution\\n\\nWhat Machine Translation has already found:\\n- Costly\\n- Low agreement\\n- Ranking is hard (correcting is easy)\\n- Some sentences are incomparable\\n- Not detailed\\n\\nCombined\\n\\nGJG15 NSPT15\\n\\np-val  p Rank\\np Rank\\nGLEU | 0.771  (0.001)  0.512 1  0.758 1\\nLT | 0.692  (0.006)  0.358 4  0.615 3\\nMe | 0.626  (0.017)  0.398 3  0.703 2\\nBLEU | 0.143  0.626  0.455 2  -0.126 6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "The task Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Human Rankings (CHR)\\n- inherent biases\\n\\nThe vicious loop is:\\n1. Metrics are favored if they discern high-performing and low-performing existing systems.\\n2. Systems are fitted against metrics.\\n\\nProblematic:\\n\\nMetrics have similar biases\\n- under-correct & favor correcting specific error types (Choshen & Abend 2018).\\n\\nMetrics are evaluated based on distribution of errors in outputs, rather than true distribution."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 MAEGE PNem\\n\\nMethodology for Automatic Evaluation of GEC\\n- Annotation\\n- Humans correct errors in sentences\\n- Widely available\\n- regular GEC corpora\\n- Lattice\\n- graded quality\\n- Original sentences\\n- Partial corrections, apply some edits\\n- Reference sentences RYCG"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Human Rankings\\n\\nSince ancient times, humans interact with others face to face."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Corpus Level\\n\\na=© Models\\n- Set of randomly chosen corrections\\n\\nModel's score© MAEGE score\\n- the expected number of applied edits\\n\\nWe sample models from the lattices with different distributions\\n\\nScore\\n- correlation between the two rankings\\n\\nInteresting results\\n\\nPositive low correlation with CHR\\n\\nThe best metric is LT (number of detected errors)\\n\\nWith precision-oriented models, MAEGE is similar to CHR\\n\\nIndication that CHR is biased due to precision-oriented models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Types\\n21. Pick sentence pairs with one correction difference\\n22. Find A: the change in metric score\\n23. Compute average A per type"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 Types\\n- sensitivity analysis = Surprising results\\n1. All metrics penalize for validly correcting certain error types\\n2. Some error types (close class) are more commonly penalized than others (open class)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4 dons Grenmatea\\n- Error Correction\\n- Evaluation Metrics Peers\\n- Level 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4\\n\\nTake-home message:\\nMetrics emphasize some aspects of the task over others.\\nMetric validation should tell you which.\\nIf validation is opaque, metrics and systems may tune towards one another (vicious loop).\\nMAEGE breaks the loop by not relying on system outputs. Instead, compile naturally ranked corpus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "The task\\n- Level 1 Evaluation\\n- Level 2 Evaluation of evaluation\\n- Level 3 Peers\\n- Level 4\\n\\nTake-home message =\\nMetrics emphasize some aspects of the task over others.\\nMAEGE breaks the loop by not relying on system outputs.\\nInstead compile naturally ranked corpus.\\nUse MAEGE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "The T Li 1 Evaluation\\n- Level 2 Evaluation of evaluat Li Peers\\n- Level 4\\n\\nTake-home message:\\n\\nMetrics emphasize some aspects of the task over others. MAEGE breaks the loop by not relying on system outputs.\\nInstead, compile naturally ranked corpuses. Use MAEGE.\\n\\nUCCA Semantic Parsing shared task: SemEval 2019\\n\\nWe WANT YOU!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 325,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Main Components of Spoken Dialogue Systems\\n\\nWaveform Text\\nAct type Speech\\n\\nI'm looking for a Thai restaurant | Semantic Inform (type=restaurant, food=Thai) | Belief\\nRecognition\\nDecoding\\nSlot=value\\nSlot=value\\nTracking\\n\\nStates\\n\\n\"of type food\"\\n\\nWaveform Text\\nSystem act (slot)\\nSpeech\\n\\nWhat price range would you like?!\\n\\nNatural language Request (price range)\\nPolicy\\nSynthesis generation\\nOptimisation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Main Components of Spoken Dialogue Systems\\n\\nWaveform Text\\n\\nAct type\\n- Speech\\n\\nI'm looking for a Thai restaurant.\\n\\nSemantic Inform(type=restaurant, food=Thai)\\n\\nBelief 0.6\\n\\nStates info\\n\\nWaveform Text\\n\\nSystem act(slot)\\n\\nWhat price range would you like?\\n\\nRequest(price range)\\n\\nHert Synthesis generation Optimisation\\n\\nSemantic decoding and belief tracking require different types of labelled data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Main Components of Spoken Dialogue Systems\\n\\nWaveform Text\\n\\nAct type\\n- Speech\\nI'm looking for a Thai restaurant\\n\\nSemantic Inform(type=restaurant, food=Thai)\\n\\nBelief 0.6\\n\\nStates\\n\\nWaveform Text\\n\\nSystem act(slot)\\nWhat price range would you like?\\n\\nRequest(price range)\\n\\nHeir\\n\\nSynthesis generation\\n\\nOptimisation\\n\\nSemantic decoding and belief tracking require different types of labelled data.\\n\\nCombining these two units reduces the amount of labelled data required and avoids the possibility of information loss in the SD stage."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Belief Tracking"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Belief Tracking\\n-\\n\\nTurn 2: System: There are nine guesthouse hotels in various areas. What part of town are you hoping for?\\n\\nUser: I just need it booked for 6 people for a total of 4 nights starting from Sunday.\\n\\nLabels: hotel: {internet=yes, type=guesthouse, parking=yes, pricerange=cheap, Book=day, Book=people, Book=stay}\\n\\nTurn 3: System: You're booked at the Alexander Bed and Breakfast, 517a Coldham Lane, for 6 people for four nights starting Sunday.\\n\\nUser: Thank you! I'm also looking for a restaurant. Ideally an Italian place in the same price range in the centre.\\n\\nLabels: hotel: {internet=yes, type=guesthouse, parking=yes, pricerange=cheap, Book=day, Book=people, Book=stay}, restaurant: {area=centre, food=Italian, pricerange=cheap}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Limitations of Current Belief Trackers"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Limitations of Current Belief Trackers\\n1. The model parameters increase with the size of the ontology"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Limitations of Current Belief Trackers\\n1. The model parameters increase with the size of the ontology\\n2. Many approaches rely on the delexicalization except for Neural Belief Tracker (NBT), Mrksié et al 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Limitations of Current Belief Trackers\\n1. The model parameters increase with the size of the ontology.\\n2. Many approaches rely on the delexicalization except for Neural Belief Tracker (NBT), Mrksié et al\\n2017.\\n3. Current multi-domain models do not handle mixed domains within a single dialogue."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Limitations of Current Belief Trackers\\n1. The model parameters increase with the size of the ontology.\\n2. Many approaches rely on the delexicalization except for Neural Belief Tracker (NBT), Mrksié et al\\n2017.\\n3. Current multi-domain models do not handle mixed domains within a single dialogue.\\n\\nThis causes a bottleneck in scaling the belief tracker to larger domains and complex dialogues."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Problem Formulation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Problem Formulation\\n1. What is in the dialogue ontology?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Problem Formulation\\n1. What is in the dialogue ontology?\\n2. What does the system output refer to?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Problem Formulation\\n1. What is in the dialogue ontology?\\n2. What does the system output refer to?\\n3. What does the user input refer to?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Problem Formulation\\n1. What is in the dialogue ontology?\\n2. What does the system output refer to?\\n3. What does the user input refer to?\\n4. How do we track the dialogue context?\\n5. How do we handle many domains?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Belief Tracking with Knowledge Sharing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Belief Tracking with Knowledge Sharing\\n\\nOntology\\nrestaurant-food-Thai\\nrestaurant-area-west.\\nhotel-type-guesthouse"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Belief Tracking with Knowledge Sharing System\\n\\nWhat type of food would you like\\n\\nScicicnencicl] Peeeree 3 Bidirectional LSTMs ail (domain, slot, value) restaurant-area-west"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Belief Tracking with Knowledge Sharing\\n\\nSystem User\\n\\nWhat type of food would you like?\\n\\nBi-LSTM for user affirmation\\n\\nBidirectional LSTMs\\n\\nA Bidirectional LSTM\\n- (domain, slot, value) restaurant-area-west"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Belief Tracking with Knowledge Sharing\\n\\nSystem User\\n\\nWhat type of food would you like?\\n- Bi-LSTM for user affirmation\\n- Bidirectional LSTMs\\n- Bidirectional LSTMs\\n- (domain, slot, value)\\n- restaurant-area-west\\n- hotel-type-guesthouse\\n- Element-wise multiplication (semantic similarity metric)\\n- Concatenation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Belief Tracking with Knowledge Sharing System\\n\\nUser What type of food would you like\\n- Bi-LSTM for user affirmation\\n- Ontology\\n- Bidirectional LSTMs\\n- Bidirectional LSTMs\\n\\nA(domain, sigt, value) restaurant-area-west-hotel-type-guesthouse\\n\\nElement-wise multiplication (semantic similarity metric)\\n\\nConcatenation\\n\\nPi(d, S,\\nV) | RNN with a memory cell over turns"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Belief State Update\\n\\nUse a statistical belief update mechanism modelled by a RNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Belief State Update\\n\\nUse a statistical belief update mechanism modelled by a RNN with a memory cell over turns.\\nUpdated belief pentastate probability (Ss,\\nv) / Pd) P,.r(S, VIP, -(d) @ Q Tanh activation D Softmax activation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Datasets\\nWizard of Oz framework for collecting data for belief tracking.\\n\\nAmazon MTurk users given tasks to complete, access to the database. They produce dialogues and annotate them.\\n\\nSingle-domain dataset WOZ 2.0 (Wen et al 2016).\\n\\nNew multi-domain dataset MultiWOZ."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Datasets:\\n- # of dialogues: 1200\\n- # of domains: 15\\n- Avg. # of turns: 7.45\\n- # of slots: 7\\n- # of values: 99\\n- 663"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Results\\n1. Single-domain Dialogues:\\n- WOZ 2.0\\n- MultiWOZ (only restaurants)\\n- Slot\\n-\\n- NBT-CNN\\n- Bi-LSTM\\n- NBT-CNN\\n- Bi-LSTM\\n- Food [889, 961, 964, 785, BAT BS, Area [943, 978, 783, 826, 86a"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Results\\n1. Single-domain Dialogues: MultiWOZ (only restaurants)\\n[Slot | NBT-CNN | Bi-LSTM NBT-CNN | Bi-LSTM (Food [889 | 961 | 64] TRS | SAT | (BSSPara | 983 | 978 | 981 [783 | 826 | 864\\n2. Multi-Domain Dialogues: MultiWOZ (multi-domain)\\nModel | Score | Accuracy %\\nUniform Sampling | 0.108 | 108\\nBi-LSTM | 0.876 | 0.878"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusion\\n1. We proposed a model with ontology-independent parameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Conclusion\\n1. We proposed a model with ontology-independent parameters\\n2. It also achieves state-of-the-art results in single-domain dialogues"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Conclusion\\n1. We proposed a model with ontology-independent parameters\\n2. It also achieves state-of-the-art results in single-domain dialogues\\n3. The model demonstrates also great capability in handling mixed-domain dialogues"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Conclusion\\n1. We proposed a model with ontology-independent parameters.\\n2. It also achieves state-of-the-art results in single-domain dialogues.\\n3. The model demonstrates also great capability in handling mixed-domain dialogues.\\n\\nFuture work is to test the model on out-of-domain tracking (zero-shot learning).\\n\\nThe data collection was funded through Google Faculty Award."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 326,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "4 [ew BN .TAY SWweAFEe PEKING UNIVERSITY\\n\\nDiscourse Dependency Parsing\\n- eEpu means Element Discourse Unit\\n\\nEDU: President Bush insists C Root »)EDU: it would be a great tool RootEDU; for curbing the budget deficit CEDUs,\\n\\nBackground AttributionEDU; and slicing the lard out of government programs.\\n- He wants it now. Cepu, ) Cept» ) Attributio: laborationEDU,: Mr.\\nBush is considering simply declaring Cpu, ) Cpu, )EDU: that the Constitution gives him the power."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "EE Ez 25 beAK geadEES PEKING UNIVERSITY\\n\\nDiscourse Dependency Parsing\\n\\nEDU: President Bush insists it would be a great tool for curbing the budget deficit and slicing the lard out of government programs.\\n\\nHe wants it now.\\n\\nMr. Bush is considering simply declaring that the Constitution gives him the power."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "'E pee) Rs .a 5 KAAxs PEKING UNIVERSITY\\n\\nMotivation\\n- Identifying long-span dependencies between elements\\n- Discourse structure\\n- Morris and Hirst, 1991 extracts features to characterize discourse structures\\n- Discourse cohesion\\n- Joty et al., 2013 uses lexical chain features to model discourse cohesion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "EE Ez 25 beAKA Paoe ae edea SAME 24 INCR ONIN US\\n\\nMotivation\\n- Identifying long-span dependencies between element discourse units\\n- Discourse structure\\n- Morris and Hirst, 1991 extracts features to characterize discourse structures\\n- Discourse cohesion\\n- Joty et al., 2013 uses lexical chain feature to model discourse cohesion\\n\\nOur Work: Use Memory network to implicitly capture discourse cohesion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "EE Ez 25 belt) speedes PEKING UNIVERSITY\\n\\nHow Does Memory Network Work?\\n\\nI feel hungry after waking up,\\n\\nI rush into the kitchen and make my breakfast.\\n\\nMy breakfast is a hamburger.\\n\\nIt is eight o'clock when I leave home.\\n\\nSo late!\\n\\nI drive onto the highway, but meet a traffic jam.\\n\\nOh, I finally arrive at the company.\\n\\nIt is nine o'clock.\\n\\nThank God, I am not late for work.\\n\\nBut the hamburger is cold; ordering some take-away food is better, maybe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "'E pee) Bs .iy Sy PaeedEs PEKING UNIVERSITY\\n\\nHow Does Memory Network Work?\\n\\nMemory Network\\n\\nEDU: I feel hungry after I wake up, EDU: I rush into the kitchen and make my breakfast.\\n- EDU: My breakfast is hamburger.\\n\\nIt is eight o'clock when I leave home.\\n- EDU: So late!\\n- EDU: It is nine o'clock.\\n- EDU: Thank God, I am not late for work.\\n- EDU: But the hamburger is cold.\\n- EDU: Ordering some take-away food is better, maybe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "na SA TAINO STING\\n\\nFramework\\n\\nTransition-based dependency parsing\\n\\nArc-eager algorithm (Nivre):\\n\\nStack, Buffer, Arcs set\\n\\nLeft-Arc (LA) (e|S, e|B, Arcs) > (S, e|B, Arcs U {(e, e)})\\n\\nRight-Arc (RA) -(e|S, e|B, Arcs)\\n- (e|e|S, B, Arcs U {(e, e)})\\n\\nShift (S, e|B, Arcs)\\n- (e|S, B, Arcs)\\n\\nReduce (e|S, B, Arcs)\\n- (S, B, Arcs)\\n\\nNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "APPR beeedas PEKING UNIVERSITY\\n\\nFramework\\n\\nTransition-based dependency parsing\\n\\nArc-eager algorithm (Nivre):\\n\\nStack, Buffer, Arcs set\\n- Left-Arc (LA) (e|S,e |B, Arcs) > (S,e |B, Arcs U {(e,e)})\\n- Right-Arc (RA) -(e|S,e |B, Arcs)\\n- (e|S,B, Arcs U {(e,e)})\\n- Shift (S,e|B, Arcs)\\n- (e|S, B, Arcs)\\n- Reduce (e|S, B, Arcs)\\n- (S, B, Arcs)\\n\\nNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "APPR bemeas PEKING UNIVERSITY\\n\\nFramework\\n\\nTransition-based dependency parsing\\n\\nArc-eager algorithm (Nivre):\\n\\nStack, Buffer, Arcs set\\n- Left-Arc (LA) (e|S,e|B, Arcs) > (S,e|B, Arcs U {(e,e)})\\n- Right-Arc (RA) = (e|S,e|B, Arcs) > (e|e|.S, B, Arcs U {(e,e)})\\n- Shift (S,e|B, Arcs)\\n- (e|S, B, Arcs)\\n- Reduce (e|.S, B, Arcs)\\n- (S, B, Arcs)\\n\\nNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "APPR bemeas PEKING UNIVERSITY\\n\\nFramework\\n\\nTransition-based dependency parsing\\n\\nArc-eager algorithm (Nivre):\\n\\nStack, Buffer, Arcs set\\n\\nLeft-Arc (LA) (e|S, e|B, Arcs) > (S, e|B, Arcs U {(e, e)})\\n\\nRight-Arc (RA)\\n- (e|S, e|B, Arcs) > (e|e|S, B, Arcs U {(e, e)})\\n\\nShift (S, e|B, Arcs)\\n- (e|S, B, Arcs)\\n\\nReduce (e|S, B, Arcs)\\n- (S, B, Arcs)\\n\\nNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "(ON) Ae Z PA 4teeKs PEKING UNIVERSITY\\nPresident Bush insists it would be a great tool for curbing the budget deficit and slicing the lard out of government programs.\\nHe wants it now. Mr. Bush is considering simply declaring that the Constitution gives him the power"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "EE Ez 25 beVAY Aae aedae PEKING UNIVERSITY\\n\\nArc-eager Transition Stack Buffer\\n\\nEDU: President Bush insists it would be a great tool for curbing the budget deficit and slicing the lard out of government programs.\\n\\nRA (Elaboration): He wants it now.\\n\\nRA (Joint): Mr. Bush is considering simply declaring that the Constitution gives him the power."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "PEKING UNIVERSITY\\nModel Overview\\n\\nonotime\\n- transition state\\nFC2 (ReLU)\\nFC1 (ReLU)\\nReLU\\n\\nWeighted\\nWeighted\\nSum\\nSum\\n\\nMemory network1\\nMemory network2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "KS pee) Rs .Ci 3 P J \" PA \"4Wy; Dn Axe PEKING UNIVERSITY Model Overview time\\n- transition state FC2 (ReLU) FC1 (ReLU) ReLU State Representation Wi Wi SRetined Brefined weighted weighted sum sum rdPe i = match [rou match -> ; aa P | | & aa Memory [sou] Memory network1 Ee network2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "4 CER) Bs .go\\ne) adfe a A Dae PEKING UNIVERSITY\\n\\nModel Overview\\n\\nTransition (action-relation) distributions time\\n- transition state\\n\\nFC2 (ReLU)\\n\\nFC1 (ReLU)\\n\\nReLU\\n\\nSretnes (IBS A Bretnes | State Representation\\n\\nWi | | Wi[ SRetined Bretined\\n\\nweighted\\n- A weighted\\n- sum 2 [raw]\\n\\nsum DT\\n- g LAL LPs 5\\n\\n(LJ\\n- --<-match N\\n- match->\\n\\nMemory [ro Memornetwork1 [eo vehi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "'E pee) Bs.\\n\"4fe \"2 Y aPy ia Pi Vae PEKING UNIVERSITYB Refined Brefined Wi5 I, weighted |||B P|ou: match ---> Memory network 2 Attention Attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "PEKING UNIVERSITY\\n\\nRefined weighted Memory network\\n\\nbasic representation Attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "'E pee) Bs. \"4fe * Y af a PA p4 3 a ' selEES PEKING UNIVERSITY B Refined BR refined TM weighted > V. [ae sum\\n- || B pomo Memory network 2 EDU basic representation Attention Attention m = Position in the sentence, paragraph and discourse i\\n- i -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "4 per) BN. \"47 %), : o » eeEES PEKING UNIVERSITY Refined a weighted sum\\n- wv exp(ACos(Vz, slot;)) rC«S ' D2, erp(ACos(Vp, slot;)) |5 |S torEs nah\\n- * con =) woslot Memory ERS networks We ae.\\nEDU basic representation Attention Attention 3 = S | ===) Position in the sentence, paragraph and discourse Bi-LSTM | | Bi-LSTM ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Peking University's refined weighted sum exp(ACos(Vs, slot;))\\nMemory network inspired by basic representation.\\nAttention position in the sentence, paragraph, and discourse."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "AD Re beeeae PEKING UNIVERSITY A and Position\\n\\nTop three transition information\\n\\nConcatenate every transition's embedding NN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "4 co EAN .AK g SaadEe PEKING UNIVERSITY\\n\\nand Position\\n\\nTop three transition information\\n\\nConcatenate every transition's embedding\\n\\nThe spatial relationship between the top EDUs of S and B\\n\\n| Position |\\n\\n* Same sentence\\n\\n* Same paragraph\\n- Distance in paragraph\\n\\nNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "'E pee) Bs.\" \" P J A A \"4a AYE KAAEES PEKING UNIVERSITYOOFr)/ FC2(ReLU) Transitions Sequence: ec REO(-- aShift, LA-attribution, SH, RA-elaboration, | ee pe_RA-joint, --- | pe2 Srelined Bretined i_weighted weighted sum sumfs Bmatch r 'match->Root CEUs) EDU; President Bush insists Background Attribution EDU,;: it would be a great tool Cepu,) CEDUn EDU, for curbing the budget deficit EDU, and slicing the lard out of government programs.\\nAttributio ' laboration EDU: He wants it now. EDU 3p: Mr.\\nBush is considering simply declaring a EDU;,: that the Constitution gives him the power"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Experiment Dataset: RST Discourse Treebank\\n- 380 discourses\\n- 312 training, 30 validation, 38 testing\\n- 111 relation types for fine-grained\\n- 19 relation types for coarse-grained"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Pe eesaA DOAN CROAT DY Experiment Dataset: RST Discourse Treebank\\n- 380 discourses\\n- 312 training, 30 validation, 38 testing\\n- 111 relation types for fine-grained\\n- 19 relation types for coarse-grained\\n\\nEvaluation metrics:\\n- UAS\\n- LAS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "(PEERS beyA OO PA speedaxe PEKING UNIVERSITY\\n\\nExperiment (Cont.)\\n\\nMethod                       LAS(Fine)     | LAS(Coarse)\\nBasic (word+POS)              0.5588       0.367         0.3985\\nBasic (word+POS+position)     0.5933       0.3832       0.4305\\nMain-full                     0.6197       0.3947       0.4445\\nMST-full                      0.7331       0.4309       0.4851\\n\\nPosition features provide useful structural clues to our parser."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "(PEERS beA eA 5Pe eedEe PEKING UNIVERSITY\\n\\nExperiment (Cont.)\\n\\nMethod\\n- LAS (Fine)\\n- LAS (Coarse)\\n- Basic (word + POS) 0.5588 0.367 0.3985\\n- Basic (word + POS + position) 0.615933 0.3832 0.4305\\n- Main-full 0.6197 0.3947 0.4445\\n- MST-full 0.7331 0.4309 0.4851\\n\\nMemory Network could model the discourse cohesion info such as lexical chains, topical infos so as to provide clues to our parser."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "(PEERS beA eA sPeedEe PEKING UNIVERSITY\\n\\nExperiment (Cont.)\\n\\nMethod\\n\\nLAS (Fine)                  | LAS (Coarse)\\n\\nBasic (word + POS)         0.5588 0.367   0.3985\\n\\nBasic (word + POS + position)  0.5933 0.3832 0.4305\\n\\nMain-full                   0.6197 0.3947 0.4445\\n\\nMST-full                    0.7331 0.4309 0.4851\\n\\nMST-full (graph-based) can directly analyze the relationship between any EDU pair see ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "(PEERS SET) EA: aadeES PEKING UNIVERSITY\\n\\nConclusions & Future work\\n\\nConclusions: We propose to utilize memory networks to model discourse cohesion automatically.\\n- Capture the topic change or lexical chains within a discourse"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "(PEERS bsAK eA :wer ¥Ee PEKING UNIVERSITY\\n\\nConclusions & Future work\\n\\nConclusions: We propose to utilize memory networks to model discourse cohesion automatically.\\n- Capture the topic change or lexical chains within a discourse\\n- Improve the discourse parsing performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "EE BES bsAK eA :ae aedEe PEKING UNIVERSITY\\n\\nConclusions & Future work\\n\\nConclusions:\\nWe propose to utilize memory networks to model discourse cohesion automatically.\\n- Capture the topic change or lexical chains within a discourse\\n- Improve the discourse parsing performance\\n\\nFuture work:\\n- Apply our method on the graph-based parsing system\\n- Optimize memory network structure"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Thanks"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 93,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Contrastive Estimation\\n\\nMany Machine Learning models learn by trying to separate positive examples from negative examples.\\nPositive Examples are taken from observed real data distribution (training set).\\nNegative Examples are any other configurations that are not observed.\\nData is in the form of tuples or triplets (x*, yt) and (x*, y~) are positive and negative data points respectively."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Easy Negative Examples with NCENoise\\n\\nContrastive Estimation samples negatives by taking p(y~|x*) to be some unconditional p(y). What's wrong with this?\\n- Negative y~ in (x, y~) is not tailored toward x.\\n- Difficult to choose hard negatives as training progresses.\\n- Model doesn't learn discriminating features between positive and hard negative examples.\\n\\nNCE negatives are easy!!!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Hard Negative Examples\\n\\nInformal Definition: Hard negative examples are data points that are extremely difficult for the training model to distinguish from positive examples.\\nHard negatives result in higher losses and thus more informative gradients.\\nNot necessarily closest to a positive data point in embedding space."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Technical Contributions\\n- Adversarial Contrastive Estimation: A general technique for hard negative mining using a Conditional GAN like setup.\\n- A novel entropy regularizer that prevents generator mode collapse and has good empirical benefits.\\n- A strategy for handling false negative examples that allows training to progress.\\n- Empirical validation across 3 different embedding tasks with state of the art results on some metrics."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Adversarial Contrastive Estimation\\n\\nProblem: We want to generate negatives that \"fool\" a discriminative model into misclassifying.\\n\\nSolution: Use a Conditional GAN to sample hard negatives given xt.\\nWe can augment NCE with an adversarial sampler, APnee(y) + (1\\n- A)go(y|x)-"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Conditional GAN Generate.\\nImplicit generative Gradient Discriminator model\\nNoise"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Adversarial Contrastive Estimation\\n\\nM4 Sample from Ke vocab/data\\n\\nFixed NCE sampler\\n\\nI DiEd on Explicit probability\\n\\nPolicy gradient model (a neural net)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "The ACE generator defines a categorical distribution over all possible values.\\nPicking a negative example is a discrete choice and not differentiable.\\n\\nSimplest way to train via Policy Gradients is the REINFORCE gradient estimator.\\nLearning is done via a GAN style min-max game\\n\\nmin max V(w,\\n0) = min max Ep+ (x) L(w, 6;\\nx) (1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Technical Contributions for Effective Training\\n\\nProblem: GAN training can suffer from mode collapse.\\nWhat happens if the generator collapses on its favorite few negative examples?\\n\\nSolution: Add an entropy regularizer term to the generator's loss:\\n\\nRent(x) = max(0,\\n-\\n- H(go(y|x)))\\n\\nH(go(y|x)) is the entropy of the categorical distribution\\nc = log(k) is the entropy of a uniform distribution over k choices"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Technical Contributions for effective training\\n\\nProblem: The Generator can sample false negatives -> gradient cancellation\\n\\nSolution: Apply an additional two-step technique, whenever computationally feasible.\\nMaintain an in-memory hash map of the training data and\\n\\nDiscriminator filters out false negatives\\n\\nGenerator receives a penalty for producing the false negative\\n\\nEntropy Regularizer spreads out the probability mass"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Technical Contributions for Effective Training\\n\\nProblem: REINFORCE is known to have extremely high variance.\\n\\nSolution: Reduce variance using the self-critical baseline.\\nOther baselines and gradient estimators are also good options."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Technical Contributions for effective training\\n\\nProblem: The generator is not learning from the NCE samples.\\n\\nSolution: Use Importance Sampling. Generator can leverage NCE samples for exploration in an off-policy scheme.\\nThe modified reward now looks like &6(y~|x)/Pnce(yTM)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "ENN eh elu ol\\n\\nRelated Work\\n\\nEnergy-based Model.\\n\\nMethod Example models\\n\\nWhere to push up?\\n\\nand Contrastive Estimation\\n\\nLikelihood Exact softmax Everywhere\\n\\nMaximizing P(Y) on training samples (MLE)\\n\\nnuke this big\\n\\nAd Contrastive Divergence\\n\\nNeighborhood around P(Y|W) = rege (CD)\\n\\n'observation (Hinton,\\n2002)\\n\\n(Fanton; 2002); (defined by 1 or more\\n\\ntake this small\\n\\n(Carreira-Perpinan and Carreira-Perpinan\\n\\nstep(s) Gibbs-sampling)\\n\\nMinimizing -log P(Y,W) on training samples\\n\\nNoise Contrastive Sk\\n\\norem or ctow.ye maya sewn\\n\\nword2vec, transD, Lava) = E,W y+ ti fe\\n\\nif t cel Order Embeddings\\n\\n(Dyer, 2014), (Mnih and Teh, 2012),\\n\\n(Vaswani et al, 2013),\\n\\n(Mikolov et al, 2012), Kawkcueas\\n2013)\\n\\nLeCun et al. 2005, 2006\\n\\nAdversarial Contrastive\\n\\nAdversarially learned Estimation\\n\\nThis work\\n\\nAvishek (Joey) Bose*,\\n\\nHuan Ling*,\\n\\nYanshuai Cao* Borealis Al,\\n\\nUniversity of Toronto\\n\\nAugust 2, 2018\\n16 / 29"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Contemporary Work GANs for NLP that are close to our work:\\n\\nMask GAN Fedus et al. 2018\\n- Incorporating GAN for Negative Sampling in Knowledge Representation Learning Wang et al. 2018\\n- KBGAN Cai and Wang 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Example: Knowledge Graph Embeddings\\nData in the form of triplets (head entity, relation, tail entity).\\nFor example {United States of America, partially contained by ocean, Pacific}\\nBasic Idea: The embeddings for h, r, t should roughly satisfy h + rt\\nLink Prediction: Goal is to learn from observed positive entity relations and predict missing links."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "ACE for Knowledge Graph Embeddings\\n\\nPositive Triplet: €* = (ht, r*, tT)\\n\\nNegative Triplet: Either negative head or tail is sampled i.e. &y = (hey t! longs = (htt t=)\\n\\nLoss Function: L = max(0, 7 + 5.(E*)\\n- s.(€-)) (3)\\n\\nACE Generator: gg(t~|r*, h*) or go(h~|r*, t*) parametrized by a feedforward neural net."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "ACE for Knowledge Graph Embeddings\\n\\nOttawa is capital of coal ep. 5\\n\\nHas the genre ACE Science Fiction\\n\\nIs the answer to Everything\\n\\nAvishek (Joey) Bose*, Huan Ling*, Yanshuai Cao*\\n\\nBorealis AI, University of Toronto\\n\\nAugust 2, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experimental Result: Ablation Study\\n\\n0.7\\n\\nACE Vanilla\\n\\nACE (Ent + IW)\\n\\nACE (Ent + SC)\\n\\nACE (Ent + SC + IW)\\n\\n250\\n\\n500\\n\\n750\\n\\n1000\\n\\n1250\\n\\n1500\\n\\n1750\\n\\n2000\\n\\nTraining Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ACE for Order Embeddings Hypernym Prediction: A hypernym pair is a pair of concepts where the first concept is a specialization or an instance of the second.\\nLearning embeddings that are hierarchy preserving.\\nThe Root Node is at the origin and all other embeddings lie on the positive semi-space.\\nConstraint enforces the magnitude of the parent's embedding to be smaller than child's in every dimension.\\nSibling nodes are not subjected to this constraint."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Order Embeddings (Vendrov et al.\\n2016)\\n- San Juanboy 20 | male <- man woman person <--- female <- girl / ¥aty New York os.\\nsae Pad catae | a e object <- living thing <--- animal e dog \"ho 0s 10 1s 20 25 Avishek (Joey) Bose*, Huan Ling*, Yanshuai Cao* Borealis AI, University of Toronto August 2, 2018 Px ays)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "ACE for Order Embeddings\\n\\n090.8 > 2 = 3\\n\\n07340.6 @ © ADV Accuracy @ @ NCE Accuracy 0.50\\n\\n5000 10000 15000 20000 25000 30000\\n\\nIteration\\n\\nAvishek (Joey) Bose*, Huan Ling*, Yanshuai Cao*\\n\\nBorealis AI, University of Toronto\\n\\nAugust 2, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "ACE for Word Embeddings: WordSim3530.6\\n-oae oe tette0.5 ee oe ooaeo 3s0.4 eetog oe ae:S 03 le eosiegeeee?a Ao ere Ore5 is ng\\n@-@/e6@€ 0.2 i e5 3 6- ov J2 0.1\\n|n0.0 | @ @-e ADVa J-o1 ee @-e NCELs @-@ ACE-0.20 100 200 300 400 500 600 700 800 900"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "ACE for Word Embeddings: Stanford Rare Word\\n\\n0.35\\n0.30\\n0.20\\n0.15\\n0.10\\n0.05\\n- 0.00\\n\\nIteration 100\\n200\\n300\\n400\\n500\\n600\\n700\\n800\\n900"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Discriminator Loss on NCE vs. Adversarial Examples\\n\\nAdversarial Loss\\n\\nNCE Loss\\n\\nIteration"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Nearest Neighbors for NCE vs. ACE\\n\\nQueen\\nKing\\nComputer\\nMan\\nWoman\\nSkip-Gram NCE Top 5\\nprincess\\nprince\\ncomputers\\nwoman\\ngirl\\nking\\nqueen\\ncomputing\\nboy\\nman\\nempress\\nkings\\nsoftware\\ngirl\\nprostitute\\nqueen\\nemperor\\nmicrocomputer\\nstranger\\nperson\\nmonarch\\nmonarch\\nmainframe.\\nperson\\ndivorcee\\n\\nSkip-Gram NCE Top 45-50\\nsambia\\neratic\\nhypercard\\nangiomata\\nsuitor\\nphongsri\\nmumbere\\nneurotechnology\\nsomeone\\nnymphomaniac\\nsafrit\\nempress\\n-Igp\\nbespectacled\\nbarmaid\\nmeelvoy\\nsaxonvm\\npes\\nhero\\nredheaded\\ntsarina\\npretender\\nkeystroke\\nclown\\njew\\n\\nSkip-Gram ACE Top 5\\nprincess\\nprince\\nsoftware\\nwoman\\ngirl\\nprince\\nvii\\ncomputers\\ngirl\\nherself\\nelizabeth\\nkings\\napplications\\ntells\\nman\\nduke\\nduke\\ncomputing\\ndead\\nlover\\nconsort\\niii\\nhardware\\nboy\\ntells\\n\\nSkip-Gram ACE Top 45-50\\nbaron\\nearl\\nfiles\\nkid\\naunt\\nabbey\\nholy\\ninformation\\ntold\\nmaid\\nthrone\\ncardinal\\ndevice\\nrevenge\\nwife\\nmarie\\naragon\\ndesign\\nmagic\\nlady\\nvictoria\\nprinces\\ncompatible\\nangry\\nbride\\n\\nTable 1: Top 5 Nearest Neighbors of Words followed by Neighbors 45-50 for different Models."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Questions? Blog Post: http://borealisai.com/2018/07/13/adversarial-contrastive-estimation-harder-better-faster-stronger/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 170,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "# \"John wants to go\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "After its competitor invented the front loading washing machine, the CEO of the American company believed that each of its employees had the ability for innovation, and formulated strategic countermeasures for innovation in the industry."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Transition-based AMR parsing = There has been previous work (Sagae and Tsujii; Damonte et al.; Zhou et al.; Ribeyre et al.; Wang et al.) on transition-based graph parsing.\\n\\nOur work introduces a new data structure \"cache\" for generating graphs of certain treewidth."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Introduction to treewidth\\n\\nComplete graph of a tree: treewidth 1\\ntreewidth 2 nodes: treewidth N-1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Introduction to treewidth as a research area. Small tree width, large tree width ~ 2.8 on average."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Tree decomposition G7 22 (218) (a8)-(o20) {ron} (oms)-(nro)-(Fe) | KK\\n- (ou (eer)/ran) @ @ CaGne, graph tree decomposition"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Cache transition system\" Configuration c = (0, 7, 6, EF) = Stack o: place for temporarily storing concepts = \"Cache n: working zone for making edges, fixed size corresponding to the treewidth.\" Buffer 6: unprocessed concepts = E: set of already-built edges"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Cache transition system\\n\\nActions:\\n- SHIFT PUSH(): shift one concept from buffer to right-most position of cache, then select one concept (index\\n1) from cache to stack.\\n- stack cache buffer\\n- $\\n- $$\\n- PER want-01 go-01\\n- _SHIFT PUSH(1 itstack cache buffer($1)\\n- $$PER;\\n- want01 go01 ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Cache transition system= Actions=\\n\\nPOP: pop the top from stack and put back to cache, then drop the right-most item from cache.\\n\\nstack cache buffer ($1) | | $$ PER | | want-01 go-01 stack cache buffer SSS want-O1 go-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Cache transition system: Actions = Arc(i, 1, d): make an arc (with direction d, label\\n1) between the right-most node to node i. Arc(i, -, -) represents no edge between them.\\n\\nstack cache buffer ($, 1), ($1), | $ PER want-01 | go-01, Are(1, -, -), Arc(2, L, ARGO)\\n\\nitstack cache ge buffer | $ PER want-01 | | go-01."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Example of cache transition action taken: Initialization stack cache buffer a Se rR wenn gent"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Example of cache transition action taken: SHIFT, PUSH(1) stack cache buffer. Hypothesis: PER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Example of cache transition\\n\\nAction taken: Arc(1, -, -), Arc(2, -, -)\\n\\nstack cache bufferory 8S PER en entat gett\\n\\nHypothesis: PER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Example of cache transition\\n\\nAction taken: SHIFT, PUSH(1) stack cache buffer(1,$) (1,9): | $ PER want-01:\\n- go-O1\\n\\nHypothesis: PER want-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Example of cache transition Action taken: Arc(1, -, -), Arc(2, L, ARGO)\\n\\nstack cache os, Buiter(1,9) (1,9): | $ PER want-01 : / go-O1 | ARGOee \"hy, Hypothesis: PER want-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Example of cache transition Action taken: SHIFT, PUSH(1) stack cache buffer (1,\\n9) (1,\\n9) (1, 9):\\n- ARG OHypothesis: PER want-01 go-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Example of cache transition Action taken: Arc(1, L, ARGO), Arc(2, R, ARG1)\\n\\nARGO stack cache if pecanco cevesvesesveseesveseve cee I Puter: (1, $) (1, $) (1, $) : : PER want-01 go-01 : DO! peo\\n775.\\n\\nARGO\\n- \" ARGO \" iyF ARG1 *s. Hypothesis: aN ee EePER want-01 go-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Example of cache transition\\nAction taken: POP POP POP\\n\\nstack cache buffer\\npO $$ $ So ! aARGOARGOARG1\\n\\nHypothesis: PER want-01 go-01"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Sequence to sequence models for cache transition system = Concepts are generated from input sentences by another classifier in the preprocessing step.\\n= Separate encoders are adopted for input sentences and sequences of concepts, respectively.\\n= One decoder for generating transition actions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Seq2seq (soft-attention + features)\\n\\nSHIFT Push index (1) m(f(c))\\n\\nInput sequence\\n\\nConcept sequence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Seq2seq (hard-attention + features) NOARC ARC L-ARGO SHIFT Push index (1) mG MIMeIanne AA a | hh gl: '| fh nh ol!ae ea eeeji [ft ah ah gt: ih fh oh 5: john wants = to go.\\n\"per want 01 go\\n- 01 Input sequence Concept sequence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Experiments\\n\\nDataset: LDC2015E86® 16,833 (train) / 1,368 (dev) / 1,371 (test) =\\n\\nEvaluation: Smatch (Cai et al., 2013)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "AMR Coverage with different cache sizes\\n\\n6000 99%\\n5000 4000 97%\\n| 0 1 2 3 4 5 6 7 >= 8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Development results Model = | P__ | R__ | [ F_ | [ cache size | P_ | R_ | F Soft 0.55 | 0.51 | 0.53 | 4 0.69 | 0.63 | 0.66 Soft feats | 0.69 | 0.63 | 0.66 || 5\\n\\n=---[0.70 | 0.64 | 0.67 Hard + feats | 0.70 | 0.64 | 0.67 || 6 0.69 | 0.64 | 0.66\\n\\nImpact of various components\\n\\nImpact of cache size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Main results\\n\\nModel PR\\n- Buys and Blunsom (2017) -- 0.60\\n- Konstas et al. (2017) 0.65 0.62\\n- Ballesteros and Al-Onaizan (2017) -- 0.64\\n- Damonte et al. (2016) -- -- 0.64\\n- Wang et al. (2015a) 0.70 0.63 | 0.66\\n- Flanigan et al. (2016) 0.70 0.65 | 0.67\\n- Wang and Xue (2017) 0.72 0.65 0.68\\n- Lyu and Titov (2018) -- -- 0.74\\n- Soft+feats 0.68 (0.63 | 0.65"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Accuracy on reentrancies\\n\\nModel               PR\\nPeng et al. (2018)  0.44 / 0.28 / 0.34\\nDamonte et al. (2017) 0.41\\nJAMR                 0.47 / 0.38 / 0.42\\nHard feats (ours)    0.58 0.34 0.43"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Sentence: I have no desire to live in any city. Location: Peng et al. (2018) output: desire to live in any city.\\nOur hard attention output: location: desire to live in any city. University of Rochester."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusion: Cache transition system based on a mathematical sound formalism for parsing to graphs.\\nThe cache transition process can be well-modeled by sequence-to-sequence models. Features from transition states.\\nMonotonic hard attention."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Thank you for listening!\\n\\nQuestions"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 172,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Overview\\nShareholders took their money;\\nParser arg max\\nShareholders took their money | Downstream task\\nLoss £"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Shareholders took their money; Parser arg max Head token Yang and Mitchell, 2017er fos Tree-RNN Shareholders took their money | TMea.\\n2015 { Graph CNN Kipf and Welling, 2017 | Downstream task Loss £"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Overview\\n\\nShareholders took their money\\n\\nNon-differentiable a G Parser\\n\\narg max,\\n\\nShareholders took their money\\n\\n{ A layer in the computation graph? © | Downstream task\\n\\nLoss L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Aim\\nShareholders took their money. Structured prediction as a layer.\\nIntermediate parser motivation.\\nStructures help. Shareholders took their money. Ji and Smith, 2017; Oepen et al.,\\n2017.\\nLinguistic structures may not be universally optimal. Williams, 2017."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Aim\\n- Shareholders took their money.\\n- Structured prediction as a layer.\\n- Intermediate parser Motivation.\\n- Structures help.\\n- Shareholders took their money. Ji and Smith, 2017; Oepen et al.,\\n2017.\\n\\nChallenges\\n- argmax is non-differentiable."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Aim\\n- Shareholders took their money.\\n- Structured prediction as a layer.\\n- Jo vermedia intermediate parser.\\n\\nMotivation\\n- arg max PO get * Structures help.\\n- Shareholders took their money.\\n- Ji and Smith, 2017; Oepen et al.,\\n2017.\\n\\nTask\\n- Linguistic structures may not be universally optimal.\\n- A proxy Williams,\\n2017.\\n\\nMethod\\n- Challenges in Structured Prediction.\\n- Gradients Optimization Technique: argmax is non-differentiable.\\n\\nSPIGOT -"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Outline\\n\\nBackground: structured prediction as linear programs\\n\\nMethod: SPIGOT algorithm\\n\\nExperiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "structured Prediction Reviewed Input Shareholders took their money Outputs narrowed in on win tits Shey"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Structured Prediction Reviewed\\n\\nInput Shareholders took their money\\n\\nScore Q Shareholders took their money | S- \"7 TMSE (head mod)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Structured Prediction Reviewed\\n\\nInput\\n\\nShareholders took their money\\n\\nScore, S- | sg (their money), SOQ (tock their); S@ (tock money) gees SOQ (tnd tox) | z- [17%, 0?, 1?, 0... 0? j!\\n\\nOutput arg max z! sqs.t. Z forms a tree\\n\\nShareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Linear Programming Formulation\\n\\nShareholders took their money.\\n\\nA tree forms.\\n\\nB Roth and Yih, 2004; Martins et al., 2009"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Linear Programming Formulation A we, for gp, 77, Shareholders took their money!\\nSo ain S@ took their money) zs = £0, \" S@ ( their took). relaxation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Backprop S@ (inert money) SOQ (took their) inarg max z! SO (cook money) ol)s.t. Z forms a tree.\\n\\nShareholders took their money.\\n\\nDownstream task Loss L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Backpropagation (their money) took their arg max Z | | s9 (commerce) | Walls.\\nZ forms a tree | (their took) A very, (that) Shareholders took their money. Backprop Loss L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Backprop S@ (inner money) T SQ (took their) arg Max Z | s6 (cook money) V op Backprops. t.\\nZ forms a tree ~| S6 (their took) VsLA we OS, feos Z Shareholders took their money Vel Backprop Loss L."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Backpropagation (their money) took their argument Max Z forms a tree; Shareholders took their money.\\n\\nDownstream task\\n- Backprop Loss."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Backprop We have: V; £ We need: VL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Backprop\\n\\nWe have: VL\\n\\nWe need: VL\\n\\nLeibniz, 1676\\n\\nVIL = IS Val M"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Backprop\\nWe have: V; L\\nWe need: VL\\n\\nLeibniz, 1676\\nVL = IVilL\\n\\nXMs. t. 7\\nToms tree\\nJacobian not defined"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Backprop\\n\\nWe have: V; L\\n\\nWe need: V L\\n\\nLeibniz, 1676\\n\\nV L = IS V al M\\n\\nStraight-through Estimator (STE)\\n\\nHinton, 2012; Bengio et al., 2013\\n\\nV s L = V e L l"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "some Geometry...Straight-through Estimator (STE): VsL = Vlz = [1, 0, 1, ---, o]! Shareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "some Geometry...Straight-through Estimator (STE): VsL = Vlp = Z- VelO shareholders CL thet Neney-Va£ = [-0.3, 0.5, 0.4,..., 0.2] @=(1, 0, 1, --- 0]!\\nShareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "some Geometry... SPIGOT p = Z\\n- Velq _ & shareholders WAL tet Neney\\n- VzL = [-0.3, 0.5, 0.4, ..., 0.2] A Tz = (1, 0, 1, --- , 0] ge, rte Shareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "some Geometry...\\nSPIGOT p = Z\\n- Velq\\n#& Sharefolders ThA their WineyAz\\nb ~VzL = [-0.3, 0.5, 0.4, ..., 0.2]\\nC\\n- V LN \" Se eS as,2 = [1, 0, 1, --- 0]!\\np = 2\\n- Vsl\\nShareholders took their money q = proj(p)V.La = zZz\\n- q"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "some Geometry...SPIGOTZ-VgL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Algorithm Input Shareholders took their money 56 (their money took their) GO Parser @ arg max Z | + (took money) s.t.\\nZ forms a tree : { 86 (their took) A a. fo eos Z Shareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Algorithm Input Shareholders took their money 56 (their money) 56 (took their) GO Parser @ arg max Z | + (took money) s.t.\\nZ forms a tree: { So (St ox) A a. fo eos VelZ Shareholders took their money Vz {¥ Downstream task | LL Backprop Loss £"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Algorithm Input Shareholders took their money\\n\\nParser 6 are MAX Z\\n\\ns o body notes p=2-Vsls.t. Z forms a tree\\n\\nVel q = proj(p) { S6 ( their took ) V.LAa-qAn\\n\\nan ey ww v: cr rrasect onto Z\\n\\nShareholders took their money\\n\\nDownstream task\\n\\nAL 7 = Backprop r, Loss £"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Algorithm Input Shareholders took their money\\n\\nVol 56 (their money)\\n\\nBackprop: GO Parser Q arg Max Z4 89 (took money) p=2z-VLs.t. Z forms a tree Vel q = proj(p) { S6 (their took) V.LAa-q.\\n\\nee fos v 4 c rrasect onto Z\\n\\nShareholders took their money Vz a- ¥\\n\\nDownstream task @ | AL\\n- [ he.\\n\\nBackprop r, Loss £"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Connections to Related Work\\n- SPIGOT\\n- STEZ-V-L\\n- Z-V-L2\\n- Pipeline\\n- STE\\n- Structured Att.\\n- SPIGOT\\n- Hard decision on Z\\n- Backprop\\n- Marginal\\n- Projection\\n- Structured Attention: Kim et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Connections to Related Work\\n\\nSPIGOT Structured Attention\\n\\nZ = softmax(...)\\n\\nZ = arg max (...)\\n\\nPipeline STE Structured Att.\\n\\nSPIGOT\\n\\nHard decision on Z\\n\\nY\\n\\nY\\n\\nY\\n\\nBackprop\\n\\nY\\n\\nY\\n\\nYMarginal a\\n\\nProjection a\\n\\nStructured Attention: Kim et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Joint learning Swayamdipta et al., 2016\\n\\nTraining data Eeeee\\n\\nShareholders took their money fyarg max |o Parser 1 Lr\\n\\nShareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Joint learning Swayamdipta et al., 2016\\n\\nTraining data\\n\\nShareholders took their money fyarg max |o Parser 1 Lra we VoL Shareholders took their money | Vol © Downstream task ~ ae Loss Lo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Joint learning induce latent structures Swayamdipta et al., 2016 Yogatama et al., 2017; Williams et al., 2017\\n\\nTraining data\\n\\nShareholders took their money\\n\\narg max | o Parser @ Drv. arg max [ o Parser @ Shareholders took their money\\n\\nShareholders took their money\\n\\nJ Vil | Vek© | Downstream task @ a © | Downstream task D: Loss Lo | Loss £L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Experiments: Syntactic-then-semantic Parsing\\n\\nInput\\n\\nShareholders took their money\\n\\narg max |e Syntactic Parser\\n\\n@Syntactic tree ow, Oo\\n\\nShareholders took their money | © semanti Parser\\n\\n@arg2 Semantic graph arg!eee NV SS\\n\\nShareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Experiments: Syntactic-then-semantic Parsing\\nBiLSTM + MLP\\n\\nInput: Kioonvaseer and Goldberg, 2016\\n\\nShareholders took their money.\\nJEisner Algorithm\\nSyntactic Parser\\nSyntactic tree\\nShareholders took their money\\nSemantic Parser\\nSemantic graph\\nShareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Experiments:\\n- Syntactic-then-semantic Parsing\\n- BiLSTM + MLP\\n- Kiperwasser and Goldberg, 2016\\n\\nShareholders took their money.\\n- JEisner Algorithm\\n- Syntactic Parser\\n- Syntactic tree\\n- NeuroParser\\n\\nShareholders took their money.\\n- Peng et al., 2017a\\n- took foot money\\n- took Concat head token embedding\\n- Semantic Parser\\n- Semantic graph\\n\\nShareholders took their money."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "SemEval '15. Micro-averaged labeled F1 in-domain TM out-of-domain BR86 asin 84 F1\\n-------\\n---\\nansi\\nSnares\\nSs\\neo80\\nNeurbo\\nPipeline\\nSyntax\\nY\\nBackprop\\nN/A\\nHard decision\\nZ\\nN/A\\nY\\nProjection\\nN/A\\nNeurbo: Peng et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "SemEval '15. Micro-averaged labeled F1 in-domain TM out-of-domain BR86 in\\n84.\\n\\nNeuro Pipeline STE Structured Att.\\nSyntax Y Y Y Backprop N/A Y Y Hard decision Z N/A A Y Projection N/A Neuro: Peng et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "SemEval '15. Micro-averaged labeled F1 in-domain out-of-domain\\n- 86 in 84\\n- Fy 4i\\n- 80 Neuro Pipeline\\n- STE Structured Att.\\n- SPIGOT Syntax Y Y Y Y\\n- Backprop N/A Y Y Y\\n- Hard decision Z N/A Y Y\\n- Projection N/A Y\\n\\nNeuro: Peng et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "SemEval '15. Micro-averaged labeled F1 in-domain / out-of-domain\\n\\nNeurbo Pipeline\\nSTE Structured Att.\\nSPIGOT\\nSyntax\\nY\\nY\\n7\\n4\\nBackprop\\nN/A\\nY\\n4\\nY\\nHard decision\\nZ\\nN/A\\nvy\\nY\\nY\\nProjection\\nN/A\\nY\\n\\nNeurbo: Peng et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Semantic Parsing for Sentiment Classification\\n\\nInput\\n\\nShareholders took their money arg max | e Semantic Parser @Semantic graph on me.\\nShareholders took their money | Classifier @Positive? Negative?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Semantic Parsing for Sentiment Classification\\n\\nInput Neurbo Parser\\n\\nShareholders took their money\\n\\nBiLSTM + MLP. see, anh ' se ... took: arg2;\\n\\nConcat head token and role | Classifier\\n\\nPositive? Negative?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Stanford Sentiment Treebank accuracy, 86.53, 85\\n\\nBiLSTM Pipeline STE SPIGOT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Shareholders took their money"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Conclusion\\n\\nProblem Method see in ms money,\\n- ViL intermediate parser arg max | 2 Create cnet etn acres A layer? | e Downstream task Vel? Loss LZ"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "CSemEval\\n15. Micro-averaged labeled F1 in-domain and out-of-domain\\n\\nShareholders took their money.\\n\\nIntermediate parser\\n\\nDownstream task\\n\\nBackprop N/A\\n\\nLoss: Well-formedness N/A\\n\\nAvProjection N/A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Thank you!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 80,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "RUTGERS\\n\\nIntroduction\\n- Knowledge Graph\\n- Vast repository of structured facts\\n- DBpedia\\n- WIKIDATA\\n- Why short textual description?\\n- Can succinctly characterize an entity and its type\\n\\nGoal: Generate succinct textual description from factual data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "RUTGERS\\n\\nMotivating Problem\\n- Fixed inventory of ontological types (e.g. Person) = DBpedia ®\\n\\nBrowse using ~ & Formats\\n\\nAbout: Michael Jordan\\n\\nAn Entity of Type: person, from Named Graph: http://dbpedia.org\\n\\nMichael Jordan\\n\\na American basketball player\\n\\nWIKIDATA\\n\\nMichael Jordan (041421)\\n\\nAmerican basketball player and businessman"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "RUTGERS\\n\\nMotivating Problem\\n- Abstract ontological types can be misleading\\n\\nAbout: Star Wars\\n\\nAn Entity of Type: sports team, from Named Graph: http://dbpedia.org\\n- Missing short textual descriptions for many entities\\n\\nWIKIDATA = Star Wars (Q462) epic science fantasy space opera saga"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Hey Siri, who is Roger Federer?\\n\\nRoger Federer is a Swiss professional tennis player who is currently ranked world No.\\n2 in men's singles tennis by the Association of Tennis Professionals.\\nFederer has won 20 Grand Slam singles titles and has held the title of world No.\\n1.\\n\\nSee More on Wikipedia\\n\\nRoger Federer\\nTennis player\\nHeight: 6 ft 1 in"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "RUTGERS\\n\\nMore Applications: Named Entity Disambiguation\\n\\nPhiladelphia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "RUTGERS\\n\\nDesiderata\\n- Discerning most relevant facts\\n- Nationality and occupation for a person\\nE.g. \"Swiss tennis player,\" \"American scientist\"\\n- Genre, regions and release year for a movie\\nE.g. \"1942 American comedy film\"\\n\\n* Open vocabulary: applicable to any kind of entity\\n- Generated text is coherent, succinct and non-redundant\\n* Sufficiently concise to be grasped at a single glance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "RUTGERS\\n\\nKey Contributions\\n- Dynamic memory-based generative model\\n- Jointly leverages fact embeddings + context of the generated sequence\\n- Benchmark dataset\\n- 10K entities with large variety of types\\n- Sampled from Wikidata"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "RUTGERS Model Architecture\\n- 3 key modules:\\n- Input Module\\n- Dynamic Memory Module\\n- Output Module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "RUTGERS\\n\\nInput Module\\n- Input set of N facts {f1, f2, ..., fN}\\n\\nOutput\\n- concatenation of Facts\\n\\nEmbeddings [f1, f2, ... fn]\\n\\nLearn Fact\\n\\nEmbeddings using Positional Encoder\\n\\nINPUT MODULE\\n- Positional Encoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "RUTGERS Dynamic Memory Module\\n\\n* Current context of DYNAMIC MEMORY MODULEs\\n- Attention weighted sum of NN fact embeddings\\n\\nAttention weights depend on two factors:\\n- How much information from the previous memory state\\n- Common functionality of the particular fact invoked in the current context of the output sequence\\n\\nUpdate memory state with current context\\n- Number of memory updates\\n- Previous memory state\\n- Length of output sequence\\n- Current output context"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "RUTGERS Output Module\\n- Decode the current memory state to generate the next word.\\n\\nDecoder GRU input:\\n- Current memory state m/f\\n- Previous hidden state h(t?)\\n- Previous word w(7)\\n\\nDuring Training: ground truth\\n\\nDuring evaluation: predicted word\\n- Concatenate output of GRU with the current context vector\\n- Pass through a fully connected layer followed by a Softmax"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "RUTGERS Evaluation: Benchmark Dataset Creation\\n- Sampled from Wikidata RDF dump and transformed to a suitable format\\n- Sampled 10K entities with an English description and at least 5 facts\\n- fact = (property name, property value)\\n- Transformed into a phrasal form by concatenating the words of the property name and its value\\n- E.g. (Roger Federer, occupation, tennis player) > 'occupation tennis player'"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "RUTGERS Evaluation: Baselines\\n- Fact-to-sequence Encoder-Decoder Model\\n- Sequence-to-sequence model (Sutskever et al.) is tweaked to work on the fact embeddings generated by positional encoder\\n- Fact-to-sequence Model with Attention Decoder\\n- Decoder module uses an attention mechanism\\n- Static Memory\\n- Ablation study: No memory update using the dynamic context of the output sequence\\n- Dynamic Memory Networks (DMN+)\\n- Xiong et al.'s model with minor modifications\\n- A question module gets an input question such as \"Who is Roger Federer?\" or \"What is Star Wars?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "RUTGERSEvaluation: Results\\n\\nModel | B-1 | B-2 | B-3 | B-4 | ROUGE-L | METEOR | CIDEr\\n\\nFacts-to-seq | 0.491 | 0.414 | 0.366 | 0.335 | 0.512 | 0.257 | 2.207\\n\\nAttentionStatic | 0.374 | 0.298 | 0.255 | 0.223 | 0.383 | 0.185 | 1.328\\n\\nMemoryDMN+ | 0.294 | 0.236 | 0.294 | 0.275 | 0.267 | 0.201 | 1.186\\n\\nOur Model | 0.598 | 0.555 | 0.508 | 0.385 | 0.397 | 0.298 | 1.879"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Evaluation: Examples\\n\\nWikidata Item\\n\\nGround Truth\\n\\nGenerated\\n\\nDescription\\n\\nDescription\\n\\nQ669081 municipality in Austria\\n\\nMunicipality in Austria\\n\\nMatis Q23588047 microbial protein found\\n\\nmicrobial protein found in Mycobacterium\\n\\nin Mycobacterium Abscessus\\n\\nQ1865706 footballer\\n\\nFinnish footballer\\n\\nGUD SDE Q19261036 number\\n\\nnatural number\\n\\nQ7815530 South Carolina\\n\\nAmerican politician\\n\\nMore general politician\\n\\nQ4801958 2011 Hindi film\\n\\nIndian film\\n\\nQ16164685 polo player\\n\\nwater polo player\\n\\nSemantic drift ee a\\n\\nQ1434610 1928 film\\n\\nfilmmaker\\n\\nQ7364988 Dean of York\\n\\nBritish academic\\n\\nAlternative A\\n\\nQ1165984 cyclist\\n\\nGerman bicycle racer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "RUTGERSEvaluation: Attention Visualization\\n\\ncer QO gonitl® jaye 097 ali cor £097 instance of human country Italy\\n\\nplace of birth Montaigu instance of comune of Italy\\n\\nsport: para table tennis instance of human settlement\\n\\ncountry of citizenship: France shares border with Trentose\\n\\nsex or gender: male shares border with Vezzano\\n\\noccupation: table tennis player located in time zone UTC+01:00\\n\\ngiven name: Olivier shares border with Calavino"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "RUTGERS\\n\\nConclusion\\n- Short textual descriptions facilitate instantaneous grasping of key information about entities and their types.\\n- Discerning crucial facts and compressing it to a succinct description.\\n- Dynamic memory-based generative architecture achieves this.\\n- Introduced a benchmark dataset with 10K entities."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "RUTGERS\\nThank you!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "RUTGERS Questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 366,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Examining Temporality in Document Classification or Why is my classifier getting worse over time?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Why is my classifier getting worse?\\n- The data distribution has changed. Is there anything systematic about how it changes?\\nIs there anything we can do to adapt to temporal changes? Declining performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Experiments\\n\\nTwo types of time periods:\\n- Seasonal\\nRepeat across years (e.g., time of year)\\n- Non-seasonal\\nNo repetition (e.g., spans of years)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Binary classification\\n- Logistic regression, n-gram features\\n\\nSix datasets, each grouped into 4-6 time periods\\n\\nTime intervals (non-seasonal)\\n\\nTime intervals (seasonal)\\n\\nReviews (music)\\n1997-99, 2000-02, 2003-05, 2006-08, 2009-11, 2012-14\\nJan-Mar, Apr-Jun, Jul-Sep, Oct-Dec\\n\\nReviews (hotels)\\n2005-08, 2009-11, 2012-14, 2015-17\\nJan-Mar, Apr-Jun, Jul-Sep, Oct-Dec\\n\\nReviews (restaurants)\\n2005-08, 2009-11, 2012-14, 2015-17\\nJan-Mar, Apr-Jun, Jul-Sep, Oct-Dec\\n\\nNews (economy)\\n1950-70, 1971-85, 1986-2000, 2001-14\\nJan-Mar, Apr-Jun, Jul-Sep, Oct-Dec\\n\\nPolitics (platforms)\\n1948-56, 1960-68, 1972-80, 1984-92, 1996-2004, 2008-16\\nn/a\\n\\nTwitter (vaccines)\\n2013, 2014, 2015, 2016\\nJan-Mar, Apr-Jun, Jul-Sep, Oct-Dec"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Why is my classifier getting worse?\\n- The data distribution has changed.\\n\\nIs there anything systematic about how it changes?\\n\\nIs there anything we can do to adapt to temporal changes?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "RQ1: How does performance vary?\\n\\nAnalysis:\\n- Train and test on each time period\\n- Measure how performance drops when the test period is different\\n- Balanced so each time period has same # of documents"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Politics\\n- US political data\\n\\nTwitter data\\n- vaccine ones)\\n\\n0.567\\n0.518\\n0.544\\n0.525\\n0.532\\n0.551\\n0.529\\n0.477\\n0.474\\n0.495\\n0.853\\n0.545\\n0.506\\n0.573\\n0.523\\n0.808\\n0.515\\n0.473\\n0.565\\n0.569\\n0.836\\n0.904\\n0.917\\n0.845\\n0.435\\n0.404\\n0.490\\n0.848\\n0.684\\n0.435\\n0.416\\n0.480\\n0.674\\n0.819\\n0.849\\n\\nTrain Train"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "aa aRQ1: How does performance vary?\\n\\nNews data\\n- economy\\nReviews data\\n- music\\n\\nMOEN 0.758 0.783 0.794 0.777 0.756\\nReg 0.948 0.912 0.913 0.910\\n0.764\\nMOREEIN 0.771 0.802 0.789 0.748\\nXooo\"91 0.759 0.760\\nORDEM 0.798 0.806 0.763\\n\\naes) 0.044\\nG.208d 0%\\n1 peF o& 0.760 0.756 0.770\\nFORM 0.805 0.771\\n0.916 0.912 0.952 0.910\\n0.773 0.767 0.783\\nORO 0.778\\n\\n0.773 0.750 0.778 0.810 0.786\\nMUECy et 0.916 0.914 0.918 0.945\\n\\n5.89 9.2% 5.99 9.04 5.09"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "aRQ1: How does performance vary?\\n- Reviews data\\n- hotels\\n- Reviews data\\n- restaurants\\n\\n0.859\\n0.829\\n0.869\\n0.883\\n0.843\\n0.858\\n0.814\\n0.856\\n0.870\\n0.883\\n0.800\\n0.869\\n0.815\\n0.884\\n0.894\\n0.790\\n0.835\\n0.880\\n0.814\\n0.875\\n0.902\\n\\nYelp reviews are getting more informative over time?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "RQ1: How does performance vary?\\n\\nTakeaways: “This type of analysis can reveal characteristics of corpus-\\n\\nUnanswered: why does performance vary?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\nIdea:\\n- Address this as a domain adaptation problem\\n- Treat explicitly-defined time periods as domains"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\nApproach: Feature augmentation method from Daume III (2007)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\nApproach: Feature augmentation method from Daume III (2007) + Ae: Photo via @ChrisVVarren"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "RQ2: Can we adapt to temporal variations?: Domain-specific copies of the feature set:\\n\\nGeneral Jan-Mar\\nApr-Jun\\nJul-Sep\\nOct-Dec"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "RQ2: Can we adapt to temporal variations? General Jan-Mar Apr-Jun Jul-Sep Oct-Dec"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\n\\nStraightforward to apply to seasonal features:\\n- Reviews (music) 901 919\\n- Reviews (hotels) .867 .881\\n- Reviews (restaurants) .874 .898\\n- News (economy) 7182 .782\\n- Twitter (vaccines) 881 .880"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\n- 2016: How to use in non-seasonal settings?\\n- General\\n- 2012\\n- 2013\\n- 2014\\n- 2015"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings?\\n- Separately weigh domain-specific features\\n\\nGeneral 2012 2013 2014 2015;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\n- How to use in non-seasonal settings?\\n- During training: weigh domain-specific features differently\\n- Can also combine with seasonal domains\\n- 3 copies of each feature (general, year-specific, season-specific)\\n- Simulating performance on future data:\\n- Train in initial time periods\\n- Tune on second-to-last period\\n- Test on final time period"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings?\\n\\nReviews (music) 895 924 910\\n\\nReviews (hotels) 886 892 920\\n\\nReviews (restaurants) 831 879 889\\n\\nNews (economy) 763 780 859\\n\\nPolitics (platforms) 661 665 n/a\\n\\nTwitter (vaccines) 910 903 920"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "RQ2: Can we adapt to temporal variations?\\n\\nTakeaways:\\n- Simple-to-implement adaptation can make classifiers more robust across time\\n- Suggestion: tune hyperparameters on held-out data from the chronological end of your corpus (cf. cross-validation)\\n- Can lead to better performance on future data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Thank you!\\n\\nQuestions?\\n\\nCode: https://github.com/xiaoleihuang/Domain Adaptation ACL2018\\n\\nCollege of Media, Communication and Information"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 317,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Bleaching Text: Abstract Features for Cross-lingual Gender Prediction.\\nJozef Stefan University Rob van der Goot, Nikola Ljubešić, Jan Matroos, Malvina Nissim & Barbara Plank"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Gender Prediction\\n\\nThe task of predicting gender based only on text."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Gender Prediction: Open Vocabulary 2000 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Gender Prediction SVM with word/char n-grams performs best!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Gender Prediction SVM with word/char n-grams performs best!\\n\\nWinner PAN 2017 shared task on author profiling:\\n- Words: 1-2 grams\\n- Characters: 3-6 grams"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Surine Women drinking\\n\\nChi own 8 less king more bmy om.\\n\\neer, men\\n\\nSo, On, Fein, ena es\\n- le Sahu Brewer\\n- Craft Beer\\n- Grow opportunity\\n- Female consumers\\n\\nhttps://www.brewbound.com/news/power-hour-craft-beer-growth-opportunity-lies-female-consumers\\n\\nhttps://www.craftbrewingbusiness.com/news/survey-women-drinking-beer-men-drinking-less/\\n\\nhttps://www.nzherald.co.nz/business/news/article.cfm?c_id=3&objectid=11802831"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "However, how would this lexicalized approach work across different time-spans, domains, languages?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Cross-lingual Gender Prediction: Train a model on source language(s) and evaluate on target language."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Cross-lingual Gender Prediction Dataset: TwiSty corpus (Verhoeven et al.,\\n2016) + English 200 tweets per user, 850\\n- 8,112 users per language = [Ld 7 | \"ZibN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Cross-lingual Gender Prediction\\n- Train:\\n- Test Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Cross-lingual Gender Prediction USER Jaaa moeten we zeker doen"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Bleaching Text"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Bleaching Text RED tees mete ae miter nee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Bleaching Text Original | Massacred a bag of Doritos for lunch!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Bleaching Text Original | Massacred a bag of Doritos for lunch!\\n\"im Freq 0 5 2 5 0 5 1 0 Length | 09 01 03 02 O07 03 06 04 Punct C | w w Ww Ww W Ww w w!\\nhi Punct A | Ww w Ww Ww W Ww Ww W P III S Shape | ULL L LL LL ULL LL LL X XX"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Bleaching Text Original\\n\\nMassacred a bag of Doritos for\\n- lunch!\\n\\nFreq 0 5 2 5 0 5 1\\nLength | 09 01 03 #402 O07 0306\\nPunct C | w w ow w ow w w!\\nPunct A | w w w w w Ww W P\\nShape | ULL L LL LL ULL LL LL\\nX x Vowels | CVCCVCCVC V CVC VC CV v CV v CV G CVC CVCC C O"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Bleaching Text\\nNo tokenization\\nReplace usernames and URLs\\nUse concatenation of the bleached representations\\nTuned in-language\\n5-grams perform best"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Bleaching Text\\n\\nLexicalized\\nBleached Train:\\nTest Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Bleaching Text Trained on all other languages:\\n80.\\nLexicalized Bleached 70- L>UV£=¥ 60- \"EN ONL FR PT. ESTest Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Bleaching Text\\n\\nMost predictive features\\n\\nMale     Female\\n\\n1   WWWW'\"W\" USER EW W W\\n2   wWwwww? 351523 25052 WWWW\\n3   *4 54454 EWWWW\\n4   WW, WW W? LL LL LL LL LX\\n5   6 44214 LLLLLLLLLUU\\n6   7 PPWWWW W W W W\\n7   *-*\\n8   8 55225 WWW WwW JJ\\n9   0202050206 WWWW &WwW:w\\n10  50552 JWWWW"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Human Experiments: Are humans able to predict gender based only on text for unknown languages?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Human Experiments\\n20 tweets per user (instead of\\n200)\\n6 annotators per language pair\\nEach annotating 100 users\\n200 users per language pair, so 3 predictions per user"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Human Experiments\\n\\nA user has posted the following tweets:\\n\\npelo amor de deus cai na realidade URL\\n\\naversao de REALITi do album é tao ruim ne eu to até meio assim*\\n\\nmeu rosto tinha tdo pra ser ok mas nao eu tive que nascer com esse nariz horroroso € esses olhos cagados*\\n\\neu nunca ouvi nada tao lindo URL\\n\\nomundo precisa ouvir isso URL\\n\\nUSER GENTE??? 27? 22???\\neu apenas conciliei elas com a situacao atual da minha vida e jé to todo em choque aqui pq to bateumeu deus eu desci o nivel da timeline dum jeito q a gente ja se encontra no pré sal moral\\n\\nquando a pessoa é tao mediocre que te chama de nerd debochando pq vc disse que gosta de ler*\\n\\nUSER bom..... eu num sei de nda «\\n\\nUSER eu to com o olho chei de agua sua mae eh tao linda vwv ¥ © eu definitivamente nao aguento mais URL\\n\\nRindo Muito De Meu Proprio Tweet*\\n\\nUSER USER sempre contribuindo para a arte de minhas amigas que saudade de camiliquia «\\n\\nUSER as arvores da minha casa tinham 70 anos..... cortaram > todas < por causa dos canos do vizinho «\\n\\nUSER o suprassumo da diferentona*\\n\\nANAO pagueia lingua, pin é a terceira melhor musica do album, que musica maravilhosa «\\n\\nUSER USER USER qual a intencdo em cmpartilhar fotos explicitas de criancas sendo abusadas?*\\n\\naminha mae reclama de absolutamente tudo ela nao para de reclamar 1 segundo, ela nunca ta de bom humor, ela nunca acha «\\n\\nUSER melissa do céu como assim explica\\n\\nDo you think that the poster of these tweets is male or female? (required) Male Female © Please use your intuition."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Human Experiments\\n\\nLexicalized\\n\\nBleached Humans\\n\\nTest Language (note that the classifier had access to 200 tweets)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Conclusions\\n- Lexical models break down when used cross-language.\\n- Bleaching text improves cross-lingual performance.\\n- Humans' performance is on par with our bleached approach."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Thanks for your attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Cross-lingual Embeddings: 'mam Lexicalized mam Bleached = Embeddings\\n\\nSee: Plank (2017) & Smith et al. (2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Lexicalized Cross-language Test EN NL FR PT ES\\nEN 52.8\\nNL 51.1\\nFR 55.2\\nPT 50.2\\nES 50.8\\nAvg 51.8 52.3 53.4 55.3 55.6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "In-language performance\\n90. Lexicalized\\n\\nBleached\\n\\n80\\n\\n70\\n\\n60\\n\\ntT i\\n\\n4 i\\n\\nEN NL FR PT ES\\n\\nTest Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Bleached + Lexicalized\\n\\nBleached Mam\\nBleached + lex 70\\n- -> U23 v 60"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Unigrams vs fivegrams\\n- Ga\\n- Unigramma\\n- Fivegram\\n\\nTest Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Number of unique unigrams for Dutch\\n\\nFeature Size\\nLexicalized 281011\\nBleached 54103\\nFrequency 8\\nLength 79\\nPunctAgr 107\\nPunctCons 5192\\nShape 2535\\nVowels 46198"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Language to language feature analysis\\n\\nTEST 6, EN NL FR PT ES°; Lene 0 I Lack to be Biss | | il J tall] a_ 69 | | Zo: | 6Zz fjcara ttie ita45 | 65 ] 1 Ess 295 Legend 6 1 ] a vow slim shape ol | | SS putewos | | He lenasl al im my ae"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 197,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "The quest for universal sentence embeddings\\n\\nUses unannotated or weakly-annotated datasets\\n\\nSkip-Thought\\n\\nUses annotated datasets\\n\\nQuick-Thought\\n\\nELMo\\n\\nDisentanglement\\n\\nGoogle's recent input-output trend\\n\\nUses several annotated or unannotated datasets\\n\\nMILA/MSR's General Purpose Sent.\\n\\nGoogle's Universal Sentence Enc.\\n\\n*Courtesy: Thomas Wolf blogpost, Hugging Face"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Now-famous Ray Mooney's quote:\\n\\n\"You can't cram the meaning of a single sentence into a single vector!\"\\n- While not capturing meaning, we might still be able to build useful transferable sentence features.\\n- But what can we actually cram into these vectors?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "The evaluation of universal sentence embeddings a positive/negative,\\n- Transfer learning on many other tasks\\n- Learn a classifier on top of pretrained sentence embeddings for transfer tasks\\n\\nSentEval downstream tasks:\\n- Sentiment/topic classification\\n- Natural Language Inference\\n- Semantic Textual Similarity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "The evaluation of universal sentence embeddings -- positive/negative,\\nDownstream tasks are complex\\n- Hard to infer what information the embeddings really capture.\\n\\nHow fine-tuning -- \"Probing tasks\" to the rescue!\\n\\nDesigned for inference\\n- evaluate simple isolated properties TRANSFER.\\nParameters trained on the task\\n- no fine-tuning."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Probing tasks and downstream tasks\\n\\nProbing tasks are simpler and focused on a single property!\\n\\nSubject Number Natural Language Inference\\n\\nprobing task downstream task\\n\\nPremise: A lot of people walking outside a row of shops with an older man with his hands in his pocket is closer to the camera.\\n\\nLabel: Plural (NNS)\\n\\nHypothesis: A lot of dogs barking outside a row of shops with a cat teasing them.\\n\\nLabel: contradiction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Our contributions\\n\\nAn extensive analysis of sentence embeddings using probing tasks.\\n- We vary the architecture of the encoder (3) and the training task (7).\\n- We open-source 10 horse-free classification probing tasks.\\n- Each task being designed to probe a single linguistic property.\\n\\nShi et al. (EMNLP\\n2016)\\n- Does string-based neural MT learn source syntax?\\n\\nAdi et al. (ICLR\\n2017)\\n- Fine-grained analysis of sentence embeddings using auxiliary prediction tasks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Probing tasks: understanding sentence embeddings content PTE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Probingtasks\\n\\nWhat they have in common:\\n- Artificially-created datasets all framed as classification\\n- but based on natural sentences extracted from the TBC (5-to-28 words)\\n- 100k training set, 10k valid, 10k test, with balanced classes\\n- Carefully removed obvious biases (words highly predictive of a class, etc)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Probingtasks grouped in three categories:\\n- Surface information\\n- Syntactic information\\n- Semantic information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Probing tasks (1/10)\\n- Sentence Length\\n\\nShe had not come all this way to let one MLP classifier stupid wagon turn all of that hard work.\\n\\nTCO Waste: input output\\n- Goal: Predict the length range of the input sentence (6 bins)\\n- Question: Do embeddings preserve information about sentence length?\\n\\nSurface information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Probing tasks (2/10)\\n- Word Content\\n\\nHelen took a pen from her purse and wrote something on her cocktail.\\n- MLP classifier\\n- Goal: 1000 output words. Which one (only one) belongs to the sentence?\\n\\n* Question: Do embeddings preserve information about words?\\n\\nAdi et al. (ICLR\\n2017)\\n- Fine-grained analysis of sentence embeddings using auxiliary prediction tasks.\\n- Surface information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Probing tasks (3/10)\\n- Top Constituents\\n\\nMLP classifier\\n\\nSlowly he lowered his head toward the anger in his voice surprised even himself.\\n- Goal: Predict top constituents of parse-tree (20 classes)\\n* Note: 19 most common top-constituent sequences + 1 category for others\\n- Question: Can we extract grammatical information from the embeddings?\\nShi et al. (EMNLP\\n2016)\\n- Does string-based neural MT learn source syntax?\\nSyntactic information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Probing tasks (4/10)\\n- Bigram Shift MLP classifier\\n- input output\\n- Goal: Predict whether a bigram has been shifted or not.\\n\\n* Question: Are embeddings sensible to word order?\\n\\nSyntactic information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Probing tasks\\n-\\n\\n5/10: Tree Depth (depth of the parse tree)\\n-\\n\\n6/10: Tense prediction (main clause tense, past or present)\\n-\\n\\n7-8/10: Object/Subject Number (singular or plural)\\n-\\n\\n9/10: Semantic Odd Man Out (noun/verb replaced by one with same POS)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Probing tasks (10/10)\\n- Coordination Inversion\\n\\nThey might be only memories, but I can still feel each one. They might be only memories.\\n\\n* Goal: Sentences made of two coordinate clauses: inverted (Il) or not (O)?\\n* Note: human evaluation: 85%\\n* Question: Can extract sentence-model information?\\n* Semantic information 16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Experiments and results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Experiments\\n\\nWe analyse almost 30 encoders trained in different ways:\\n- Our baselines:\\n- Human evaluation, Length (1-dim vector)\\n- NB-uni and NB-uni/bi with TF-IDF\\n- CBOW (average of word embeddings)\\n- Our 3 architectures:\\n- Three encoders: BiLSTM-last/max, and Gated ConvNet\\n- Our 7 training tasks:\\n- Auto-encoding, Seq2Tree, SkipThought, NLI\\n- Seq2seq NMT without attention En-Fr, En-De, En-Fi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "I myself was out on an island in the Swedish archipelago, at Sandhamn.\\n\\nJe me trouvais ce jour-là sur une île de l'archipel suédois, Sandhamn.\\n\\nWe really need to up our particular contribution in that regard.\\n\\nIt is too early to see one system as a universal panacea and dismiss another.\\n\\nThe new Sami didn't mind standing barefoot in dirty. The old Sami was gone, and he was a different person now.\\n\\nDikoya is a village in Sri Lanka.\\n- Source and target examples for seq2seq training tasks\\n- Sutskever et al. (NIPS\\n2014)\\n- Sequence to sequence learning with neural networks\\n- Kiros et al. (NIPS\\n2015)\\n- SkipThought vectors\\n- Vinyals et al. (NIPS\\n2015)\\n- Grammar as a Foreign Language"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Baselines and sanity checks\\n\\nPrabing Bis®usédiati-inneaseithiesil CBOWio ll Majority vate.\\nos1.684 BZ79.87566.6 68.1 oT 65.5a Ef °3 0.850 50U<25 23\" 2050 1SentLen WC TopConst BShift ObjNum 20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Impact of training tasks\\n\\nME\\nCBOW\\nMR\\nOIOG\\nRaider\\nRUN\\nTENE\\nQT\\nMash\\niraime\\nddan\\ndie\\nngnsmayeught\\nME\\nNb. 100\\na ve\\nos\\n94.782\\n59\\n- 81.4\\n18%\\n79.82\\n1e\\n66\\n8\\n68\\na\\n62g\\ngub0.1UO\\n4.5\\n50\\nos\\n47.3\\ntt\\n< 35.25\\nBy 140\\nSentLen\\nWC\\nTopConst\\nBShift\\nObjNum\\na"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Impact of model architecture\\n\\nAverage accuracies for different models\\n\\nMi BiLSTM-max\\n\\nMf BiLSTM-last\\n\\nGatedConvNet\\n\\n70.8\\n81.2\\n79.2\\n73.7\\n72.6\\n73.1\\n68.7\\n62.4\\n46.2\\n40.3\\n35.2\\n22.5\\n0\\n\\nSentLen\\nWC\\nTopConst\\nBShift\\nObjNum\\nCoordInv\\n22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Evolution during training\\n\\n100 NMT En-Fr\\n- BiLSTM-max\\nNMT En-De\\n- BiLSTM-max\\n- Evaluation on probing tasks at each epoch of training\\n60 | 40\\nWhat do embeddings encode along training?\\nNMT: Most increase and converge rapidly (only 7 SentLen decreases).\\nWC correlated with BLEU.\\n20\\nL---0 1 10 20 30 40 Epoch\\n10 20 30 40 50"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Correlation with downstream tasks\\n\\nCorrelation between probing and downstream tasks\\n- Strong correlation between WC and downstream tasks: 0.67\\n- Tree Depth\\n- Word-level information: 0.4\\n- Top Const important for downstream tasks (classification, NLI, STS): 0.2\\n- Tense: 0.0\\n- Subj Num: 0.2\\n\\nIf WC is a good predictor, maybe current downstream tasks are not the right ones?\\n- Coord I inv: -0.6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Take-home messages and future work\\n- Sentence embeddings need not be good on probing tasks.\\n- Probing tasks are simply meant to understand what linguistic features are encoded and are designed to compare encoders.\\n\\nFuture work\\n- Understanding the impact of multi-task learning.\\n- Studying the impact of language model pretraining (ELMO).\\n- Study other encoders (Transformer, RNNG)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Thank you!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "qT n a M K YOU. Task Type #train #test.\\n\\nSentLen Length prediction 100k 10k\\n- Publicly available in SentEvalWC Word Content analysis 100k 10k.\\n\\nTreeDepth\\n- Tree depth prediction 100k 10k\\n- Automatically generated datasets (generalize to other languages)\\n\\nTopConst\\n- Top Constituents prediction 100k 10k\\n\\nBShift\\n- Word order analysis 100k 10k\\n\\nTense\\n- Verb tense prediction 100k 10k\\n\\nNatural sentences from Toronto\\n- subjnum subject number prediction 100k 10k\\n\\nBook Corpus\\n\\nObjNum\\n- Object number prediction 100k 10k\\n\\nSOMO\\n- Semantic odd man out 100k 10k\\n- Used Stanford parser for grammatical tasks\\n\\nCoordIinv\\n- Coordination Inversion 100k 10k\\n\\nhttps://github.com/facebookresearch/SentEval/tree/master/data/ \"probing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Probing tasks\\n- Semantic Odd Man Out\\n\\nNo one could see this Hayes and MLP classifier wanted to know if it was real or a -.\\n\\nMspoonful (orig: \"ploy\")\\n- Goal: Predict whether a sentence has been modified or not: one verb/noun randomly by another verb/noun with same POS.\\n\\nNote: preserved bigrams frequency, human eval.: 81.2%\\n\\nQuestion: Can we identify well-formed sentences (sentence model)?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 201,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n\\nIntroduction\\n\\nBackground\\n\\nDefinition & Motivation\\n\\nOverview & Contribution\\n\\nModel Architecture\\n\\nExperiments\\n\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Outline\\nIntroduction\\nBackground"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Background: What is Aspect/Opinion Extraction\\n\\nFine-grained Opinion Mining\\n\\nPositive Negative\\n- Opinion terms\\n- Summary statistics\\n- Location\\n- Summary generation Service for each review\\n\\nOur focus: Aspect and Opinion Terms Co-extraction\\n\\nChallenge: Limited resources for fine-grained annotations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Background: What is Aspect/Opinion Extraction\\n\\nFine-grained Opinion Mining\\n\\nPositive Negative\\n\\nOpinion terms\\n\\nSummary statistics\\n\\nLocation\\n\\nSummary generation Service for each review\\n\\nDesign\\n\\nFigure 1: An example of review outputs.\\n\\nOur focus: Aspect and Opinion Terms Co-extraction\\n\\nChallenge: Limited resources for fine-grained annotations\\n\\nCross-domain extraction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Outline\\n\\nIntroduction\\n\\nDefinition & Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Problem Definition\\n\\nTask formulation: Sequence labeling\\n\\nLabels:\\n- B\\n- Beginning of aspect\\n- I\\n- Inside of aspect\\n- O\\n- Beginning of opinion\\n- I\\n- Inside of opinion\\n- N\\n- None\\n\\nInput: The phone has a good screen size\\n\\nFigure 2: A deep learning model for sequence labeling.\\n\\nDomain Adaptation\\n\\nGiven: Labeled data in source domain Ds = {(x_s, y_s)}^n, unlabeled data in target domain D_t = {x_t}^m\\n\\nIdea: Build bridges across domains, learn shared space"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Motivation: Domain Adaptation\\n\\nDomain shift & bridges\\n\\nFigure 3: Domain shift for different domains.\\n\\nFigure 4: Syntactic patterns."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Motivation: Domain Adaptation\\n\\nDomain shift & bridges\\n\\nFigure 3: Domain shift for different domains.\\n\\nFigure 4: Syntactic patterns.\\n\\nRelated work\\n- Adaptive bootstrapping [Li et al., 2012]\\n- Auxiliary task with Recurrent neural network [Ding et al., 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Outline\\nIntroduction\\nOverview & Contribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Overview & Contribution\\n\\nRecursive Neural Structural Correspondence Network (RNSCN)\\nStructural correspondences are built based on common syntactic structures.\\nUse relation vectors with auxiliary labels to learn a shared space across domains.\\nLabel denoising auto-encoder\\nDeal with auxiliary label noise.\\nGroup relation vectors into their intrinsic clusters in an unsupervised manner.\\nA joint deep model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Outline\\nBackground\\nDefinition & Motivation\\nOverview & Contribution\\nModel Architecture"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Model Architecture: Recursive Neural Network\\n\\nDomain Adaptation\\n\\nRelation vectors: Relations as embeddings in the feature space.\\n\\nFe3 = tanh(Wh3 + Wxx4)\\n\\nhg = tanh(Wamodtas + Wxx4 +\\nb)\\n\\nFigure 5: A recursive neural network."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Model Architecture: Recursive Neural Networks\\n\\nDomain Adaptation\\n\\nRelation vectors: Relations as embeddings in the feature space\\n\\nBees:\\n\\nFie t 3 = tanh(Wh3 + Wxx4)\\n\\nh = tanh(Wamodtes + Wxxs +\\nb)\\n\\nAuxiliary task: Dependency relation predictions\\n\\nFigure 5: A recursive neural network."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Model Architecture: Learn Shared Representations\\n\\nRecursive Neural Structural Correspondence Network (RNSCN)\\n\\nThey offer good appetizers. The hall has a nice screen.\\n\\nSource Target MeTM\\n\\nFigure 6: An example of how RNSCN learns the correspondences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Model Architecture: Learn Shared Representations\\n\\nRecursive Neural Structural Correspondence Network (RNSCN)\\n\\nRNSCN hy i.ia acts to ls re aE -jooe) aa r M m (ies a 7[oe | | | __ | __ [til |tooo || [ooo|rs | hlooo | hoo] fooo|re\" |-~ lil ope il Fo bl.\\nr -inoo] » food | afoo0) aloo 1000] fod\\n000) a dacsthey offer good.\\n\\nappetizers\\n\\nThe laptop has m nice screen\\n\\nSource Target MeTM\\n\\nFigure 6: An example of how RNSCN learns the correspondences.\\n\\n10/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Model Architecture: Learn Shared Representations\\n- GRU\\n- They offer good appetizers.\\n- The laptop has a nice screen.\\n\\nSource\\n\\nTarget\\n\\nFigure 6: An example of how RNSCN learns the correspondences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Model Architecture: Auxiliary Label Denoising correct label noisy label hem4 @oo, Lae\"s T65,13 T4000)\\n3) #{000 good appetizers nice sereneTe Beetamod dobj Source Target Figure 7: An autoencoder for label denoising."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Model Architecture: Auxiliary Label Denoising Auto-encoder\\nAuto-encoder Reduce label noise: intrinsic: intrinsic: auto-encoders\\n\\nEncoding:\\nfenc(Wenc; nm)\\n\\nDecoding:\\na = faec(Wdec; Enm)\\n\\nAuxiliary task:\\nKRY wn aeamod \"doby\"\\naRYnm = softmax(Wrgnm)\\n\\nSource Target\\nFigure 7: An autoencoder for label denoising."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Model Architecture: Auxiliary Label Denoising auto-encoder\\n- Fronto-encoder\\n\\nFigure 8: An autoencoder for relation grouping.\\n\\n(Gam = itam) = exp(trimWencBi) (1)\\n- BeSaoe = amt => exp (rl Wencgt)\\n\\nle, = [Iam\\n- WeecSnml3JEG KR oR161 bey = Yo vent 108 FeteBm = > P(Gam = itn) Bi (2)\\n- kelae = r = |2int lr, = |! oe érG||fe = lr, tale, + Ber, (3)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Outline\\n\\nBackground\\n\\nDefinition & Motivation\\n\\nOverview & Contribution\\n\\nExperiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Experiments Dataset Testing R\\n\\n5,841 4,381 1,460 c\\n3,845 2,884 961 D\\n3,836 2,877 | 959\\n\\nTable 1: Data statistics with number of sentences.\\n\\nModel\\nDSLoes [aS TOP [AS TOP | AS | OP | AS | OP\\nGCRF 19.72 | 59.20 65.52 | 6.59 | 39.38 46.67\\ncross-domain (1.82) | (1.34) | (0.58) | (0.89) | (0.49) | (3.06) | (2.54) | (2.43)\\n\\nbaselines\\nRAP 25.92 | 62.72 | 46.90 | 67.98 | 45.44 | 60.67 | 28.22 | 59.79\\n(2.75) | (0.49) | (1.64) | (1.05) | (1.61) | (2.15) | (2.42) | (4.18)\\n\\nHierJoim | 33.06 48.10 47.97\\n- =~) 34.74\\n(2.47) (1.45) (0.46) |\\n- | (2.27) |\\n-\\n\\nRNCRE 24.26 60.86 40.88 66.50 34.59 63.89 40.59 60.17\\nsingle-domain (3.97) | (3.35) | (2.09) | (1.48) | (1.34) | (1.59) | (0.80) | (2.20)\\n\\nbaselines\\nRNGRU 24.23 60.65 39.78 62.99 38.15 64.21 39.44 60.85\\n(2.41) | (1.04) | (0.61) | (0.95) | (2.82) | (1.11) | (2.79) | (1.25)\\n\\n37.77 | 62.35 | 53.18 | 71.44 | 49.62 69.42 | 45.92 | 63.85\\n(0.97) | (0.34) | (2.27) | (1.97)\\n\\n40.43 | 65.85 | 52.91 | 72.51 | 48.36 | 73.75 | 51.14 | 71.18\\nANSCN-GRU (hig) (2.75) | (9) | (58)\\n\\nTable 2: Comparisons with different baselines.\\n\\n14/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Experiments: Injecting noise into syntactic relations\\n\\nModel: ba\" [AS | OP: [AS | OR | AS | Oe: | AS: [OP [AS | OP | AS: | OP.\\n\\nRNSCN-GRU: 37.77 | 62.38 | 33.02 | 57.54 | 83.18 | 71.44 | 35.65 | 60.02 | 49.62 | 69.42 | 45.92 | 63.85\\nRNSCN-GRU (1): 59.18\\nRNSCNT-GRU: 40-43 | 65.85 | 35.10 | 60.17 | 52.01 | 72.51 | 40.42 | 61.15 | 48.36 | 73.75 | $1.14 | 71.18\\nRNSCNT-GRU (1): 68.05\\n\\nTable 3: Effect of auto-encoders for auxiliary label denoising.\\n\\nWords grouping learned from auto-encoders:\\n\\nthis, the, their, my, here, it, our, not\\nquality, jukebox, maitre-d, sauces, portions, volume, friend, noodles, calamari\\nin, slightly, often, overall, regularly, since, back, much, ago\\nhandy, tastier, white, salty, right, vibrant, first, ok\\nget, went, impressed, had, try, said, recommended, call, love\\nis, are, feels, believes, seems, like, will, would\\n\\nTable 4: Case studies on word clustering\\n15/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Experiments\\n\\n0.64\\n0.645\\n0.63\\n5\\n0.632\\n0.62\\n0.620\\n0.61\\n0.612\\n0.60\\n9\\n0.60\\n0.59\\n0.599985792\\n03\\n04\\n05\\n06\\n07\\n08\\n09\\n10\\n58\\n50\\n15\\n20\\n25\\n30-35\\n40\\n0.42\\n0.42\\n0.41\\n0.40\\n0.39\\n0.38\\n0.382\\n0.37\\n0.379\\n36\\n97-97\\n03\\n04\\n05\\n06\\n07\\n08\\n09\\n10\\n0.36\\n30\\n15\\n20\\n25\\n30\\n35\\n40\\n- trade-off parameter (7)\\n- number of groups (|G|)\\n(a) trade-off\\n(b) Groups\\n\\nFigure 9: Sensitivity studies for LD."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Domain Adaptation: Experiments\\n\\n0.41 0.52\\n- 0.40\\n- 0.51\\n0.39 20503 0.38\\n0.49 > 0.37 + 0.48\\n0.36 0.34 = 0.36\\n0.33 0.35 0.32\\n0.345031 0.33 = 0.30\\n= 0.32 = 0.29 = 0.31\\n\\nproportion of unlabeled target data\\n\\n(a) RoL\\n(b) DoL\\n\\nFigure 10: F1 vs proportion of unlabeled target data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Outline\\nBackground\\nDefinition & Motivation\\nOverview & Contribution\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusione\\n\\nA novel deep learning framework for cross-domain aspect and opinion terms extraction.\\n- Embed syntactic structure into a deep model to bridge the gap between different domains.\\n- Apply auxiliary task to assist knowledge transfer.\\n- Address the problem of negative effect brought by label noise.\\n- Achieve promising results."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "References\\n\\nDing, Y., Yu, J., and Jiang, J. (2017).\\nRecurrent neural networks with auxiliary labels for cross-domain opinion target extraction. In AAAI.\\n\\nLi, F., Pan, S. J., Jin, O., Yang, Q., and Zhu, X. (2012). Cross-domain co-extraction of sentiment and topic lexicons.\\nIn ACL."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Appendix: Domain Adaptation Models DSL\\n- AS Top\\n- AS Top\\n- AS Top\\n- AS\\n- op\\n- AS Top\\n- AS TOP (2.82)\\n- (2.34)\\n- (0.44)\\n- (2.67)\\n- (0.58)\\n- (0.89)\\n- (2.69)\\n- (2.49)\\n- (0.49)\\n- (3.06)\\n- (2.54)\\n- (2.43)\\n- (2.75)\\n- (0.49)\\n- (0.52)\\n- (2.20)\\n- (2.64)\\n- (2.05)\\n- (0.64)\\n- (2.65)\\n- (2.61)\\n- (2.15)\\n- (2.42)\\n- (4.18)\\n- (1.47)\\n- (0.52)\\n- (1.45)\\n- (0.49)\\n- (0.46)\\n- (2.27)\\n- (3.97)\\n- (3.35)\\n- (2.57)\\n- (2.78)\\n- (2.09)\\n- (2.48)\\n- (2.40)\\n- (2.09)\\n- (2.34)\\n- (2.59)\\n- (0.80)\\n- (1.20)\\n- (2.41)\\n- (1.04)\\n- (2.68)\\n- (2.69)\\n- (0.61)\\n- (0.95)\\n- (1.12)\\n- (2.37)\\n- (2.82)\\n- (2.11)\\n- (2.79)\\n- (2.25)\\n- (2.31)\\n- (2.35)\\n- (1.48)\\n- (2.29)\\n- (2.49)\\n- (0.99)\\n- (2.38)\\n- (2.10)\\n- (0.71)\\n- (0.66)\\n- (1.16)\\n- (1.52)\\n- (0.45)\\n- (1.85)\\n- (0.58)\\n- (1.27)\\n- (0.75)\\n- (0.97)\\n- (0.77)\\n- (0.80)\\n- (0.34)\\n- (2.27)\\n- (2.14)\\n- (1.97)\\n- (2.23)\\n- (1.36)\\n- (1.49)\\n- (2.59)\\n- (2.27)\\n- (2.03)\\n- (0.50)\\n- (0.93)\\n- (0.42)\\n- (2.55)\\n- (2.00)\\n- (1.11)\\n- (0.96)\\n- (1.50)\\n- (0.62)\\n- (0.75)\\n- (1.82)\\n- (1.03)\\n- (0.70)\\n- (0.60)\\n- (1.14)\\n- (1.76)\\n- (1.68)\\n- (1.58)\\n\\nTable 5: Comparisons with different baselines."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 320,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Problem Statement\\n\\nMotivation\\n\\nRelated Work\\n\\nProposed Approach\\n\\nExperiments and Results\\n\\n1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Table of Contents\\nProblem Statement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Problem Statement\\n\\nJudiciously select labeled data from assisting language to improve the NER performance in the primary language for multilingual learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Table of Contents\\n\\nMotivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Many languages have less named entity annotated data.\\nSeveral approaches have explored use of data from one or more languages (assisting languages) [Gillick et al.\\n[2016], Yang et al. [2017]].\\nHowever, annotated data from assisting languages might negatively influence the performance on the primary language."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "- Vocabulary\\n- False Friends\\n- Dataset Characteristics\\n- Sub-word features\\n- Capitalization feature\\n- Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish\\n- Contextual features\\n- Different Word Order"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Why need to judiciously select data from assisting language?\\n- Vocabulary\\n- False Friends\\n- Dataset Characteristics\\n\\nEnglish Spanish\\n\\nWord | Per | Loc | Org | Misc\\nWord | Per | Loc | Org | Misc\\n\\nChina = 91 7 : China\\nFrance = 423 4 1 France\\nReuters = 40 | 18 3 Reuters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Table of Contents\\n\\nRelated Work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Related Work\\n\\nAxelrod et al. [2011]\\n- Select sentences from general domain data most similar to in-domain data.\\n\\nMoore and Lewis [2010]\\n- Used language model to measure similarity of general domain data with the in-domain training data.\\n\\nRuder and Plank [2017]\\n- Learn to weigh various data selection measures using Bayesian Optimization.\\n\\nZhao et al. [2018]\\n- Select assisting data for multi-task domain adaptation.\\n- Assisting language sentences with highest log likelihood value were selected.\\n\\nPonti et al. [2018]\\n- Measure cross-lingual syntactic variation considering both morphological and structural properties.\\n- Selecting an assisting language with a lower degree of anisomorphism is crucial for knowledge transfer.\\n\\nTable 1: Literature most relevant to our work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Table of Contents\\nProposed Approach"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Proposed Approach\\n\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Proposed Approach\\n\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data\\n\\nEnglish Spanish pivoted [Meera [Mtoe ira lbisce pivoted a iReta bcs Loney Mises China s 91 7 = China\\n- 20 49 z France\\n- 123 4 1 France es = 10 = Reuters 40 18 i Reuters\\n- 2 £ -7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Proposed Approach\\n\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data\\n\\nEnglish Spanish\\n\\nprem era AE cored ise plore i | Eeed foes ors)\\n\\nMisce\\n\\nChina e 91 7 = China = | 20 49 £ France 1.23. 4 2 France = Z 10 f. Reuters | -| 40| 18 = Reuters | = | 3 | 1 | :7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Proposed Approach\\n\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data\\n\\nEnglish Spanish\\n\\nWord | Per | Loc | Org | Misc\\nWord | Per | Loc | Org | Misc\\nChina | se '|\\n- Cringy) | EE i\\nFrance ahd A 4, neem.\\n- 10\\n-\\n\\nSelect English sentences containing entities with similar tag distribution"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Proposed Approach\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data\\n\\nEnglish            Spanish\\nWord      | Per | Loc | Org | Misc\\nWord      | Per | Loc | Org | Misc\\nChina     91  |  7  | =   | China  20  | 49 | 1\\nFrance    ~   |.123 | 4  | 4 | Feomen\\n-\\n- 10 =baia\\n-\\n\\nUse Symmetric Kullback-Leibler Divergence to calculate the tag disagreement for common entities between English and Spanish"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Proposed Approach\\n\\nSelect sentences based on the agreement in tag distribution of common entities\\n\\nGoal: Improve Spanish NER performance by adding English NER annotated data\\n\\nEnglish Spanish\\n\\nWord Per | Loc | Org | Misc | Per | Loc | Org | Misc | KL(Eng||Esp) | KL(Esp||Eng) | SKL\\n\\nChina = 91 7 * * 20 49 1 0.9314 1.3972 2.3287\\n\\nFrance = 423 -4 1 * = 10 = 10.4332 2.6388 | 13.0721\\n\\nReuters a 40 18 * * 3 1 a 0.1088 0.1531 0.26207"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Proposed Approach\\n\\nfor every sentence X, in assisting language do\\n\\nScore(X) + 0.0\\n\\nfor every word x; in sentence X do\\n\\nif word x; appears in primary language then\\n\\nSKL(X;)\\n- [KL(Pp(xi))Pa(xi)) + KL(Pa(x)|IPo(x))] / 2 {Po(x) and P,(xj) are tag distributions of x; in primary and assisting languages}\\n\\nScore(X) < Score(X) + SKL(x;)\\n\\nend if\\n\\nend for\\n\\nend for\\n\\nAdd assisting language sentences with sentence score Score(X) less than a threshold @ to the primary language data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Table of Contents\\nExperiments and Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Dataset Statistics\\n\\nTrain   Test\\n- Language        Source                         (Tokens)     (Tokens)\\n- Word Embeddings\\n- English         Tjong Kim Sang                 204,567      46,666\\n- Spanish         Dhillon et al. [2015]          264,715      51,533\\n- Dutch           Tjong Kim Sang [2002]          202,931      63,994\\n- Italian         Speranza [2009]                149,651      86,420\\n- German          Faruqui and Pado [2010]        74,907       20,696\\n- Hindi           Lalitha Devi et al. [2014]     81,817       23,696\\n- Marathi         In-house                        71,299       36,581\\n- Tamil           Lalitha Devi et al. [2014]     66,143       18,646\\n- Bengali         Lalitha Devi et al. [2014]     34,387       16,168\\n- Malayalam       Lalitha Devi et al. [2014]     26,295       8,275\\n\\nTable 2: Dataset Statistics"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Network Details\\n\\nParameter sharing configurations\\n\\nSub-word feature extractors are shared across languages (Yang et al. 2017).\\n\\nNeural network trained in a language independent way.\\n\\nFigure 1: Architecture of the Neural Network (Murthy and Bhattacharyya 2016)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "CRS Primary Assisting Layers Data Selection\\n\\nPrimary Assisting Layers Data Selection\\n\\nLanguage\\n- Language Shared all SKL\\n\\nMonolingual None 87.64\\n\\nMonolingual None 75.98\\n\\nny All 89.08\\n\\n89.46\\n\\neal All 76.22\\n\\n76.91\\n\\nGarman Sub-word 88.76\\n\\n89.10\\n\\nItalian Sub-word 79.44\\n\\n79.44\\n\\nAll 89.02\\n\\n91.61\\n\\nAll 74.94\\n\\n76.92\\n\\nSpanish Sub-word 88.37\\n\\n89.10\\n\\nSpanish Sub-word 76.99\\n\\n77.45\\n\\nAll 89.66\\n\\n90.85\\n\\nAll 75.59\\n\\n72.29\\n\\na Sub-word 89.94\\n\\n90.11\\n\\ncia Sub-word 77.38\\n\\n77.56\\n\\nTable 3: F-Score for German and Italian Test data using Monolingual and Multilingual learning strategies.\\n\\n+ indicates that the SKL results are statistically significant compared to adding all assisting language data with p-value < 0.05 using two-sided Welch t-test."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Analysis Histogram of assisting language sentences ranked by their sentence scores.\\n\\nFigure 2: English-Italian: Histogram of English Sentences\\n\\nFigure 3: Spanish-Italian: Histogram of Spanish Sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Analysis: European Languages\\n- Adding all Spanish/Dutch sentences to Italian data leads to a drop in Italian NER performance.\\n- Label drift from overlapping entities is one of the reasons for the poor results.\\n- We compare the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning.\\n- A similar pattern is observed in the case of Dutch sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "CRS Nes Assisting Language\\n\\nMary Language § AP\\n\\nHindi\\nMarathi\\nBengali\\nMalayalam\\nTamil\\n\\nALL SKL\\nALL SKL\\nALL SKL\\nALL SKL\\nALL SKL\\n\\nHindi 64.93 59.30 66.33 58.51 = 59.30 58.21 = 59.13 56.75 58.75\\n\\nMarathi 54.46 63.30 61.46\\n- 47.67 61.28 50.13 61.05 59.04 58.62\\n\\nBengali 44.34 SLOS t = 41.28 S5.7F\\n- 40.02 = 48.79 49.84\\n- 38.38\\n\\nMalayalam 59.74 64.00\\n- 65.88 66.42 58.01 63.65 + 57.94\\n- 58.25 58.92\\n\\nTamil 60.13 61.51 = 60.54 53.27 60.32\\n- 61.03 61.45 53.13\\n-\\n\\nTable 4: Test set F-Score from monolingual and multilingual learning on Indian languages.\\n\\nResult from monolingual training on the primary language is underlined.\\n+ indicates SKL results statistically significant compared to adding all assisting language data with p-value < 0.05 using two-sided Welch t-test."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Analysis: Indian Languages\\n- Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy.\\n\\nHindi and Marathi NER performance improves when the other is used as assisting language.\\n\\nHindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam, and Tamil."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Analysis Influence of SKL Threshold\\n\\nPlot of Italian Test F-Score v/s Sentence Score\\n\\n# 760g5 75.5 75.0 449 a0 20 30 40 50 60 7.0 80 90 19.0\\n\\nSentence Score (SKL)\\n\\nFigure 4: Spanish-Italian Multilingual Learning: Influence of Sentence Score (SKL) on Italian NER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "- Train for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages.\\n- We vary the threshold value from 0.0 to 9.0 in steps of\\n1.\\n- Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusion And Future Work\\n\\nWe address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER.\\nWe show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy.\\nA more principled approach for data selection would be exploring the work of Ponti et al. [2018].\\n\\nWe plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, and neural machine translation.\\nWe also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Thank You"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "References\\n- Amittai Axelrod, Xiaodong He, and Jianfeng Gao. Domain adaptation via pseudo in-domain data selection.\\nIn Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, United Kingdom,\\n2011.\\n- Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information.\\nTransactions of the Association for Computational Linguistics,\\n2017.\\n- Paramveer S. Dhillon, Dean P. Foster, and Lyle H. Ungar. Eigenwords: Spectral word embeddings.\\nJournal of Machine Learning Research,\\n2015.\\n- Manaal Faruqui and Sebastian Pado.\\nTraining and evaluating a German Named Entity Recognizer with semantic generalization. In Proceedings of KONVENS, 2010."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Neil Alec Dan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag Subramanya.\\n\\nMultilingual language processing from bytes.\\nIn Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics, San Diego, US,\\n2016.\\n\\nShobha Lalitha Devi, Pattabhi RK Rao, Malarkodi C.S, and R Vijay Sundar Ram.\\n\\nIndian language NER annotated FIRE 2014 corpus (FIRE 2014 NER Corpus).\\nIn Named-Entity Recognition Indian Languages FIRE 2014 Evaluation Track,\\n2014.\\n\\nRobert C. Moore and William Lewis.\\n\\nIntelligent selection of language model training data.\\nIn Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 2010."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "eur @Ti aca LTRudra V. Murthy and Pushpak Bhattacharyya. A deep learning solution to Named Entity Recognition.\\nIn CICLing, Konya, Turkey,\\n2016.\\n\\nEdoardo Maria Ponti, Roi Reichart, Anna Korhonen, and Ivan Vulic.\\nIsomorphic transfer of syntactic structures in cross-lingual NLP. In ACL 2018,\\n2018.\\n\\nSebastian Ruder and Barbara Plank. Learning to select data for transfer learning with Bayesian Optimization.\\nIn Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Copenhagen, Denmark,\\n2017.\\n\\nManuela Speranza. The Named Entity Recognition task at EVALITA\\n2009. In Proceedings of the Workshop Evalita, 2009."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "sail Tice\\n\\nAErik F. Tiong Kim Sang. Introduction to the conll-2002 shared task: Language-independent Named Entity Recognition.\\nIn Proceedings of the 6th Conference on Natural Language Learning at COLING-02, Taipei, Taiwan,\\n2002.\\n\\nErik F. Tiong Kim Sang and Fien De Meulder.\\nIntroduction to the conll-2003 shared task: Language-independent Named Entity Recognition.\\nIn Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, Edmonton, Canada,\\n2003.\\n\\nZhilin Yang, Ruslan Salakhutdinov, and William Cohen. Multi-task cross-lingual sequence tagging from scratch.\\nIn International Conference on Learning Representations, Toulon, France, 2017."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Nel CTIAH\\n\\nuasha Zhao, Yi Yang, Qiong Zhang, and Luo Si.\\nImprove neural entity recognition via multi-task data selection and constrained decoding.\\nIn Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers).\\nAssociation for Computational Linguistics, 2018."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Why need to judiciously select data from assisting language?\\n- Vocabulary\\n- False Friends\\n- Dataset Characteristics\\n- Sub-word features\\n- Capitalization feature\\n- Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish\\n- Contextual features\\n- Different Word Order\\n\\nI am going to Washington."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 117,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "IPlCer eee le Vee OE mT amu tela mh (inlet cd Overview Introduction Document MT as Structured Prediction Document NMT with MemNets Experiments and Analysis Conclusion f@ References"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdLintroductionOverviewIntroduction\\n- 3/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdLintroduction\\n\\nWhy document-level machine translation?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdLintroduction\\n\\nWhy document-level machine translation?\\n\\nMost MT models translate sentences independently."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdLintroduction\\n\\nWhy document-level machine translation?\\n\\nMost MT models translate sentences independently.\\n\\nDiscourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdLintroduction\\n\\nWhy document-level machine translation?\\n\\nMost MT models translate sentences independently. Discourse phenomena are ignored, e.g.\\npronominal anaphora and lexical consistency which may have long range dependencies.\\n- verbs\\n- subject\\n- \"gameansomgen.\"\\n- \"Shellikes to read.\"\\n- \"pronounverb\"\\n- \"firfanlis doing\"\\n- \"Ph.D.\"\\n- \"He is in second year.\"\\n- \"Aia a Hono Hel likes to read.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cd\\n\\nIntroduction\\n\\nWhy document-level machine translation?\\n\\nStatistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014] 5/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nIntroduction\\n\\nWhy document-level machine translation?\\n- Statistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014].\\n- Previous context-NMT models only use local context and report deteriorated performance when using the target-side context [Jean et al., 2017, Wang et al., 2017, Bawden et al., 2018]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdretical meee etree Rare att Overview Document MT as Structured Prediction\\n- 6/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured PredictionDocument MT as Structured PredictionSi.\\nAck cul ma. os,é Tad, { -- }ett) Pegs Gi)> \">\"Us Sls ec pipog ey { yz)- Pealan os=e aun Us 5\\na) ( » }--» )"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction L.\\naf 4 oo '<td Kehoe (on s m ) 2 Use Ls 2 pr groy (x2} fy: )~My Lia jp ul (x} oye)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured PredictionDocument MT as Structured PredictionL .\\n> a eosts) BS sigh Ge (| cs2 Use Ls 2 pr groy (x xf vn )~My Lia jp ul (| oy )"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdretical meee etree Rare attDocument MT as Structured Prediction=> ft\\n- gl(ox | + yi.\\nioo Nooni>' 2 ie g2[owe } aa Me lt' ' !1' ' |!(xia) | Vialae fidj \\ gid]Two types of factors: fo(yt; Xt, x-t), Bo(¥ei y-t)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured PredictionDocument MT as Structured PredictionTraining objective: o a = = = e as"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdretical meee etree Rare attDocument MT as Structured Prediction\\n\\nTraining objective: Maximise P(yi, ..., yj | X1, ..., Xj)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdretical meee etree Rare attDocument MT as Structured Prediction\\n\\nTraining objective:\\n\\nMaximise P(yi,...; ¥jaj|X1,...,Xj|) == Maximise the pseudo-likelihood | arg max | Po(y|x, y_t, Xt)\\n\\n(1)\\n\\nwhere f and g are subsumed in the Po(y|x, y_t, Xt)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdretical meee etree Rare attDocument MT as Structured Prediction Challenge: During test time, the target document is not given."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdPeete eee marc iaen Document MT as Structured Prediction Challenge: During test time, the target document is not given Coordinate Ascent (i.e., Iterative Decoding)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction Iterative Decoding Step 0Cp)eT@-|1fo \\Vidi)@- ON"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction Iterative Decoding Step 0 Step 1 ios eA*) Coor 1i (1 \\ak yial |ar"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction Iterative Decoding Step 0 Step 1 Po % /wOr vi } \\ vi } x N\\A ulNor dt|1(faOAL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured Prediction Document MT as Structured Prediction Iterative Decoding Step 0 Step 1 (o> aVi yi) AN) wara a=an (#) Or) #1 1I I(a) OE) &"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument MT as Structured PredictionDocument MT as Structured PredictionIterative DecodingStepO Step 1 Stept/ @ \\ AK @ ) 'ey .I 1 !I\\n-\\n- |Ory Ory ory11/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument NMT with MemNetsOverviewDocument NMT with MemNets-\\n- 12/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdesteem on esDocument NMT with MemNetsqimonda fulfils the objectives of the Lisbon strategy \"OHO\") =\\n- itd| a ct7 wi BEESgimonda taidab lisaboni strateegia eesmarke 15/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdesteem on esDocument NMT with MemNetsqimonda fulfils the objectives of the Lisbon strategy, OO) = & osJ ct tj Foannanenennnneneen Year M[x-t] Mly-]qimonda taidab Lisbon strategy eesmarke 16 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument NMT with MemNets Document NMT with MemNets gimonda fulfils the objectives of the Lisbon strategy M[x-+] Mly-] gimonda taidab lisaboni strateegia eesmarke Memory-to-Context: treSj = GRU(s:j-1, Er [veya], ery, €7\"°, €;*) 17/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument NMT with MemNets Document NMT with MemNets gimonda fulfills the objectives of the Lisbon strategy M[x-+] Mly-] gimonda taidab lissaboni strateegia eesmarke Memory-to-Output:.\\nsofts. src _ tteYej ~ Softmax(Wy\\n- nj + Wym + oF + Wy\\n-\\n- ;'% + by) 18 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdDocument NMT with MemNets Document NMT with MemNets.\\nUse only source, target, or both external memories.\\nUse Memory-to-Context / Memory-to-Output architectures for incorporating the different contexts."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdSe nore Ur as Overview Experiments and Analysis\\n- 20 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdSe nore Ur as Experimental Setup"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nExperimental Setup\\n\\nTraining /dev/test corpora statistics:\\ncorpus              #docs (H) | #sents (K) | avg doc len\\nFr-En | Ted-Talks     10 / 1.2 / 1.5   | 123 / 15 / 19  | 123 / 128 / 124\\nEt-En | Europarl v7   150 / 10 / 18    | 209 / 14 / 25  | 14 / 14 / 14\\nDe-En | News-Commentary                   | 49 / .9 / 1.6  | 191 / 2 / 3   | 39 / 23 / 19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nExperimental Setup\\n\\nTraining /dev/test corpora statistics:\\n- corpus #docs (H) | #sents (K) | avg doc len\\n- Fr-En | Ted-Talks 10 / 1.2 / 1.5 | 123 / 15 / 19 | 123 / 128 / 124\\n- Et-En | Europarl v7 150 / 10 / 18 | 209 / 14 / 25 | 14 / 14 / 14\\n- De-En | News-Commentary | 49 / .9 / 1.6 | 191 / 2 / 3 | 39 / 23 / 19\\n\\nEvaluation Metrics: BLEU, METEOR"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nSe nore Ur as\\n\\nExperimental Setup\\n\\nTraining/dev/test corpora statistics:\\n\\ncorpus             #docs (H) | #sents (K) | avg doc len\\nFr-En | Ted-Talks        10 / 1.2 / 1.5  | 123 / 15 / 19 | 123 / 128 / 124\\nEt-En | Europarl v7      150 / 10 / 18  | 209 / 14 / 25 | 14 / 14 / 14\\nDe-En | News-Commentary   | 49 / .9 / 1.6 | 191 / 2 / 3 | 39 / 23 / 19\\n\\nEvaluation Metrics: BLEU, METEOR\\n\\nBaselines:\\n- Context-free baseline (S-NMT)\\n- Local source context baselines: [Jean et al., 2017] & [Wang et al., 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdSe nore Ur as Memory-to-Context Results: 22/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdSe nore Ur as Memory-to-Context Results 23 uu 2310.522 22}\\n- uw 10a21 20.85 21 | 9.59.1820 9 20 Fr-En De-En Et -> En 22/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdSe nore Ur as Memory-to-Context Results 23 11 2310.522 21.91 us 22 7=os 10a21 20.85 21 | 9.5 } 9.18 | ) 20 = 9 LL 20 [ | = Fr > En De\\n- En Et > En.\\n22 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nMemory-to-Context Results\\n\\n23\\nuu\\n2310.5\\nna22\\n21.91\\nman\\n108\\n22\\nIL\\n21.94\\nnm\\n10\\n9.97\\na21\\n20.85\\n21\\n9.52\\n0.42\\n9.18\\n20\\no_\\n20\\n[|\\nFr-En\\nDe-En\\nEt->En\\n22/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nMemory-to-Context Results\\n\\n23 11 ! 23 ! 10.54 | 105} 2 Ae.\\nies 22= 9au 10 b 0.97a21> 2.85 4 21i 9.55 =] 9.1820 9 = 20 [| Fr> En De-En Et-> En QOs-nmt (0 S-NMT+src[] 0 S-NMT-+trg J 1 S-NMT+both"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdSe nore Ur as Memory-to-Output Results 23 11 2310.522 Si 22a 10 9.98 21.5a21 20.85 21i 9.5 | 20.42) 9.18 | 20 = 9 LL 20 [| = Fr>En De-En Et>En.\\n23/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nMemory-to-Output Results\\n\\n23\\nuu\\n2310.522\\nHA\\n21.76\\n22\\n21.82\\n1\\n0g\\n1204\\n'3a21\\n20.85\\n219.5i\\n20.42\\n29.18\\n20\\no_\\n20\\n[|Fr-En\\nDe-En\\nEt->En\\n23/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdSe nore Ur as Memory-to-Output Results 23 11 !\\n2310 5 22.222 21.8 21.76 21.77 10.23 22 | 21.82> 10.04 nm 10 9.98 21.5 a21> 2.85 21 i 9.520.429.18 [] 20 9 = 20 Fr-En De-En Et-> En QOs-nmt (0 S-NMT + src [] 0 S-NMT\\n- + trg J 1 S-NMT + both 23 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "PLC eae eee le Ve MOET telameh (init cdSe nore Ur asMain Results 24 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nMain Results\\n- 23 1\\n- 23\\n- 22.5 m8\\n- 22.5 = 10.6 um\\n- 22\\n- 10.4\\n- 21.5 ma\\n- 21.5, 10.2\\n- 21\\n- 10\\n- [Jean et al., 2017]\\n- [Wang et al., 2017]\\n- 24/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nMain Results\\n\\n23 11 ! 23 !\\n22.5 10.8 22.5 = 10.6 | pe = 22 22 10.4 a K 21.5 = 21.5 | Jean et al., 2017 | Wang et al., 2017 | S-NMT + sre 24/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdSe nore Ur asMain Results\\n\\n23 11 ! 2322.5 10.8 22.5= » | 10:6 1054SP\\n22) 7298 gy21.01 22a 10.421.5 ne 21.5| . | ry | |21 10 [| 21Fr>En De-En Et>En[0\\n\\n[Jean et al., 2017}\\n[Wang et al., 2017}\\n\\n1 S-NMT+src\\n1 S-NMT+both 24/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdSe nore Ur as Example translation 25 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nExample translation\\n\\nSource: qimonda taidab lissaboni strateegia eesmarke.\\n\\nTarget: qimonda meets the objectives of the lisbon strategy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nExample translation\\n\\nSource qimonda taidab lissaboni strateegia eesmarke.\\n\\nS-NMT <UNK> is the objectives of the Lisbon strategy.\\n\\nSrc Mem the millennium development goals are fulfilling the millennium goals of the Lisbon strategy.\\n\\nTrg Mem in writing.\\n- (ro) the Lisbon strategy is fulfilling the objectives of the Lisbon strategy.\\n\\nBoth Mems qimonda fulfills the aims of the Lisbon strategy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nExample translation\\n\\nSource qimonda taidab lissaboni strateegia eesmarke.\\nS-NMT <UNK> is the objectives of the lisbon strategy.\\n\\nSrc Mem the millennium development goals are fulfilling the millennium goals of the lisbon strategy.\\nTrg Mem in writing.\\n- (ro) the lisbon strategy is fulfilling the objectives of the lisbon strategy.\\n- Both Mems qimonda fulfils the aims of the lisbon strategy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nExample translation (contd.)\\n\\nSource: et riigis kehtib endiselt lukashenko diktatuur, mis rikub inim- ning etnilise vahemuse Gigusi.\\n\\nTarget: this country is still under the dictatorship of lukashenko, breaching human rights and the rights of ethnic minorities."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Document Context Neural Machine Translation with Memory Networks\\n\\nExample translation (contd.)\\n\\nSource ... et riigis kehtib endiselt lukashenko diktatuur, mis rikub inim- ning etnilise vähemuse Gigusi.\\n\\nTarget ...\\nthis country is still under the dictatorship of Lukashenko, breaching human rights and the rights of ethnic minorities.\\n\\nS-NMT ... the country still remains in a position of Lukashenko to violate human rights and ethnic minorities.\\n\\n+Src Mem ... the country still applies to the brutal dictatorship of human and ethnic minority rights.\\n\\n+Trg Mem ... the country still keeps the <UNK> dictatorship that violates human rights and ethnic rights.\\n\\n+Both Mems ...\\nthe country still persists in Lukashenko's dictatorship that violates human rights and ethnic minority rights."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdcena teeny Overview Conclusion\\n- 27/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdreenter Conclusion 28 / 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Proposed a model which incorporates the global source and target document contexts."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Pleo nano ca Le Eo MCU Lee mT moa Cn) Cel cdeee ten\\n\\nConclusion\\n\\nProposed a model which incorporates the global source and target document contexts.\\n\\nProposed effective training and decoding methodologies for our model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Document Context\\n\\nNeural Machine Translation with Memory Networks\\n\\nConclusion\\n- Proposed a model which incorporates the global source and target document contexts.\\n- Proposed effective training and decoding methodologies for our model.\\n\\nFuture Work:\\n- Investigate document-context NMT models which incorporate specific discourse-level phenomena."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "PLCeae eee le Ve MOET telameh (init cdeee Overview f@ References\\n- 29/30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "References\\n\\nHardmeier, C. and Federico, M. (2010). Modelling pronominal anaphora in statistical machine translation.\\nInternational Workshop on Spoken Language Translation.\\n\\nGong, Z. and Zhang, M. and Zhou, G. (2011). Cache-based document-level statistical machine translation.\\nProceedings of the Conference on Empirical Methods in Natural Language Processing.\\n\\nGarcia, E. M. and Espajia-Bonet, C. and Marquez, L. (2014).\\nDocument-level machine translation as a re-translation process. Procesamiento del Lenguaje Natural, 53:103-110.\\n\\nJean, S. and Lauly, L. and Firat, O. and Cho, K. (2017). Does Neural Machine Translation Benefit from Larger Context?\\narXiv:1704.05135.\\n\\nWang, L. and Tu, Z. and Way, A. and Liu, Q. (2017). Exploiting Cross-Sentence Context for Neural Machine Translation.\\nProceedings of the Conference on Empirical Methods in Natural Language Processing.\\n\\nBawden, R. and Sennrich, R. and Birch, A. and Haddow, B. (2018).\\nEvaluating Discourse Phenomena in Neural Machine Translation. Proceedings of the NAACL-HLT 2018."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 315,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Adequacy in Neural Machine Translation\\n\\nSource: und wir benutzen dieses Wort mit solcher Verachtung\\n\\nRepetition\\n\\nReference: and we say that word with such contempt.\\n\\nTranslation: and we use this word with such contempt.\\n\\nEin 28-jähriger Koch, der kürzlich nach Pittsburgh\\n\\nSource:\\n- gezogen war, wurde diese Woche im Treppenhaus eines örtlichen Einkaufszentrums tot aufgefunden.\\n\\nA 28-year-old chef who recently moved to\\n\\nDropped words\\n\\nReference: Pittsburgh was found dead in the staircase of a local shopping mall this week.\\n\\nTranslation: Pittsburgh was found dead in the staircase this week."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Previous Work\\n- Conditioning on coverage vectors to track attention history (Mi, 2016; Tu, 2016).\\n- Gating architectures and adaptive attention to control amount of source context (Tu, 2017; Li & Zhu, 2017).\\n- Reconstruction Loss (Tu, 2017).\\n- Coverage penalty during decoding (Wu, 2016)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Main Contributions\\n\\nJ'ai mangé le sandwich\\n1. Fertility-based Neural Machine Translation Model (Bounds on source attention weights)\\n2. Novel attention transform function: Constrained Sparsemax (Enforces these bounds)\\n3. Evaluation Metrics: REP-Score and DROP-Score"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "NMT + Attention Architecture"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Pt = softmax(W [g; ct]) I ate the sandwich = Ha; el e2 63 e4 CtC1 C2 C3 C4 sil [sel Lol [oeat1 ha attn_score: e dot-product (Luong,\\n2015) a a e bilinear function e MLP (Bahdanau,\\n2014) attn_transform: e traditional softmax f q f2 {3 t4 e constrained softmax (Martins & Kreutzer,\\n2017) Fai moaned Je sandwich ° sparsemax (Martins & Astudillo,\\n2016) § * constrained sparsemax (this work)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Attention Transform Functions\\n- Sparsemax: Euclidean projection of z provides sparse probability distributions.\\nsparsemax(z) := argmin |a\\n- z|^2\\n- Constrained Softmax: Returns the distribution closest to softmax whose attention probabilities are bounded by upper bounds u.\\ncsoftmax(z;\\nu) := arg min KL(a || softmax(z)) subject to a < u"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Attention Transform Functions sparse and Constrained?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Constrained Sparsemax provides sparse and bounded probability distributions.\\ncsparsemax(z;\\nu) := argmin ||a\\n- z||\\nThis transformation has two levels of sparsity: over time steps & over attended words at each step.\\nEfficient linear and sublinear time algorithms for forward and backward propagation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Visualization: Attention transform functions\\n- softmax\\n- sparsemax\\n- csoftmax\\n- csparsemax\\n\\nt = O / ve (0.35, 0.13) / e (0.3,\\n0) / ve (0.35, 0.13) / e (0.3,\\n0) (0.4, 0.6,\\n0) (0.3, 0.7,\\n0) t = 7 [x Botte Dee) /X [x (0.44, 0.2) JXt = ? fore (0.55) bodes hve (0.67)*\\n\\ncsparsemax provides sparse and constrained probabilities."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Fertility-based NMI Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Fertility-based NMT\\n- Allocate fertilities J for each source word as attention budgets that exhaust over decoding.\\n- Fertility Predictor: Train bILSTM model supervised by fertilities from fast_align (IBM Model 2)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Fertility-based NMTe Fertilities incorporated as: Qy = csparsemax(z, f\\n- [+-1) [|t-1 otDr-1 -= KI Ore Exhaustion strategy to encourage more attention for words with larger credit remaining: z = 2 + Cur13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Experiments performed on 3 language pairs: De-En (IWSLT 2014), Ro-En (Europarl), Ja-En (KFTT).\\n- Joint BPE with 32K merge operations.\\n- Default hyperparameter settings in OpenNMT-Py.\\n- Baselines: Softmax, + CovPenalty (Wu,\\n2016) and + CovVector (Tu, 2016)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Evaluation Metrics: REP-Score & DROP-Score\\n\\nREP Score:\\n- Penalizes n-gram repetitions in predicted translations.\\n- Normalize by number of words in reference corpus.\\n\\nDROP Score:\\n- Find word alignments from source to reference & source to predicted.\\n- % of source words aligned with some word in reference, but not with any word in predicted translation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "BLEU Scores SL\\n- | ee | a | i ; ; 15 De-En Ja-En Ro-En \" softmax {) softmax + CovPenalty |! softmax + CovVector |) csparsemax 17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Lower is better!\\n\\nREP Scores\\nYO 12.8 ii | 13.2 1 'al i ' I 0.0 i I I = i | I y | | | |\\nDe-En\\nJa-En\\nRo-En\\nsoftmax ©\\nsoftmax+CovPenalty |\\nsoftmax+CovVector !§\\ncsparsemax\\n\\nDROP Scores\\nOI | 1 I 19.2 ! ! 14.4 ! ! 48 | | II | I | Il | I | I | | 0.0 i | I = i I I || I | |\\nDe-En\\nJa-En\\nRo-En"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "das\\n- zist fmoores @& agesetz a |der a Ooletzten a ihundert E a ajahre A = ..\\na iBPSkoRS°SkS OES' SROR O\" \"go \"5 O* 6 ~-~so Ocm Cc w e cosy Ww2 z YV = Vich baal ® csparsemaxwerde [il fn lnun a Eee yields Sparse set ofthema.\\n\\nalignments andregierung nn i avoids repetitions.wahlen an.\\n\\nLu\\n- E Wyoo \"a *>> >od 3Om Dsoftmax csparsemax19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Examples of Translations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "iiberlassen sie das ruhig uns.\\ngive us a silence.\\nso ungefihr, sie wissen schon.\\nlike that, you know.\\nso, you know, you know. like that, you know.\\nwir sehen das dazu, dass phosphor wirklich kritisch ist.\\nwe can see that phosphorus is really critical.\\nwe see that phosphorus is really critical.\\nMore in the paper..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Thank You!\\n\\nCode: www.github.com/Unbabel/Sparse_constrained_attention\\n\\nQuestions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 331,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Parsing by Local Decisions\\n\\nSoNNP J Ne-TM-aTMN\\n\\nThe cat took a nap.\\n\\np(y|x; @) = log p(y|x; @) = log p(¥ | ¥1:t-1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Non-local Consequences\\n\\nLoss-Evaluation Mismatch\\n\\n\"A(y, 9): -F1(y,\\nV)\\n\\nExposure Bias\\n\\nTue yy [1S |-+[(NP | [The] [eat |.\\n\\nParse Prediction ¥ (S\\n- (NP.\\n- (VP\\n- ??\\n\\n[Ranzato et al. 2016; Wiseman and Rush 2016]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Dynamic Oracle Training\\n\\nExplore at training time. Supervise each state with an expert policy.\\n\\nParse [5 |~[(NP]\\n- [The] | eat |~.\\naddresses exposure Prediction y (S (NP (VP The _ue (sample, or greedy) \\ \\ \\ laS(0) | (yz | ) choose Vi to maximize aeLQ) = » og P(VElV1:1-1, X5 0 .\\n, | os: achievable F1 (typically) veifarredieth [Goldberg & Nivre 2012; Ballesteros et al. 2016; inter alia]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Dynamic Oracles Help! Expert Policies / Dynamic Oracles\\n\\nDaume III et al., 2009; Ross et al., 2011; mostly Choi and Palmer, 2011; Goldberg and Nivre, 2012; dependency Chang et al., 2015; Ballesteros et al., 2016; Stern et al.\\n2017 parsing PTB Constituency Parsing F1\\n\\nStatic Dynamic\\nSystem Oracle Oracle\\nCoavoux and Crabbé, 2016 88.6 89.0\\nCross and Huang, 2016 91.0 91.3\\nFernandez-Gonzalez and Gomez-Rodriguez, 2018 91.5 91.7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "What if we don't have a dynamic oracle? Use reinforcement learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Reinforcement Learning Helps! (in other tasks) machine translation\\n- Auli and Gao, 2014\\n- Ranzato et al., 2016\\n- Shen et al., 2016\\n- Xu et al., 2016\\n- Wiseman and Rush, 2016\\n- Edunov et al., 2017\\n\\nssCCG several, machine parsing including translation dependency parsing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Policy Gradient Training\\n\\nMinimize expected sequence-level cost: True\\n\\nParse y Prediction\\n\\nYR(O) = p(x, θ) A(y, θ) V R = p(x; θ) A(y, θ) V log p(H | x; θ)\\n\\nAddresses compute in exposure bias loss the same way (compute by mismatch as for the sampling) (compute F1) true tree\\n\\nWilliams, 1992"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Policy Gradient Training VR(6) = p(IIx;\\n8) AVY,\\n9) V log p(IIx;\\n6) y Input, Xx\\n\\nThe cat took a nap.\\n\\nS S-INV s Ssk candidates, V Po \"AY aN AN¥ & fe x Ix x Ss x Mp\\n\\nThe cat took a nap.\\n\\nThe cat took a nap.\\n\\nThe cat took a nap.\\n\\nThe cat took a nap.\\n\\n-A(y,\\n9) -89 -80 -80 -100 (negative F1) . . . . gradient a Ke Te exefor candidate V log p(W1|x;\\n8) V log p(2|x;\\n0) V log p(y3|x;\\n6) V log p(y|x; @)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Lay Setup"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "La English PTB F1bint93. . . .\\nStatic oracle\\nPolicy gradient\\nDynamic oracle\\n92.5\\n92.5\\n91.5\\n90.5\\n|\\n90\\nSpan-Based\\nTop-Down\\nRNNG-128\\nRNNG-256\\nIn-Order"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Training Efficiency\\n\\nPTB learning curves for the Top-Down parser\\n\\nStatic oracle\\n- dynamic oracle policy gradient\\n\\n89.5  89.5  10  15  20  25  30  35  40  45\\n\\nTraining Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Las French Treebank F184 Static oracle Policy gradient Dynamic oracle iSpan-Based Top-Down RNNG-128 RNNG-256 In-Order"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Lay Chinese Penn Treebank v5.1 F188 Static oracle Policy gradient Dynamic oracle 878685, mil iSpan-Based Top-Down RNNG-128 RNNG-256 In-Order"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusions\\n- Local decisions can have non-local consequences\\n- Loss mismatch\\n- Exposure bias\\n- How to deal with the issues caused by local decisions\\n- Dynamic oracles: efficient, model specific\\n- Policy gradient: slower to train, but general purpose"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Thank you!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "For Comparison: A Novel Oracle for RNN\\n1. Close current constituent if it's a true constituent ...... or it could never be a true constituent.\\n2. Otherwise, open the outermost unopened true constituent at this position.\\n3. Otherwise, shift the next word."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 67,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Y = pare aia lem ae ac ayes Mapping natural language to structured representations Human-friendly -> Computer-friendly all flights from Dallas before 10am Parser(lambda $0 e (and (flight $0) (from $0 Dallas:ci) (< (departure_time $0) 1000:ti))) Example from ATIS (Kwiatkowski et al., 2011)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Neural Semantic Parsing Sequence decoder (Jia and Liang, 2016; Dong and Lapata, 2016; Ling et al., 2016; Iyer et al.,\\n2017)\\n\\nSyntactically-constrained decoder (Dong and Lapata, 2016; Xiao et al., 2016; Alvarez-Melis and Jaakkola, 2017; Yin and Neubig, 2017; Cheng et al., 2017; Krishnamurthy et al., 2017; Rabinovich et al., 2017; Xu et al.,\\n2017)\\n\\nWhat microsoft jobs\\n- _ ntl nnicrocaty: Wn wn yWV, TOSOIT\\n\\nInput Structured Utterance Encoder Decoder Representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "This Work all flights from dallas before 10 am\\n\\nMeaning\\n\\nSketch (lambda #2 (and flight @1 from @2 (< departure time @1 ?)))\\n\\nLow-level Details (e.g., arguments and variable names)\\n\\n(lambda $0 e (and (flight $0) (from $0 dallas:ci) (< (departure_time $0) 1000:ti)))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Meaning Sketche Python code example\\n\\nif length of bits is lesser than integer 3 or second element of bits is not equal to string 'as':\\n\\nif len(NAME) < NUMBER or NAME[NUMBER] != STRING:\\n\\nif len(bits) < 3 or bits[1] != 'as':\\n\\ne SQL example\\n\\nWhat record company did conductor Mikhail Snitko record for after 1996?\\n\\nWHERE > AND =\\n\\nSELECT Record Company WHERE (Year of Recording >\\n1996) AND (Conductor = Mikhail Snitko)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "e Disentangle high-level from low-level semantics\\n\\nModel meaning at different levels of granularity\\n\\ne More compact meaning representation\\n\\nLength: 21.1\\n- 9.2 (on ATIS)\\n\\ne Explicit sharing coarse structure\\n\\nFor examples that have the same basic meaning\\n\\ne Provide global context to fine meaning decoder\\n\\nKnow what the basic meaning of input looks like"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "departure(lambda#2 (and flight@1 (< time@1 2?)) )\\n\\nSk f t T. re i t f f tetchce \"OOOO OOT T tT T T T tT tT it\\n\\n(lambda#2 (and flight@1 (< departure ?)) )_time@1\\n\\nInput\\n- |\\n- Encoding all flights before tid"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Sketch departure (lambda#2 (and flight@1 (< _time@1 2?)))\\nSketch t t f i f iT f f i. tom GEocececean\\n(lambda#2 (and flight@1 (< departure ?))) _time@1\\nInput\\n-\\n- -- Encoding all flights before tid"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "(departure(lambda $0 e (and (flight $0) (< time $0) tid)))\\n\\nSketch-Guided ot ot of ot of ot ot of ot ot of ot ot ot ot ftOutput\\n\\nDecoding $0 e $0) $0) tid\\n\\nSketchEncoding = has s = \"O-\\n\\ndeparture(lambda#2 (and flight@1 (< time@1 2)))\\n\\nSk f f i Te ol t f t if tetchwim +OBOOBBBOOO-2f tT if T tT T tT t T t\\n\\n(lambda#2 (and flight@1 (< departure ?)))_time@1\\n\\nInput\\n- Encoding all flights before tid"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "MethodSketch constrains the decoding output.\\n\\nExample 1: one augment is missing\\nflight @ 1 --> (flight @)\\n\\nExample 2: type information\\nNUMBER\\n- e (a numeric token)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Training and Inference:\\nX: input, a: sketch, y: meaning representation\\nTraining: maximize the log likelihood\\nmax Y\\n- log p(y | a,\\na) + log p(a | a)(2, a,\\ny) ∈ D\\n\\nFine Meaning\\nCoarse Meaning\\n\\nDecoder\\nInference: greedy search\\na' = argmax p(a' |\\nz)\\ny' = argmax p(y' | x, a)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Seana ten es aa ELCe Natural language to logical form (Geo/ATIS)\\n\\nwhat is the population of the state with the largest area?\\n\\n(argmax SO (and (mountain:t SO) (loc:t SO alaska:s)) (elevation:i SO))\\n\\ne Natural language to source code (Django)\\n\\nif length of bits is lesser than integer 3 or second element of bits is not equal to string 'as'\\n\\nif len(bits) < 3 or bits[1] != 'as':\\n\\ne Natural language to SQL (WikiSQL)\\n\\nPianist\\nConductor\\nRecord Company\\nYear of Recording\\nFormat\\n\\nWhat record company did conductor Mikhail Snitko record for after 1996?\\n\\nSELECT Record Company WHERE (Year of Recording >\\n1996) AND (Conductor = Mikhail Snitko)\\n\\n(Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2011; Oda et al., 2015; Zhong et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Natural Language to Logical Form\\npyVariable information \"@\"\\n- (e.g., lambda, Arguments of Partial ?\\n'count, and predicate or argmax) operator information (lambda #2 (and flight @1 from @2 (< departure time @1 ?))) (lambda $0 e (and (flight $0) (from $0 dallas:ci) (< (departure_time $0) 1000:ti)))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Natural Language to Source Code\\n\\nSubstitute tokens with their token types\\n- Except Delimiters (e.g., \"[\", and \":\")\\n- Operators (e.g., \"+\", and \"*\")\\n- Built-in keywords (e.g., \"True\", and \"while\")\\n\\nif NAME[:NUMBER].NAME() == STRING:\\nfs] 4], jower() == http\"https://docs.python.org/3/library/tokenize.html"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Natural Language to SQL Wiki SQL (Zhong et al.,\\n2017)\\n\\nSELECT agg operator agg column\\n\\nWHERE (cond_column cond operator cond value)\\n\\nAND ...\\n\\nSELECT Record Company\\n\\nWHERE (Year of Recording >\\n1996)\\n\\nAND (Conductor = Mikhail Snitko)\\n\\nWHERE >\\n\\nAND ="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Natural Language to SQL\\n\\nDecoding is table-aware\\n\\nHow many presidents are graduated from A?\\n\\nPresident College\\n\\nSELECT COUNT(President) WHERE (College =\\nA)\\n\\nCollege Number of Presidents\\n\\nSELECT Number of Presidents WHERE (College = A)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Natural Language to SQL Table-aware input encoder\\nLSTM units\\nVectors\\n- Attention\\n- college\\n- number of presidents\\nInput Question\\nColumn 1\\nColumn 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Natural Language to SQL\\n\\nSELECT agg operator agg column él Softmax agg operator {empty, COUNT, Classifier MIN, MAX, SUM, AVG}\\n\\nQuestion Column Vector; === a column tT fT tT Of t t i college || number of presidents || Column 1 Column 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Natural Language to SQL WHERE Clause WHERE (cond_column cond_operator cond_value) AND ...\\nae Record Year of What record company did conductor janist | Conductor : Format. ; .\\nCompany | PR Seeheilte Mikhail Snitko record for after 1996? Sketch la | Classification WHERE ff AND &"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Natural Language to SQL\\n\\nWHERE Clause\\n\\nWHERE (cond_column cond_operator cond_value)\\n\\nAND\\n\\n...ae Record Year of What record company did conductor janist\\n\\n| Conductor : Format : s\\n\\n5 So in painy BReverains Mikhail Snitko record for after 1996 ?\\n\\ncond_colf condPointer f Pointer\\n\\nAND\\n\\nSketch-Guided\\n\\nWHERE teDecodingCy e} PaSketchEncoding\\n\\noaSketch zClassification M2\\n\\nWHERE\\n- AND &"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Natural Language to SQL\\n\\nWHERE Clause\\nWHERE (cond_column cond_operator cond_value)\\nAND ...\\n- Record Year of What record company did\\n- conductor | Conductor eee\\n- Format : z 5\\n- Company [ia Mikhail Snitko record for after 1996 ?\\n- Mg --Point to a ees eee eee\\n- cond_colt\\n- cond TRY Tp\\n- Pointer ff\\n- Pointer .\\n- Point to a\\n- Sketch-Guided text span\\n\\nWHERE hn 1, 5 1, oS\\nDecoding C4 Tl ey\\nSketch Encoding 9-4)\\nSketch z s\\nClassification\\n\\nWHERE\\nAND"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Experimental Results\\n\\nCode (Django) 75 74.17 1.6\\nWW 70 69.5\\nZA = 65\\n© 62.3\\nD > O = < 60 55 50\\n\\n(Ling et al.,\\n2016)\\n(Yin and Neubig, One Stage (w/o Coarse 2 Fine\\n2017) sketch)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Experimental Results\\n\\nLogical Form\\n\\n89 88.2 87.1 f gel!\\n87 f 85.9 ow.gs 85.3 O£ 335 Qg 81797775 Geo ATIS mSeq2Seq MSeq2Tree MASN MOneStage mCoarse2Fine Baseline: (Dong and Lapata, 2016; Rabinovich et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Experimental Results\\n\\nNL->SQL (WikiSQL) 80 78.5 59 PD 75 Ooo 70 68 2 65 60 59.4\\na) o O x 55 53.345\\n\\nAug Pointer (Zhong et al., Xu et al.,\\n2017) One Stage (w/o Coarse 2 Fine Network (Zhong\\n2017) sketch) et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Sketch Accuracy 95.49 95.99 90 89.3 88 85.4 85.95 85.2 80 77.4 75 73.26 Geo ATIS Django Wiki SQL mM One Stage m Coarse 2 Fine"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Oracle Meaning Sketch = 93.9 32-190 88.2 87.73 85 83 74.165 Geo ATIS Django Wiki SQL m Coarse 2 Fine m + Oracle Sketch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "The alternative ways of defining meaning sketches\\n\\nDifferent levels of granularity\\n\\nWeakly supervised setting\\n\\nMeaning sketch reduces search space\\n\\nPartial annotation\\n\\nOnly annotate meaning sketches for some examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Thanks! Q&A Code Available: http://nomepages.inf.ed.ac.uk/s1478528"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 318,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\nOverview\\nResearch question\\nTask and general approaches\\nBaseline system\\nProposed modifications\\nResults\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Overview\\n- Research question: Can orthographic (spelling) information enable better word translations in low-resource contexts?\\n- Languages with common ancestors and/or borrowing exhibit increased lexical similarity.\\n- Spelling of words can carry signal for translation.\\n- Low-resource pairs are most in need of additional signal."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Overview\\n- Task and general approach\\n- Bilingual lexicon induction: single-word translations (modern-moderno)\\n- Operate on word embeddings\\n- Haghigi et al. (2008): orthographic features\\n- Mikolov et al. (2013): word2vec, linear mapping\\n- Minimal supervision\\n- horse\\n- caballo (horse)\\n- vaca (cow)\\n- cow\\n- perro (dog)\\n- pig\\n- cerdo (pig)\\n- cat\\n- gato (cat)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Baseline: Artetxe et al. (2017)\\n\\nD=1-a, 2-b, 3-c, 4-x, 5-y\\n\\nStart with dictionary D (inferred from numerals).\\n\\nLearn matrix W minimizing Euclidean distance between target (Z) and mapped source (XW) embeddings of pairs in D.\\n\\nUse nearest neighbors as entries in new dictionary.\\n\\nRepeat until convergence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Baseline: Artetxe et al. (2017)\\n- Problems\\n\\nEnglish Word Baseline's Prediction\\n\\ngleichmaBig (evenly)\\nungleichmaBig\\n\\n[German | Ethiopians | Afrikaner (Africans) | Achiopier | Tealian | autumn | primavera (spring) | autunno | Finnish | Latvians | ukrainalaiset (Ukrainians) | latvalaset\\n\\ne Suffers from clustering problems present in word2vec. Similar distributions > similar embeddings.\\nHints of correct translation present in spelling."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Proposed modifications\\n1. Use normalized edit distance in nearest-neighbor calculation.\\nDuring dictionary induction, distances between similarly-spelled words are reduced.\\n2. Extend embedding vectors with character counts.\\nExtend vectors with scaled counts of letters in both languages' alphabets (scale constant k < 1).\\n\\nA || aba |} 0.123 | 0.456 ||{|\\n\\nWord || ah | co | a | b || aba_ | 0.123 | 0.456 | 2k | 1k |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Quantitative results\\n\\nEnglish Word Translation Accuracy\\n\\n80 Combined === 70\\n\\nEmbedding Extension\\n\\nSmEdit Distance B = 6c\\n\\nArtetxe et al. (2017)\\n\\nSEEsS\\n\\n50 = ® & 4032 302010 oO\\n\\nGerman\\n\\nItalian\\n\\nFinnish\\n\\nTarget Language\\n- Universally outperform baseline\\n- Best when combined; largest contribution from embedding extension\\n- Improvement less pronounced for English-Finnish (linguistic dissimilarity)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Qualitative results\\n\\nEnglish Word Baseline's Prediction\\n\\ngleichmaBig (evenly)\\nungleichmaBig\\n\\n[German | Ethiopians | Afrikaner (Africans) | Äthiopier | (Italian | autumn | primavera (spring) | autunno\\n\\n[Finnish | Latvians | ukrainalaset (Ukrainians) | Tatvialaisete\\n\\nUse orthographic information to disambiguate semantic clusters\\n\\nSignificant gains in adequacy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Conclusione: Orthographic information can improve unsupervised bilingual lexicon induction, especially for language pairs with high lexical similarity.\\nThese techniques can be incorporated into other embedding-based frameworks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Results with Identity\\nEnglish Word Translation Accuracy w/ Identity\\n80 Combined === 70\\nEmbedding Extension SE\\nEdit Distance MEE\\n60 Artetxe et al. (2017)\\nSIE = 50\\nooe 40\\n- 3Zz\\n30\\n20\\n10\\nOo\\nGerman\\nItalian\\nFinnish\\nTarget Language\\nUniversity of Rochester\\nJuly 17, 2018\\n11/10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Proof of optimal \\( W \\V ||v_2|_{we} = \\arg \\min d \\) \\( D_j y ||X_i x W\\n- Z||_{i=1}^{j=1} |v^*| = \\arg \\min ||X_j x W\\n- (DZ) j x|| \\)\\n\\n\\(|v^*| = \\arg \\min )\\n- ||X_j e W||^2 + ||(DZ) i x||^2\\n- 2 X_i x W ((DZ) i\\nx) \" V W' |v^*| |v_x| = \\arg \\min -2 X_i, W ((DZ) i,.)' = \\arg \\max X_i z W ((DZ) i,)\" g_n » ((DZ) i\\nx) \\)\\n\\n\\(\\ner d ((DZ) i\\nx) = \\arg \\max \\text{Tr}(X W Z T M D\") W w\\n\\)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Proof of optimal W, continued\\n\\nW* = arg max Tr(XWZ^T D^T)\\nW = arg max Tr(Z^T D^T M X\\nW)\\nW = arg max Tr(UL V^T\\nW)\\n[U X L V^T = SVD(Z^T M D^T X)|\\nW = arg max Tr(2 V^T W\\nU)\\nW = V U^T"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "[Artebe et al (2017)\\n\\nif Embedding extension | 5033 | 4840 | 29.63\\n\\nEmbedding extension | 5540 | 4713 | 43.5\\n\\nEdit distance | 43-73\\n\\nEat distance | 52.20\\n\\nCombined | 83.53\\n\\nCombined | 55.53"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 131,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Neural Motivation Language exhibits hierarchical structure. The cat that he adopted sleeps.\\nLSTMs work so well without explicit notions of structure."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Number Agreement: Number agreement example within the river valley have/has two attractors (Linzen et al., 2016).\\nNumber agreement is a cognitively motivated probe to distinguish hierarchical theories from purely sequential ones."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Number agreement is sensitive to syntactic structure.\\n\\nNPAGREE/nsubjnmod iocasedet\\n\\nParts of the river valley have/has = Parts of the river valley have/has.\\n\\nNumber agreement reflects the dependency.\\n\\nModels that can capture dependency should do better at number agreement.\\n\\nDespina and Gales’ coast line should also be considered."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Neen Overview\\n\\nRevisit the prior work of Linzen et al.\\n(2016) that argues LSTMs trained on language modeling objectives fail to learn such dependencies.\\n\\nInvestigate whether models that explicitly incorporate syntactic structure can do better, and how syntactic information should be encoded.\\n\\nDemonstrate that how the structure is built affects number agreement generalization."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Meee Number Agreement Dataset Overview\\n\\nTrain aS)| AGREE\\n\\nParts of the river valley have/has\\n\\nSentences = 141,948\\n1,211,080 Tokens\\n3,159,622\\n26,512,851 Number agreement dataset\\n\\nAll intervening nouns must be derived from dependency-parsed the same number Wikipedia corpus © Deepmind Sauk"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Neen Number Agreement Dataset Overview\\n\\nAttractors\\n\\nInstances\\n\\nwf AGREE\\n\\nInstances\\n\\nParts of Sole valley have/has\\n- 1,146,330 94.7% n=1 52,599 4.3%\\n\\nAll intervening nouns must be of the same number\\n\\nn=2 9,380 0.77%\\n\\nn=3 2,051 0.17%\\n\\nThe vast majority of number\\n\\nsequential? n=5 159 0.01%\\n\\n© Deepming"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "First Part: Can LSTMs Learn Number Agreement Well? The model is trained with language modelling.\\nRevisit the same question as Linzen et al.\\n(2016): To what extent are LSTMs able to learn non-local syntax-sensitive dependencies in natural language?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Neen et al. LSTM Number Agreement Error Rates\\n\\nRandom 3 sMajority\\n- Linzen LSTM (H=50)\\n- d=70\\n- ac5\\n- 60== 50\\n- o€ 40@5\\n- 30<=\\n- 20=1\\n- 10Lower is 20 better\\n- n=0\\n- n=1\\n- n=2\\n- n=3\\n- n=4\\n\\nNumber of attractors\\n\\n© DeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Neural Small LSTM Number Agreement Error Rates\\n\\nRandom Majority\\n\\nLinzen LSTM (H=50)\\nOur LSTM (H=50)\\n\\nLower is better\\n\\nn=0\\nn=1\\nn=2\\nn=3\\nn=4\\n\\nNumber of Attractors\\n\\nDeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Neen eee\\n\\nLarger LSTM Number Agreement Error Rates\\n\\nOur LSTM (H=50)\\nOur LSTM (H=150)\\nOur LSTM (H=250)\\nOur LSTM (H=350)\\n\\nCapacity matters for capturing non-local structural dependencies.\\n\\nDespite this, relatively minor perplexity difference (~10%)\\nn=0\\nn=1\\nn=2\\nn=3\\nn=4\\n\\nLower IS Number of Attractors\\n- H=150\\nDeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n-\\nAdhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Neural LSTM Number Agreement Error Rates\\n- Random = Majority = Our LSTM (H=350)\\n==== Pretrained large-scale LM (Jozefowicz et al.,\\n2016)\\n\\nCapacity and size of the training corpus are not the full story.\\n\\nDomain and training settings matter too\\n\\nn=0\\nn=1\\nn=2\\nn=3\\nn=4\\n\\nNumber of Attractors\\n\\nLower is better\\n\\n© DeepMind\\n\\nLSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Meee eeCan Character LSTMs Learn Number Agreement Well? AGREE Parts\\n\\n...river valley have/hasiS ages a he oe Character LSTMs have been used in various tasks, including machine translation, language modelling, and many others.\\n- It is easier to exploit morphological cues.\\n- Model has to resolve dependencies between sequences of tokens.\\n- The sequential dependencies are much longer.\\n\\n© Deepmtind So tue unos Cutalijes Jens Wale ari vous tarpsiStee tien Gla aiei Puikinscrn (aoe ate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Neural Character LSTM Agreement Error Rates\\n- Majority: Our LSTM (H=350)\\n- Melis et al. (2018) char LSTM State-of-the-art character LSTM (Melis et al.,\\n2018) is a model on Hutter Prize, with 27M parameters. Trained, validated, and tested on the same data.\\n\\nNumber of Attractors\\n- Lower is Strong character LSTM model\\n- Consistent with earlier work better performs much worse for (Sennrich,\\n2017) and potential multiple attractor cases avenue for improvement."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Neen eee\\n\\nFirst Part Quick Recape\\n\\nLSTM language models are able to learn number agreement to a much larger extent than suggested by earlier work.\\n- Independently confirmed by Gulordava et al. (2018).\\n- We further identify model capacity as one of the reasons for the discrepancy.\\n- Model tuning is important.\\n\\nA strong character LSTM language model performs much worse for number agreement with multiple attractors."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Two Ways of Modelling Sentences\\n\\nP(x) = NP VP\\n\\nP(x,\\ny) = NP ( ) Po: the dog ate the bone"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Three Concrete Alternatives for Modeling Sentences:\\n- Sequential LSTMs without Syntax (MEE,\\n2016)\\n- Sequential LSTMs with Syntax (Choe and Charniak,\\n2016)\\n- Deep and See"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Meee eeEvidence of Headedness in the Composition Function\\n\\nThe hungry cat = 0.1v, ct 0.15v, at 0.75v3(xX)\\n\\nKuncoro et al. (2017) found evidence of syntactic headedness in RNNGs (Dyer et al., 2016).\\n\\nThe discovery of syntactic heads would be useful for number agreement.\\n\\nInspection of composed representation through the attention weights."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experimental Settings\\n\\nAll models are trained, validated, and tested on the same dataset.\\nOn the training split, the syntactic models are trained using predicted phrase-structure trees from the Stanford parser.\\nAt test time, we run the incremental beam search (Stern et al.,\\n2017) procedure up to the main verb for both verb forms, and take the highest-scoring tree.\\n\\nThe most probable tree might potentially be different for the correct/incorrect verbs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Meee eeExperimental Findingsee\\n\\nOur LSTM (H=350)\\n\\nmemeSeq. Syntactic LSTM exe.RNNG20£ 18\\n\\n50% error rate reductions for n=4 and wi=-12\\nn=5=10ov2 8a0oOaos\\n\\nPerformanceEs\\n\\n3 differences are significant (p < 0.05, n=0 n=1 n=2 n=3 n=4 n=5 g (p)\\n\\nLower IS Number of Attractors better\\n\\n© DeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Perplexity for syntactic models\\n\\nJo Dev. ppl. are obtained with importance sampling (Dyer et al.,\\n2016)\\n- LSTM LM 72.6\\n- Seq. Syntactic LSTM 79.2\\n- RNNGs 77.9\\n\\nLSTM LM has the best perplexity despite worse number agreement performance.\\n\\n© Deepmind"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Further Remarks: Confound in the Dataset\\n\\nAGREE\\n\\nLSTM language models largely succeed in number agreement.\\nIn around 80% of cases with multiple attractors, the agreement controller coincides with the first noun.\\n\\nKey question: How do LSTMs succeed in this task?\\n- Identifying the syntactic structure\\n- Memorising the first noun\\n\\nKuncoro et al., LZHM 2018\\n© deepmina"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "MeeeControl Condition Experiments for LSTM LMDISAGREE\\n- Control condition breaks the AGREE correlation between the first The scientist thinks that parts of the river valley have/has 0UNn and agreement controller acral condition Control Condition LSTM LM Error Rates 45 35 30 25 Confounded by first nouns 5 20 15 Much less likely to affect human experiments.\\n- of\\n- p\\n- 3\\n- gattr=0\\n- attr=1\\n- attr=2\\n- attr=3\\n- attr=4\\n- attr=5 Lower\\n- IS\\n- Number of Attractors\\n- better Standard setting TM\\n- Control setting DeepMind\\n\\nLSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Meee Control Condition Experiments for RNNG\\n\\nControl Condition RNNG Error Rates\\n\\nControl for cues that 35 artificial learners can exploit in a cognitive task.\\n\\nAdversarial evaluation can better distinguish between models with correct number of attractors and those that overfit to surface cues.\\nLower is same y-axis scale better as LSTM LM.\\n\\nDeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Related Work\\n\\nAugmenting our models with a hierarchical inductive bias is not the only way to achieve better number agreement.\\nAnother alternative is to make relevant past information more salient, such as through memory architectures or attention mechanisms.\\nYogatama et al. (2018) found that both attention mechanisms and memory architectures outperform standard LSTMs.\\nThey found that a model with a stack-structured memory performs best, also demonstrating that a hierarchical, nested inductive bias is important for capturing syntactic dependencies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Second Part Quick Recap\\n\\nRNNGs considerably outperform LSTM language models and sequential syntactic LSTM for number agreement with multiple attractors.\\n- Syntactic annotation alone has little impact on number agreement accuracy.\\n- RNNGs' success is due to the hierarchical inductive bias.\\n- The RNNGs' performance is a new state of the art on this dataset (previous best from Yogatama et al.\\n(2018) for n=5 is 88.0% vs 91.8%).\\n- Perplexity is only loosely correlated with number agreement.\\n- Independently confirm the finding of Tran et al. (2018)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Different Tree Traversals\\n\\nRNNGs operate according to a top-down, left-to-right traversal.\\nHere we propose two alternative tree construction orders for RNNGs: left-corner and bottom-up traversals.\\n\\nx: the flowers in the vase are [blooming] -- KS 7\\n\\nTop-down | (NP (NP the flowers) (PP in (NP the vase)))\\n\\nBottom-up\\n\\nLeft-corner\\n\\nDeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Quick Illustration of the Differences:\\n\\nTop-Down\\nTOP-DOWN\\n\\nDeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Mee Quick Illustration of the Differences: Top-Down TOP-DOWN Peeping FL ESRI STR Uae"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Meee eeQuick Illustration of the Differences: Left-Corner (LEFT-CORNER)\\n\\nThe Juna cat\\n- DeepMind LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modelling Structure Makes Them Better\\n- Adhiguna Kuncoro, Chris Dyer, John Hale, Dani Yogatama, Stephen Clark, and Phil Blunsom (ACL 2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Why Does The Build Order Matter?\\n\\nMachine learning\\n\\nThe three different strategies yield different intermediate states during the generation process and impose different biases on the learner.\\n\\nCognitive\\n\\nEarlier work in parsing has characterised the strategies' plausibility in human sentence processing (Johnson-Laird, 1983; Pulman, 1986; Resnik, 1992).\\nWe evaluate these strategies as models of generation (Manning and Carpenter,\\n1997) in terms of number agreement accuracy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Meee eeBottom-up Traversal x, y: (S (NP the hungry cat) (VP meows))\\n\\nTopmost stack element\\n\\nfoAction: GEN(The) © Deepmind Be oe ee Ohiie ves ci bale ani toucoaeeicte veh glade enemas Gel aie"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Bottom-Up Traversal x, y: (S (NP the hungry cat) (VP meows))\\n\\nhungry cat\\n- Topmost stack element\\n\\nAction: GEN(hungry), GEN(cat)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Bottom-Up Traversal, y: (S (NP the hungry cat) (VP meows))(NP The hungry cat)\\n\\nTopmost stack element: A\\n- the tuna cat\\n\\nAction: REDUCE-3-NP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Bottom-Up Traversal\\n\\nx, y: (S (NP the hungry cat) (VP meows))\\n\\nTopmost stack element (NP the hungry cat) (VP meows)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Bottom-Up Traversal: After REDUCE-1-VP, y: (S (NP the hungry cat) (VP meows)) (NP the hungry cat) (VP meows) Topmost stack element in na LA Action: REDUCE-1-VP"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Bottom-Up Parameterisation of Constituent Extent\\nComposed: constituent type\\n\\nReduce further?\\nAction Softmax\\n\\nPP\\nNP*\\nvp\\n- No\\n- Yes\\n\\nReduce GEN\\nStack LSTM\\nStick-breaking Construction\\n\\nThe hungry cat\\n© Deepmina"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Summary Statistics\\n\\nAvg. Stack Depth    Dev    ppl.\\nP(x,\\ny)\\nTop-Down           12.29    94.9\\nLeft-Corner        11.45    95.9\\nBottom-Up          7.41     96.5\\n\\nNear-identical perplexity for Bottom-up has the shortest each variant stack depth.\\n© Despina So"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Different Traversal Number Agreement Error Rates\\n\\nOur LSTM (H=350) 58 9.6 14.1. Top-down performs best for n=3 and n=4.\\n\\nTop-Down 5.5 72.8 8.9\\nLeft-Corner 5.4 8.2 9.9\\nBottom-Up 5.7\\n\\nSignificant (p < 0.05) Lower is better"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Part Three Recap and Outlook\\n\\nWe proposed two new RNNG variants with different tree construction orders: left-corner and bottom-up RNNGs.\\nTop-down construction still performs best in number agreement.\\nIt is the most anticipatory (Marslen-Wilson, 1973; Tanenhaus et al., 1995).\\nWe can apply the three strategies to parsing and as linking hypotheses to human brain signals during comprehension (Hale et al., 2018)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Meee eeConclusione\\n\\nLSTM language models with enough capacity can learn number agreement well, while a strong character LSTM performs much worse.\\n\\nExplicitly modelling the syntactic structure with RNNGs that have a hierarchical inductive bias leads to much better number agreement.\\n\\nSyntactic annotation alone does not help if the model is still sequential.\\n\\nTop-down construction order outperforms left-corner and bottom-up variants in difficult number agreement cases.\\n\\nPerplexity does not completely correlate with number agreement."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "The end & thank you"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 73,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "MOTIVATION\\n\\nMost high-performance data-driven models rely on a large amount of labeled training data.\\nHowever, a model trained on one language usually performs poorly on another language.\\n\\nExtend existing services to more languages:\\n- Collect, select, and pre-process data\\n- Compile guidelines for new languages\\n- Train annotators to qualify for annotation tasks\\n- Annotate data\\n- Adjudicate annotations and assess the annotation quality and inter-annotator agreement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "MOTIVATION\\n\\nMost high-performance data-driven models rely on a large amount of labeled training data.\\nHowever, a model trained on one language usually performs poorly on another language.\\n\\nExtend existing services to more languages:\\n- Collect, select, and pre-process data\\n- Compile guidelines for new languages\\n- Train annotators to qualify for annotation tasks\\n\\nAnnotate data:\\n- Adjudicate annotations and assess inter-annotator agreement\\n\\n7,097 languages are spoken today.\\n\\nRapid and low-cost development of capabilities for low-resource languages.\\n\\nDisaster response and recovery"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "TRANSFER LEARNING & MULTI-TASK LEARNING\\n\\nLeverage existing data of related languages and tasks and transfer knowledge to our target task.\\n\\nThe Tasman Sea lies between Australia and New Zealand.\\nl'Australie est séparée de l'Asie par les mers d'Arafura et de Timor et de la Nouvelle-Zélande par la mer de Tasman.\\n\\nMulti-task Learning (MTL) is an effective solution for knowledge transfer across tasks.\\n\\nIn the context of neural network architectures, we usually perform MTL by sharing parameters across models.\\n\\nTask A Data Parameter Sharing: When optimizing model A, we update and hence.\\nIn this way, we can partially train model B as.\\n\\nModel B\\n\\nTask B Data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "SEQUENCE LABELING\\n\\nTo illustrate our idea, we take sequence labeling as a case study.\\n\\nIn the NLP context, the goal of sequence labeling is to assign a categorical label (e.g., Part-of-speech tag) to each token in a sentence.\\nIt underlies a range of fundamental NLP tasks, including POS Tagging, Name Tagging, and Chunking.\\n\\nPOS TAGGING\\n\\nKoalas are largely sedentary and sleep up to 20 hours a day.\\n\\nNNS VBP RB JJ CC VB IN TO\\n\\nNAME TAGGING\\n\\nB-PER E-PER GPE GPE Itamar Rabinovich, who as Israel's ambassador to Washington conducted unfruitful negotiations with Syria, told Israel Radio it looked like Damascus wanted to talk rather than fight.\\n\\nPER ORG GPE\\n\\nB-, I-, E-, S-: beginning of a mention, inside of a mention, the end of a mention and a single-token mention\\n\\nO: not part of any mention\\n\\nAlthough we only focus on sequence labeling in this work, our architecture can be adapted for many NLP tasks with slight modification."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "BASE MODEL: LSTM-CRF (CHIU AND NICHOLS,\\n2016)\\n\\nThe CRF models the dependencies between labels.\\n1) Linear Layer\\nThe linear layer projects hidden states to label space.\\n\\nThe Bidirectional LSTM (long-short term memory) processes the input sentence from both directions, encoding each token and its context into a vector (hidden states).\\n\\nInput (x1) he (x2) was (x3) born (x4) Edgar (x5) Poe\\n\\nSentence\\nEach token in the given sentence is represented as the combination of its word embedding and character feature vector.\\n\\nFeatures\\nWord Embedding\\nCharacter Embedding"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "PREVIOUS TRANSFER MODELS FOR SEQUENCE LABELING\\n\\nSource Task | Target Task [Label Mapping]\\nLabel Mapping\\n\\nSource Task | Target Task\\nSource Task is\\n\\nShared\\n\\nWord\\n\\nWord\\n\\nEmbedding\\nShared Char\\n\\nCross-domain transfer\\nCross-lingual Transfer sets\\n\\nYang et al. (2017) proposed three transfer learning architectures for different use cases.\\n\\nAbove figures are adapted from (Yang et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK ARCHITECTURE\\n\\nPart-of-speech Tagging i Name Tagging\\n\\nDET NOUN ADP PROPN PROPN ADJ NOUN ADP PRON NOUN | © B-PERE-PER O S-ORG SPERO © O\\n\\nFinal tags\\n\\nShared CRF\\n\\nShared CRF\\n- Shared across languages\\n\\nUnary tag scores\\n\\nShared across languages\\n\\nSpanish Shared Linear\\n\\nEnglish Linear\\n\\nSpanish Shared Linear\\n\\nEnglish Linear\\n\\nLinear Layer\\n\\nLayer\\n\\nLayer\\n\\nLinear Layer\\n\\nLayer\\n\\nLayer\\n\\nLanguage-specific\\n\\n\"4. Encode each word and its context into a vector\\n\\nCross-lingual Cross-task Shared Bidirectional LSTM\\n\\nEmbeddings\\n\\nHead:\\n\\nSpanish Word Embeddings\\n\\nSpanish Sentence\\n\\nEnglish Sentence\\n\\nCross-lingual Cross-task Shared CharCNN:\\n\\nEmbeddings\\n\\nOur model combines multi-lingual transfer and multi-task transfer is able to transfer knowledge from multiple sources"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK MODEL\\n\\nPart-of-speech Tagging Name Tagging\\n\\nRET.NOUN.ADP-PROPN.PROPN ADJ NOUN ADP PRON NOUN | _ © B-PERE-PER O S-OR SPERO O O O\\n\\nFinal tags; if ft ff ft fF) ft ttt t):\\n\\nShared CRF | peo ere at\\n- Shared across languages\\n\\nUnary tag scores\\n\\nShared across languages Spanish | Shared Linear | English Linear\\n\\nSpanish Shared Line English Linear\\n\\nLinear Layer\\n\\nLayer |\\n\\nLanguage-specific\\n\\nLSTM-CRF\\n\\nEncode each word and its context into a vector\\n\\nEmbeddings\\n\\nSpanish Sentence\\n\\nEnglish Sentence\\n\\nCross-lingual Transfer\\n\\nCross-task Transfer\\n\\nPOS Tagging > Name Tagging"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK MODEL\\n\\nEmbeddings: Spanish Sentence English Sentence\\n\\nThe bidirectional LSTM, character embeddings and character-level networks serve as the basis of the architecture.\\nThis level of parameter sharing aims to provide universal word representation and feature extraction capability for all tasks and languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK MODEL\\n- CROSS-LINGUAL TRANSFER\\n\\nPart of speech Tagging\\n- DET\\n- NOUN\\n- ADP\\n- PROPN\\n- ADJ\\n- NOUN\\n- ADP\\n- PRONOUN\\n\\nFinal tags:\\n- Shared across languages:\\n- Spanish\\n- Shared\\n\\nLinear Layer\\nLanguage-specific\\nEncode each word and its context into a vector\\n\\nEmbeddings:\\n- Spanish Sentence\\n- English Sentence\\n\\nFor the same task, most components are shared between languages.\\nAlthough our architecture does not require aligned cross-lingual word embeddings, we also evaluate it with aligned embeddings generated using MUSE's unsupervised model (Conneau et al.\\n2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK MODEL\\n- LINEAR LAYER\\n\\nPart-of-speech Tagging\\net DET NOUN ADP PROPN PROPN ADJ NOUN ADP PRON NOUN | English: improvement, development, payment, ...\\n| Shared CRF | French: vraiment, complètement, immédiatement pay\\n\\nWe combine the output of the shared linear layer and the output of the Spanish Shared Linear.\\n\\nEnglish Linear Layer\\nCross-lingual Cross-task | where and are optimized during training.\\n\\nis the LSTM hidden states.\\n\\nAS is a square matrix, and have the same dimension.\\n\\nSpanish Sentence\\nEnglish Sentence\\n\\nWe add a language-specific linear layer to allow the model to behave differently towards some features for different languages."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "OUR MODEL: MULTI-LINGUAL MULTI-TASK MODEL\\n- CROSS-TASK TRANSFER\\n\\nPart-of-speech Tagging } Name Tagging | DET NOUN ADP PROPN PROPN\\n\\nFinal tags Shared CR Shared CF\\n\\nShared across languages\\n\\nUnary tag scores\\n\\nShared across languages\\n\\nSpanish Shared Linguistic Features\\n\\nLinear Layer\\n\\nLanguage-specific\\n\\nEncode each word and its context into a vector\\n\\nCross-task Shared Bidirectional LSTM\\n\\nWord: can\\n\\nEmbeddings\\n\\nSpanish Word\\n\\nEmbeddings\\n\\nSpanish Sentence\\n\\nShared CharCNN\\n\\nLinear layers and CRF layers are not shared between different tasks.\\n\\nTasks of the same language use the same embedding matrix: mutually enhance word representations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "ALTERNATING TRAINING To optimize multiple tasks within one model, we adopt the alternating training approach in (Luong et al., 2016).\\n\\nAt each training step, we sample a task with probability: CeP(Q) = Sa Elye.\\n\\nIn our experiments, instead of tuning mixing rate, we estimate it by: n = Hen N; where is the task coefficient, is the language coefficient, and is the number of training examples.\\n(or) takes the value 1 if the task (or language) of is the same as that of the target task; otherwise it takes the value 0.1."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "EXPERIMENTS\\n- DATA SETS\\n- Name Tagging\\n- English: CoNLL 2003\\n- Spanish and Dutch: CoNLL 2002\\n- Russian: LDC2016E95 (Russian Representative Language Pack)\\n- Chechen: TAC KBP 2017\\n- 10-Language EDL Pilot Evaluation Source Corpus\\n- Part-of-speech Tagging: CoNLL 2017 (Universal Dependencies)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "EXPERIMENTS\\n- SETUP\\n- 50-dimensional pre-trained word embeddings\\n- English, Spanish and Dutch: Wikipedia\\n- Russian: LDC2016E95\\n- Chechen: TAC KBP 2017 10-Language EDL Pilot Evaluation Source Corpus\\n- Cross-lingual word embedding: we aligned mono-lingual pre-trained word embeddings with MUSE (https://github.com/facebookresearch/MUSE).\\n- 50-dimensional randomly initialized character embeddings\\n- Optimization: SGD with momentum, gradient clipping (threshold: 5.0) and exponential learning rate decay.\\n- LSTM Dropout Rate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "EXPERIMENTS\\n- COMPARISON OF DIFFERENT MODELS\\n\\nTarget task: Dutch Name Tagging\\n\\nAuxiliary task: Dutch POS Tagging, English Name Tagging, English POS Tagging\\n\\n18.2%\\n- 50.0% F-score Gain\\n\\n70\\n\\n11.9%\\n- 24.9% F-score Gain\\n\\n60\\n\\nBaseline\\n\\n+ 20\\n\\nCross-task\\n\\nCross-lingual\\n\\nOur Model\\n\\nOur Model*"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "EXPERIMENTS\\n- COMPARISON OF DIFFERENT MODELS\\n\\nTarget task: Spanish Name Tagging\\n\\nAuxiliary task: Spanish POS Tagging, English Name Tagging, English POS Tagging\\n\\n13.5%\\n- 50.5% F-score Gain\\n\\n80\\n\\na\\n\\n11.6%\\n- 22.6% F-score Gain\\n-\\n\\nBaseline\\n\\nCross-task = Cross-lingual\\n\\nOur Model\\n\\n0 10 20 30 40 50 100 200\\n\\n#Spanish Name Tagging Training Sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "EXPERIMENTS\\n- COMPARISON OF DIFFERENT MODELS\\n\\nTarget task: Chechen Name Tagging\\n\\nAuxiliary task: Russian POS Tagging + Name Tagging or English POS Tagging + Name Tagging\\n\\nBaseline 15.8%\\n- 25.4% F-score Gain = Cross-lingual 440\\n\\nOur Model 43%\\n- 15.9% F Gain\\n\\nOur Model + Mixed Raw Data\\n\\nOur Model (Auxiliary language: English)\\n\\nAll training data:\\n\\nBaseline: 78.9%\\n\\nOur Model: 82.3%\\n\\n10 20 30 40 50 100 200\\n\\n# Chechen Name Tagging Training Sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "EXPERIMENTS\\n- COMPARISON WITH STATE-OF-THE-ART MODELS\\n\\nDutch\\n- Glilick et al. (2016) 82.84\\n- Lample et al. (2016) 81.74\\n- Yang et al. (2017) 85.19\\n- Baseline 85.14\\n- Cross-task 85.69\\n- Cross-lingual 85.71\\n- Our Model 86.55\\n\\nSpanish\\n- Glilick et al. (2016) 82.95\\n- Lample et al. (2016) 85.75\\n- Yang et al. (2017) 85.77\\n- Baseline 85.44\\n- Cross-task 85.37\\n- Cross-lingual 85.02\\n- Our Model 85.88\\n\\nWe also compared our model with state-of-the-art models with all training data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "EXPERIMENTS\\n- COMPARISON WITH STATE-OF-THE-ART MODELS\\n\\n#1 [DUTCH]: If a Palestinian State is, however, the first thing the Palestinians will do.\\n\\n[B] Als er een Palestijnse staat komt, is dat echter het eerste wat de Palestijnen zullen doen.\\n\\n[A] Als er een Palestijnse staat komt, is dat echter het eerste wat de Palestijnen zullen doen.\\n\\nOur Model\\n\\n#2 [DUTCH]: That also frustrates the Muscovites, who still live in the proud capital of Russia but cannot look at the soaps that the stupid farmers can see on the outside.\\n\\n[B] Ook dat frustreert de Moskovieten, die toch in de fiere hoofdstad van Rusland wonen maar niet naar de soaps kunnen kijken die de domme boeren op de buiten wel kunnen zien.\\n\\n[A] Ook dat frustreert de Moskovieten, die toch in de fiere hoofdstad van Rusland wonen maar niet naar de soaps kunnen kijken die de domme boeren op de buiten wel kunnen zien.\\n\\n#3 [DUTCH]: And the PMS centers are merging with the centers for school supervision, the MSTs.\\n\\n[B] En smelten de PMS-centra samen met de centra voor schooltoezicht, de MST's.\\n\\n[A] En smelten de PMS-centra samen met de centra voor schooltoezicht, de MST's.\\n\\n#4 [SPANISH]: The trade union section of CC.OO.\\nin the Department of Justice has today denounced more attacks of students to educators in centers dependent on this department.\\n\\n[B] La sección sindical de CC.OO.\\nen el Departamento de Justicia ha denunciado hoy más agresiones de alumnos a educadores en centros dependientes de esta conselleria.\\n\\n[A] La sección sindical de CC.OO.\\nen el Departamento de Justicia ha denunciado hoy más agresiones de alumnos a educadores en centros dependientes de esta conselleria.\\n\\n#5 [SPANISH]: ...\\nand the Single Trade Union Confederation of Peasant Workers of Bolivia, agreed upon when the state of siege was ended last month.\\n\\n[B] ...\\ny la Confederación Sindical Única de Trabajadores Campesinos de Bolivia, pactadas cuando se dio fin al estado de sitio, el mes pasado.\\n\\n[A] ...\\ny la Confederación Sindical Única de Trabajadores Campesinos de Bolivia, pactadas cuando se dio fin al estado de sitio, el mes pasado."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "EXPERIMENTS\\n- CROSS-TASK TRANSFER VS CROSS-LINGUAL TRANSFER [DUTCH]\\n\\nIngeborg Marx is her name, a formidable\\n\\nWith 100 Dutch training sentences: heavy weight to high above her head!\\n\\nThe baseline model misses the name\\n\\nZag ik zelfs onlangs niet dat een lief, mooi \"Ingeborg Marx\" vrouwtje, Ingeborg Marx is haar naam, een formidabel zwaar gewicht tot hoog boven haar hoofd stak!\\n\\nThe cross-task transfer model finds the name\\n\\nRUbBeesais aainang!\\n\\n[CROSS-TASK]\\n\\nZag ik zelfs onlangs niet dat een lief,\\n\\nThe cross-lingual transfer model correctly identifies the whole name.\\n\\nZag ik zelfs onlangs niet dat een lief, mooi vrouwtje, [B-PER Ingeborg] [S-PER Marx] is haar naam, een formidabel zwaar gewicht tot hoog boven haar hoofd stak!\\n\\n[CROSS-LINGUAL]\\n\\nZag ik zelfs onlangs niet dat een lief, mooi vrouwtje, [B-PER Ingeborg] [E-PER Marx] is haar naam, een formidabel zwaar gewicht tot hoog boven haar hoofd stak!\\n\\nThe task-specific knowledge that B-PER > S-PER is an invalid transition will not be learned in the POS Tagging model.\\n\\nThe cross-lingual transfer model transfers such knowledge through the shared CRF layer."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "EXPERIMENTS\\n- ABLATION STUDIES\\n\\nModel for ttc fc\\n\\nBasic 2.06 20.03 47.98 51.52 77.63\\n\\n+C 1.69 24.22 48.53 56.26 83.38\\n\\n+CL 9.62 25.97 49.54 56.29 83.37\\n\\n+CLS 3.21 25.43 50.67 56.34 84.02\\n\\n+CLSH 7.70 30.48 53.73 58.09 84.68\\n\\n+CLSHD 12.12 35.82 57.33 63.27 86.00\\n\\nC: Character embedding; L: Shared LSTM; S: Language-specific; H: Highway Networks; D: Dropout\\n\\n* Generally, all components improve the performance.\\n\\n* Sharing the LSTM layer slightly hurts the performance in the \"high-resource\" setting.\\n\\n* Language-specific Layer can impair the performance in extreme low-resource settings because this layer is trained only on the target task data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "EXPERIMENTS\\n- EFFECT OF THE AMOUNT OF AUXILIARY TASK DATA\\n- 200 Training Sentences\\n- 50 Training Sentences\\n- 10 Training Sentences\\n\\nDoes our model heavily rely on the amount of auxiliary task data?\\n- The performance goes up when we increase the sample rate from 0 to 0.2 for auxiliary task data.\\n- However, we do not observe substantial improvement when we further increase the sample rate.\\n\\nUsing only 1% auxiliary data, our model already obtains 3.7%-9.7% absolute F-score gains."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "REFERENCES\\n\\nJason P. C. Chiu and Eric Nichols.\\n2016. Named entity recognition with bidirectional LSTM-CNNs. TACL, 4:357-370.\\n\\nAlexis Conneau, Guillaume Lample, Marc'Aurelio Ranzato, Ludovic Denoyer, and Herve Jégou.\\n2017. \"Word translation without parallel data.\" arXiv preprint arXiv:1710.04087.\\n\\nDan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag Subramanya.\\n2016. Multilingual language processing from bytes. In NAACL HLT.\\n\\nGuillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer.\\n2016. Neural architectures for named entity recognition. In NAACL HLT.\\n\\nZhilin Yang, Ruslan Salakhutdinov, and William W. Cohen.\\n2017. Transfer learning for sequence tagging with hierarchical recurrent networks. In ICLR."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Thank you @ A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling YING LIN, SHENGQI YANG, VESELIN STOYANOV, HENG Jl"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 92,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Background\\n- Sarcasm: \"a form of verbal irony that is intended to express contempt or ridicule\" (The Free Dictionary) commonly manifests on social communities (e.g.\\nTwitter, Reddit).\\nPrior work considered sarcasm to be a contrast between a positive and negative sentiment (Riloff et al., 2013).\\n\\n\"I love to be ignored!\"\\n\\n\"Perfect movie for people who can't fall asleep.\"\\n\\nScope of this work: sarcasm detection based on document's content and commonsense knowledge but not external knowledge, or user's profile and context.\\n\\n\"I love to solve math problems every day.\"\\n\\n\"Cool. It took me 10 hours to fly from Sydney to Melbourne.\"\\n\\nConfidential slide in A*STAR PR"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation\\n- State-of-the-art sarcasm detection systems mainly rely on deep and sequential neural networks (Ghosh and Veale, 2016; Zhang et al., 2016):\\n- Compositional encoders (GRU, LSTM) are often employed, with the input document being parsed one word at a time.\\n- No explicit interaction between word pairs hampers ability to explicitly model contrast, incongruity or juxtaposition of situations.\\n- Difficult to capture long-range dependencies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Proposed approach\\n- Our idea: modeling contrast in order to reason with sarcasm either between positive-negative sentiments or between literal-figurative scenarios.\\n\\nHow?\\nLooking in-between: propose a multi-dimensional intra-attention recurrent network to capture both word-word relationship and long-range dependency.\\n\\n\"I absolutely love to be ignored!\"\\n\\n\"Perfect movie for people who can't fall asleep.\"\\n\\nUNIVERSITY Confidential\\n- A*STAR GR,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "aArchitecture Intra-Attentive = Compositional Representation\\n\\n7 x Representation co LSTM\\n- Encoder\\n\\na'sey, t &\\n- single-dimensional intra-attention:\\n\\nSig = Wa((wi sw;]) + m -divenet\\n\\nintra-attention' voy:\\n\\nas hl Sig = Wp(ReLU (Wa ([wi; wy]) + bq) + bp2\\n\\nintra-attention weight vector = softmax(max s)Tian.\\n\\ni:nie ' va =\\nD) wiei é Desmb, DS, PDR\\n\\nNANYANG TECHNOLOGICAL\\n\\nBy, SINGAPORE\\n\\nA*STAR\\n\\nabsolutely love to be ignored"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Experiments Dataset\\n\\nTrain    Dev   Test   Avg\\nTweets (Ptacek et al.)      44017  5521  5467  18\\nTweets (Riloff et al.)      1369   195   390   14\\nReddit (/r/movies)         5895   655   1638\\nReddit (/r/technology)     16146  1793  4571  11\\nDebates IAC-V1             3716   464   466   54\\nDebates IAC-V2             1549   193   193   64\\n\\nTECHNOLOGICAL UNIVERSITY\\nConfidential\\n- A*STAR"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Experimental results\\n\\nTweets (Ptacek et al.,\\n2014)\\nTweets (Riloff et al.,\\n2013)\\n\\nModel\\nP\\nR\\nFl\\nAcc\\nP\\nR\\nFl\\nAcc\\n\\nNBOW\\n80.02\\n79.06\\n79.43\\n80.39\\n71.28\\n62.37\\n64.13\\n79.23\\n\\nVanilla CNN\\n82.13\\n79.67\\n80.39\\n81.65\\n71.04\\n67.13\\n68.55\\n79.48\\n\\nVanilla LSTM\\n84.62\\n83.21\\n83.67\\n84.50\\n67.33\\n67.20\\n67.27\\n76.27\\n\\nAttention LSTM\\n84.16\\n85.10\\n83.67\\n84.40\\n68.78\\n68.63\\n68.71\\n77.69\\n\\nGRNN (Zhang et al.)\\n84.06\\n83.02\\n83.43\\n84.20\\n66.32\\n64.74\\n65.40\\n76.41\\n\\nCNN-LSTM (Ghosh and Veale)\\n84.06\\n83.45\\n83.74\\n84.39\\n69.76\\n66.62\\n67.81\\n78.72\\n\\nSIARN (this paper)\\n85.02\\n84.27\\n84.59\\n85.24\\n73.82\\n73.26\\n73.24\\n82.31\\n\\nMIARN (this paper)\\n86.13\\n85.79\\n86.00\\n86.47\\n73.34\\n68.34\\n70.10\\n80.77\\n\\nNANYANG TECHNOLOGICAL UNIVERSITY\\nSINGAPORE\\nConfidential\\nA*STAR\\n7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Experimental results\\n\\nReddit (/r/movies)             Reddit (/r/technology)\\n\\nModel                      P       R       F1      Acc\\nNBOW                  67.33  66.56  66.82  67.52\\nVanilla CNN        65.97  65.97  65.97  66.24\\nVanilla LSTM      67.57  67.67  67.32  67.34\\nAttention LSTM   68.11  67.87  67.94  68.37\\nGRNN (Zhang et al.)  66.16  66.16  66.16  66.42\\nCNN-LSTM (Ghosh and Veale)  68.27  67.87  67.95  68.50\\nSIARN (this paper)  69.59  69.48  69.52  69.84\\nMIARN (this paper)  69.68  69.37  69.54  69.90\\n\\nied NANYANG\\nPE TECHNOLOGICAL/\\nUNIVERSITY OF SINGAPORE\\n\\nConfidential\\nA*STAR"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Experimental results\\n\\nDebates (I[AC-V1)\\nDebates (I[AC-V2)\\n\\nModel          P      R      F1     Acc\\nNBOW          57.17  57.03  57.00  57.51\\nVanilla CNN   58.21  58.00  57.95  58.55\\nVanilla LSTM  54.87  54.89  54.84  54.92\\nAttention LSTM 58.98  57.93  57.23  59.07\\nGRNN (Zhang et al.) 56.21  56.21  55.96  55.96\\nCNN-LSTM (Ghosh and Veale)  55.50  54.60  53.31  55.96\\nSIARN (this paper)  63.94  63.45  62.52  62.69\\nMIARN (this paper)  63.88  63.71  63.18  63.21\\n\\nNANYANG TECHNOLOGICAL UNIVERSITY SINGAPORE\\nConfidential A*STAR"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Visualization of attention weights\\n\\nSentence\\n\\nMIARN I totally being !\\nATT-LSTM | I totally love being ignored\\nATT-RAW | I being ignored = aentcne\\nPe 2R\\n\\nConfidential A*STAR 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Conclusion\\n- We proposed a new neural network architecture for sarcasm detection that incorporates a multi-dimensional intra-attention component that learns an intra-attentive representation of the sentence, enabling it to detect contrastive sentiment, situations, and incongruity.\\n- Outperforms strong state-of-the-art baselines such as GRNN and CNN-LSTM-DNN over six public benchmarks.\\n- Able to learn highly interpretable attention weights, paving the way for more explainable neural sarcasm detection methods."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "References\\n\\n[1] Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Ruihong Huang.\\n2013. Sarcasm as contrast between a positive sentiment and negative situation. In proceedings of EMNLP,\\n2013.\\n\\n[2] Meishan Zhang, Yue Zhang, and Guohong Fu.\\n2016. Tweet sarcasm detection using deep neural network. In proceedings of COLING,\\n2016.\\n\\n[3] Aniruddha Ghosh and Tony Veale.\\n2016. Fracking sarcasm using neural network. In proceedings of NAACL, 2016."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 167,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Semantic Parsing\\n\\nWhat is the capital of the largest US state?\\n\\nCapital Of.argmax (Type.State n LocatediIn.US, Population) : Sacramento\\n\\nIntroduction » Semantic parser » Abstract examples ® Results ® Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Training with Full Supervision\\n\\nTraining examples:\\nCapital of Axompee Rctstate\\nLocated in U.S., Population:\\nIntroduction 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Training with Weak Supervision\\n\\nTraining examples: X.y: Sacramento\\n\\nIntroduction\\n\\nSemantic parser\\n\\nAbstract examples\\n\\nResults\\n\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Problems with Weak Supervision\\nExponential search space\\n3 + 3 * 15 XX1 Xx5 + 30ji x2\\n- 2 x4 + 60 / 3 XK\\nIntroduction\\nSemantic parser\\nAbstract examples\\nResults\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Problems with Weak Supervision\\n\\nSpurious Programs (Pasupat and Liang, 2016; Guu et al.,\\n2017)\\n\\nCorrect program: 2*2\\n\\nIntroduction\\nSemantic parser\\nAbstract examples\\nResults\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "CNLVR (Suhr et al.,\\n2017)\\n\\nThere is a small yellow item not touching any wall.\\n\\nTrue\\n\\nIntroduction\\n\\nSemantic parser\\n\\nAbstract examples\\n\\nResults\\n\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Semantic Parsing\\n\\nThere is a blue square exist (filter (ALL ITEMS, Ax.IsBlue(x) n IsSquare(x)))\\n\\nKB: |= «i-fie \"Binary! --=- True 50% spurious\\n\\nIntroduction » Semantic parser >» Abstract examples > Results ® Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Insight\\n\\nThere is one black circle not touching the\\n\\nfilter(ALL_ITEMS, Ax.IsTouching(x)) > GreaterEqual(3, (filter(ALL_ITEMS, Ax.IsBlue(x) n IsTriangle(x) n IsTouchingWall(x))) > GreaterEqual(1, (filter(ALL_ITEMS, Ax.IsBlue(x) n IsTriangle(x) n IsTouchingWall(x))) > LessEqual(3, (filter(ALL_ITEMS, Ax.IsYellow(x) n IsRectangle(x) n IsTouchingWall(x)))\\n\\nIntroduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Contributions\\n\\nThere is a yellow circle exist (filter (ALL ITEMS, Ax.IsYellow(x) AIsCircle(x)))\\n\\nThere is a C\\n- COLOR C\\n- SHAPE exist (filter (ALL ITEMS, Ax.IsC-COLOR(x) AISC-SHAPE(x)))\\n\\nData augmentation\\n\\nAbstract cache helps search tackles spuriousness\\n\\nCNLVR improvement: 67.8 > 82.5\\n\\nIntroduction: 2eSU 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Semantic Parsing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Logical Program: exist (filter (ALL BOXES, Ax.ge(3,count (filter (x, Ay.IsBlue(y))))))\\n\\nFunction Variable VariableSet() > Bool\\n\\nSet(Item)\\n\\nItemConstantSet(Set(Item))\\n\\naeset()\\n\\nInt Set()\\n\\nBoolFunc() > Set()\\n\\nSemantic parser"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Model Exist (Filter (ALL_ITEMS, Ax.And(IsYellow(x), IsTriangle(x))))\\n\\nExist (Filter (ALL_ITEMS, Ax.IsYellow(x)))\\n\\nfEncoder\\n- pean | _, (Fil ( | _ ad. (llow(x) i le(x)))))\\n\\nxDecoder | S€are | a | T > Training maximizes log-likelihood of correct programs > + discriminative re-ranker > Semantic parser"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Abstract Examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "There is a yellow circle.\\n\\nThere is a blue square.\\n\\nexist (filter (ALL_ITEMS, Ax.IsYellow(x) AIsCircle(x)))\\n\\nexist (filter (ALL_ITEMS, Ax.IsBlue(x) AIsRectangle(x))\\n\\nIUtterance | Program Cluster\\n\\n#\"yellow\" IsYellow | C-Color\\n\\n\"big\" IsBig C-Size\\n\\n\"square\" IsSquare C-Shape\\n\\n\"exactly\" EqualiInt C-QuantMod\\n\\n\"top\" Side.Top C-Location\\n\\n\"above\" GetAbove C-SpaceRel\\n\\nTotal: 25\\n\\nThere is a C --COLOR C-SHAPE\\n\\nexist (filter (ALL_ITEMS, Ax.IsC-COLOR(x) AISC-SHAPE(x)))\\n\\nIntroduction semantic parser ® Abstract examples > Results ® Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Analysis 3163 CNLVR sentences\\n- There is...........\\n- One of the.......\\n- There are........\\n- Exactly that.\\n- ~1300 abstract sentences.\\n- In two of..........\\n- There is...\\n- There is...........\\n- There are............\\n- There are........\\n- There is...........\\n- There is...........\\n- There is abstraction\\n- There are...\\n- One of the.......\\n- C-Num C-Shape...\\n- There are........\\n- There is........\\n- There is..........\\n- C-Num towers.....\\n- Two towers.....\\n- Another last.........\\n- There are........\\n- There is...........\\n- One circle.......\\n- There is...........\\n- Last one...........\\n\\n~150 abstract sentences cover 50% of CNLVR.\\n\\nIntroduction\\n- Semantic parser\\n- Abstract examples\\nResults\\n- Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Abstraction\\nData augmentation\\nAbstract cache\\nIntroduction\\nSemantic parser\\nAbstract examples\\nResults\\nConclusions 17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Data Augmentation\\n\\nThere is a yellow circle.\\n\\nThere is a blue rectangle exist(filter(ALL_ITEMS, Ax.|sBlue(x) AlsSquare(x))).\\n\\nThere is a yellow triangle exist(filter(ALL_ITEMS, Ax./s Yellow(x) AlsTriangle(x))).\\n\\nThere is a black circle; exist(filter(ALL_ITEMS, Ax.!sBlack(x) A!sCircle(x))).\\n\\nThere is a C\\n- COLOR C\\n- SHAPE exist(filter(ALL_ITEMS, Ax.IsC-COLOR(x) AISC-SHAPE(x))).\\n\\nIntroduction\\n- Semantic parser\\n- Abstract examples\\n- Results\\n- Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Training Procedure\\n100 Abstract examples (abs. sent., abs. prog.)\\n6000 Instantiated examples\\n===> Supervised model (sentence, program)\\nSupervised training deinitialization\\n3163 CNLVR training examples\\nWeakly-supervised model (sentence, answer)\\n= y supervised training\\n\\nIntroduction\\n® Semantic parser\\n® Abstract examples\\n> Results\\n® Conclusions 19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "decoding y\"There is a yellow triangle\" W Beam:\\n=0\\nt=1\\nt=2\\nt=3\\nt=4\\nt=5\\n\\nExist Filter ALL BOXES Ax. And Count Filter\\nExist Filter ALL ITEMS Ax. And IsYellow\\n\\nIsYellow abstraction. GreaterThan 1\\nCount Filter ALL BOXES Ax. Equal Equal 2\\n\\nCount Filter ALL BOXES Ax. Equal\\nExist Filter ALL ITEMS Ax. And IsYellow\\nIsTriangle \"There is a C-Color C-Shape\" GreaterEqual 1\\n\\ne@ Count Filter ALL ITEMS Ax. And retrieval GreaterEqual 1\\n\\nCount Filter ALL ITEMS Ax. And CACHE\\n\\nExist (Filter (ALL_ITEMS, Ax. And (IsC-COLOR (x), IsC-SHAPE (x))))\\n\\n95%---- GreaterEqual (1, count (Filter (ALL_ITEMS, Ax. And (IsC-COLOR (x), IsC-SHAPE(x))))\\n\\n90% Sassa\\nExist (Filter (ALL_ITEMS, Ax. IsCOLOR (x))\\n\\n30% hss =|> Abstract examples 20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Reward TyingFs\\n\\nThere is a small yellow item not touching any wall\\n\\n50% Spurious\\n\\nIntroduction\\n\\nSemantic parser\\n\\nAbstract examples\\n\\nResults\\n\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Reward Tying:\\n\\nThere is a small yellow item\\n\\nThere is a small yellow item\\n\\nThere is a small yellow item not touching any wall.\\n\\nTrue 6.25% spurious:\\n- Exist(Filter(ALL_ITEMS, And(And(IsYellow(x), IsSmall(x)), Not(IsTouchingWall(x, Side.Any)))))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Models B, Majority label (True)\\n\"Selling\" (Suhr et al.,\\n2017)\\nMax Entropy classifier on extracted features\\nSupervised trained model (+Re-ranker)\\nWeakly supervised trained model (+Re-ranker)\\n\\nIntroduction\\nSemantic parser\\nAbstract\\nExamples\\nResults\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "IB Test-P Accuracy\\nJ Test-P Consistency\\n81.7\\n76.6\\n67.7\\n66.9\\n65.6\\n0.1\\n56.2\\n51.8\\n38.3\\n\\nMajority\\nMaxEnt\\nSup.\\nSup. + Rerank\\nW. Sup.\\nW. Sup. + Rerank\\n\\nIntroduction\\nSemantic parser\\nAbstract examples\\nResults\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Ablations\\n\\nNo documentation\\n\\nract weakly supervised parser\\n\\nIntroduction\\n\\nSemantic parser\\n\\nAbstract examples\\n\\nResults\\n\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Data augmentation addition\\n\\n85.777.271.467.458.2 56.1 I Dev Accuracy I Dev Consistency A1.27.1\\n- Abstraction\\n- Data augment.\\n- Beam cache W. Sup.\\n- Rerank NZ Cache addition\\n- NUI\\n- Introduction\\n- Semantic parser\\n- Abstract examples\\n- Results\\n- Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusions\\n\\nClosed domains and abstraction facilitate information sharing.\\n\\nSimilar ideas in: Dong and Lapata (2018) and Zhang et al. (2017).\\n\\nAutomation would be useful.\\n\\nIntroduction » Semantic parser » Abstract examples » Results » Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "https://github.com/udiNaveh/nlvr_tau_nlp_final_proj"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 327,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Background: discourse dependency structure & treebanks\\n- Main work: details about SciDTB\\n- Annotation framework\\n- Corpus construction\\n- Statistical analysis\\n- SciDTB as evaluation benchmark\\n- Conclusion & summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Discourse Dependency Structure & Treebanks\\n\\nExample text: [Syntactic parsing is useful in NLP.], [We present a parsing algorithm,] [which improves classical transition-based approach.]\\n\\nROOT Discourse dependency tree: peungranni th aera [Li. 2014; Yoshida. 2014]\\n\\nAdvantage: Co €1 C2 63 flexible, simple, support non-projection (ROOT node)\\n\\nDiscourse dependency treebanks:\\n- Conversion based dependency treebanks from RST or SDRT representations [Li. 2014; Stede. 2016]\\n- Limitations: conversion errors and not support non-projection\\n- Build a dependency treebank from scratch\\n- Scientific abstracts: short with strong logics"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Annotation Framework: Discourse Segmentation\\n\\nDiscourse segmentation: Segment abstracts into elementary discourse units (EDUs)\\n\\nGuidelines:\\n- Generally treats clauses as EDUs [Polanyi, 1988; Mann and Thompson, 1988]\\n- Subjective and some objective clauses are not segmented [Carlson and Marcu, 2001]\\n\\nExample 1: [The challenge of copying mechanism in Seq2Seq is that new machinery is needed], [to decide when to perform the operation.]\\n- Strong discourse cues always start a new EDU\\n\\nExample 2: [Despite bilingual embedding's success,], [the contextual information], [which is important to translation quality,], [was ignored in previous work.]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Annotation Framework: Obtain Tree Structure\\n\\nA tree is composed of relations:\\n- the EDU with essential information\\n- the EDU with supportive content\\n- r: relation type (17 coarse-grained and 26 fine-grained types)\\n- Each EDU has one and only one head\\n- One EDU is dominated by ROOT node\\n- Polynary relations joint process step\\n- Multi-coordination One-dominates-many"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Annotation Example in SciDTB\\n\\nThere is rich knowledge encoded in online web data.\\nFor example, entity tags in Wikipedia data define some word boundaries.\\n\\nIn this paper, we adopt partial-label learning with conditional random fields to make use of this knowledge for semi-supervised Chinese word segmentation.\\nThe basic idea of partial-label learning is to optimize a cost function that marginalizes the probability mass in the constrained space that encodes this knowledge.\\n\\nBy integrating some domain adaptation techniques, such as EasyAdapt, our result reaches an F-measure of 95.98% on the CTB-6 corpus.\\n\\nAbstract from http://www.aclweb.org/anthology/6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Corpus Construction\\n\\nAnnotator Recruitment:\\n- 5 annotators were selected after test annotation\\n\\nEDU Segmentation:\\n- Semi-automatic: pre-trained SPADE [Soricut, 2003] + Manual proofreading\\n\\nTree Annotation:\\n- The annotation lasted 6 months\\n- 63% abstracts were annotated more than twice\\n- An online tool was developed for annotating and visualizing DT trees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Onli |nline Annotation Tools\\n\\nWe present a series of algorithms with theoretical guarantees for learning accurate ensembles of several structured prediction rules for which no prior knowledge is assumed.\\n\\nThis includes a number of randomized and deterministic algorithms devised by converting on-line learning algorithms to batch ones, and a boosting-style algorithm applicable in the context of structured prediction with a large number of labels.\\n\\nWe also report the results of extensive experiments with these algorithms.\\n\\nWebsite: http://123.56.88.210/demo/depannotate/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Reliability: Annotation Consistency\\n\\nThe consistency of tree annotation is analyzed by 3 metrics:\\n- Unlabeled accuracy score: structural consistency\\n- Labeled accuracy score: overall consistency\\n- Cohen's Kappa: consistency on relation label conditioned on same structure\\n\\nAnnotators | Doe. | UAS | LAS | Kappa score\\n\\nAnnotator 1 & 2 93 0.811 0.644 0.763\\n\\nAnnotator 1 & 3 147 0.800 0.628 0.761\\n\\nAnnotator 1 & 4 42 0.772 0.609 0.767\\n\\nAnnotator 3 & 4 46 0.806 0.639 0.772\\n\\nAnnotator 4 & 5 44 0.753 0.550 0.699"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Annotation Scale- SciDTB is comparable with PDTB and RST-DT considering size of units and relations\\n- much larger than existing domain-specific discourse treebanks.\\n- corpus | Hoe. | Doe. (unique) |\\n- #Textunit | #Relation | Source | Annotation form.\\n\\nSciDTB 1355 798 18978 18978 = Scientific abstracts\\n\\nDependency trees\\n\\nRST-DT 438 385 24828 23611 Wall Street Journal RST trees\\n\\nPDTB v2.0 2159 2159 38994 40600 Wall Street Journal Relation pairs\\n\\nBioDRB 24 24 5097 5859 Biomedical articles Relation pairs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Structural Characteristics\\n- Dependency distance\\n- Most relations (61.6%) occur between neighboring EDUs\\n- The distance of 8.8% relations is greater than 5\\n- Non-projection: 3% of the whole corpus"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "SciDTB as Benchmark\\n- We make SciDTB as a benchmark for evaluating discourse dependency parsers.\\n\\nData partition: 492/154/152 abstracts for train/dev/test set.\\n\\n3 baselines are implemented:\\n- Vanilla transition based parser\\n- Two-stage transition based parser, a simpler version of [Wang, 2017]\\n- Graph based parser\\n\\nVanilla transition: 0.730 0.557 0.702 0.535\\nTwo-stage transition: 0.730 0.577 0.702 0.545\\nGraph-based: 0.577 0.455 0.576 0.425\\nHuman: 0.806 0.627 0.802 0.622"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Conclusions\\n\\nSummary:\\n- We propose a discourse dependency treebank with following features:\\n* constructed from scratch\\n* Scientific abstracts\\n* comparable with existing treebanks in size\\n- We further make SciDTB as a benchmark\\n\\nFuture work:\\n- Consider longer scientific articles\\n- Develop effective parsers on SciDTB"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Contact: yangan@pku.edu.cn\\n\\nSciDTB is available: https://github.com/PKU-TANGENT/SciDTB"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 101,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "HEASRMASGER SRAREALOSSy Key Laboratory of Network Data Science & Technology, CAS\\n\\nBackground\\n-\\n- Dialog Task-Oriented Dialog\\n- Chit-Chat Dialog\\n- Personal assistant, helps people\\n- No specific goal, attempts to complete specific tasks\\n- Produce natural responses\\n- Combination of rules and statistical components\\n- Using variants of seq2seq model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "PHA SiM Sade S SRAB LSSY Key Laboratory of Network Data Science & Technology, CAS\\n\\nBackground\\n- Neural Model\\n\\nBeoe } iiieii seater\"© utterance-response:\\n- TA-Seq2Seq relationship le anal Haan'* e.g., the response \"Must anes _ © pre-defined a set of topics -' support!\\nCheer!\" is used from an external corpus' for 1216 different input utterances.\\n- Performance MARM =r Seq2Seq framework anh Lb cen\\n- treat all the utterance-response pairs uniformly,\\n- introduce latent responding: employ a single model to learn the mapping a factors f° model mule' between utterance and response\\n- lack of interpretation favor such general responses with high frequency."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "(S) PRES Ra S SRA RS, / Key Laboratory of Network Data Science & Technology, CAS\\nHow to capture different utterance-response relationships?\\n\\nConversation context\\nTopic information\\nKeyword\\nCoherence\\nScenarios heuristics\\n\\nOur motivation comes from\\nHuman Conversation Process"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "(S) PEA Shi Sees S SIRESoS, Key Laboratory of Network Data Science & Technology, CA\\n\\nHuman Conversation Process\\n\\nDo you know a good eating place for Australian special food?\\n\\ngeneral response: I don't know a good place.\\n\\nspecific response: Good Australian eating places include steak, seafood, cake, etc. What do you want to choose?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "PEA Sim auER S SRA LS, Key Laboratory of Network Data Science & Technology, CAS\\n\\nKey Idea\\n- Introduce an explicit specificity control variable s to represent the response purpose.\\n- s summarizes many latent factors into one variable.\\n- s has explicit meaning on specificity.\\n- s actively controls the generation of the response."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "PEA Sim auER S SRA LSSy Key Laboratory of Network Data Science & Technology, CAS\\n\\nModel Architecture\\n- The specificity control variable s is introduced into the Seq2Seq model.\\n- Single model -> multiple model\\n- different <utterance, response>, different s, different models.\\n- Word representation.\\n- Semantic representation: relates to the semantic meaning.\\n- Usage representation: relates to the usage preference."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Key Laboratory of Network Data Science & Technology, CAS Model\\n- Encoder Bi-RNN: modeling the utterance from both forward and backward directions {h;,..., hy} thr, AT}Bh, = [hy hp_t41]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "PEA Shi Sees S SIRESSy Key Laboratory of Network Data Science & Technology, CAS Model\\n- Decoder predicts target word based on a mixture of two probabilities: the semantic-based and specificity-based generation probability (PV) = Bom Oe) + vPs(Ve).\\nSemantic-based probability decides what to say next given the input P(\"John\") = uC John!) + Hs *)o6eepu(e =\\nw) = Ww\" (WH ny, + WS, ep + By) [SO Pee [oe eee4 \\ fa] Specificity® if Control Variable hidden state semantic representation\\n\\nGemantio Representation\\nUsage Representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "PHA SiM Sade SRAB LSSy Key Laboratory of Network Data Science & Technology, CAS\\n\\nModel\\n- Decoder\\n\\nSemantic-based & Specificity-based Generation\\n\\nPC*Sohn\")= Py(\"John\") + Ps(\"Fohn\") > specificity-based probability decides how specific we should reply.\\n\\nSpecificity Control Variable @ Gaussian Kernel layer\\n\\nThe specificity control variable interacts with the usage representation of words through the layer.\\nLet the word usage representation regress to the variable through certain mapping functions (sigmoid).\\n\\ns = 2 exp(- (¥s(U,w) ~ s))\\n\\nPst Tro p it @ specificity control variable s € [0,1]\\n\\n(U,w) = o(w? (U-Wy + by))\\n\\n0 denotes the most general response\\n\\nvariance | denotes the most specific response usage representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "CPE bel BURR A SR SLI, Key Laboratory of Network Data Science & Technology, CAS\\n\\nModel Training\\n\\n* Objective function\\n- log likelihood L = Σ log P(Y|X,s)\\n\\n(X,Y) ∈ D\\n- Training data: triples (X,Y,s)\\n\\n* s is not directly available in the raw conversation corpus.\\n\\nHow to obtain s to learn our model?\\n\\nWe propose to acquire distant labels for s."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "PHA Shem Sates SSA ALS, Key Laboratory of Network Data Science & Technology, CAS\\n\\nDistant Supervision @ Normalized Inverse Response Frequency (NIRF)\\n\\nA response is more general if it corresponds to more input utterances.\\nThe Inverse Response Frequency (IRF) in a conversation corpus:\\n\\nIRFy = log(1 + |R|)/fy\\n\\nIRFy\\n- minyrep (IRFy)\\n\\n@ Normalized Inverse Word Frequency (NIWF)\\n\\nA response is more specific if it contains more specific words.\\nThe maximum of the Inverse Word Frequency (IWF) of all the words in a response:\\n\\nIWFy = log(1 + |R|)/fy\\n\\nIWFy = maxycy(IWF,)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "| PERS bea SURE scaSEY | Key Laboratory of Network Data Science & Technology, CAS\\n\\nSpecificity Controlled Response Generation\\n- Given a new input utterance, we can generate responses at different specificity levels by varying the control variable s.\\n- Different s, different models, different responses\\nM@ s = 1: the most informative response\\nM@ s ∈ [0,1]: more dynamic, enrich the styles in the response\\nM@ s = 0: the most general response\\n- General response\\n- Specific response"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "PEA Sim auER S SRA LSSy Key Laboratory of Network Data Science & Technology, CAS\\n\\nExperiments\\n- Dataset: Short Text Conversation (STC) dataset released in NTCIR-13, a large repository of post-comment pairs from the Sina Weibo.\\n\\n3.8 million post-comment pairs.\\n- Jieba Chinese word segmenter\\n- Utterance-response pairs: 3,788,571\\n- Utterance vocabulary #w: 120,930\\n- Response vocabulary #w: 524,791\\n- Utterance max #w: 38\\n- Utterance avg #w: 13\\n- Response max #w: 74\\n- Response avg #w: 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "PHA SiM Sade S SRAB LSHey Key Laboratory of Network Data Science & Technology, CAS\\n\\nModels\\n- BLEU-1: 5258/0.064\\n- BLEU-2: 16195/0.269\\nAverage: 15.109 7.023 0.578 0.380\\n\\ns=0.8\\n- 5337/0.065\\n- 16105/0.271\\nAverage: 15.112 7.003 0.578 0.381\\n\\ns=0.5\\n- 5318/0.065\\n- 16183/0.269\\nAverage: 15.054 7.001 0.578 0.380\\n\\ns=0.2\\n- 5323/0.065\\n- 16087/0.270\\nAverage: 15.168 7.032 0.580 0.380\\n\\ns=0\\n- 5397/0.066\\n- 16319/0.271\\nAverage: 15.093 7.011 0.577 0.380\\n\\ng=1\\n- 11588/0.116\\n- 27144/0.347\\nAverage: 12.392 5.869 0.554 0.353\\n\\ns=0.8\\n- 6006/0.051\\n- 17843/0.257\\nAverage: 11.492 5.703 0.553 0.350\\n\\nSC-Seq2Seqnwr\\ns=0.5\\n- 2835/0.050\\n- 9537/0.235\\nAverage: 16.122 7.674 0.609 0.399\\n\\ns=0.2\\n- 1534/0.048\\n- 5117/0.218\\nAverage: 8.313 4.058 0.542 0.335\\n\\ns=0\\n- 1038/0.046\\n- 3154/0.211\\nAverage: 4417 3.283 0.549 0.334\\n\\nTable 2: Model analysis of our SC-Seq2Seq under the automatic evaluation.\\n1. We vary the control variable s by setting it to five different values (i.e., 0, 0.2, 0.5, 0.8,\\n1)\\n2. NIWF (word-based) is a good distant label for the response specificity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "HEASRMASGER SRAREALOSEY\\nKey Laboratory of Network Data Science & Technology, CAS\\n\\nExperiments\\n- Model Analysis\\n\\nModels\\nBLEU-1     BLEU-2     Average\\nExtremas=1\\n5258/0.064  16195/0.269  15.109  7.023  0.578  0.380\\ns=0.8\\n5337/0.065  16105/0.271  15.112  7.003  0.578  0.381\\nSC-Seq2Seq\\ns=0.5\\n5318/0.065  16183/0.269  15.054  7.001  0.578  0.380\\ns=0.2\\n5323/0.065  16087/0.270  15.168  7.032  0.580  0.380\\ns=0\\n5397/0.066  16319/0.271  15.093  7.011  0.577  0.380\\ns=1\\n11588/0.116  27144/0.347  12.392  5.869  0.554  0.353\\n\\nspecifics=0.8\\n6006/0.051  17843/0.257  11.492  5.703  0.553  0.350\\nSC-Seq2Seq\\ns=0.5\\n2835/0.050  9537/0.235  16.122  7.674  0.609  0.399\\ns=0.2\\n1534/0.048  5117/0.218  8.313  4.058  0.542  0.335\\ns=0\\n1038/0.046  3154/0.211  4.417  3.283  0.549  0.334\\n\\nTable 2: Model analysis of our SC-Seq2Seq under the automatic evaluation.\\n1. Varying the variable s from 0 to 1, the generated responses turn from general to specific.\\n2. Different s -> different models -> different focus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Key Laboratory of Network Data Science & Technology, CAS\\n\\nModels distinct-1 distinct-2\\nBLEU-1 BLEU-2 Average Extrema\\n\\nSeq2Seq-att\\n5048/0.060\\n15976/0.168\\n15.062\\n6.964\\n0.575\\n0.376\\n\\nMMILI-bidi\\n5074/0.082\\n12162/0.287\\n15.772\\n1.215\\n0.586\\n0.381\\n\\nMARM\\n2566/0.096\\n3294/0.312\\n7.321\\n3.714\\n0.512\\n0.336\\n\\ntSeq2Seq+IDF\\n4722/0.052\\n15384/0.229\\n14.423\\n6.743\\n0.572\\n0.369\\n\\naSC-Seq2Seq\\n11588/0.116\\n27144/0.347\\n12.392\\n5.869\\n0.554\\n0.353\\n\\nSC-Seq2Seq\\n2835/0.050\\n9537/0.235\\n16.122\\n7.674\\n0.609\\n0.399\\n\\nTable 3: Comparisons between our SC-Seq2Seq and the baselines under the automatic evaluation.\\nWhen s = 1, our SC-Seq2Seq model can achieve the best specificity performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "() PEE Sie Ra S SRS IS\\n\\nKey Laboratory of Network Data Science & Technology, CAS\\n\\nModels distinct-1 distinct-2\\n- BLEU-1 BLEU-2 Average Extrema\\n\\nSeq2Seq-att 5048/0.060 15976/0.168 | 15.062 6964 0575 0.376\\n\\nMML-bidi 5074/0.082 12162/0.287 | 15.772 7.215 0586 0.381\\n\\nMARM 2566/0.096 3294/0.312 | 7.321 3.714 0.512 0.336\\n\\ntSeq2Seq+IDF 472210.052 15384/0.229 | 14.423 6743 0572 0369 |\\n\\nWfSC-Seq2Seq uwrs-, | 11588/0.116 27144/0.347 | 12.392 5.869 0.554 0.353\\n\\nSC-Seq2Seq iwrs-os | 2835/0.050 9537/0.235 | 16.122 7.674 0.609 0.399\\n\\nTable 3: Comparisons between our SC-Seq2Seq and the baselines under the automatic evaluation.\\n1. Our SC-Seq2Seq model can best fit the ground truth data.\\n2. There are diverse responses in real data in terms of specificity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "(PES Sich Sates S Sih SIS, Key Laboratory of Network Data Science & Technology, CAS\\n\\nkappaSeq2Seq-att\\n29.32%\\n25.27%\\n45.41%\\n0.448\\n\\nMML-bidi\\n30.40%\\n24.85%\\n44.75%\\n0.471\\n\\nMARM\\n20.11%\\n27.96%\\n51.93%\\n0.404\\n\\nSeq2Seq+IDF\\n28.81%\\n23.87%\\n47.33%\\n0.418\\n\\ntSC-Seq2Seq\\n95\\n20.62%\\n40.16%\\n39.22%\\n0.451\\n\\nTable 4: Results on the human evaluation.\\n1.\\nSC-Seq2Seq generates the most informative responses and interesting, and the least general responses than all the baseline models.\\n2. The largest kappa value is achieved by SC-Seq2Seq."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "(S) PEA Shi Sees S SIRESSy Key Laboratory of Network Data Science & Technology, CAS\\n\\nUtterance: {H4! HAH T | MEA SERB A 3604? Oh! Got caught! Why\\n\\nUtterance: R12 3#- AIX AEM ARE, LCR BRF-BKK. Iis Tang Wei so beautiful?\\nwill keep such a sweet samoyed, and let it accompany my children to grow up.\\n\\nSeq2Seq-att: #8 BH CKH ! I really like her!\\n\\nSeq2Seq-att: XV EI\" EN4? Is it a samoyed?\\n\\nMML-bidi: 32» FH UL ! So beautiful. I really like her!\\n\\nMMI-bidi: FF] 2 H5\"2E\\n- What a lovely samoyed.\\n\\nMARM: #2452 GME © I don't like Tang Wei.\\n\\nMARM: #4] 2h] « So lovely.\\n\\nSeq2Seq+IDF: KEM, BEM I really like her, I like.\\n\\nSeq2Seq+IDF: 4A) 2 W494\\n- What a lovely dog.\\n\\ns=1: REVEL, WAITERS! Ireally like her eye make-up, and\\n\\ns=1: B® AEWS- F HT, AAGFF-H! The samoyed is so lovely, and I really want to keep one!\\n\\ns=0.8: SUA, WeAvHRHS 7B 335 |! Ireally like her, and her eyes are so bright!\\n\\ns=0.8: (EEWFATH, UARHGIG\\n- The samoyed is so lovely, and I really want to pinch it.\\n\\ns=0.5: Ft ABHOR, WEP WC! I really think she is very beautiful, and I really\\n\\ns=0.5: HARA %y, KF Hl VA IAFy © What a lovely dog, what a lovely dog.\\n\\ns=0.2: Bet EMER SE ! I think she is very beautiful.\\n\\ns=0.2: {FATZ! LATA! So lovely, so lovely!\\n\\ns=0: FJ» Yes.\\n\\ns=0: FT Z! So lovely!\\n\\nThe responses generated by the four baselines are often quite general and short."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "PHASE State Sikh aslie =<- Key Laboratory of Network Data Science & Technology, CAS\\n\\nUtterance: SH! BAHL T | MEA SERB A 3404?\\nOh! Got caught!\\n\\nUtterance: R12 3#- AIX AEM ARE, LCR BAF BKK.\\nIs Tang Wei so beautiful? I will keep such a sweet samoyed, and let it accompany my children to grow up.\\n\\nSeq2Seq-att: #4 = WAH! I really like her!\\n\\nSeq2Seq-att: XA} IY? Is it a samoyed?\\n\\nMML-bidi:\\n32. FH UL ! So beautiful. I really like her!\\n\\nMMI-bidi: {F772\\n(\"HE\\n- What a lovely samoyed.\\n\\nMARM: #2482 GME © I don't like Tang Wei.\\nMARM: 45] ZI» So lovely.\\n\\nSeq2Seq+IDF: KHUN, BEM I really like her, I like.\\n\\nSeq2Seq+IDF: 4A) 2 W494\\n- What a lovely dog.\\n\\ns=1: RBS HL, HAULS! I really like her eye make-up, and\\n\\ns=1: 7 AEM HH, AALFE- A!\\nThe samoyed is so lovely, and I really want to keep one!\\n\\ns=0.8: SUH, WORE 7h 333! I really like her, and her eyes are\\n\\ns=0.8: EEUFATZ, WARSI\\nThe samoyed is so lovely, and I really want to pinch it.\\n\\ns=0.5: Ft AMOR, WEP WCHG! I think she is very beautiful, and I really like her!\\n\\ns=0.5: ALAM %y, KF HT VA IAFy ©\\nWhat a lovely dog, what a lovely dog.\\n\\ns=0.2: FR i 7EUEARSS |\\nI think she is very beautiful.\\n\\ns=0.2: {FATZ! LATA!\\nSo lovely, so lovely!\\n\\ns=0: FJ\\nYes.\\n\\ns=0: FT Z!\\nSo lovely!\\n\\nWith s from 1 to 0, SC-Seq2Seq can generate very long and specific responses, to more general and shorter responses."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "PHASE Sate S Sikh aslie = Ezy Key Laboratory of Network Data Science & Technology, CAS\\n- AHLOSLR\\n- Uiage\\n- Semi Uae SemanHF (better)\\n- 4545 cmother\\n- ZiX(attempt)\\n- HX(vegetables)\\n- 44 (outsit)\\n- RE (fat)\\n- TANPR(Asian Cup)\\n- FAAB#L(camera)\\n- fETi(sleep)\\n- Ff#f(brother)\\n- iRXtempt\\n- \"FW4(milk)\\n- ABE XU vegetarian\\n- RAL iet\\n- BEA(read)\\n- #@¥ (photography)\\n- RA (happy)\\n- ZA(husband)\\n- #HA(express)\\n- PHJM(watermelon)\\n- #{27(walk)\\n- ill (hypertension)\\n- *#2K(hemispherical)\\n- {54(shot)\\n- FMboring\\n- #44 (grandfather)\\n- ##A(own)\\n- K'HK(rice)\\n- AX Acausality\\n- WZER(sub-health)\\n- Hi#¥5i(anti-radiation)\\n- #YFE(studio)\\n- HM(movie)\\n- *e4R(girl)\\n- #E(dream)\\n- 15527] (chocolate)\\n- /#4(dumbbell)\\n- Akt (emesis)\\n- FLABLUAV) 5 (image)\\n\\nTable 6: Target words and their top-5 similar words under usage and semantic representations respectively.\\n1. Neighbors based on semantic representations are semantically related.\\n2. Neighbors based on usage representations are not so related but with similar ag Tonia as.\\n\\nFigure 3: t-SNE embeddings of usage and semantic vectors."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "PEA Sim auER S SRA LS, Key Laboratory of Network Data Science & Technology, CAS\\n\\nConclusion: We argue that employing a single model to learn the mapping between the utterance and response will inevitably favor general responses.\\n\\nWe propose that an explicit specificity control variable is introduced into the Seq2Seq model to handle different utterance-response relationships in terms of specificity.\\n\\nFuture work:\\n- Employ some reinforcement learning technique to learn to adjust the control variable depending on users' feedback.\\n- Apply to other tasks, like summarization, QA, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "% abs: fe | PERSE Sede SSRAB ALStp *@ aS ta 8 REE | Key laboratory of Network Data Science & Technology, CAS | Name: Ruging Zhang | Email: zhangruqing@software.ict.ac.cn"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 316,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction\\n\\nAttention-based neural translation models attend to specific positions on the source side to generate translation improvements over pure encoder-decoder sequence-to-sequence approaches.\\nNeural HMM has been successfully applied on top of SMT systems [Wang & Alkhouli, 2017].\\nThis work explores its application in standalone decoding, end-to-end, only with neural networks\\n- NMT. LSTM structures outperform FFNN variants in [Wang & Alkhouli, 2017].\\n\\nW. Wang: Neural HMM for MT\\n2/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Neural Hidden Markov Model\\nTranslation\\nsource sentence f = f1... f2... f7\\ntarget sentence e = e1... e2... e7\\nalignment\\n\\nModel translation using an alignment model and a lexicon model:\\nP(f2) = p(e1 | f2) = plej, bil fy) (1)\\nbff... = S[[peilbi.es, e2)\\n- p(bilby | e | f7) (2)\\nAA Ne OOFbf w = lexicon model alignment model\\np(bilby | e0 | f7) = p(Ailbr | e0 | f7)\\npredicts the jump A; = 6;\\n- 6;_1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Neural Hidden Markov Model -os PF ELI CI LI LI [|Fe |OOOOOOT4Be; OoOooo0fooHe O00PO oo oooee a |+ PF LI LI LF EI LI> Neural network based lexicon model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Neural Hidden Markov Model TMon PJ} LI LI UI LI [| Pair sine)§\\n- 7OOOOO0RtUa Pr] EJ GI ro [|Hej OOOOeo oo oko oaee yOoodoada= MP} LILI LF LD od>\\n\\nNeural network based alignment model (7' = b;_1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Training criterion for sentence pairs (F, E), r = 1,..., R:\\nargmax log mo(eiF) (3)\\n\\nDerivative for a single sentence pair (F,\\nE) = (f/, e/):\\na, fal n| gd I.g a, ° lal pt-1 J.9 A9 OS PAEIF) = >) > pild's JF €13\\n8) 5 los PG, els'se | F758) (4) ee\"j',j_ % HMM posterior weights\\n\\nEntire training procedure:\\n- backpropagation in an EM framework\\n1. compute:\\n- the HMM posterior weights\\n- the local gradients (backpropagation)\\n2. update neural network weights\\n\\nW. Wang: Neural HMM for MT 5/12 July 17th, 2018 'G"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Decoding: Search over all possible target strings\\n\\nmax p(e|f) = max p(bi, eilbi-a, ey's fi)\\n\\nExtending partial hypothesis from e' to e\\n\\nQ(t, eh) = Σ p(ei|fj) ° Q(t-1, ej)\\n\\nPruning:\\n\\nQ(i|e) = Σ Q(i-1, ej)\\n\\nargmax(z; ei) + select several candidates\\n\\nW. Wang: Neural HMM for MT 6/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Decoding\\n\\nNo explicit coverage constraints\\n\\nOne-to-many alignment cases and unaligned source words\\n\\nSearch space in decoding\\n\\nNeural HMM: consists of both alignment and translation decisions\\n\\nAttention model: consists only of translation decisions\\n\\nDecoding complexity (J = source sentence length, J = target sentence length)\\n\\nNeural HMM: O(J²\\n-\\n7)\\n\\nAttention model: O(J\\n-\\nI)\\n\\nIn practice, neural HMM 3 times slower than attention model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Experimental Setup\\n- WMT 2017 German<>English and Chinese-English translation tasks\\n- Quality measured with case sensitive BLEU and TER on newstests2017\\n- Moses tokenizer and truecasing scripts [Koehn & Hoang TM 07]\\n- Jieba segmenter for Chinese data\\n- 20K byte pair encoding (BPE) operations [Sennrich & Haddow 16]\\n- Joint for German<>English and separate for Chinese-English\\n- Attention-based systems are trained with Sockeye [Hieber & Domhan 17]\\n- Encoder and decoder embedding layer size 620\\n- A bidirectional encoder layer with 1000 LSTMs with peephole connections\\n- Adam [Kingma & Ba 15] as optimizer with a learning rate of 0.001\\n- Batch size 50, 30% dropout\\n- Beam search with beam size 12\\n- Model weights averaging\\n\\nW. Wang: Neural HMM for MT 8/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Experimental Setup\\n- Neural hidden Markov model implemented in TensorFlow [Abadi & Agarwal 16].\\n- Encoder and decoder embedding layer size\\n350.\\n- Projection layer size 800 (400 + 200 + 200).\\n- Three hidden layers of sizes 1000, 1000, and 500 respectively.\\n- Normal softmax layer.\\n- Lexicon model: large output layer with roughly 25K nodes.\\n- Alignment model: small output layer with 201 nodes.\\n- Adam as optimizer with a learning rate of 0.001.\\n- Batch size 20, 30% dropout.\\n- Beam search with beam size\\n12.\\n- Model weights averaging."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "ReExperimental Results WMT 2017\\n\\n# free German-English | English-German | Chinese-English parameters\\n\\nBLeu! Ter! | Breul! Ter! | Breul! Ter!\\n\\nFFNN-based neural HMM 28.3 51.4 23.4 58.8 19.3 64.8\\nLSTM-based neural HMM 29.6 50.5 24.6 57.0 20.2 63.7\\n\\nFFNN-based neural HMM: [Wang & Alkhouli 17] applied in decoding\\nLSTM-based neural HMM: this work\\nAttention-based neural network: [Bahdanau & Cho 15]\\n\\nAll models trained without synthetic data\\nSingle model used for decoding\\nLSTM models improve FFNN-based system by up to 1.3% BLEU and 1.8% TER\\nComparable performance with attention-based system\\n\\nW. Wang: Neural HMM for MT 10/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Summary: Apply NNs to conventional HMM for MT\\n- End-to-end with a stand-alone decoder\\n- Comparable performance with the standard attention-based system\\n- Significantly outperforms the feed-forward variant\\n\\nFuture work:\\n- Speed up training and decoding\\n- Application in automatic post editing\\n- Combination with attention or transformer [Vaswani & Shazeer 17] model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Thank you for your attention\\n\\nWeiyue Wang\\nwwang@cs.rwth-aachen.de\\nhttp://www-i6.informatik.rwth-aachen.de/\\n\\n(ee) W. Wang: Neural HMM for MT\\n12/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Appendix: Motivation\\n\\nNeural HMM compared to attention-based systems\\n\\nRecurrent encoder and decoder without attention component\\n\\nReplacing attention mechanism by a first-order HMM alignment model\\n- Attention levels: deterministic normalized similarity scores\\n- HMM alignments: discrete random variables and must be marginalized\\n\\nSeparating the alignment model from the lexicon model\\n- More flexibility in modeling and training\\n- Avoids propagating errors from one model to another\\n- Implies an extended degree of interpretability and control over the model\\n\\nW. Wang: Neural HMM for MT 13/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "ROTNVENSITY\\n\\nAppendix: Analysis\\n\\nAttention-based NMT Neural HMM\\n\\naltercation of any kind\\n\\nAttention weight and alignment matrices visualized in heat map form.\\n\\nGenerated by attention NMT baseline and neural HMM.\\n\\nW. Wang: Neural HMM for MT 14/12 July 17th, 2018 @"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Appendix: Analysis\\n\\nReference 28-Year-Old Chef Found Dead at San Francisco Mall\\n\\nAttention NMT | 28-year-old cook in San Francisco Mall found dead\\n\\nNeural HMM | 28-year-old cook found dead in San Francisco Mall\\n\\nSource Frankie has been riding winners in the UK for the best part of 30 years, which is great to see.\\n\\nAttention NMT | Frankie has been a winner in the UK for almost 30 years, which is great.\\n\\nNeural HMM | Frankie has ridden winners in the UK for almost 30 years, which is great.\\n\\nSource Who is going to build Braunschweig's low-cost housing?\\n\\nAttention NMT | Who does Braunschweig build cheap apartments?\\n\\nNeural HMM | Who builds Braunschweig's cheap apartments?\\n\\nSample translations from the WMT German-English newstest2017 set\\n\\nUnderline source words of interest\\n\\nItalicize correct translations\\n\\nBold-face for incorrect translations\\n\\nW. Wang: Neural HMM for MT 15/12 July 17th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "References\\n\\n[M. Abadi, A. Agarwal, P. Barham et al.: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems.\\nCoRR, Vol. abs/1603.04467, 2016.]\\n\\n[D. Bahdanau, K. Cho, Y. Bengio: Neural Machine Translation by Jointly Learning to Align and Translate.\\nIn Proceedings of the 3rd International Conference on Learning Representations, San Diego, CA, USA, May 2015.]\\n\\n[F. Hieber, T. Domhan, M. Denkowski, D. Vilar, A. Sokolov, A. Clifton, M.\\nPost: Sockeye: A Toolkit for Neural Machine Translation. ArXive-prints, Vol. abs/1712.05690, December 2017.]\\n\\n[D.P. Kingma, J.L. Ba: Adam: A method for stochastic optimization.\\nIn Proceedings of the Third International Conference on Learning Representations, San Diego, CA, USA, May 2015.]\\n\\n[P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C.\\nDyer, O. Bojar, A. Constantin, E. Herbst: Moses: Open Source Toolkit for Statistical Machine Translation.\\nIn Proceedings of the 45th Annual Meeting of the Association for W. Wang: Neural HMM for MT 16/12 July 17th, 2018.]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pp.\\n177-180, Prague, Czech Republic, June\\n2007.\\n\\n[Sennrich & Haddow 16] R. Sennrich, B. Haddow, A. Birch: Neural Machine Translation of Rare Words with Subword Units.\\nIn Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp.\\n1715-1725, Berlin, Germany, August\\n2016.\\n\\n[Vaswani & Shazeer 17] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez, L. Kaiser, I.\\nPolosukhin: Attention Is All You Need.\\nIn 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA, December\\n2017.\\n\\n[Wang & Alkhouli 17] W. Wang, T. Alkhouli, D. Zhu, H.\\nNey: Hybrid Neural Network Alignment and Lexicon Model in Direct HMM for Statistical Machine Translation.\\nIn Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp.\\n125-131, Vancouver, Canada, August\\n2017.\\n\\nW. Wang: Neural HMM for MT 17/12 July 17th, 2018"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 21,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Fake News is not our friend."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Donald J. Trump @realDonaldTrump \".... It is very possible that those sources don't exist. Fake news writers.\\n#FakeNews is the enemy! 5:45 AM\\n- 23 May 12,418 Retweets 56,686 Likes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "What are Fake News? Disinformation displayed as news articles"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "What are Fake News?\\nDisinformation displayed as news articles\\n\\nFIRST DRAFT\\n\\n7 TYPES OF MIS- AND DISINFORMATION\\n- SATIRE OR PARODY\\n- MISLEADING CONTENT\\n- IMPOSTER CONTENT\\n- FABRICATED CONTENT\\n\\nNo intention to cause harm but has potential to deceive and do harm.\\n\\nWhen headlines, visuals, or captions don't support the content.\\nWhen genuine sources are misleadingly used to frame an issue or individual.\\nWhen genuine content is manipulated to deceive.\\n\\nImage: Claire Wardle, First Draft"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "What are Fake News?\\nDisinformation displayed as news articles\\n\\nFIRST DRAFT\\n\\n7 TYPES OF MIS- AND DISINFORMATION\\n- SATIRE OR PARODY\\n- MISLEADING CONTENT\\n- IMPOSTER CONTENT\\n- FABRICATED CONTENT\\n\\nNo intention to cause harm but has potential to deceive and do harm\\n- FALSE CONNECTION\\n- FALSE CONTEXT\\n- MANIPULATED CONTENT\\n\\nWhen headlines, visuals or captions don't support the content\\nWhen genuine information or imagery is manipulated to deceive\\n\\nImage: Claire Wardle, First Draft"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "A Stylometric Inquiry into Hyperpartisan \"News\" and \"News\" in False Context and/or with Content that is Impostered, Manipulated, and/or Fabricated\\n\\nMartin Potthast*, Johannes Kiesel', Kevin Reinartz', Janek Bevendorff', Benno Stein'\\n\\nLeipzig University, Bauhaus-Universität Weimar\\n\\nwebis.de\\n\\nACL, July 16th, 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "The Political Spectrum\\n\\nThe left-right political spectrum is a system of classifying political positions, ideologies and parties.\\nLeft-wing politics and right-wing politics are often presented as opposed, although either may adopt stances from the other side.\\n- Alt-left\\n- Left\\n- Center\\n- Right\\n- Alt-right\\n- Liberal\\n- Conservative"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "The Political Spectrum\\n\\nThe left-right political spectrum is a system of classifying political positions, ideologies and parties.\\nLeft-wing politics and right-wing politics are often presented as opposed, although either may adopt stances from the other side.\\n[Wikipedia]\\n\\nAlt-left\\nLeft\\nCenter\\nRight\\nAlt-right\\nLiberal\\nConservative\\nHyperpartisan\\nPartisan\\n\\nPartisan: someone with a psychological identification with one major party. [Wikipedia]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "The Political Spectrum\\n\\nThe left-right political spectrum is a system of classifying political positions, ideologies and parties.\\nLeft-wing politics and right-wing politics are often presented as opposed, although either may adopt stances from the other side.\\n[Wikipedia]\\n\\nAlt-left\\nLeft\\nCenter\\nRight\\nAlt-right\\nLiberal\\nConservative\\nHyperpartisan\\nPartisan\\n\\nPartisan: someone with a psychological identification with one major party. [Wikipedia]\\n\\nNews media reporting on politics can be aligned on this spectrum as well.\\nWe are observing an increasing number of hyperpartisan news publishers."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Fake News and Hyperpartisan News\\n\\nBuzzFeed News / #2u\"s\\n\\nHyperpartisan Facebook Pages Are Publishing False And Misleading Information At An Alarming Rate\\n\\nA BuzzFeed News analysis found that three big right-wing Facebook pages published false or misleading information 38% of the time during the period analyzed, and three large left-wing pages did so in nearly 20% of posts.\\n\\nBy Craig Silverman (BuzzFeed Founding Editor, Canada), Lauren Strapagiel (BuzzFeed Staff), Hamza Shaban (BuzzFeed News Reporter), Ellie Hall (BuzzFeed News Reporter), Jeremy Singer-Vine (BuzzFeed News Reporter)\\n\\nFreedom Daily\\n\\nNasty Surprise: Obama Told Americans That Their Freedom is Over And New World Government is Taking Over\\n\\nVIDEO\\n\\nOBAMA GIVES FINAL ADDRESS TO UNITED NATIONS | CAN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Why are Fake News Published by Hyperpartisan Pages?\\n\\nFIRST DRAFT MISINFORMATION MATRIX\\n- Poor Journalism\\n- Parody\\n- Punk?\\n- Passion for Partisanship\\n- Profit\\n- Influence\\n- Propaganda\\n\\nImage: Claire Wardle, First Draft\\n13 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Why are Fake News Published by Hyperpartisan Pages?\\n\\nFIRST DRAFT MISINFORMATION MATRIX\\n\\nImage: Claire Wardle, First Draft"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Fake News Detection Taxonomy of Approaches\\n\\nKnowledge-based\\n- Fake news detection;\\n- Knowledge-based (also called fact checking)\\n- Requires political knowledge base\\n- Information retrieval Magdy and Wanas, 2010\\n- Unavailable ahead of time\\n- Eiremeitel, BOTE\\n- We cannot trust the web | et al, 2014\\n- Semantic web / LOD Ciampaglia et al, 2015\\n- Shi and Weninger, 2016\\n- Long et al., 2017\\n- Mocanu et al., 2015\\n\\nContext-based\\n- Context-based Acemoglu et al., 2010\\n- Limited to social media platforms Ma et al., 2017\\n- Social network analysis Volkova et al., 2017\\n- Part of damage already done Budak et al., 2011\\n- Nguyen et al., 2012\\n- Derczynski et al., 2017\\n\\nStyle-based\\n- Tambuscio et al., 2015\\n- Style-based Wei et al., 2013\\n- Chen et al.,\\n2015.\\n- Detection detection Rubin et al., 2015\\n- Allows for pre-posting check Wang et al., 2017\\n- Bourgonje et al., 2017\\n- Real-time reaction possible Afra dataL, BO1D\\n- Badaskar et al., 2008\\n- Hard to mask Rubin et al., 2016\\n- Text categorization Yang et al., 2017\\n- But are style differences sufficient? Rashkin et al., 2017\\n- Horne and Adali, 2017\\n- Pérez-Rosas et al., 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Fake News and Hyperpartisan News Corpus Construction\\n\\nSra 7 Se 4MI THEY ega: iim * a ae- pa A Pegt wySie NEWS\\n- WM ATICTMOMEO ORG, eats a DEMOCRATSBLEs, gther\\n28) Neminree is SULLY RIGHT WING"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Fake News and Hyperpartisan News Corpus Construction\\n\\nOrientation\\n\\nFact-checking results\\n\\nPublisher                   true   mix   false   n/a   y\\nCenter                      806    8     0      12    826\\nABC News                    90     2     0      3     95\\nCNN                         295    4     0      8     307\\nPolitico                    421    2     0      1     424\\nLeft-wing                   182    51    15     8     256\\nAddicting Info              95     25    8      7     135\\nOccupy Democrats            59     25    7      0     91\\nThe Other                   98%    28    1      0     1     30\\nRight-wing                  276    153   72     44    545\\nEagle Rising                106    47    20     36    214\\nFreedom Daily               49     24    22     4     99\\nRight Wing News            121    82    25     4     232\\n\\n»y   1264   212   87    64    1627"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Fake News and Hyperpartisan News Selected Results\\n\\nOrientation Fact-checking results\\n\\nPublisher true mix false n/a y\\n\\nCenter 806 8 0 12 826\\n\\nABC News =\\n- por 95\\n\\nCNN\\n- 307\\n\\nPolitico Fake News Detection wf 424\\n\\nLeft-win 13 8 256\\n\\nInfo Precision = 42%\\n\\nOccupy Democrats Recall ~ 41%\\n\\nThe Other 98%\\n\\nRight-wing 276 153 72 44 545\\n\\nEagle Rising 106 47 25 36 214\\n\\nFreedom Daily 49 24 22 4 99\\n\\nRight Wing News 121 82 25 4 232\\n\\ny 1264 212 87 64 1627"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Fake News and Hyperpartisan News Selected Results\\n\\nOrientation Fact-checking results\\n\\nPublisher true mix false n/a yCenter 806 8 0 12 826\\n- WOR tp 307\\n\\nPolitic Orientation Detection\\n\\nPrecision + 21%\\n- Precision ~ 56%\\n\\nRecall ~ 20% Recall ~ 59%\\n\\nRight-wing 276 153 72 44 545\\n\\nEagle Rising 106 47 25 36 214\\n\\nFreedom Daily 49 24 22 4 99\\n\\nRight Wing News 121 82 20 4 232"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Fake News and Hyperpartisan News\\n\\nSelected Results\\n\\nOrientation\\n\\nFact-checking results\\n\\nPublisher\\n\\ntrue\\n\\nmix\\n\\nfalse\\n\\nn/a\\n\\nyCenter\\n\\n806\\n\\n8\\n\\n0\\n\\n12\\n\\n826\\n\\nABC News\\n-\\n\\nCNN\\n-\\n\\nPolitico\\n\\nHyperpartisanship Detection\\n-\\n\\nLeft-wing\\n\\n3\\n\\n4\\n\\n256\\n\\nAddicting Info\\n-\\n\\nThe Other\\n\\n9\\n\\n30\\n\\nRight-wing\\n\\n276\\n\\n153\\n\\n72\\n\\n44\\n\\n545\\n\\nEagle Rising\\n\\n106\\n\\n47\\n\\n25\\n\\n36\\n\\n214\\n\\nFreedom Daily\\n\\n49\\n\\n24\\n\\n4\\n\\n99\\n\\nRight Wing News\\n\\n121\\n\\n82\\n\\n20\\n\\n4\\n\\n232\\n\\nAnnotations provided by journalists at BuzzFeed"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Fake News and Hyperpartisan News\\n\\nHow can it be that the alt left and the alt right cannot be distinguished from the mainstream, when both together (hyperpartisan news) can be?\\n\\nAlt-left\\nLeft\\nCenter\\nRight\\nAlt-right\\nLiberal\\nConservative\\nHyperpartisan\\nPartisan\\nPartisan\\nHyperpartisan"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Fake News and Hyperpartisan News\\n\\nHow can it be that the alt left and the alt right cannot be distinguished from the mainstream, when both together (hyperpartisan news) can be?\\n\\nCenter\\nLeft\\nRight\\nPartisan\\nAlt-left\\nHyperpartisan\\nAlt-right"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Fake News and Hyperpartisan News\\n\\nHow can it be that the alt left and the alt right cannot be distinguished from the mainstream, when both together (hyperpartisan news) can be?\\n\\nCenter\\nLeft\\nRight\\nPartisan\\nAlt-left\\nHyperpartisan\\nAlt-right\\n\\nThe horseshoe theory asserts that the alt left and the alt right, rather than being at opposite and opposing ends of a linear political continuum, in fact closely resemble one another, much like the ends of a horseshoe.\\n[Wikipedia]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Horseshoe Validation Experiment | Leave-out Classification is ve ma 3 iG ell ey I Fin eee RIGHIeS = left-wing center right-wing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Horseshoe Validation Experiment | Leave-out Classification\\n\\nLeft-wing  center  right-wing\\n\\nA classifier is trained to distinguish left-wing and center articles. Right-wing articles are used for testing."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Horseshoe Validation Experiment | Leave-out Classification\\n\\nClassifier is trained to distinguish left-wing and center articles. Right-wing articles are used for testing.\\nMajority of right-wing articles are classified as left-wing rather than center.\\n\\n74% | 26%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Horseshoe Validation Experiment | Leave-out Classification v7\\n\\nAEN Come.\\n\\nSE (oct ds RIG Ne\\n\\nleft-wing center right-wing 74% | 26%\\n\\nA classifier is trained to distinguish left-wing and center articles. Right-wing articles are used for testing.\\nMajority of right-wing articles are classified as left-wing rather than center.\\n\\nABN Crouréoe\\n\\nleft-wing center right-wing 34% | 66%\\n\\n27 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Horseshoe Validation Experiment II\\nUnmasking (Koppel/Schier\\n2004)\\nKtKe28 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking (Koppel/Schier\\n2004) Keke"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking. [Koppel/Schler 2004] @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking.\\n\\n[Koppel/Schler 2004] Vv 3 for fc\\n- 00 fo2 fos [os| ot | o3] Jor | oa1 02 | o03 | oo | o1j = 1 5 02 | o1 | ]o4 | os | ZEEE | ae | [fo | [Sa [es = = S = 3 o1 | o3 | o2 | o2_ 1 | Jor |\\n-\\n- o1 | o2 | ]o2 | }o1 2 02 | o1 | 02 | oo1 | oA o1 | o2 | ]o4 | os | , | [a Ae | / 05 | o2 | ]o2 | osA B / 02 | 04 o2 | or | oo | os/ 0.2 | 0 ( 02 | [0.1 0.0 | 0.0 l A BC28bob 100 907060500 6 12 18 24 3031 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking.\\n\\n{Koppel/Schler 2004} W 3 for Jo\\n- 0.0 0.2 0.5 0.3 4 1 ot | | o3 Jor | oa\\n- o2 | oi | ) o« | fos | 2 2 = BEB.\\n\\neee oles === 2EEE sf fos | e a1 | fos [oz | fo2 | | be R/S) |\\nB) | | a TESTE TSHSTTEETIST | A B 1 | | | o2 | o4 | 02 | 01 | oo | os | 02 | |\\n- | (\\n02) | 0.4 0.0 | | 0.0 A B 100 | 90 / 80 / 70 : 60500 6 12 18 24 30 32 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking.\\n{Koppel/Schler 2004]W 3] for] fc ( 00] fo2z] fos] fosy o1| }os| for] |oa1 02} |03] }oo]} | o1=P BBea WBUEUEL [BIE 82eEeBeE lle lea | | TIE| / |e EET esA B f 1 | } | 0.2 | | | 0.2 O41 0.0 0.3/ 0.2 | | 0 ( 02} [0.1 0.0 | | 0.0l A BC28bob\\ 100\\ 90Ne 07060500 6 12 18 24 3033 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking. {Koppel/Schler 2004}\\n\\n90\\n- 80\\n- 70\\n- 60\\n- 50\\n- 40\\n- 30\\n- 20\\n- 10\\n- 0\\n\\n@kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking (Koppel/Schier\\n2004)\\n\\nRik ee TTT Tasoc + [Tee | Toe | Te [o2 [or | [ox | [2s22ee.\\nfer [fer[Te: [fest [or] [oz | [02] [os |et | [oa] [og] [os] [oa] | oe | | oa | [oeee ool ores Tee Fes | fez | [02] [os | A B ee ee ee las & A B 100.: ne35 @kKieselJohannes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking (Koppel/Schier\\n2004)\\n\\nTypical learning characteristic for different authors\\n\\n100 90 80 70\\n\\n60 00 6 12 18 24 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking. [Koppel/Schler 2004] Typical learning characteristic for ... 100 90 80\\n70. different authors (A ≠\\nB) 60 same author (A =\\nB) 500 6 12 18 24 30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Horseshoe Validation Experiment II\\n\\nUnmasking [Koppel/Schier 2004\\n\\nTypical learning characteristic for\\n100 = 90 ms, * 80 = 70 KX. ts, different authors (A ≠\\nB)\\n60 by same author (A =\\nB)\\n50\\n\\nThe typical learning characteristic can be learned.\\n- \"Meta Learning\"\\n\\nWe apply Unmasking to distinguish style genres."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Horseshoe Validation Experiment II Unmasking [Koppel/Schier 2004 Mainstream vs Left\\n\\n0.6 Mainstream vs Right\\n\\n0.4 Left vs Right\\n\\n0.3 6 9 12 15 Iterations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Summary and Outlook\\n\\nHyperpartisan news pages produce relatively many fake news articles.\\n\\nHyperpartisan news can be distinguished quite well based on style. Style-based detection allows for real-time detection.\\nPolitical extremism in news can be ousted or at least flagged. The style of alt left and alt right news is very similar.\\n\\nLinguistic evidence for the horseshoe theory of the political spectrum? Large-scale analysis required."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Hyperpartisan News Detection\\n- SemEval 2019\\n\\nTeaser: Hyperpartisan News Detection"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Style Model\\n\\nFeatures\\n- n-grams with n € [1,3] of characters\\n- stop words\\n- parts-of-speech\\n- 10 readability scores\\n- Dictionary features based on General Inquirer\\n- Ratios of quoted words, external links, number of paragraphs, and their average length\\n\\nFeature selection\\n- Discard word features (n-gram features) occurring in less than 2.5% (10%) of documents\\n\\nTraining set\\n- Balancing using oversampling\\n- Publishers are not represented in both training and test set\\n\\nLearning algorithm\\n- WEKA's random forest with default parameters"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 369,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Text Simplification\\n\\nIf the trend continues, the researchers say, some of the rarer amphibians could disappear in as few as six years from roughly half the sites where they're now found, while the more common species could see similar declines in 26 years.\\n\\nIf the trend continues, some of the rarer amphibians could be gone from roughly half the sites where they are now found in as few as six years.\\nMore common species could see similar declines in 26 years.\\n- For a specific target audience, e.g. non-native speakers\\n- For improving NLP tasks, e.g. MT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Newsela Corpus\\nWikipedia\\n- Simple Wikipedia (W-SW)\\nrather small\\nnot professionally simplified\\nno defined target audience"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Newsela Corpus\\nWikipedia\\n- Simple Wikipedia (W-SW)\\nrather small\\nnot professionally simplified\\nno defined target audience\\nOriginal Professionally\\nNewsela (version 2016-01-29.1) articles\\nsimplified versions target different grade levels in the US\\nprofessionally simplified"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Newsela Corpus\\n\\nWikipedia\\n- Simple Wikipedia (W-SW)\\n- Rather small\\n- Not professionally simplified\\n- No defined target audience\\n\\nOriginal Professionally\\n- Newsela (version 2016-01-29.1)\\n- Simplified versions target different grade levels in the US\\n- Professionally simplified\\n\\nAutomatic sentence-level alignments\\n- Identical (146,251)\\n- Many-to-one (merge) (24,661)\\n- One-to-many (split) (121,582)\\n- Elaboration (258,150)\\n\\nNewsela: ~550K sentence pairs (+ 280K W-SW)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Sequence-to-Sequence: state-of-the-art for other text-to-text transformation tasks\\n[Nisioi et al., 2017]\\n- state-of-the-art on W-SW4/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Sequence-to-Sequence: state-of-the-art for other text-to-text transformation tasks. [Nisioi et al., 2017]\\n- state-of-the-art on W-SW. Previous work disregards specificities of different audiences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Sequence-to-Sequence: state-of-the-art for other text-to-text transformation tasks\\n\\nNTS [Nisioi et al., 2017]\\n- state-of-the-art on W-SW\\n\\nPrevious work disregards specificities of different audiences\\n\\nGoogle's multilingual NMT approach [Johnson et al., 2017]: artificial token to guide the encoder\\n\\nHow are you? -> Cémo estas?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Sequence-to-Sequence: state-of-the-art for other text-to-text transformation tasks.\\n\\n[Nisioi et al., 2017]\\n- state-of-the-art on W-SW.\\n\\nPrevious work disregards specificities of different audiences.\\n\\nGoogle's multilingual NMT approach [Johnson et al., 2017]: artificial token to guide the encoder.\\n\\nHow are you? -> ¿Cómo estás?\\n\\nOur approach: artificial token representing the grade level of the target sentence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "TS for Different Grade Levels\\n\\ndusty handprints stood out against the rust of the fence near Sasabe.\\ndusty handprints could be seen on the fence near Sasabe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "TS for Different Grade Levels\\n\\nAdvantages:\\n- More adequate simplifications for audiences with different educational levels\\n- Real world scenario -> grade level is given by the end-user\\n- Robust for repetitions of source sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "TS for Different Grade Levels\\n\\nAdvantages:\\n- More adequate simplifications for audiences with different educational levels\\n- Real world scenario\\n- grade level is given by the end-user\\n- Robust for repetitions of source sentences\\n\\nDusty handprints stood out against the rust of the fence near Sasabe.\\nDusty handprints could be seen on the fence near Sasabe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "TS for Different Grade Levels\\n\\nAdvantages:\\n- More adequate simplifications for audiences with different educational levels\\n- Real world scenario\\n- grade level is given by the end-user\\n- Robust for repetitions of source sentences\\n\\ndusty handprints stood out against the rust of the fence near Sasabe.\\ndusty handprints could be seen on the fence near Sasabe.\\n\\ndusty handprints stood out against the rust of the fence near Sasabe.\\ndusty handprints stood out against the rust of the fence near Sasabe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Simplification Operations Information\\n\\nSentence-level alignments\\n- coarse-grained operations\\n\\nIdentical, Elaborate, Split, Merge\\n\\nElaboration\\n\\nDusty handprints stood out against the rust of the fence near Sasabe.\\nDusty handprints could be seen on the fence near Sasabe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Simplification Operations Information\\n\\nSentence-level alignments\\n- coarse-grained operations:\\n- Identical\\n- Elaborate\\n- Split\\n- Merge\\n\\nElaboration: Dusty handprints stood out against the rust of the fence near Sasabe.\\nDusty handprints could be seen on the fence near Sasabe.\\n\\nProblem: not available at test time"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Simplification Operations Information\\n\\nSentence-level alignments\\n- coarse-grained operations\\n- Identical\\n- Elaborate\\n- Split\\n- Merge\\n\\nElaboration: dusty handprints stood out against the rust of the fence near Sasabe.\\nDusty handprints could be seen on the fence near Sasabe.\\n\\nProblem: not available at test time\\n\\nSimplification operations classification\\n\\nFour-class classifier\\n- Naive Bayes with nine features\\n\\nAccuracy: 0.517/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Experiment and results\\n\\nNMT approach\\n- default OpenNMTx Y\\n\\nA A B Cc x 1."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Experiments and Results\\n\\nNTS (w2v): no artificial tokens"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experiments and Results\\n\\nNTS (w2v): no artificial tokens\\n\\nOur models:\\n\\ns2s (baseline): no artificial tokens\\n\\ns2s+to-grade\\n\\ns2s+operation (pred/gold) + elaboration\\n\\ns2s+to-grade+operation (pred/gold) + 2-elaboration\\n9/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Experiments and Results\\n\\nNTS (w2v): no artificial tokens\\n\\nOur models:\\n\\ns2s (baseline): no artificial tokens\\n\\ns2s+to-grade\\n\\ns2s+operation (pred/gold) + elaboration\\n\\ns2s+to-grade+operation (pred/gold) + elaboration\\n\\nBLEU + | SARI + | Flesch\\n\\ntNTS 61.60 33.40 79.95\\ns2s 61.78 33.72 79.86"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Experiments and Results\\n\\nNTS (w2v): no artificial tokens\\n\\nOur models:\\n\\ns2s (baseline): no artificial tokens\\n\\ns2s+to-grade\\n\\ns2s+operation (pred/gold)\\n\\ns2s+to-grade+operation (pred/gold)\\n\\nBLEU\\n- | SARI*+ | Flesch\\n\\nNTS 61.60 33.40 79.95\\n\\ns2s 61.78 33.72 79.86\\n\\ns2s+to-grade 62.91 41.04 82.91\\n\\ns2s+operation (pred) 59.83 37.36 84.96\\n\\ns2s+to-grade+operation (pred) 61.48 40.56 83.11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Experiments and Results\\n\\nNTS (w2v): no artificial tokens\\n\\nOur models:\\n\\ns2s (baseline): no artificial tokens\\n\\ns2s+to-grade\\n\\ns2s+operation (pred/gold)\\n\\ns2s+to-grade+operation (pred/gold)\\n\\nBLEU\\n- | SARI*+ | Flesch\\n\\nNTS 61.60 33.40 79.95\\n\\ns2s 61.78 33.72 79.86\\n\\ns2s+to-grade 62.91 41.04 82.91\\n\\ns2s+operation (pred) 59.83 37.36 84.96\\n\\ns2s+to-grade+operation (pred) 61.48 40.56 83.11\\n\\ns2s+operation (gold) 63.24 41.81 84.47\\n\\ns2s+to-grade+operation (gold) 64.78 45.41 85.44"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Examples\\n\\nWe want to reassure you that we take fire safety very seriously and we are doing everything we can to make sure our residents are safe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Examples\\n\\nWe want to reassure you that we take fire safety very seriously and we are doing everything we can to make sure our residents are safe.\\n\\nWe want to reassure you that we take fire safety very seriously.\\nWe are doing everything we can to make sure our residents are safe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Examples\\n\\nWe want to reassure you that we take fire safety very seriously and we are doing everything we can to make sure our residents are safe.\\n\\nWe want to reassure you that we take fire safety very seriously.\\n\\nWe are doing everything we can to make sure our residents are safe.\\n\\nWe want to make sure we take fire safety very seriously.\\n\\nWe are doing everything we can to make sure our people are safe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Examples\\n\\nWe want to reassure you that we take fire safety very seriously and we are doing everything we can to make sure our residents are safe.\\n\\nWe want to reassure you that we take fire safety very seriously and we are doing everything we can to make sure our residents are safe.\\n\\nWe want to reassure you that we take fire safety very seriously.\\nWe are doing everything we can to make sure our residents are safe.\\n\\nWe want to make sure we take fire safety very seriously.\\nWe are doing everything we can to make sure our people are safe.\\n\\nWe want to make sure people take fire safety very seriously.\\nWe are doing everything we can to make sure our people are safe.\\n\\nWe want to make sure people take fire safety very seriously.\\nWe are doing everything we can to make sure people are safe."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Zero-shot TS\\nZero-shot TS among grade levels\\nExample: from grade level 12 to grade level 4\\nNo instances of 12-to-4 in the training set\\nOther into 4 levels (e.g. 10-to-4, 6-to-4)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Zero-shot TS\\nZero-shot TS among grade levels\\nExample: from grade level 12 to grade level 4\\nNo instances of 12-to-4 in the training set\\nOther into 4 levels (e.g. 10-to-4, 6-to-4)\\n\\nBLEU + | SARIt | Flesch\\n+12-to-4\\ns2s 44.56 37.56 79.50\\ns2s + to-grade\\nee | e 50.76 91.04\\ns2s + to-grade + zs 91.08\\n11/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Zero-shot TS among grade levels\\n\\nExample: from grade level 12 to grade level 4\\n\\nNo instances of 12-to-4 in the training set\\n\\nOther into 4 levels (e.g. 10-to-4, 6-to-4)\\n- BLEU\\n- SARI*\\n- Flesch\\n\\n12-to-4\\ns2s 44.56 37.56 79.50\\ns2s+to-grade 49.43 50.76 91.04\\ns2s+to-grade+zs 50.18 50.85 91.08\\n\\n6-to-5\\ns2s 69.71 26.47 84.74\\ns2s+to-grade 69.39 26.32 87.07\\ns2s+to-grade+zs 68.78 26.23 86.80\\n\\n11/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Conclusions: TS without target audience -> results not ideal"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Conclusions: TS without target audience -> results not ideal.\\n\\nUsing a simple artificial token with grade level to guide the encoder can improve the quality of TS.\\n- Enables target-audience-oriented simplifications.\\n- Enables zero-shot TS."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Conclusions: TS without target audience -> results not ideal.\\n\\nUsing a simple artificial token with grade level to guide the encoder can improve the quality of TS.\\n- Enables target-audience-oriented simplifications.\\n- Enables zero-shot TS.\\n\\nSimplification operation information can help improve classifier for the task.\\n\\nExplore multi-task learning."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Learning Simplifications for Specific Target Audiences\\nCarolina Scarton and Lucia Specia\\n{c.scarton, 1.specia}@sheffield.ac.uk\\nACL 2018, Melbourne, Australia: 13/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "References\\n- Johnson, M., Schuster, M., Le, Q.\\nV., Krikun, M., Wu, Y., Chen, Z., Thorat, N., Viégas, F., Wattenberg, M., Corrado, G., Hughes, M., and Dean, J. (2017).\\nGoogle's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation. TACL, 5:339-351.\\n- Nisioi, S., Stajner, S., Ponzetto, S. P., and Dinu, L. P. (2017). Exploring neural text simplification models.\\nIn Proceedings of ACL, pages 85-91."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 173,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Roadmap\\n\\nIntroduction to active learning (AL)\\n\\nMarkov decision process (MDP) for agent-based AL\\n\\nDeep imitation learning to train the AL policy\\n\\nExperiments & Analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Roadmap\\n\\nIntroduction to active learning (AL)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction\\n\\nRaw unlabeled data points X1, X2, ..., Xn\\nWe classify (X,\\nY) using Oracle/Expert: \"nN é (X22)\"\\nProvides labels for queries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "2 Introduction\\nAt any time during the AL process, we have a current guess for the classifier of Be-e-_@___- 69 6 -_eo ° e © oOze)o ° ©@e\\n\\nAL Strategy: Query the point closest to the decision boundary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "2 Introduction AL Heuristics (x,,?) (x,y)\\n- tt, Cewy ' Po<7 Ts AL Heuristics (x,,?) Ba)St (X2,Y2) [\" Oracle/Expert: Classifassinier a Provides labels for queries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Introduction\\nAL Agent (x,?)(X,Y)\\nClassifier Oracle/Expert: Provides labels for queries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Roadmap Markov decision process (MDP) for agent-based AL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "2 Agent-based Active Learning\\na AL Agent (x,?,) (x,y)\\noe aa ty, aa AL Agent (x,?,) Ba)\\nClassifier Oracle/Expert:\\na Provides labels for queries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "2AL Query Strategy by an Agent\\n\\nSY1, M7 = i => a, FFTFC; is Ciés Y Raw unlabeled data points x1, x2, ... a AL Agent (x?) we (xpyp @Pm\\n- Ga a, Od VY AL Agent (x?) Ba) so = GF; (Xp, Y2)\\n\\nThe Tutoring AL Oracle/Expert: Agent & Learning ms Provides labels for queries\\n\\nStudent (Classifier)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Agent Operates in Markov Decision Process\\nReward: Accuracy (6. Sez)\\nLearn the Optimal Query Policy R(s, at, s:+1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Roadmap: Deep imitation learning to train the AL policy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "2° e } eTraining Agent's Policy\\n\\nIDEA: Let's train the agent based on AL simulation for a rich-data task and then transfer it to AL problem of interest.\\n\\nThis is Meta-Learning: Learning to Actively Learn.\\n- Synthesize many AL problems.\\n- Use Imitation/Reinforcement Learning algorithms."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "= We =e = Oef\\n- opal Exper / Once ime\\n- a Expert Oace |: 3 opal Expert / Onceaan a -- Training Set\\n\\nTraining Set\\n\\nTraining Set\\n\\nwae Original Labeled Data\\n\\nPool of unlabeled data\\n\\nPool of unlabeled data\\n\\nPool of unlabeled data\\n\\nBK;plab, punt, pevly vp Ex, ) R(s:, av, 8141)| 1t=1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Imitation Learning\\n- The algorithmic oracle gives the correct action in each world state.\\n- Train the agent (policy network) to prefer the \"correct\" action compared to \"incorrect\" ones (i.e. classification)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Algorithmic Oracle: It computes the correct action in each world state.\\n- Re-train the underlying model using all possible queries/actions.\\n- Mark the one leading to the most accurate prediction on the evaluation set.\\n\\nAccuracy (Retrain Ors. Xie) in Pool: y ( + i\\ny) e e.\\n\\nToo slow for typical large pools of data.\\n\\nIDEA: Randomly sample a subset and maximize over it. Leads to efficient training and effective learned policies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Imitation Learning paccere\\n\\nThe collected state-action pairs are not i.i.d. hence problematic for classifier learning.\\n- Data Aggregation (DAGGER): Once in a while, use the predicted action by the policy network during training (Ross et al 2011).\\nThis is to make sure the policy sees bad states and the correct action to recover from them in the training time."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Roadmap Experiments & Analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Experiments (Task 1: text classification)\\n- Sentiment Classification: Positive/Negative sentiment of a review\\n- Train the AL policy on one product, and apply to the reviews of another.\\n- Authorship Profiling: Gender of the author of a tweet\\n- Train the AL policy on one language, and apply to another.\\n\\nsrc  tgt  number  avg. len. (tokens)\\nelec.  music  dev.  27k/1k  35/20\\nbook  movie  24k/2k  140/150\\nen  sp  3.6k/4.2k  1.15k/1.35k\\nen  pt  3.6k/1.2k  1.15k/1.03k"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Experiments (Baseline methods)\\n- Random sampling\\n- Uncertainty-based sampling\\n- Diversity-based sampling\\n\\nPAL (Fang et al., 2017): A deep reinforcement learning based approach, they designed a Q-network for stream-based AL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Experiments (Task 1: text classification)\\n\\nmusical device movie\\n\\nes\\n\\npt\\n0.9\\n0.80\\n0.75\\na.0.80\\n0.705\\na\\nA\\nde?\\n0.60s\\n0.6\\nLz\\na\\nli\\n0.55\\nptbe\\nrz\\n0.50\\n4os|\\ny7/\\n- 50.45\\n|0.4\\n0.400\\n25\\n50\\n75-100\\n0\\n25\\n50\\n75-100\\n0\\n50\\n100\\n150\\n200\\n0\\n50\\n100\\n150\\n200\\n\\nNum. Labeled Doc.\\n- Random\\n- Uncertainty\\n- Diversity\\n- Uncertainty-rationale\\n- PAL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "@Experiments (Task 1: text classification) 0.85. 0.8\\n- GF 075 jal: = direct transfer; 07 | Lisa cold-start ALo * warm-start ALo 0.65 0.6\\n\\n-musical movie Spanish Portuguese\\n- Direct transfer: Initialize the classifier on the source data, without AL.\\n- Cold-start: Start training the classifier from random initialization, continue training with AL agent.\\n- Warm-start: Start training the classifier from the pre-trained model on the source data, continue training with AL agent."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Experiments (Task 2: Named Entity Recognition)\\n- Data sets: CONLL 2002/2003\\n- Bilingual | Multilingual\\n\\ntgt src | tgt src\\nde en | de\\n- en, nl, es\\nnl en | nl\\nen, de, es\\nes en | es\\n- en, de, nl\\n\\nTable 2: Experimental settings for cross lingual NER, in which source language (src) is used for policy training."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Experiments (Task 2: Named Entity Recognition)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "@Analysis: Insight on the selected data movie sentiment gender pt NEResaces\\n\\nMRR Unc. 0.06 0.58 0.51\\n0.083 0.674 0.551 acc\\nDiv. 0.05 0.32 0.45\\nMRR = nies\\n- MRR\\nDiv. 0.057 0.593 0.530\\nacc PAL 0.15 0.56 0.52\\n\\nWe use MRR (Mean reciprocal rank) and acc to show the agreement of queried data points returned by our AL agent and other strategies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Analysis: Sensitivity to K (size of unlabeled subset)\\n\\nK: size of subset from the original unlabelled set in oa\\n- k=50\\n- k=10\\n- k=100\\n\\nNum. of labeled Sen."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Analysis: (schedule parameter for the policy)\\nTr = Brit + (1\\n- Br)ite\\n\\nOptions for B\\n- Fixed: B = 0.50\\n- Linear: B = max(0.5, 1\\n- 0.017)\\n- Exponential: B = 0.9\\n- Inverse sigmoid\\nNum. of labeled Sen."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Related work:\\n- Meta learning e.g. learning to learn without gradient descent by gradient descent (Chen et al., 2016).\\n- Stream-based AL as MDP; learning the policy with reinforcement learning (Fang et al.,\\n2017) suffers from the credit assignment problem (Bechman et al., 2017).\\n- Imitation Learning: Learning from expert demonstrations e.g. (Schaal, 2009; Abbeel & Ng, 2004; Silver et al., 2008)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusione\\n\\nUse heuristics or learn an agent for the AL query strategy.\\n- Agent-based AL as a Markov Decision Process.\\n- Formulate learning AL strategies/policies as an imitation learning problem.\\n- Our imitation learning approach performs better than previous heuristic-based and RL-based methods."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Thanks"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 115,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Key point: Syntactic Information\\n- To use or not to use?\\n- How to use?\\n- To what extent?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Key point: Syntactic Information\\n- To use or not to use?\\n- string-to-string model: Use implicitly\\n- tree/graph-to-string model: Use explicitly\\n- How to use?\\n- To what extent?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Key point: Syntactic Information\\n- To use or not to use?\\n- string-to-string model Use implicitly\\n- tree/graph-to-string model Use explicitly\\n- How to use?\\n- Change network structure Complicated\\n- Change model input Simple\\n- To what extent?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Key point: Syntactic Information\\n- To use or not to use?\\n- string-to-string model\\n- Use implicitly\\n- tree/graph-to-string model\\n- Use explicitly\\n- How to use?\\n- Change network structure\\n- Complicated\\n- Change model input\\n- Simple\\n- To what extent?\\n- One parsing tree\\n- Less information\\n- Multiple parsing trees\\n- More information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Background"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Sequence-to-sequence Model with Attention Mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Tree-based NMT: Change network structure\\n- Eriguchi et al. (2016) Yi"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Tree-based NMI: Change model input\\n- Li et al. (2017) hw: hw2 hwshw hwe hws 'Ab 'Als 'AbCG) (+) _Gaie = hw: -4hwo |\\n- | hws ni} IL-l hbwit hwetlhwall | Als Flt ol PP ab | love dogs || S NP PRN VP VBP NP NNS word RNN structural label RNN Parallel RNN encoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Tree-based NMT: Change model input\\nLi et al. (2017)\\nHow to represent syntactic information appropriately using a sequence?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Tree Linearization\\n- Vinyals et al. (2015)\\n\\nJohn has a dog.\\n- NP\\n\\nJohn has a dog.\\n- (S (NP NNP) (VP VBZ (NP DT NN)) )"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "John has a dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Our Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Overview\\n- Use syntactic information explicitly\\n- Do not use tree/graph-structured network\\n- Use multiple parsing trees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Overview\\n- Use syntactic information explicitly\\n- Do not use tree/graph-structured network\\n- Use multiple parsing trees\\n- Source Forest NMT\\n- Target Parsing Sequence (seq2seq)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Forest Linearization\\n- Packed forest is directed acyclic graph, not tree.\\n- Fixed traversal order does not exist.\\n- Topological sort?\\n- Outputs are not always optimal for MT.\\n- Important information may be lost.\\n- Word sequential information.\\n- Parent-child information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "(11) Sos Word sequential 5.8665 information PVP 4-6.7403 f*-18.1946! t-1.3092\\n\\nNPo, 3 \"INP > 4 INP 4PR eee [10]>[1]>[2]>...>[9]> [11] 1NNPo 'WBZi2 \"'DT23\"'NN3g \"45 Valid topological sort\\n\\nWords are disordered\\n\\nJohn has a dog,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Sos Parent-child information PVP\\n- 5.8665\\n- 4-6.7403\\n- f*-18.1946\\n- t-1.3092\\n\\nNPo1 MINP 4 \"INP 5480] | 4.7280\\n_____---15.0983\\n\\nNNPo: VBZi2 \"DT2,3'NN34 \"a5 Valid topological sort\\n\\nDistances between [2][9][10] John has a dog, and [11] vary a lot."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "function LINEARIZEFOREST((V, FE),\\nw)\\nv + FINDROOT(V)\\nre | EXPANDSEQ(v, r, (V, E),\\nw)\\nreturn r\\n\\nfunction FINDROOT(V)\\nfor v € V do\\nif v has no parent then\\nreturn v"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Word sequential procedure EXPANDSEQ(v, r, (V, £),\\nw) for € E do\\nif head(e) = v then\\nif tails(e) ~ @ then\\nfor t € SORT(tails(e)) do\\nEXPANDSEQ(t, r, (V, E),\\nw)\\nParent-child\\n- LINEARIZE EDGE(head(e),\\nw)\\nr.append((1, 0(0.0)))\\n- LINEARIZE EDGES(tails(e),\\nw)\\nr.append((1, a(score(e))))\\nelse\\n- LINEARIZE EDGE(head(e),\\nw)\\nr.append((/, 0(0.0)))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Linearization of Leaf nodes\\n\\nfunction LINEARIZEEDGE(X; w):\\nreturn X|®|(©j,_;\\nw)\\n\\nfunction LINEARIZEEDGES(v,\\nw)\\nreturn LINEARIZEEDGE(v, w)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "So, 55.8665 yp, -6.7403 [-18.1946 \"So. f -1.309221 NPo, : \"INP, 4 \"INP 4 -3.9490 f 4.7280 f.\\n_______--- 15.0983 \"NNPo, = 'VBZi2 \"'DTa3. 'NN34 Ml.\\n\\nJohn has a dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "m So. function LINEARIZEFOREST((V, E),\\nw) 5.8665 = v + FINDROOT(V) r\\n- |] EXPANDSEQ(v, r, (V, £),\\nw) IVP, 4 return r\\n- 6.7403 f *\\n- 18.1946 | Bg. 4! t\\n- 1.30922] NPo, : \"INP, 4 \"INP 4\\n- 3.9490 f | 4.7280 ______ --- f 5.0983 \" NNPo: 'VBZ 12 \"'DT 23, NN 3 y M 45 | | | | | John has a dog; NNP @ John / NP @ John / QNNP @ John / VBZ @ has / DT @ a / NN @ & dog / NP @ a @ dog / © DTS a SNN & dog / NP @ a @ dog / © DT @ a SNN @ dog / S @ a @ dog / © NP @ a © dog / VP @ has © a O dog | O VBZ @ has @ NP a @ dog / © VBZ Shas O @ S @ a O dog / .\\n& . / S ® John © has O © a © dog ©. | O © NPR John GVP Shas O a © dog. ® &."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "ms Sos procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\n\\nif head(e) = v then\\n\\nif tails(e) A 0 then\\n\\nfor t € SORT(tails(e)) do\\n\\nVP i 4 EXPANDSEQ(t, r, (V, E),\\nw)\\n\\n| + LINEARIZEEDGE(head(e),\\nw)\\n\\nsropemi(t oO) veh?gn mm Ne imetiinry,\\n\\n| + LINEARIZEEDGES(tails(e),\\nw)\\n\\nr.append((J, o(score(e))))\\n\\nelse, I\\n- LINEARIZEEDGE(head(e),\\nw)\\n\\nf\\n- r.append((J, 0(0.0)))\\n\\nNP,\\n\\n\"INP,\\n\\n\"INP,\\n\\nJohn has a dog\\n\\nNNP@John / NP@John / QNNP@John / VBZ@has / DT@a / NN@dog / NP@a@dog / DTSaSNN@dog / NP@a@dog / DT@aSNN@dog / S@a@dog / NP@a@dog / VP@has@a@dog / OVBZ@has@NPa@dog / VBZ@has@S@a@dog\\n\\nS John has a dog.\\n\\nONPSJohn@VP@hasOa@dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "ms Sos procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\nif head(e) = v then\\nif tails(e) A 0 then\\nfor t € SORT(tails(e)) do\\nr.append((J, 0(0.0)))\\nLINEARIZEEDGE(head(e),\\nw)\\nr.append((J, o(score(e))))\\nelse\\nLINEARIZEEDGE(head(e),\\nw)\\nr.append((J, 0(0.0)))\\n\\nfunction LINEARIZEEDGE(X;,;,\\nW)\\nreturn X @ (O22)\\n\\nJohn as a dog\\nNNP@John / NP@John / Q©NNP@John / VBZ@has / DT@a / NN@dog / NP@a@dog / ©DTSaSNN@dog / NP@a@dog / ©DT@aSNN@dog / S@a@dog / ©NP@a©dog / VP@has©aOdog\\nOVBZ@has@NP@dog / ©VBZ@hasO@S @aOdog\\nS®John©hasO©a©dog©.\\nO©NPR@JohnGVP@hasOa©dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\nif head(e) = v then\\nif tails(e) ≠ 0 then\\nfor t ∈ SORT(tails(e)) do\\nr.append(EXPANDSEQ(t, r, (V, EF), w))\\nr.append(LINEARIZEEDGE(head(e), w))\\nelse\\nr.append((J, o(score(e))))\\nelse\\nr.append((J, 0.0))\\n\\nfunction LINEARIZEEDGE(X,\\nW)\\nreturn X\\n\\nJohn has a dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "ms So. procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\n5.8665 fore\\nEdoif head(e) = v then if tails(e) A 0 then\\nfor t € SORT(tails(e)) do\\nVPi4 EXPANDSEQ(t, r, (V, E),\\nw)\\n+ LINEARIZEEDGE(head(e), w\\n6.7403 i 718.1946 sropemi(t oO) veh?ee eee\\n+ LINEARIZEEDGES(tails(e),\\nw)\\nr.append((J, o(score(e))))\\nelse,\\n- LINEARIZEEDGE(head(e),\\nw)\\nr.append((J, 0(0.0)))\\n1 4.7280\\nG33\\n'VBZi2 \"'DTn3 IA, 45\\nJohn has dog\\nNNP@John / NP@John / QNNP@John / VBZ@has / DT@a / NNP@dog /\\nNP@a@dog / DTSaSNN&dog / NP@a@dog / DT@aSNN@dog /\\nS@a@dog / NP@a@dog / VP@has@a@dog\\nOVBZ@has@NPa@dog / VBZ@hasO@S@a@dog / .&. /\\nS®John©hasO©a©dog©.\\nONPSJohn@VP@hasOa©dogO."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "ms Sos procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\nif head(e) = v then\\nif tails(e) A 0 then\\nfor t € SORT(tails(e)) do\\nVPi 4 EXPANDSEQ(t, r, (V, E),\\nw)\\n+ LINEARIZEEDGE(head(e),\\nw)\\n718.1946 sropemi(t oO) veh?porter nny nnn\\n+ LINEARIZEEDGES(tails(e),\\nw)\\nr.append((l, a(score(e))))\\nelse\\n- LINEARIZEEDGE(head(e),\\nw)\\nr.append((J, 0(0.0)))\\n\\nNP,\\n\"INP,\\n\"INP,\\n\\nJohn has a dog;\\nNNP@John / NP@John / QNNP@John / VBZ@has / DT@a / NNP@dog /\\nNP@a@dog / DTSaSNN&dog / NP@a@dog / DTSabNN&dog /\\nS®a©dog / ONPSa©dog / VP@has©aOdog\\nOVBZ@has@NPa@dog / VBZ@hasO@S@aOdog /\\n\\nS®John©hasO©a©dog©.\\nONPSJohn@VP@hasOa©dogO.®."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "ms So. procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\n5.8665 for e € Edo\\nif head(e) = v then\\nif tails(e) A 0 then\\n\\nfor t € SORT(tails(e)) do\\nVPi4 EXPANDSEQ(E, r, (V, FE),\\nw)\\n+ LINEARIZEEDGE(head(e),\\nw)\\n6.7403 {18.1946 a hopendf et) (head(e)®) peor trrr tyne\\n+ LINEARIZEEDGES (tails(e),\\nw)\\nr.append((l, a(score(e))))\\nelse\\n- LINEARIZEEDGE(head(e),\\nw)\\nr.append((J, 0(0.0)))\\n21 NPy} ! \"INP, 4\"\\n\"INP, 4\"\\nf i 47280 nee 20289\\n\\nfunction LINEARIZEEDGE(X,\\nw)\\nNNPo,1 VBZ} > DT)\\nNN34 0 UL\\nreturn X @ (©! wx)\\n\\nJohn has a dog;\\nNNP@John / NP@John / Q©NNP®John / VBZ@has / DT@a / NN@dog / NP@a@dog / ©DTSaSNNdof/ NPSaGdog / ©DTSabNN&dog / S®a©dog / ONPS$KoOdog / VP@has©aOdog\\n©OVBZ@has@NPRgdog / ©VBZShasO@S@aOdog / .&. /\\nS®JohnOhasO©a©dog©.\\nONPSJohn@VP@hasOa©dogO.®."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "ms So. procedure EXPANDSEQ(v, r, (V, EF),\\nw)\\nfor e € Edo\\nif head(e) = v then\\nif tails(e) A 0 then\\nfor t € SORT(tails(e)) do\\nVPi4 EXPANDSEQ(t, r, (V, E),\\nw)\\n+ LINEARIZEEDGE(head(e),\\nw)\\nr.append((7, 0(0.0)))\\nelse\\n- LINEARIZEEDGE(head(e),\\nw)\\nr.append((J, 0(0.0)))\\n\\nfunction LINEARIZEEDGES(v,\\nw)\\nreturn LINEARIZEEDGE(v,\\nw)\\n\\nJohn has a dog;\\nNNP@John / NP@John / QNNP@J@fin / VBZ@has / DT@a / NNP@dog / NP@a@dog / CDT Q@MBNN@dog / NP@a@dog / DT@a^SNNdog / S@aQ gos / ONPSa@dog / VP@has@aOdog\\nOVBAhasPNP@a@dog / VBZ@hasOS SaQ@e\\nS@JohnOhas@a@dog."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "SOE.\\n- at Decodertf Attention Layers\\n\\nHidden Layer\\n\\nEmbedding Layers\\n\\nPre-Embedding Layer\\n\\nNode/Operator Layer\\n\\nSymbol Layers\\n\\nScore Layer\\n\\nInput Layer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "SOE.\\n- Mae Decoder Attention Layer\\n\\nHidden Layer\\nEmbedding Layer\\nPre-Embedding Layer\\n\\nNode/Operator Layer\\nSymbol Layer\\nInput Layer ((lo,€0), +++; (lr, Er))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "a tf Attention Layer\\nFx 2\\n- Hidden Layer\\n- Embedding Layer\\n- Pre-Embedding Layer\\n- Node/Operator Layer\\n- Input Layer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "SOE -s- Decorft Attention Layers\\n\\nHidden Layer.\\n\\nLayer:\\n\\nRator Layers\\n\\nInput Layer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "- Hidden Layer\\n- Embedding Layer\\n- Pre-Embedding Layer\\n- Input Layer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "I Soe! sie > > | wn Decoder Attention Layer -- .. == a .. =.\\nHidden Layer i i i Embedding Layer 4 4, PEPkay a ay Pre-Embedding Layer p\\n- Wemb J (x) A 6 Bh 80minrtm on Om], Ww N \" ', wv Symbol Layer l= (lo, \"em lr) O LI [I Score Layer E\\n- (£0, vee Er) Input Layer ((lo, £0), ee, (lr, Er))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "0.9 x (emb(©) + emb(NNP) + emb(@) + emb(John))\\nPEPka> Al : edding Layer p= W emi [I (x)]ee / oan / Sn i wall 1, 0s ys 00,0 Oma) ve , Ww Symbol Layer ] = (Io, sey lr) to os pe (B= br)1/ L/ t/ Input Layer ((lo, 0), -- +5 (lr, &r))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "I Soe! Le > > | Le Decoderoon | exp(a(si-1, hy) Attention Layer i; = <TDy p-0 CXP(a(Si-1, he))-- .. == a .. =.\\nHidden Layer i i Embedding Layer au au é PEPkay a ay Pre-Embedding Layer p\\n- Wemb J (x) A 6 Bh 80 min rtmon Om]N Ww N \" ', wv Symbol Layer l= (lo, \"em lr) a Ld [I Score Layer E\\n- (£0, vee Er) Input Layer ((lo, £0),\\na) (lr, Er)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "SoA. se\\n- wn DecoderCeo Attention Layer Qi = exp (Galsinas fy)a fl os dk=0 CXP(Ena(Si-1, Re)a\\n\\n= = <= =o Hidden Layeri J ; i ', i Embedding Layer/ \\, PEPKi : % Pre-Embedding Layer p= Wemb J (x)|CB Beano ns\\ Ww \\ ve Ww Symbol Layer l= (J Osee*s ly)a * O Score Layer E\\n- (£0, vee Er)L Input Layer ((lo, £0),\\na) (lr, Er))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "SoA.\\n\" > Decoder- | a expSjalsi-t, hj) 10.9 x a x hidden (©NNP ® John) Dio xP(6(5i-1, Me) | (emb(©) + emb(NNP) + emb(®) + emb(John)) mere: ) er | DP = Wemb (x)oes / eo (C) NN & John I saver 9 ep ESL/ || 1/ Input Layer ((lo, £0), aw y (lp, Er))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Data Language Sent train 100,000 English-Japanese ASPEC dev. 1,790 test 1,812 LDC train 1,423,695 FBIS ral 233,510.\\nNIST MT 02 876 English-Chinese NIST MT 03 919 NIST MT 04 test 1,788 NIST MT 05 1,082"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "System Systems & MT 03 MT 04 MT 05\\n\\nTypes Configurations | FBIS LDC FBIS LDC FBIS'~ LDC\\n\\nMiet al. (2008) | 27.10 28.21 28.67 30.09 26.57 28.36\\n\\nPrevi Eriguchi et al. (2016) | 29.00 29.71 30.24 31.56 28.38 30.33\\n\\nFEVIOUS | TN Chen et al. (2017) | 28.34 29.64 30.00 31.25 28.14 29.59\\n\\nLiet al. (2017) | 28.40 29.60 29.66 31.96 27.74 29.84\\n\\n27.44 | 29.18 29.73 30.53 27.32 28.80\\n\\n1-best (No score)\\n\\nJ 28.61 J 29.38 30.07 31.58 28.59 30.01\\n\\nTM 1-best (SoE)\\n\\n§ 28.78 | 30.65 30.36 32.22 29.31 30.16\\n\\nOurs 1-best (SoA)\\n\\nJ 29.39 J 30.80 30.25 32.39 29.30 30.61\\n\\nForest (No score)\\n\\n§ 28.06 J 29.63 29.51 31.41 28.48 29.75\\n\\nFN Forest (SoE)\\n\\nJ 29.58 | 31.07 30.67 32.69 29.26 30.41\\n\\nForest (SoA)\\n\\n§ 29.63 | 31.35 30.31 33.14 29.87 31.23\\n\\ne s2s is the worst- Syntactic information is useful\\n\\nEnglish-Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "System Systems & MT 03 MT 04 MT 05 Types Configurations | FBIS LDC FBIS LDC FBIS'~ LDC Mi et al.\\n(2008) | 27.10 28.21 28.67 30.09 26.57 28.36\\n\\nPrevi Eriguchi et al. (2016) | 29.00 29.71 30.24 31.56 28.38 30.33\\n\\nFEVIOUS | TN Chen et al. (2017) | 28.34 29.64 30.00 31.25 28.14 29.59\\n\\nLi et al. (2017) | 28.40 29.60 29.66 31.96 27.74 29.84\\n\\n27.44 29.18 29.73 30.53 27.32 28.80\\n\\n1-best (No score) | 28.61 § 29.38 § 30.07 31.58 28.59 30.01\\n\\nTM 1-best (SoE) | 28.78 § 30.65 § 30.36 32.22 29.31 30.16\\n\\nOurs 1-best (SoA) | 29.39 J 30.80 J 30.25 32.39 29.30 30.61\\n\\nForest (No score) | 28.06 29.63 29.51 J 31.41 J 28.48 29.75\\n\\nFN Forest (SoE) | 29.58 31.07 30.67 § 32.69 § 29.26 30.41\\n\\nForest (SoA) | 29.63 31.35 30.31 J 33.14 § 29.87 31.23\\n- s2s is the worst\\n- Syntactic information is useful\\n- No score is the worst English\\n- Score is useful Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "System Systems & MT 03 MT 04 MT 05\\n\\nTypes Configurations | FBIS LDC FBIS LDC FBIS LDC\\n\\nMi et al. (2008) | 27.10 28.21 28.67 30.09 26.57 28.36\\n\\nPrev Eriguchi et al. (2016) | 29.00 29.71 30.24 31.56 28.38 30.33\\n\\nFEVIOUS | TN Chen et al. (2017) | 28.34 29.64 30.00 31.25 28.14 29.59\\n\\nLi et al. (2017) | 28.40 29.60 29.66 31.96 27.74 29.84\\n\\n27.44 29.18 29.73 30.53 27.32 28.80\\n\\nl-best (No score) | 28.61 29.38 30.07 31.58 28.59 30.01\\n\\nTM l-best (SoE) | 28.78 30.65 30.36 32.22 29.31 30.16\\n\\nOurs l-best (SoA) | 29.39 30.80 30.25 32.39 29.30 30.61\\n\\nForest (No score) | 28.06 29.63 29.51 31.41 28.48 29.75\\n\\nFN Forest (SoE) | 29.58 31.07 30.67 32.69 29.26\\n\\nForest (SoA) | 29.63 31.35 30.31 33.14 29.87 31.23\\n- SoA is better than SoE\\n- Adjusting attention is better than adjusting word embedding\\n- Forest is better than l-best English\\n- More syntactic information is useful Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "System Systems & MT 03 MT 04 MT 05 Types Configurations | FBIS LDC FBIS LDC FBIS LDC Mi et al.\\n(2008) | 27.10 28.21 28.67 30.09 26.57 28.36\\n\\nEriguchi et al. (2016) | 29.00 29.71 30.24 31.56 28.38 30.33\\n\\nTN Chen et al. (2017) | 28.34 29.64 30.00 31.25 28.14 29.59\\n\\nLi et al. (2017) | 28.40 29.60 29.66 31.96 27.74 29.84\\n\\nI-best (No score) | 28.61 29.38 30.07 31.58 28.59 30.01\\n\\nTN 1-best (SoE) | 28.78 30.65 30.36 32.22 29.31 30.16\\n\\nOurs 1-best (SoA) | 29.39 30.80 30.25 32.39 29.30 30.61\\n\\nForest (No score) | 28.06 29.63 29.51 31.41 28.48 29.75\\n\\nForest (SoE) | 29.58 31.07 30.67 32.69 29.26 30.04\\n\\nForest (SoA) | 29.63 31.35 30.31 33.14 29.87 31.23\\n- Forest (No score) is worse than 1-best (SoE/SoA)\\n* Influence of noise English-Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "System Systems & MT 03\\nMT 04\\nMT 05\\n\\nTypes Configurations | FBIS LDC\\nFBIS = LDC Miet al. (2008) | 27.10 28.21 928.67\\n30.09 26.57 28.36\\nEriguchi et al. (2016) | 29.00 29.71 930.24\\n31.56 28.38 30.33\\nFEVIOUS | TN Chen et al. (2017) | 28.34 29.64 [30.00]\\n31.25 28.14 29.59\\nLiet al. (2017) | 28.40 29.60 [29.66]\\n31.96 27.74 29.84\\n2744 2918 29.73 30.53\\n27.32 28.80\\nI-best (No score) | 28.61 29.38 30.07\\n31.58 28.59 30.01\\nTN l-best (SoE) | 28.78 30.65 930.36\\n32.22 29.31 30.16\\nOurs 1-best (SoA) | 29.39 30.80 930.25\\n32.39 29.30 30.61\\nForest (No score) | 28.06 29.63\\n9.\\n31.41 28.48 29.75\\nFN Forest (SoE) | 29.58 31.07 30.67\\n32.69 29.26 30.41\\nForest (SoA) | 29.63 31.35 30.31\\n33.14 29.87 31.23\\n- Forest (No score) is worse than 1-best (SoE/SoA)\\n- Influence of noise\\n- FS/TN is worse than 1-best (SoE/SOA)\\n- English-- Better to use score in linearization\\n- Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "English-Japanese P\\n- s2s is the worst\\nSystem Systems & | BLEU\\n- No score is the worst\\nTypes Configurations | (test)\\n- SoA is better than SoE\\nMiet al. (2008) | 34.13\\nPrevious Frguchi et al. (0016) | 37.35\\nForest is better than 1-best\\nTN Chen et al. (2017) | 36.94\\n- Forest (No score) is worse\\nLiet al. (2017) | 36.21 than 1-best (SoE/SoA)\\n37.10 | I-best (No score) 38.01 = FS/TN is worse than 1-best\\nTN 1-best (SoE) | 38.53 (SoE/SoA)\\nOurs 1-best (SoA) | 39.42\\nForest (No score) | 37.92\\nFN Forest (SoE) | 41.35\\nForest (SoA) | 42.17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Merits & Demerits\\n- Use syntactic information explicitly\\n- Simpler model, more information\\n- Robust to parsing errors\\n- Lots of sentences are filtered out due to lengths\\n- Memory consumption\\n- Training/decoding efficiency\\n- Implementation tricks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Conclusion\\n\\nFirst attempt to use forest in neural machine translation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Thanks Q&A"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 188,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Main points of this talk:\\n1. Introducing Scholar: a neural model for documents with metadata\\nBackground (LDA, SAGE, SLDA, etc.)\\nModel and related work\\nExperiments and Results\\n2. Power of neural variational inference for interactive modeling\\nSparse Contextual Hidden and Observed Language Autoencoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Latent Dirichlet Allocation\\n\\nTopics Documents state one\\n\\nSeeking Life's Bare (Genetic) Necessities\\n\\nDavid Blei, Ng, and Jordan. Latent Dirichlet Allocation. JMLR.\\n2003.\\n\\nDavid Blei. Probabilistic topic models. Comm. ACM. 2012."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "e Date or time\\nAuthor(s)\\nRating\\nSentimente\\nIdeology\\netc.\\n3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "- Author topic model (Rosen-Zvi et al,\\n2004)\\n- Supervised LDA (SLDA; McAuliffe and Blei,\\n2008)\\n- Dirichlet multinomial regression (Mimno and McCallum,\\n2008)\\n- Sparse additive generative models (SAGE; Eisenstein et al,\\n2011)\\n- Structural topic model (Roberts et al, 2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Desired features of model\\n\\nFast, scalable inference.\\n\\nEasy modification by end-users."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Fast, scalable inference.\\nEasy modification by end-users.\\n\\nIncorporation of metadata:\\n- Covariates: features which influence text (as in SAGE).\\n- Labels: features to be predicted along with text (as in SLDA).\\n- Possibility of sparse topics.\\n- Incorporate additional prior knowledge."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "e Fast, scalable inference.\\ne Easy modification by end-users.\\n\\nIncorporation of metadata:\\n- Covariates: features which influence text (as in SAGE).\\n- Labels: features to be predicted along with text (as in SLDA).\\n- Possibility of sparse topics.\\ne Incorporate additional prior knowledge.\\n- Use variational autoencoder (VAE) style of inference (Kingma and Welling, 2014)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Coherent groupings of words (something like topics), with offsets for observed metadata"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Coherent groupings of words (something like topics), with offsets for observed metadata\\n\\nEncoder to map from documents to latent representations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Coherent groupings of words (something like topics), with offsets for observed metadata.\\n\\nEncoder to map from documents to latent representations.\\n\\nClassifier to predict labels from latent representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "mT 4 generator network: p(w | 6;) = fy(-)COT wordsY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "COED 6/€a*ap(O; |\\nw) : | generator network: p(w | 6)) = fy(-) CORO words8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Or 6 €a*aeet | generator network: p(w | 6;) = fy(-)COCO words9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Or 6 €a*aeet | generator network: p(w | 6;) = fy(-)COCO words ELBO = E[log p(words | 0;)]\\n- Dicz[a(0; | words) | (6;)]10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "CT TT words encoder network: q(6; |\\nw) = fe(-)Or 6 €a* generator network: p(w | 6;) = fy(-)COCO words ELBO = E[log p(words | 0;)]\\n- Dicz[a(0; | words) | (6;)]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "CUT TT words encoder network: p(w |\\nr) = fe(-)BOM nex | 0; = softmax(r) mT generator network: p(w |\\nr) = fy(-)COT words ELBO = E[log p(words | r)]\\n- Dxi[q(r | words) || p(r)]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "CUT TT words encoder network: (6; |\\nW) = fe(-)Bo eR| 0; = softmax(r))GO 4 € 4* generator network: p(w | 6;) = fy(-)COT words ELBO ~ 273, [log p(words | r!)]\\n- Dict.[q(ri | words)||p(r)]13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "CUT TT words ~ N(0,\\n1) | encoder network: q(r |\\nw) = fe(-) ~ BLM One rR = ug + e\" 0, 0; = softmax(r)\\n\\ngenerator network: p(w |\\nr) = fy(-)COT words ELBO ~ 273, [log p(words | r)]\\n- Dict. [q(r | words) || p(r)]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "CT TT words N(O,\\n1) | encoder network: q(; |\\nW) = fe(-)BOM ek = 15 + 00, | 0; = softmax(r))Go 4a* | generator network: p(w | 6;) = fy(-)CUT TT words Srivastava and Sutton, 2017, Miao et al, 2016"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "COST TT wordsée N(0,\\n1) | encoder network: q(θ |\\nW) = f(θ) BOD ee = 4, +2 00, | 0; = softmax(r) Go 4€a*A | generator network: p(w | θ) = f(θ) YOO COSTE words"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "CT TT words N(0,) | encoder network: q(@; |\\nW) = fe(:) BOM 1 E% = u, +600, | 0; = softmax(rj) cao Or 6 € a * | rN | generator network: p(w | 6;) = fy(-) yO = CORBCTO words"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "CT TT words, ci, yiée~ N(0,\\n1)\\n\\nencoder network: q(6; |\\nw) = fe(-)BOM\\nEe = u, +6\" 004 | 0; = softmax(rj) co } = 6om cat | rN\\n\\ngenerator network: p(w | 6;) = fy(-) YOO COSTE words"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Generator network: p(word | 6,\\n- ;) = softmax(d + 67 Bltoric) + CHB)20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Generator network: p(word | 6,\\n- ;) = softmax(d + 67 Bltoric) + CHB) Optionally include interactions between topics and covariates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Generator network: p(word | 6;,\\n- ;) = softmax(d + 67 Bltoric) + CHB) Optionally include interactions between topics and covariates p(y | 9:, c1) = fy(9:, ci)20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Generator network: p(word | 6,\\n- ;) = softmax(d + 67 Bltoric) + CHB)\\n\\nOptionally include interactions between topics and covariates p(y | 9:, c1) = fy(9:, ci)\\n\\nEncoder: yj = f(words,\\n- ;, yi)\\n\\nlogo; = f(words, cj, yi)\\n\\nOptional incorporation of word vectors to embed input"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Optimization: Stochastic optimization using mini-batches of documents. Tricks from Srivastava and Sutton, 2017:\\n- Adam optimizer with high learning rate to bypass mode collapse.\\n- Batch-norm layers to avoid divergence.\\n- Annealing away from batch-norm output to keep results interpretable."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Output of Scholar@ Bltopic) B(ov). Coherent groupings of positive and negative deviations from background (~ topics) 22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Output of Scholar@ Btopic) B(ov).\\nCoherent groupings of positive and negative deviations from background (~ topics) @ f,,,f,: Encoder network: mapping from words to topics: 6; = softmax(f.(words, c, y;, €)) 22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Output of Scholar@ Bltopic) B(ov).\\nCoherent groupings of positive and negative deviations from background (~ topics)@ f,,,f,: Encoder network: mapping from words to topics: 6 = softmax(f.(words, c;, yi, €)) e f,: Classifier mapping from 6; to labels: 7 = fy (Gi;\\n6) 22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "1. Performance as a topic model, without metadata (perplexity, coherence)\\n2. Performance as a classifier, compared to SLDA\\n3. Exploratory data analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Quantitative results: basic model\\n2000\\nPerplexity 100\\nCoherence 0.0\\nSparsity 95\\n\\nLDA SAGE IMDB dataset (Maas,\\n2011)\\n25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Quantitative results: basic model\\n\\n2000\\n\\nPerplexity 100000.2\\n\\nCoherence 00\\n\\ncS Sparsity 95 if 00\\n\\n\"LDA SAGE\\n- NVDM IMDB dataset (Maas,\\n2011)\\n\\n26"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Quantitative results: basic model\\n\\n2000\\n\\nPerplexity 100000.2\\n\\nCoherence 0\\n\\nSparsity 95\\n\\nLDA\\n\\nSAGE\\n\\nNVDM\\n\\nScholar\\n\\nIMDB dataset (Maas, 2011)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Quantitative results: basic model\\n\\n2000\\n\\nPerplexity 100000.2\\n\\nCoherence 00\\n\\n=Sparsity 95\\n\\nif 0.0\\n\\nLDA SAGE NVDM_ Scholar Scholar+WVI\\n\\nMDB dataset (Maas,\\n2011) 28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Quantitative results: basic model\\n\\n2000\\n\\nPerplexity 100000.2\\n\\nCoherence 00\\n\\n=~ i LJ0.0\\n\\nLDA\\n\\nSAGE\\n\\nNVDM_ Scholar\\n\\nScholar\\n\\nScholar+wv\\n\\n+sparsity\\n\\nIMDB dataset (Maas,\\n2011)\\n\\n29"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Classification results\\n1.00\\n0.9\\np08\\n©\\n5OooOf07\\nLO\\n0.5\\n»LR SLDA Scholar Scholar\\n(labels) (covariates)\\nIMDB dataset (Maas,\\n2011)\\n30"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Exploratory Data Analysis\\n\\nData: Media Frames Corpus (Card et al,\\n2015)\\n\\nCollection of thousands of news articles annotated in terms of tone and framing.\\n\\nRelevant metadata: year of publication, newspaper, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Tone as a label\\n\\nEnglish language city Spanish community\\n\\nBoat desert died men miles coast Haitian\\n\\nVisas visa applications students citizenship asylum judge appeals deportation court labor jobs workers percent study wages\\n\\nBush border president bill Republicans state gov benefits Arizona law bill bills\\n\\nArrested charged charges agents operation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Base topics\\n- Anti-immigration\\n- Pro-immigration\\n- Customs agency\\n- Criminal customs detainees\\n- Detention population\\n- Born percent jobs million illegals\\n- English newcomers\\n- Judge case court guilty guilty charges\\n- Man\\n- asylum court judge\\n- Patrol border miles\\n- Patrol border died authorities desert\\n- Licenses drivers card foreign\\n- Sept visas green citizenship card\\n- Island story Chinese smuggling federal\\n- Island school Ellis\\n- Guest worker workers bill\\n- Border house workers tech skilled\\n- Benefits bill welfare\\n- Republican California law welfare students"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Variational autoencoders (VAEs) provide a powerful framework for latent variable modeling.\\nWe use the VAE framework to create a customizable model for documents with metadata.\\nWe obtain comparable performance with enhanced flexibility and scalability.\\n\\nCode is available: www.github.com/dallascard/scholar34"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 198,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Motivation\\n- Algorithm\\n- Experiments\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Outline\\n- Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Relation Extraction\\n\\nRelation Type with Labeled Dataset\\n\\nPlain Text C + Entity-Relation Triple\\n\\nPlain Text Corpus: Entity-Relation Triple (Unstructured Info) > Classifier\\n- (Structured Info)\\n\\nRelation Type without Labeled Dataset"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Distant Supervision\\n\\n\"If two entities participate in a relation, any sentence that contains those two entities might express that relation.\" (Mintz, 2009)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Distant Supervision Freebase Data (x):\\n\\n<Belgium, Nijlen> Label (y): /location/contains\\n\\nRelation Label: /location/contains\\n\\nSentence Bag: Nijlen is a municipality located in the Belgian province of Antwerp."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Wrong Labeling\\n- Within-Sentence-Bag Level: Hoffmann et al., ACL 2011\\n- Surdean et al., ACL 2012\\n- Zeng et al., ACL 2015\\n- Li et al., ACL 2016\\n- Entity-Pair Level: None"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Wrong Labeling: Place of Death (William O'Dwyer, New York City)\\n\\nSome New York City mayors\\n- William O'Dwyer, Vincent R. Impellitteri and Abraham Beame\\n- were born abroad.\\n\\nEntity-Panel events have, too, including two New York City mayors, James J.\\nWalker, in 1932, and William O'Dwyer, in 1950."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Wrong Labeling\\n\\nMost of entity pairs only have several sentences\\n\\nOther"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Outline\\n- Algorithm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Overview\\nDS Dataset\\nCleaned Dataset\\nIN (eee Mom\\nIN (eS-e TomIe ioe a ee oe eee\\n|aT 1\\nFalse Positive\\n|Positive set\\n--------\\n3\\nFalse Positi\\nPositive set\\n|\\nFalse Positive\\n|\\n»\\nIndicator\\n11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Requirements\\n\\nFalse-Positive Indicator\\n\\nSentence-Level Indicator\\n\\nWithout Supervised Information\\n\\nGeneral Purpose and Offline Process\\n\\nLearn a Policy to Denoise the Training Data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Overview DS Dataset Cleaned Dataset IN yee Mom = 1 y Classifier IN e-era Moet 8irae\\n- I Reward oewoe we! owen aes Positive | Positive set Action  at Ise. Positive set | Poli 2 \" Based Agent\\n- I h icator 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Deep Reinforcement Learning\\n\\nState = Sentence vector = The average vector of previous removed sentences\\n\\nAction = Remove & retain\\n\\nReward = ???"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Deep Reinforcement Learning\\n\\nOne relation type has an agent\\n\\n* Sentence-level\\n* Positive: Distantly-supervised positive sentences\\n* Negative: Sampled from other relations\\n\\nSplit into training set and validation set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Deep Reinforcement Learning\\n\\nNoisy dataset\\n\\nEpoch 1\\n\\nRelation Fit RL Agent dataset\\n\\nClassifier"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Rewardent = AccurateRN\\neee = Steady\\n= Fast-\\n= \"Obvious Positive Set\\nNegative Set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Epoch iPositive Negative-a eeeeeee, nrs\\ni | i! 1I I\\n1) i; f iI I I I ete Z I; I 1!\\n1ne1 I; False Positive I I| Train ;II Train P I : ;i s Relation | Relation i' Classifier | ClassifierI I|| coma' I ' I\\nPositive Set Negative Set ! I I© eee eee eee I F,18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Outline\\n- Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Evaluation on a Synthetic Noise Dataset\\n\\nDataset: SemEval-2010 Task 8\\n\\nTrue Positive: Cause-Effect\\n\\nFalse Positive: Other relation types\\n\\nTrue Positive + False Positive: 1331 samples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Evaluation on a Synthetic Noise Dataset\\n\\n200 FPs in 1331 Samples\\n\\n0.685\\n\\n0.68\\n\\nners (180/279) (179/260)\\n\\nne (195/308)\\n\\n5 0.665\\n\\nA ogg f (197/339)\\n\\n0.655\\n\\n0.65\\n\\n0.645\\n\\n* (198/388)\\n\\nate fs 30 40 50 60 70 80 90 100\\n\\nFalse Positive Removed Part Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Evaluation on a Synthetic Noise Dataset\\n\\nFPs in 1331 samples\\n\\n0.75 0.74 (0/32) 0.73 (0/59) 5 0.724 on (0/121) 07 (0/150) 0.69 (0/258) 0.68\\n\\n10 20 30 40 50 60 70 80 90 100 Epoch"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Distant Supervision Dataset: Riedel et al., 2010 = http://iesl.cs.umass.edu/riedel/ecml/\\n- CNN+ONE, PCNN+ONE: Distant supervision for relation extraction via piecewise convolutional neural networks.\\n(Zeng et al.,\\n2015)\\n- CNN+ATT, PCNN+ATT: Neural relation extraction with selective attention over instances. (Lin et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Distant Supervision\\n\\nCNN-based\\n\\n1-CNN+ONE 0.9\\n-CNN+ONE_RL\\n-CNN+ATT 0.8\\n-CNN+ATT_RL 0.7\\n\\nNace 0.6\\nSS~ a tee 0.4\\n0.05\\n0.1\\n0.15\\n0.2\\n0.25\\n0.3\\n0.35\\n0.4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Distant Supervision\\n\\nPCNN-based\\n\\n1-PCNN+ONE 0.9\\n\\n-PCNN+ONE_RL\\n\\n-PCNN+ATT 0.8\\n\\n-PCNN+ATT_RL 0.7\\n\\nhy A 0.6\\n\\n=, SS 0.5\\n\\n= Sl \"Se 0.4\\n\\n0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Outline\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusion: We propose a deep reinforcement learning method for robust distant supervision relation extraction.\\nOur method is model-agnostic. Our method boosts the performance of recently proposed neural relation extractors."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Thank you! Q&amp;A"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 85,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "(m Motivatione What action causes this?aA =P | . 'aiax z="
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Pr(& Motivation\\n- What is the result state of \"open box\"? €Sy)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Understanding Cause-Effect\\n\\nThe developing understanding that one event brings about another.\\n\\nAt around eight months of age, children perform simple actions to make things happen, notice the relationships between events, and notice the effects of others on the immediate environment.\\n\\nAt around 18 months of age, children combine simple actions to cause things to happen or change the way they interact with objects and people in order to see how it changes the outcome.\\n\\nAt around 36 months of age, children demonstrate an understanding of cause and effect by making predictions about what could happen and reflect upon what caused something to happen.\\n(California Department of Education [CDE]\\n2005)\\n\\nFrom: cde.ca.gov. (California Department of Education)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Naive Physical Action-Effect Prediction Action to Effect"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Naive Physical Action-Effect Prediction\\n\\nEffect to Action\\n\\nAction x | Action x (peel-carrot) (juice-carrot) => Action x\\n\\nAction V (grate-carrot) (chop-carrot)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Related Work\\n- The NLP community: Most existing studies focus on the causal relations between high-level events.\\nE.g., \"the collapse of the housing bubble\" causes the effect of \"stock prices to fall\" (Yang and Mao, 2014; Sharp et al., 2016).\\n- This paper studies the basic cause-effect knowledge related to concrete actions and their effects to the world.\\n- Recent advances in Computer Vision and Robotics:\\n- Object physical state prediction (Zhou and Berg, 2016; Wu et al., 2017).\\n- Action recognition through detection of state changes (Yang et al., 2013).\\n- Robot following natural language commands (She et al., 2014; Misra et al., 2015)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "® This Work\\n- Introduce a new task on physical action-effect prediction and create a dataset for this task.\\n- Data collection and analysis\\n- Propose an approach that harnesses the large amount of image data available on the web with minimum supervision.\\n- Web images acquisition\\n- Bootstrapping strategy\\n- Automatic prediction of effect knowledge for novel actions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Om Action-Effect Data\\n- Actions (Verb-Noun Pairs)\\n\\n140 verb-noun pairs\\n- 62 unique verbs (e.g., bend, boil, chop, crack, fold, grind, ignite, kick, peel, soak, trim)\\n- 39 unique nouns (e.g., apple, baseball, book, car, chair, cup, flower, orange, shoe)\\n- Effects\\n\\nEffects described in language\\n- Effects depicted by images"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "2 | | Effects Described in Language\\n- Action effect is often presupposed in our communication and not explicitly stated.\\n- Crowd-sourcing data collection\\n- Workers were shown a verb-noun pair, and were asked to describe what changes might occur to the object as a result of the action.\\n- 1400 effect descriptions (10 for each verb-noun pair)\\n- Examples:\\n\\nAction\\n- Effect Text =\\n- ignite paper The paper is on fire.\\n- soak shirt The shirt is thoroughly wet.\\n- fry potato The potatoes become crisp and golden.\\n- stain shirt There is a visible mark on the shirt."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "na; Effects Depicted by Images\\n\\nHuman labeled image set: 4163 images (Data available on the project webpage.)\\n- Positive images are those capturing the resulting world state of the action.\\n- Negative images are those deemed to capture some state of the related nouns, but are not the resulting state of the corresponding action.\\n\\nAction: Fry-Egg\\n\\nPositive: 2\\nNegative: 4 = os13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "av'(& Web Search Images\\n- Searching keywords: phrases extracted from language effect descriptions\\n- Phrases were extracted using syntactic patterns: Example patterns\\n\\nExample Effect Phrases (bold) extracted from effect descriptions\\n\\nVP with a verb {be, become, turn, get}\\nThe ship is destroyed.\\n\\nVP + PRT\\nThe wall is knocked off.\\n\\nVP + ADVP\\nThe door swings forward.\\n\\nADJP\\nThe window would begin to get clean.\\n\\nbook\\nbook is on fire\\nbook is set aflame"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Bootstrapping Approach\\n\\nWeb Search Images Prediction\\n\\nResNet\\n\\nAction 1\\n\\nBPR\\n\\nAction 2\\n\\nBootstrapping\\n\\nCross-Entropy Loss\\n\\nSeeding Images Prediction\\n\\nAction 1\\n\\nAction 2\\n\\nCross-Entropy Loss: L(t,\\nq) = Σ t; log (qi) i=1\\n\\nBootstrapping Cross-Entropy Loss: L(t,\\nq) = (Bt; + (1\\n- 𝛼) Σ | log (qi) (Reed et al.,\\n2014) i=145"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "nsr | ® Evaluations\\n- Human annotated image data: use 10% as seeding images (training), 30% for development and 60% for test.\\n- On average, each verb-noun pair only has 3 seeding images.\\n- Web search images: over 60,000 images were downloaded using around 2,000 effect phrases as searching keywords.\\n- Methods for comparison\\n- Seed\\n- Seed + Act + Eff\\n- BS + Seed + Act + Eff\\n\\nBS: bootstrapping approach; Seed: seed images; Act: web images downloaded using verb-noun as keywords; Eff: web images downloaded using effect phrases as keywords."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Frf |® Evaluation Results\\n\\nAction to Effect: MAP Top 5 Accuracy\\n4 0.29\\nas \"7025\\n0.247\\n07 0.679\\n0.629\\na2 0.182\\n7 a6\\n[| |Q15 [od as\\nEffect to Action: Micro F1 Score\\nMacro F1 Score\\na3 0.272\\na30.21265\\nw o.1g9\\n9.207\\nQ1 oO i\\na1 0.062\\n| |3 3\\n7@ Seed\\nMSeed+Act-Eff\\nTM&BS+tSeed+Act+tff\\n17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "rau'(& Examples Top Action Top Action Predictions Predictions bite apple fry egg background background/ cut apple crack egg peel apple mix eggs\\n- 4 aews 5 background background.\\n| chop carrot wee insert key grate carrot close drawer | peel carrot \"a fasten door background pile books cut potato background fry potato wrap book mash potato roll paper 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Examples\\n\\nTop Action\\n\\nTop Effect\\n\\nPredictions\\n\\nbite apple\\napple is eaten\\n\\nfry egg\\negg into a harder background\\napple is being cut\\nbackground substance\\ncut apple\\napple is chewed\\n\\ncrack egg\\ncup into smaller pieces\\n\\npeel apple\\napple in tiny pieces\\n\\nmix eggs\\negg edible\\n\\nbackground\\n\\ncarrot into tiny pieces\\nbackground key in the keyhole\\n\\nchop carrot\\ncarrot is being cut\\n\\ninsert key\\ndrawer without a key\\n\\ngrate carrot\\ncarrot into many smaller pieces\\n\\nclose drawer\\ndoor is locked\\n\\npeel carrot\\npieces fasten door\\ndoor is being bolted\\n\\nbackground\\n\\npotato into a pot\\npile books\\nbooks in a stack\\n\\ncut potato\\npotato is being sliced\\nbackground\\n\\nbook on\\n\\nfry potato\\npotato for wrap\\n\\nbook\\nbooks in a large stack\\n\\nmash potato\\npotato edible\\n\\nroll paper\\nbooks in a pile"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Examples eggs beat me argue beat us (0.783 | BD gts bite apple | 0.484 apple bite apple son om | @ Bree_"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Examples: eggs, beatae, osbeateges, apple, bite, apples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "navS, & Handling Unseen Verb-Noun Pairs\\n\\nGeneralize effect knowledge to new verb-noun pairs through an embedding model.\\n- Action Effect: slice apple into many small pieces\\n- V 4 4 sy oYLSTM ~> Sw...\\n- Cosine Embedding Loss\\n- Action-Effect Embedding trained from seed knowledge"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Handling Unseen Verb-Noun Pairs\\n\\nGeneralize effect knowledge to new verb-noun pairs through an embedding model.\\nA New Action Effect phrases (ignite-paper) paper is being charred, slice apple into many small pieces paper is being burned, paper is set, paper is being destroyed, LSTM -> LS gd soospaper is litLT.\\n\\nAction-Effect Embedding trained from seed knowledge: Bins23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Cei e® Evaluation Results\\n\\nAction to Effect:\\nMAP Top B dieu racya 0.507 0.529\\nTRSy 928 a 0.369 a 0.7860 a (p<0.05)\\n\\nEffect to Action:\\nMicro F1 Score\\nMacro F1 Score\\n0.472 0.926\\n0.392 0.378\\n0.278 0.402\\n0.179 (p<0.05)\\n\\nMSeed\\nMTMBS + tSeed + Act + pEff\\nmM BS + tSeed + Act + tff pEff: web images downloaded using the predicted effect phrases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "eMr i | ( ® Action-Effect Embedding Space GloVe Verb GloVe Verb + Noun Action-Effect 25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "eMr i i(® Action-Effect Embedding Space GloVe Verb GloVe Verb + Noun Action-Effect\\n- bind\\n- coil\\n- bend\\n- twist\\n- knot\\n- grate\\n- grind"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "eMr i i( ® Action-Effect Embedding Space\\nGloVe Verb\\nGloVe Verb + Noun\\n\\nAction-Effect\\nbind\\n- lock\\n- coil\\n- fasten\\n- grate\\n- bend\\n- grind\\n- twist\\n- knot"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Action-Effect Embedding Space\\n\\nGloVe Verb\\nGloVe Verb + Noun\\n\\nAction-Effect\\n- bind\\n- lock\\n- coil\\n- fasten\\n- bend\\n- grind\\n- twist\\n- break\\n- tear\\n- knot"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Action-Effect Embedding Space\\n\\nGloVe Verb\\nGloVe Verb + Noun\\n\\nAction-Effect:\\n- bind\\n- fasten\\n- coil\\n- lock\\n- bend\\n- grind\\n- rack\\n- crack\\n- trim\\n- break\\n- twist\\n- tear\\n- knot\\n- grate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "rauj |é ® Learning from a few examples\\n\\nGoal: learn from a few examples to make it possible for humans to teach agents for tasks at hand.\\n\\nFP: Effect Phrases\\n2) Action Effect Descriptions = (brown and crispy) ea. (f Ta (the potatoes are brown and crispy)\\n\\nHarness web:\\n- BY perce ee negate examples\\n- os oxyMi Be 'es\\n- Web es results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "rrf on-tft ean] ' WNT; Action-Effect Prediction in Interactive Task Learning\\n\\nDialogue History Causality Knowledge\\n\\nNext you turn on the blender.\\n\\nAction Effect Phrases:\\n- Detector= R: Did you first close the blender lid?\\n- V: peel is peeled,\\n- V: skin is removed,\\n- V: chop into small pieces, carrot is divided,\\n- V: tear is ripped,\\n- WN: paper into pieces,\\n- V: soak completely wet,\\n- V: shirt with water,\\n- V: close is closed,\\n- WN: blender lid is sealed,\\n- V: mash is squished,\\n- V: fry brown and crispy,\\n- WN: potato is crisp and golden.\\n\\nDialogue Actions:\\n- N potato into paste,\\n- make smoothie,\\n- cutting orange,\\n- close blender lid,\\n- turn on blender,\\n- peeled orange in blender,\\n- running blender."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "co Action-Effect Prediction in Interactive Task Learning LAI"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "® Summary\\n- Presented an initial investigation on action-effect prediction.\\n- Explored method using web image data to facilitate the training of action-effect prediction models.\\n- Explored using semantic embedding space to extend effect knowledge to new verb-noun pairs.\\n\\n* Future Directions\\n- Develop better models to improve task performance\\n- Extend action-effect prediction to video data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Thank you!"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 122,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Generative Models for Conversations\\n- Context encoder: RNN\\n- Hierarchical RNN\\n- Decoder: RNN\\n- Objective: log probability of GT response given context.\\n- Can generate novel responses for novel contexts!!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Retrieval Models for Conversations\\n- Retrieve a response from a nearest neighbor index constructed from the training data.\\n- Can be used for closed domain problems.\\n\\nAdvantages:\\n- Answers are grounded in the domain.\\n- Easy to prune answers according to requirements.\\n\\nDisadvantage:\\n- Cannot generate novel responses.\\n\\nCan we use generative models to fix this?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Exemplar Encoder Decoder\\n- Build an index from all context-response pairs offline.\\n\\nFor each context c:\\n- Retrieve a set of exemplar contexts and corresponding responses.\\n- Match the exemplar contexts with c and get the similarities.\\n- Use these similarities to weigh the exemplar responses."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Exempl text Matching Exemplar Contexts\\nccssnmansentesears\\n\\nEncoder\\nInput Context\\nGiana\\n\\nAgent\\n(2) C Age Encoder,\\n\\nNormalized Customer similarities\\n\\nThe normalized similarities are used to weigh the exemplar responses."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "- rt I] = log) s® p(r|e) :ma elt) at: zm : : ie) k=1 := ran -N x m :i -s BS\\n- ee :: = O e(2) : : Ze ::\\n- ya >: is :3 a -H: i Likelihood an:a : Computation :wa Pi: mg O 4\\n5. :: Om\\n- :2 m x< , & :: __ ai\\n- :Exemplar Encoder: Exemplar Decoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Analyzing the Objective, think of exemplar contexts and responses as latent variables log p(r|c) = log p(r|e, r*) p(c*|c) 1 < k < K = log p(r|e) s 1 < k < K"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Evaluation\\n- Exemplar Encoder Decoder\\n- Hierarchical Recurrent Encoder\\n- TF-IDF for retrieving exemplar conversations\\n\\nDatasets used:\\n- Ubuntu Dialogue Corpus\\n- IBM Tech Support Dataset\\n\\nComparison Metrics\\n- Activity and Entity metrics\\n- Embedding metrics"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Activity and Entity metrics\\n\\nThese metrics compare the precision, recall and F1 score of specific nouns and verbs present in the generated response as compared to the ground truth response.\\n\\nUbuntu Dialogue Corpus\\n\\nActivity Entity Tense Cmd Model P R F1 P R F1\\n\\nAce. Ace. LSTM* 1.7 1.03 1.18 1.18 0.81 0.87 14.57 94.79\\n\\nVHRED* 6.43 4.31 4.63 3.28 2.41 2.53 20.2 92.02\\n\\nHRED* 5.93 4.05 4.34 2.81 2.16 2.22 22.2 92.58\\n\\nEED 6.42 4.77 4.87 3.8 2.91 2.99 31.73 95.06\\n\\nFor comparison, the retrieval only model has an activity F1 score of 4.23 and entity F1 score of 2.72 respectively."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Embedding metrics\\n- These metrics compare the word embeddings of the generated response with the words of the ground truth response.\\n- These metrics do not correlate with human judgments for Ubuntu Corpus.\\n\\nUbuntu Tech Support Model Average Greedy Extrema Average Greedy Extrema\\n\\nHRED 0.5131 0.4103 0.3263 0.6372 0.5100 0.4355\\n\\nEED 0.5528 0.4172 0.3134 0.6420 0.5125 0.4356\\n\\nHow NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Input Context (C) and exemplar response (R) Generated/Ground Truth Responses\\n\\nC: I want to check NTFS file systems. Is fsck ok with NTFS?\\nARRED: I know, but I don't know how to do that.\\n- No, you'd need to use chkdsk from Windows.\\n\\nVHRED: How can I do that?\\nRi: I already symlinked ntfsfix to fsck.\\n\\nEED: I am trying to use ntfs-3g. I have a Windows partition.\\nScanning the unmounted devices.\\n\\nGT: I don't have Windows installed.\\nC: Anyone help me?\\n- Seems that it's detecting GRUB.\\n\\nHRED: Yes, I did, but I have no idea how to fix it.\\nHave you tried checking continue without installing?\\n\\nVHRED: Yes, I did; don't know how to do it.\\n\\nEED: Nope, not yet. GRUB install CD is not working: try the live ed... you can't boot into Linux.\\n\\nGT: No, I did not unless GRUB install...\\n\\nHRED: I did that, but it didn't work.\\nC: Any ideas on my mplayer problem?\\n- Reinstall.\\n\\nVHRED: I don't know how to do that.\\nEED: Does not work. Package does not work.\\n\\nR: But half my system depends on this package...\\nGT: That doesn't seem like a solution."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Discussion\\n- A generative model that utilizes similar conversations for response generation.\\n- Can generate novel responses while ensuring that the responses are grounded in the domain.\\n- Incorporating retrieved conversations during generation improves performance as evident from several metrics.\\n- The proposed idea is general and can be used for image captioning and neural machine translation."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 359,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "SNLI [Bowman et al., 2015]\\n- A large scale dataset for NLI (Natural Language Inference; Recognizing Textual Entailment [Dagan et al., 2013])\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "SNLI [Bowman et al., 2015] A large scale dataset for NLI (Natural Language Inference; Recognizing Textual Entailment [Dagan et al., 2013]).\\nPremises are image captions, hypotheses generated by crowdsourcing workers:\\n\\nStreet performer is doing his act for kids\\n\\nHypotheses\\n1. A person performing for children on the street = ENTAILMENT\\n2. A juggler entertaining a group of children on the street > NEUTRAL\\n3. A magician performing for an audience in a nightclub = CONTRADICTION\\n\\nEvent co-reference assumption\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg + Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 2 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Neural NLI Models\\n\\nEnd-to-end, either sentence-encoding or attention-based\\n\\nLabel: Max Glockner, Vered Shwartz and Yoav Goldberg\\n\\nBreaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Neural NLI Models\\n\\nEnd-to-end, either sentence-encoding or attention-based:\\n\\nAttention:\\n\\nEncode [_Encoder_]|\"_Encoder _1\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n\\n+ Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Neural NLI Models\\n\\nEnd-to-end, either sentence-encoding or attention-based.\\n\\nLabel\\n- Extract Features\\n- Act Features\\n- Attention\\n- Encode\\n\\nLexical knowledge: only from pre-trained word embeddings, as opposed to using resources like WordNet.\\n\\nMax Glockner, Vered Shwartz, and Yoav Goldberg\\n\\nBreaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Neural NLI Models\\n\\nEnd-to-end, either sentence-encoding or attention-based\\n\\nLabel\\n- Extract Features\\n- Attention\\n\\nLexical knowledge: only from pre-trained word embeddings. As opposed to using resources like WordNet.\\nSOTA exceeds human performance...\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Neural NLI Models, End-to-end, either sentence-encoding or attention-based\\nLabel [saact Features] [Extract Features | Attention [Premise] | Hypothesis]\\nPremise im 0 hypothesis Lenser\\n\"theoder\\nEncoder\\n* Enderm\\n\\nLexical knowledge: only from pre-trained word embeddings.\\nAs opposed to using resources like WordNet.\\nSOTA exceeds human performance...\\n[Gururangan et al., 2018, Poliak et al., 2018]: by learning \"easy clues\"\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n\\n+ Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Do neural NLI models implicitly learn lexical semantic relations?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "New Test Set\\nWe constructed a new test set to answer this question.\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "New Test Set\\n\\nWe constructed a new test set to answer this question.\\n\\nPremise: sentences from the SNLI training set.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "New Test Set: We constructed a new test set to answer this question.\\n\\nPremise: sentences from the SNLI training set.\\n\\nHypothesis: Replacing a single term w in the premise with a related term w'.\\n\\nMax Glockner, Vered Shwartz, and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "New Test Set\\n\\nWe constructed a new test set to answer this question.\\n\\nPremise: sentences from the SNLI training set.\\n\\nHypothesis: Replacing a single term w in the premise with a related term w' (w' is in the SNLI vocabulary and in pre-trained embeddings).\\n\\nCrowdsourcing labels (mostly contradictions!):\\n- The man is holding a saxophone\\n- The man is holding an electric guitar\\n- A little girl is very sad\\n- A little girl is very unhappy\\n- A couple drinking wine\\n- A couple drinking champagne\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg + Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Evaluation Setting\\n\\n3 representative models:\\n- Residual-Stacked-Encoder [Nie and Bansal, 2017]\\n- ESIM (Enhanced Sequential Inference Model) [Chen et al., 2017]\\n- Decomposable Attention [Parikh et al., 2016]\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg + Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Evaluation Setting\\n\\n3 representative models:\\n- Residual Stacked-Encoder [Nie and Bansal, 2017]\\n- ESIM (Enhanced Sequential Inference Model) [Chen et al., 2017]\\n- Decomposable Attention [Parikh et al., 2016]\\n\\nTrain on SNLI training set, test on the original & new test set.\\n\\nIn the paper: enhancing with additional existing datasets.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg + Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 6 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Results Can neural NLI models recognize lexical inferences?\\n\\n100 [ J SNL Test Set 84.7 g78 86 [] New Test Set 65.6 622 $ 1.9500\\n\\nDecomposable Attention\\nESIM\\nResidual-Stacked-Encoder\\n\\nDramatic drop in performance across models.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n+ Breaking NLI Systems with Sentences that Require Simple Lexical Inferences\\n7 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Sanity Check\\n\\nPerformance of WordNet-informed Models\\n\\n100 [] Best Neural Models 858 {J Kim {chen et al., 2018} []\\n\\nWordNet baseline 65.6500\\n\\nThe test set is solvable using WordNet.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n\\n+ Breaking NLI Systems with Sentences that Require Simple Lexical Inferences\\n\\n8 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "What do neural NLI models learn with respect to lexical semantic relations?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Analysis 1: Word Similarity Models err on contradicting word-pairs with similar embeddings.\\n\\nAman starts his day in India + A man starts his day in Malaysia.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg + Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Analysis 1: Word Similarity\\n\\nModels err on contradicting word-pairs with similar embeddings.\\n\\nA man starts his day in India + A man starts his day in Malaysia.\\n\\nEspecially for fixed word embeddings.\\n\\nCosine Similarity of (word, replacement)\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n\\nBreaking NLI Systems with Sentences that Require Simple Lexical Inferences\\n\\n10 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Analysis 2: Frequency in Training\\n\\nTuning embeddings may associate specific (word, replacement) pairs to a label, e.g. (man, woman)\\n- contradiction\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Analysis 2: Frequency in Training\\n\\nTuning embeddings may associate specific (word, replacement) pairs to a label, e.g. (man, woman)\\n- contradiction. Accuracy increases with frequency in training set.\\n\\n100\\n97.5\\n98.5\\n91.4\\n92.1\\n80.3\\n70.6\\n\\nFrequency of (word, replacement) pairs in contradiction training examples\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n\\n+ Breaking NLI Systems with Sentences that Require Simple Lexical Inferences\\n\\n11 / 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Recapm New NLI test set that evaluates systems' ability to make inferences that require very simple lexical knowledge.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Recap: New NLI test set that evaluates systems' ability to make inferences that require very simple lexical knowledge.\\nSOTA systems perform poorly on the test set. Max Glockner, Vered Shwartz, and Yoav Goldberg.\\n\\nBreaking NLI Systems with Sentences that Require Simple Lexical Inferences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Recap: New NLI test set that evaluates systems' ability to make inferences that require very simple lexical knowledge.\\nSOTA systems perform poorly on the test set. Systems are limited in their generalization ability.\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\nBreaking NLI Systems with Sentences that Require Simple Lexical Inferences 12/13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Recap: NewNLI test set that evaluates systems' ability to make inferences that require very simple lexical knowledge.\\nSOTA systems perform poorly on the test set. Systems are limited in their generalization ability.\\nMay be used as a complementary test set to assess the lexical inference abilities of NLI systems."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Recap of NewNLI test set that evaluates systems' ability to make inferences that require very simple lexical knowledge.\\nSOTA systems perform poorly on the test set. Systems are limited in their generalization ability.\\nMay be used as a complementary test set to assess the lexical inference abilities of NLI systems.\\n\\nThank you!\\n\\nMax Glockner, Vered Shwartz and Yoav Goldberg\\n- Breaking NLI Systems with Sentences that Require Simple Lexical Inferences 12/13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "References\\n- Bowman, S. R., Angeli, G., Potts, C., and Manning, D. C. (2015).\\nA large annotated corpus for learning natural language inference.\\nIn Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632-642.\\nAssociation for Computational Linguistics.\\n- Chen, Q., Zhu, X., Ling, Z-H., Inkpen, D., and Wei, S. (2018).\\nNeural natural language inference models enhanced with external knowledge.\\nIn The 56th Annual Meeting of the Association for Computational Linguistics (ACL), Melbourne, Australia.\\n- Chen, Q., Zhu, X., Ling, Z-H., Wei, S., Jiang, H., and Inkpen, D. (2017).\\nEnhanced LSTM for natural language inference.\\nIn Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1657-1668, Vancouver, Canada.\\nAssociation for Computational Linguistics.\\n- Dagan, I., Roth, D., Sammons, M., and Zanzotto, F. M. (2013). Recognizing textual entailment: Models and applications.\\nSynthesis Lectures on Human Language Technologies, 6(4):1-220.\\n- Gururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., and Smith, N. A. (2018).\\nAnnotation artifacts in natural language inference data.\\nIn The 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), New Orleans, Louisiana.\\n- Nie, Y. and Bansal, M. (2017). Shortcut-stacked sentence encoders for multi-domain inference.\\narXiv preprint arXiv:1708.02312.\\n- Parikh, A., Tackstrém, O., Das, D., and Uszkoreit, J. (2016).\\nA decomposable attention model for natural language inference.\\nIn Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2249-2255, Austin, Texas.\\nAssociation for Computational Linguistics.\\n- Poliak, A., Naradowsky, J., Haldar, A., Rudinger, R., and Van Durme, B. (2018).\\nHypothesis Only Baselines in Natural Language Inference.\\nIn Joint Conference on Lexical and Computational Semantics (StarSem)."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 109,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Constituency Parsing is Useful\\n- Textual Entailment (Bowman et al.,\\n2016)\\n- Semantic Parsing (Hopkins et al.,\\n2017)\\n- Sentiment Analysis (Socher et al.,\\n2013)\\n- Language Modeling (Dyer et al.,\\n2016)\\n\\nBAD ASOT cee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Penn Tree Bank (PTB) (Marcus et al.,\\n1993) 40,000 annotated sentences\\nSWnewswire domain a OSNP VP traders said\\nInvestor focus shifted ADVP quickly"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Geometry Problem: In the rhombus PQRS, PR = 24 and QS =\\n10.\\n\\nQuestion: What's the second-most-used vowel in English?\\n\\nBiochemistry: Ethoxycoumarin was metabolized by isolated epidermal cells via dealkylation to 7-hydroxycoumarin (7-OHC) and subsequent conjugation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Performance Outside Source Domain\\n\\nParse geometry sentence with PTB trained parser.\\n\\nSelect a NP and NP ~ VE.\\n\\nA triangle has a perimeter of 16 and one side of length 4."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "How can we cheaply create high-quality parsers for new domains?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Relevant Recent Developments in NLP\\n- Contextualized word representations improve sample efficiency. (Peters et al.,\\n2018)\\n- Span-focused models achieve state-of-the-art constituency parsing results. (Stern et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Contributions Show contextual word embeddings help domain adaptation. E.g., Over 90% F1 on Brown Corpus.\\nAdapt a parser using partial annotations. E.g., Increase correct geometry-domain parses by 23%. BAZ 2 SNERence 1°"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Outline\\n\\nReview Contextual Word Representations\\n\\nPartial Annotations:\\n\\nDefinition\\n\\nTraining\\n\\nParsing as Span Classification\\n\\nThe Span Classification Model\\n\\nExperiments and Results:\\n\\nPerformance on PTB and new Domains\\n\\nAdapting Using Partial Annotations Aid secs..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Contextualized Word Representations ELMo trained on Billion Word Corpus (reters et al., 2018)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Contextualized Word Representations ELMo trained on Billion Word Corpus (reters et al., 2018).\\nC) SNLI (Accuracy) SRL (F1) Cc 90: 80 70 +20.5 raFal 60 #704412.\\n\\n50 {18-5 #eof\" no; / |\"- 30} \"|\\n- with ELMo 505 a' 20 if ----\\n\\nBaseline 0.1% | 1% 10% 100% 0.1% | 1% 10% 100% Improve sample efficiency BAD 288 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Definitioneae late; Training Annotations Parsing as Span Classification The Span Classification Model BAD. See 14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Selectively Annotate Important Phenomena\\n\\nA triangle has a perimeter of 16 and one side of length 4."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Full Versus Partial Annotation\\n\\nA triangle has a perimeter of 16 and one side of length\\n4.\\n\\nBAZ ASN ence 19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Partial annotation is a labeled span. A triangle has a perimeter of 16 and one side of length 4."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Why Partial Annotations?\\n\\nAllowing annotators to selectively annotate important phenomena makes the process faster and simpler. (Mielens et al.,\\n2015) BAD ASW eee?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Training Parsing as Span Classification\\n\\nThe Span Classification Model Pad sees en"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Objective for Full Annotation L(0) =\\n- Ss log Prg (parse|sentence) (sentence, parse)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Objective for Partial Annotation\\n\\nSince we do not have a full parse, marginalize out components for which no supervision exists.\\n\\nL(6) =-- S> log | S> Prg (parse|sentence) (sentence annotations) \\ parses consistent with annotations\\n\\nBAD ASL cece 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Objective for Partial Annotation\\n\\nMarginalize out components for which no supervision exists.\\n\\nL(6) =\\n- S > log | > Prg (parse | sentence) (sentence annotations) parses consistent with annotations\\n\\nExpensive!\\n\\nBAZ 2S ence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "One Solution: Approximation L(0) =\\n- S° log Prg (parse|sentence) (sentence, annotations) (Mirroshandel and Nasr, 2011; Majidi and Crane, 2013; Nivre et al., 2014; Li et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Our Solution: Parsing as Span Classification\\n\\nAssume probability of a parse factors into a product of probabilities.\\nPr(parse|sentence) = I] Prg(label|sentence, span)(span, label) consistent with parse BAZ ASN ence?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Assume probability of a parse factors into a product of probabilities.\\nPr (parse|sentence) = I] Prg (label|sentence, span) (span, label) consistent with parse\\nObjective now simplifies to:\\nL£(6) =-- S° S- log Pro (label|sentence, span) (sentence, annotations) (span, label) €annotations\\nEasy if model classifies spans!\\nPad sees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Parsing as Span Classification\\n\\nThe Span Classification Model\\n\\nBAZ sss ece"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "- Parse Tree Labels\\nAll\\nSPAN: sNP VP: PRP VBZ\\nSH/_ : She enjoys\\nNP playing NN tennis\\ninput: { She enjoys playing tennis. }\\n*(Cross and Huang, 2016; Stern et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nF\" SsNP VP . | | , | PRP VBZ (She enjoys playing tennis. (Cross and Huang, 2016; Stern et al.,\\n2017) ALLEN INSTITUTE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "ryParse Tree Labels All Spans cc Ss NP VP.\\n\\nPRP VBZ sees She enjoys playing\\n\\nvisa, She enjoys playing tennis.\\n\\n(Cross and Huang, 2016; Stern et al.,\\n2017) ki2 aucen institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nss NP VP, PRP VBZ SJ: She enjoys\\n\\nVP VBG NP playing NN: tennis input { She enjoys playing tennis. *(Cross and Huang, 2016; Stern et al.,\\n2017)\\n\\nki2 ALLEN INSTITUTE 36"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nSsNP VP, Zs: PRP | VBZ S (She | enjoys | VP) VBG NP playing | a NN: tennis\\n\\ninput { She enjoys playing tennis. *(Cross and Huang, 2016; Stern et al.,\\n2017) }"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nSsNP VP\\n- PRP\\n- VBZ\\n- S\\n- (S, VP) VBG NP\\n- playing\\n- a\\n- NN\\n\\nInput: She enjoys playing tennis.\\n\\n*(Cross and Huang, 2016; Stern et al.,\\n2017)\\nki2 ALLEN INSTITUTE 38"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nNP VP\\n- PRP VBZ S\\n(S, VP) VBG NP\\n\\nShe enjoys playing tennis.\\n*(Cross and Huang, 2016; Stern et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nNP VP\\n- She enjoys\\n- playing tennis\\n\\ninput { She enjoys playing tennis. *(Cross and Huang, 2016; Stern et al.,\\n2017) }"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "ryParse Tree Labels All Spans\\n\\nSo a Pa NP VP . (NP) @ PRP VBZ SJ: She enjoys\\n\\n(VP) a (S, VP) VBG NP playing NN tennis input { She enjoys playing tennis.\\n\\n(Cross and Huang, 2016; Stern et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Training on Full and Partial Annotations\\n\\nA partial annotation is a labeled span. A full parse labels every span in the sentence.\\nTherefore, training on both is identical under our derived objective.\\nLAG = log Prg (label|sentence, span)(span, label, sentence) Pad sees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Parsing Using Span Classification Model\\n\\nFind maximum using dynamic programming:\\n\\nPrg(parse|sentence) = I] Pro (label of span in parse|sentence, span)\\n\\nspan € spans BA. 2:88.20 ce 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Summary\\n\\nPartial annotations are labeled spans."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Summary\\n\\nPartial annotations are labeled spans. Use a span classification model to parse. BQ. BSNS ence 46"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Summary\\nPartial annotations are labeled spans.\\nUse a span classification model to parse.\\nTraining on partial and full annotations becomes identical.\\nBAD ASE cece A?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "The Span Classification Model BAD ss8 NTE aee 48"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Model Architecture (Stern et al.\\n2017)\\nShe enjoys playing\\n- tennis\\nBAQ SEMIN ETE ence 49"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Model Architecture (Stern et al.,\\n2017) enjoys playing tennis."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "(Wang and Chang, 2016; Cross and Huang, 2016; Stern et al.,\\n2017) \"enjoys playing.\"\\nCerinis Pad sees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Model Architecture (Stern et al.\\n2017) \"enjoys playing\" a eed7\\n- f f i i ff | | . She enjoys playing tennis and sees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Differences Objective Maximum Maximum margin likelihood on labels on trees BAZ SENSE ence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Experiments Performance on PTBand Learning Curve on New Domains\\n\\nAdapting Using Partial Annotations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Performance on PTB\\n\\n91.8 F1 Stern et al., 2017 +0.3 F1 = 94.3\\nF1 + Maximum Likelihood on Labels\\nOurs\\n- POS tags + 2.2 F1 + ELMo\\nPad sees"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Performance on PTB\\n\\n92.6 Fl\\n94.3 Fl\\n\\nEffective Inference for Ours\\nGenerative Neural Parsing\\n+1.7 Fl Over Previous SoTA\\n\\n**New SoTA is 95.1 (Kitaev and Klein, ACL\\n2018)\\ni. usu 81"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Learning Curve on New Domains\\nAdapting Using Partial Annotations\\nBAZ 2S N TR ence 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Question Bank (Judge et al.,\\n2006) = 4,000 questions.\\n\\nIn contrast, PTB has few questions.\\n\\nWho is the author of the book, 'The Iron Lady: A Biography of Margaret Thatcher'?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Do We Need Domain Adaptation?\\n\\nTraining on QB880\\n\\nNumber of parses from Question Bank"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "How Much Data Do We Need?\\n\\n9896 gc cine ESN +6.3 % of From 0 to 100 parses Fl: 92 | 907 +0.9 %\\n\\n8° 0 500 1000 1500 2000 From 100 to 2,000 parses\\n\\nNumber of parses from Question Bank\\n\\nBAD ASE cree"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "How Much Data Do We Need?\\n\\nNot Much\\n\\nImprovements taper quickly\\n\\nNumber of parses from Question Bank"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Adapting Using Partial Annotations PAZ esstiet etree"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Geometry Problems (Seo et al.,\\n2015)\\n\\nIn the diagram at the right, circle O has a radius of 5, and CE =\\n2. Diameter AC is perpendicular to chord BD at E. What is the length of BD?\\n\\nBiochemistry (Nivre et al.,\\n2007)\\n\\nEthoxycoumarin was metabolized by isolated epidermal cells via dealkylation to 7-hydroxycoumarin (7-OHC) and subsequent conjugation.\\n\\nBAD AST cree 8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "SetupAnnotator is a parsing expert. Sees parser output. Annotated sentences randomly split into train and dev.\\nAD BSE cree 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Biochemistry Annotations\\n\\n610 partial annotations (Avg. 4.6 per sentence)\\n\\ntrain: 72 sent, dev: 62 sent\\n\\n{ In situ } hybridization has revealed a striking subnuclear distribution of { c-myc RNA transcripts }.\\n\\nCell growth of neuroblastoma cells in { serum containing medium } was clearly diminished by { inhibition of FPTase }.\\n\\nBAZ 28382 Et ence 7"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "What do partial annotations buy us?\\n\\n80 ' = PTB + 9.4% = PTB + 60 Biochem 4029.79 200 Correct Constituent % Error-Free Sentences % Bad reference"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Geometry Annotations\\n\\n379 partial annotations (Avg. 3 per sentence)\\ntrain: 63 sent, dev: 62 sent\\n\\nWhat is the value of fy {+z}?\\nDiameter AC is perpendicular to chord BD at E.\\nFind the measure of the angle designated by x.\\nPAZ este ETE ence?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "What do partial annotations buy us? 90 = PTB = PTB + Geo 80 + 15.1% 706090 + 33.49 AO mm Correct Constituent %\\n- Error-Free Sentences % BAQ SENS Eee 3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Iterative Annotation BAZ SSN NST ence 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Error Analysis on Geometry Training Set\\n\\n44% math syntax\\nEg: \"dimensions 16 by 8,\" \"BAC = % * ACB\"\\n\\n19% right-attaching participial adjectives\\nEg: \"segment labeled x,\" \"the center indicated\"\\n\\n19% PP-attachment\\nPad sense!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Right Attaching Participial Adjective Errors\\nFind the hypotenuse of the triangle labeled."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Iterative Annotation Proof-of-Concept\\n\\nInvent 3 sentences similar to the incorrect one:\\n\\nFind the hypotenuse of the triangle labeled t."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Iterative Annotation Proof-of-Concept\\n\\nInvent 3 sentences similar to the incorrect one:\\n\\nFind the hypotenuse of the triangle labeled t.\\n\\nGiven a circle with the tangent shown.\\n\\nPAZ SHEET ence 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Iterative Annotation Proof-of-Concept\\n\\nInvent 3 sentences similar to the incorrect one:\\n- Find the hypotenuse of the triangle labeled t.\\n- Given a circle with the tangent shown.\\n- Examine the following diagram with the square highlighted."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Correctly identified constituents: 87.0%\\n- 88.6% (+1.6)\\n\\nError free sentences: 72.6%\\n- 75.8% (+2.7)\\n\\nPAZ, asset nce OO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Conclusione\\n\\nRecent developments make it much easier to train on partial annotations and build custom parsers.\\nMaking a few partial annotations can lead to significant performance improvements.\\n\\nDemo: http://demo.allennlp.org/constituency-parsing\\n\\nDatasets: https://github.com/vidurj/parser-adaptation/tree/master/data"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 129,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Dependency Parsing\\nBut there were no buyers.\\nBut there were no buyers."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Process the input sequentially in order.\\nUse actions that build up a tree.\\nChoose which actions to apply with a classifier."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Example: Arc-standard Parsing [Yamada+ 2003, Nivre 2004]\\nOrder: Left-to-right\\nActions: Shift, reduce-right, reduce-left\\nshift right\\nx x\\n\\n\\TTMNROOT! saw a girl @ ie ROOT! sawa_ girl\\nxy \\KROOT! sawa_ girl\\ne Classifier: e Support vector machines [Nivre+ 2004]\\ne Feed-forward neural networks [Chen+ 2014]\\ne Recurrent neural networks [Dyer+ 2015]\\ncS FanEUE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Our Proposal: Stack-pointer Networks (StackPtr)\\nOrder: Top-down, depth-first\\nActions: \"Point\" to the next word to choose as a child\\nModel: A neural network, based on \"pointer networks\"\\nAdvantages:\\n- Top-down parsing maintains a global view of the sentence\\n- High accuracy\\n- Can maintain full history, low asymptotic running time (c.f. graph-based)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Background: Pointer Network [Vinyals+ 2015]\\n\\nOutput sequence with elements that are discrete tokens corresponding to positions in an input sequence.\\n\\nUse attention as a pointer to select a member of the input sequence as the output.\\n\\ne!\\n= score(hz, 8;) a' = softmax(e') s and / are the hidden states of encoder and decoder, and score() is the attention scoring function, e.g.\\nbi-affine attention [Luong+ 2015; Dozat+ 2017]\\n\\nLanguage Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Carnegie Mellon S = {S1, ..., Sn}: hidden states of encoder h = {h1, ..., hn} hidden states of decoder x = {w1, ..., wn}: an input sentence y = {p1, ..., pn}: a sequence of paths, each of which is a sequence:\\n- \" : of words from root to a leaf\\n\\nLanguage Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Transition Systeme\\n\\nTwo data structures:\\n- List (a): of words whose head has not been selected.\\n- Stack (o): of partially processed head words whose children have not been fully selected.\\n\\nStack o is initialized with the root symbol $e. At each decoding step:\\n- receive the top element of stack o as head word w_y, and generate the hidden state h,\\n- compute the attention vector a' using h, and encoder hidden states s,\\n- generate an arc: choose a specific word (w_) from a as the child of w_y, remove w_y from a and push it onto o,\\n- complete a head: pop w_z out of o."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Features for the Classifier\\n\\nUtilize higher-order information at each step of the top-down decoding procedure. Sibling and grandchild structures\\n- proven beneficial for parsing performance (McDonald and Pereira 2006; Koo and Collins 2010).\\n\\nUse element-wise sum of the encoder hidden states instead of concatenation\\n- does not increase the dimension of Bt. Bt = Spr Sg + Ss"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Carnegie Mellon SO OW ®$ But there were no buyers see Language 10 Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Carnegie Mellon\\nVia But there were no buyers\\nBut there were no buyers\\nsee Language\\nTechnologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Carnegie Mellon But there were no buyers: +181 aLanguage 14 Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Carnegie Mellon But there were no buyers But there were no buyers :) Sy + a Language 15 Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Carnegie Mellon But there were no buyers"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Carnegie Mellon But there were no buyers But there were no buyers"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Learning StackPtree Maximum likelihood Factorize into sequence of top-down paths\\n\\np(y|x) = ∏ Po(pi|p<i,X) ∏ ∏ Po(Ci,j|Ci,<jsP<isX); i=1 j=1\\n- Pre-defined inside-out order for children of each head word\\n- Enables parser to utilize higher-order sibling information\\n- Train separate classifier for dependency label prediction\\n- Use head word and child information [Dozat+ 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Experiment 1: Main Results & Analyses\\n\\nDatasets:\\n- English PTB\\n- Chinese PTB\\n- German CoNLL 2009 shared task\\n\\nParsing models for comparison:\\n- Baseline: Deep Biaffine (BiAF) parser (Dozat et al., 2017), augmented with character-level information\\n- Four versions of StackPtr:\\n- Org: utilizes only head word information\\n- +gpar: augment Org with grandparent information\\n- +Sib: augment Org with sibling information\\n- Full: include all the three information\\n\\nEvaluation metrics:\\n- Unlabeled Attachment Score (UAS)\\n- Labeled Attachment Score (LAS)\\n- Unlabeled Complete Match (UCM)\\n- Labeled Complete Match (LCM)\\n- Root Accuracy (RA)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "aI Carnegie Mellon English 95.9 94.4 62.5 52.5 98.3 95.8 94.3 61.5 51.5 98.1\\n\\nn = = sg s S E e 95.7 94.2 60.5 50.5 97.9 95.6 94.1 59.5 49.5 97.7 95.5 94.0 56.5 48.5 97.5\\n\\nChinese 90.6 89.5 46.5 42 87.9\\n90.4 89.3 45.5 41 87.7\\n90.2 89.1 44.5 40 87.5\\n90.0 88.9 43.5 39 87.3\\n89.8 88.7 42.5 38 87.1\\n\\nGerman 94.0 92.5 63.5 55.5 98.0\\n93.8 92.3 62.5 54.5 97.8\\n93.6 92.1 61.5 53.5 97.6\\n93.4 91.9 60.5 52.5 97.4\\n93.2 91.7 59.5 51.5 97.2\\n\\nMm BiAf ©) org @@\\n+ gpar Mm\\n+sib Mm\\n\\nFull Language Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Parsing Performance on Test Data w.r.t Sentence Length\\n\\n0.97\\n- BiAF\\n\\n0.96\\n\\n0.95\\n\\ngo.\\n\\n0.94\\n\\n[1,10]\\n\\n[11,20]\\n\\n[21,30]\\n\\n[31,40]\\n\\n[41,50]\\n\\n> 50\\n\\nSentence Length\\n\\nStackPtr tends to perform better on shorter sentences, consistent with transition-based/graph-based comparison in McDonald and Nivre (2011)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Parsing Performance w.r.t Dependency Length\\n\\n0.97 me -- BiAF\\n0.96\\n0.96 -- STACKPTRS\\n0.95\\n0.94\\n0.93\\n0.92\\n0.91\\n0.90\\n1 2 3 4 5 6 7\\n> 7\\n1 2 3 4 5 6 7\\n> 7\\n\\nDependency Length\\n\\nDependency Length\\n\\nThe gap between Stack-Ptr and BiAF is marginal; graph-based BiAF still performs better for longer arcs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Parsing Performance w.r.t Root Distance\\n\\n0.98 0.98 -- BiAF\\n0.98 0.98 -- STACKPTR\\n5 0.97\\n- 0.97\\nWH ©3 0.97 o 0.97 a 0.96 0.96 0.96 0.95\\n\\n1 2 3 4 5 6 7 >7\\nDistance to Root\\nDistance to Root\\n\\nDifferent from McDonald and Nivre (2011), StackPtr and BiAF similar regardless of root distance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Effect of POS Embedding\\n\\nGold: Parser with gold-standard POS tags\\nPred: Parser with predicted POS tags (97.3% accuracy)\\nNone: Parser without POS tags"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Experiment 2: Universal Dependency Treebanks\\n\\nDatasets: Universal Dependency Treebanks (V2.2)\\n\\n12 languages: Bulgarian, Catalan, Czech, Dutch, English, French, German, Italian, Norwegian, Romanian, Russian and Spanish.\\n\\nNote: we also ran experiments on 14 CoNLL Treebanks. (see the paper for details)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "LAS on UD Treebanks\\nW @ BiAF TM Stack\\nPtr 9492.588\\nbg ca cs de en es fr it nk no ro\\n- fu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Conclusion & Future Work\\n- Stack-Pointer network for dependency parsing\\n- A transition-based neural network architecture\\n- Top-down, depth-first decoding procedure\\n- State-of-the-art performance on 21 out of 29 treebanks\\n\\nFuture Work\\n- Learn an optimal order for the children of head words, instead of using a pre-defined fixed order\\n- End-to-end training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Questions? Our code is published at: https://github.com/XuezheMax/NeuroNLP2BS aeTechnologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Model Details\\n\\nEncoder- Bi-directional LSTM-CNN (Chiu and Nichols 2016; Ma and Hovy\\n2016)\\n- Three input embeddings: word, character and POS\\n- CNN encodes character-level information\\n- 3-layer LSTM with recurrent dropout (Gal et al.,\\n2016)\\n\\nDecoder- Uni-directional LSTM\\n- Use encoder hidden states as input instead of word embeddings\\n- 1-layer LSTM with recurrent dropout"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 182,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Who cares about stock movements?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Who cares about stock movements? No one would be unhappy if they could predict stock movements."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Background: Two mainstreams in finance: technical and fundamental analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Background: Two mainstreams in finance: technical and fundamental analysis.\\n\\nTwo main content resources in NLP: public news and social media."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Background: Two mainstreams in finance: fundamental analysis.\\n\\nTwo main content resources in NLP: public news and history of NLP models.\\n- Feature engineering (before\\n2010)\\n- Topic models (2013-2015)\\n- Event-driven neural nets (2014-2015)\\n- Hierarchical attention nets (2018)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "However, it has never been easy...\\n\\nComplexities\\n\\nThe market is highly stochastic, and we make temporally-dependent predictions from chaotic data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Divide and Treat\\n- Chaotic market information\\n- Noisy and heterogeneous\\n- High market stochasticity\\n- Random-walk theory (Malkiel,\\n1999)\\n- Temporally-dependent prediction\\n\\nWhen a company suffers from a major scandal on a trading day, its stock price will have a downtrend in the coming trading days.\\nPublic information needs time to be absorbed into movements over time (Luss and d'Aspremont, 2015), and thus is largely shared across temporally-close predictions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Divide and treat\\n\\nChaotic market information\\nMarket Information Encoder\\n\\nNoisy and heterogeneous\\nHigh market stochasticity\\n\\nVariational Movement Decoder\\nRandom walk theory (Malkiel,\\n1999)\\n\\nTemporally-dependent prediction\\nAttentive Temporal Auxiliary\\n\\nWhen a company suffers from a major scandal on a trading day, its stock price will have a downtrend in the coming trading days.\\nPublic information needs time to be absorbed into movements over time (Luss and d'Aspremont, 2015), and thus is largely shared across temporally-close predictions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Problem Formulation\\n\\nStock Movement Prediction\\n\\nWe estimate the binary movement where 1 denotes rise and 0 denotes fall.\\n\\nTarget trading day: d\\n\\nWe use the market information comprising relevant tweets and historical prices, in the lag [d\\n- Ad, d\\n- 1] where Ad is a fixed lag size."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Generative Process\\nEligible trading days in the Ad lag\\nx)\\nv)\\nEncode observed market information as a random variable X = [x1;...; Xz]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Generative Process\\n\\nT eligible trading days in the Ad lag\\n\\nEncode observed market information as a random variable X = [x1; ...; Xz]\\n\\nGenerate the latent driven factor i = [Zs s weezz]o\\n- (Ze 010/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Generative Process\\n\\nT eligible trading days in the Ad lag\\n\\n> Encode observed market information as a random variable X = [x1; ...; Xz]\\n\\n> Generate the latent driven factor Z = [Z1, Z2, ..., Zn] @ 0\\n\\n> Generate stock movements Y = f(X, Z)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "For multi-task learning, we model pg(y|X) = ∑ Pe(y, Z|X) instead of pe(yr|X).\\n\\nMain target: yr\\n\\nTemporal auxiliary target: y* = [W1,..., yr_1]>\\n\\nFactorization Po(¥, Z|X) = po(yr|X,\\nZ) po(Zr|Z<r,\\nX) T A[I 2 (el X<t,\\n21) pa(Z1|Zct, X<ts Yt)t=111/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Primary components (x) (y)\\n@ Market Information Encoder (MIE)\\nEncodes X\\n@ Variational Movement Decoder (VMD)\\nInfers Z with X, y and decodes stock movements y from X, Z\\n@ Attentive Temporal Auxiliary (ATA)\\nIntegrates temporal loss for training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "StockNet architecture\\n\\nTraining Objective\\n\\nOnePe esgee TR ~an SON\\n\\nAttentive Temporal Auxiliary (ATA)\\n\\nVariational decoder\\n\\nVariational Movement\\n\\nVariational encoder\\n\\nHistorical Market Information\\n\\nPrices\\n\\n[input Encoder (MIE)]\\n\\nVAEs\\n\\nBi-GRUs Message Embedding Layer\\n\\nMessage Corpora"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Variational Movement Decoder\\nGoal: recurrently infer Z from X, y and decode y from X, Z\\nChallenge: posterior inference is intractable in our factorized model\\n14/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Variational Movement Decoder\\n\\nGoal: recurrently infer Z from X, y and decode y from X, Z\\n\\nChallenge: posterior inference is intractable in our factorized model\\n\\nVAE solutions\\n- Neural approximation and reparameterization\\n- Recurrent ELBO\\n- Adopt a posterior approximators (Zt|X<t, Yt) ~ N(μ, Σ)\\nwhere μ = {1,0}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Interface between VMD and ATATraining Objective UT; Lee\\n\\nIntegrate the deterministic feature of Temporal Attention and the latent variable z; Dependency Score\\n\\nDecode movement hypothesis: first Information Score for auxiliary targets, then main target\\n\\nTemporal attention: v*9 92 9316/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Attentive Temporal Auxiliary\\n\\nBreak down the approximated L to temporal objectives\\n\\nf\\n- RTM'f = log Po (yt|X<t, Z<t)\\n- AD [9 (2t|Z<t, X<t; Yt) || Po (Zt|Z<t, X<t)]\\n\\nReuse v* to build the final temporal weight vector\\n\\nv\\n- R'*7v = [av*, 1] where a € [0, 1] controls the overall auxiliary effects.\\n\\nRecompose FN1:\\n- (1)\\n- (7) F (0,4; X,y) NO yang 17/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Experimental setup\\n\\nDataset\\nTwo-year daily price movements of 88 stocks\\nTwo components: a Twitter dataset and a historical price dataset\\nTraining: 20 months, 20,339 movements\\nDevelopment: 2 months, 2,555 movements\\nTest: 2 months, 3,720 movements\\n\\nLag window: 5\\n\\nMetrics: accuracy and Matthews Correlation Coefficient (MCC)\\n\\nComparative study: five baselines from different genres and five StockNet variations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Baselines\\n\\nStockNet variants:\\n- RAND: a naive predictor making\\n- HEDGEFUNDANALYST: fully-equipped random guess\\n- TECHNICALANALYST: from only prices\\n- ARIMA: Autoregressive Integrated Moving Average\\n- FUNDAMENTALANALYST: from only tweets\\n- INDEPENDENTANALYST: optimizing only\\n- RANDFOREST (Pagolu et al.,\\n2016) the main target\\n- TSLDA (Nguyen and Shirai,\\n2015)\\n- DISCRIMINATIVEANALYST: a discriminative\\n- HAN (Hu et al.,\\n2018) variant"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Results\\n\\nBaseline models\\nAcc. | MCC | Baseline comparison\\nRAND 50.89 | -0.002266\\nARIMA 51.39 | -0.020588\\nRANDFOREST 53.08 | 0.012929\\nTSLDA 54.07 | 0.065382\\nHAN 57.64 | 0.051800\\n\\nARIMA: does not yield satisfying results\\nTwo best baselines: TSLDA and HAN\\n\\nStockNet variations\\nAcc. | MCC | Variant comparison\\nTECHNICAL ANALYST 54.96 | 0.016456\\nFUNDAMENTAL ANALYST 58.23 | 0.071704\\nINDEPENDENT ANALYST 57.54 | 0.036610\\nDISCRIMINATIVE ANALYST 56.15 | 0.056493\\nHEDGE FUND ANALYST 58.23 | 0.080796\\n\\nTwo information sources are integrated effectively\\nGenerative framework incorporates randomness properly"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Effects of temporal auxiliary\\n\\nThe auxiliary weight controls overall auxiliary effects. Our models do not linearly benefit from temporal auxiliaries.\\n\\nTweaking acts as a trade-off between focusing on the main target and generalizing by denoising.\\n- Acc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Summary: We demonstrated the effectiveness of deep generative approaches for stock movement prediction from social media.\\n\\nOutlook: Better way to integrate fundamental information and technical indicators. Other market signals, e.g.\\nfinancial disclosures, periodic analyst reports, and company profiles.\\n\\nInvestment simulation with modern portfolio theory.\\n\\nDataset is available at https://github.com/yumoxu/stocknet-dataset22/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Ziniu Hu, Weiging Liu, Jiang Bian, Xuanzhe Liu, and Tie-Yan Liu.\\n2018. Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction.\\nIn Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining.\\nACM, Los Angeles, California, USA, pages 261-269.\\n\\nRonny Luss and Alexandre d'Aspremont.\\n2015. Predicting abnormal returns from news using text classification. Quantitative Finance 15(6):999-1012.\\n\\nBurton Gordon Malkiel.\\n1999. A random walk down Wall Street: including a life-cycle guide to personal investing. WW Norton & Company.\\n\\nThien Hai Nguyen and Kiyoaki Shirai.\\n2015. Topic modeling based sentiment analysis on social media for stock market prediction.\\nIn Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.\\nBeijing, China, volume 1, pages 1354-1364.\\n\\nVenkata Sasank Pagolu, Kamal Nayan Reddy, Ganapati Panda, and Babita Majhi.\\n2016. Sentiment analysis of twitter data for predicting stock market movements.\\nIn Proceedings of 2016 International Conference on Signal Processing, Communication, Power and Embedded System.\\nIEEE, Rajaseetapuram, India, pages 1345-1350."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Appendix\\n- Market Information\\n\\nEncoder Temporal input: x; = [c;, pr]\\nCorpus embedding c; Historical price vector p;\\n\\nMultiple tweets with varied quality\\n- Price signals: the adjusted closing,\\n- Message embedding: Bi-GRU highest and lowest\\n- Corpus embedding: messages\\n\\nComposition with salience e\\n\\ne 4u; = softmax(w7 tanh(WmnuMr)) = Rotation Ct = Mruy Pt = Pr/Br_4-124/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Appendix\\n- Variational Inference\\n\\nMercure Laice\\n\\nLOA SAI e210) a L£(0, 6: X,\\ny)\\n\\n96 (Z | X,\\ny) = Il O (2t | Z<t; X<t, Y<e) T_ ~ » E_g, (z | z_c, x_c,\\ny) log Po (Y|X<t, Z<t)\\n- ti Likelihood equation\\n\\nDut [40 (2t Z<t, X<t, Yt) || Po (Z | Z<t, X<t)]\\n\\n< log po (y |\\nX)\\n\\nlog po (y |\\nX) = Dxt [9 (Z | X,\\nY) || Be (Z | X, Y)]\\n\\nwhere the likelihood term\\n\\n+ E_g, (z) x,\\ny) [log po (y | X, Z)]\\n\\npo (vile ze) = 1\" (y | x<t, 2t), if t < T\\n- Dat [ae (Z | X,\\ny) || Po (Z | X)]\\n\\nhee\" \"po (|X 2), it = T.\\n25/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Appendix\\n- Attentive Temporal Auxiliary\\nInformation score\\nTemporal Attention\\nDependency score\\nDependency Score\\nIntegration"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Appendix\\n- Trading-day Alignment\\n\\nWe reorganize our inputs, including the tweet corpora and historical prices, by aligning them to the T trading days in a lag.\\nSpecifically, on the tth trading day, we recognize market signals from the corpus M in [d_{1}, d_{t}) and the historical prices p on d_{1}, for predicting the movement y on at 27/28."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Appendix\\n- Denoising Regularizer\\n\\nObjective-level auxiliary can be regarded as a denoising regularizer: for a sample with a specific movement as the main target, the market source in the lag can be heterogeneous.\\n\\nExample:\\n- Affected by bad news, tweets on earlier days are negative but turn to positive due to timely crisis management.\\n\\nWithout temporal auxiliary tasks, the model tries to identify positive signals on earlier days only for the main target of rise movement, which is likely to result in pure noise.\\n\\nTemporal auxiliary tasks help to:\\n- Filter market sources in the lag as per their respective aligned auxiliary movements.\\n- Encode more useful information into the latent driven factor Z.\\n\\n28/28"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 361,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Simultaneous Interpretation (Sl) Translation of the spoken word in real time"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Computer Assisted Interpretation (CAI)\\nSource Transcription\\n\\nLast year, I showed these two slides to demonstrate that the Arctic ice cap, which for most of the last 3 million years has been the size of the lower 48 states, has shrunk by terms.\\n\\nEntities and Numbers\\n\\nLast year\\nArctic\\n3 million\\n483 @ Carnegie Mellon University\\nLanguage Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Computer Assisted Interpretation (CAI) How do we ensure maximum utility with minimum distraction?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Estimating Interpreter Performance\\n\\nDon't offer help when they don't need it!\\n\\nEstimate how well the interpreter is doing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Quality Estimation\\nWe already do this in Machine Translation!\\nCan we apply it to Simultaneous Interpretation?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Quality Estimation\\n\\nQuEst++ is an existing framework for QE (Specia et al., 2015)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Quality Estimation\\n\\nQuEst++ is an existing framework for QE (Specia et al.,\\n2015)\\n\\nSource/Target Reference Sentence Pairs Translations Extract Features Metric"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Quality Estimation\\nQuEst++ is an existing framework for QE (Specia et al.,\\n2015)\\nSource/Target Reference Sentence Pairs\\nTranslations\\nExtract\\nc\\naa\\nLearn\\nFeatures\\nvaluation\\nModel\\nMetric"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Quality Estimation\\n\\nQuEst++ is an existing framework for QE (Specia et al., 2015).\\n\\nSource/Target Reference Sentence Pairs Translations Extract\\n\\nLearn Features\\n\\nEvaluation Model\\n\\nMetric Score Predictions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "14 Carnegie Mellon University Language Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Method Source/Target Reference Sentence Pairs Translations Apply. Learn Postias Evaluation Model Saturation Metric.\\nScore Predictions 15 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations Apply .. Learner Evaluation Model= Metric.\\nScore Predictions 16 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations English-Japanese Appl (3 interpreters) Evia Learn English-French Metric Model English-Italian Score Predictions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations QuEst++ baseline Appl features pply Wear Evaluation Model a\\n- Score Predictions 18 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations QuEst++ baseline features Apply earn Evaluation; Model Features tailored Metric to interpretation Score Predictions 19 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations features Evaluation\\n- earn Metric Model Features tailored Score Predictions 20 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations; Learn QuEst++ baseline Apply Model features Evaluation | Features tailored Vector to interpretation (METEOR) Regression) Score Predictions 21 pe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Method Source speaker/ Reference Interpreter transcripts Translations; Learn QuEst++ baseline Apply Model features Evaluation\\n\\nFeatures tailored Vector to interpretation (METEOR) Regression Test using 10-fold cross-validation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Baseline Features\\nNumber of words\\nAverage word length\\nLanguage model probability\\nN-gram frequency\\nPunctuation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Features of interpretation\\n\\nSOURCE: \"Will the Parliament grant President Dilma Rousseff, on the very first occasion after her groundbreaking election and for no sound formal reason, the kind of debate that we usually reserve for people like Mugabe?\\nSo, I ask you to remove Brazil from the agenda of the urgencies.\" (48 words)\\n\\nINTERP: \"Ehm il Parlamento... dopo le elezioni...\\ndaremo spazio a un dibattito sul ehm sul caso per esempio del presidente Mugabe invece di mettere il Brasile all'ordine del giorno?\" (27 words)\\n\\nGLOSS: \"Ehm the Parliament... after the elections...\\nwe'll give way to a debate on the ehm on the case for example of President Mugabe instead of putting Brazil on the agenda?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "S| Model Features\\n\\nPauses/hesitations/incomplete words\\n\\nNon-specific words\\n- is the interpreter avoiding specific terminology?\\n\\nCognates/loan words\\n- if a word is almost identical in both languages an interpreter shouldn't struggle with it (unless it's a 'false friend'!)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "0.8 = proposed baseline 0.62\\n\\nCarnegie Mellon University\\nLanguage Technologies Institute"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Analysis SOURCE: \"Will the Parliament grant President Dilma Rousseff, on the very first occasion after her groundbreaking election and for no sound formal reason, the kind of debate that we usually reserve for people like Mugabe?\\nSo, I ask you to remove Brazil from the agenda of the urgencies.\" (48 words)\\n\\nINTERP: \"Ehm il Parlamento... dopo le elezioni...\\ndaremo spazio a un dibattito sul ehm sul caso per esempio del presidente Mugabe invece di mettere il Brasile all'ordine del giorno?\" (27 words)\\n\\nACTUAL METEOR: 0.0789\\n\\nBASELINE PREDICTION: 0.1271\\n\\nS/MODEL PREDICTION: 0.0660%2 eh eT awe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Future Work Evaluation Metric\\n- finding a metric better aligned with the uniqueness of strategies in Sle Live system integration\\n- streamlining the system to provide instantaneous feedback.\\n\\nASR\\n- evaluate the model on ASR output.\\n\\nSpeech model\\n- enhance the model using prosodic speech features."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Questions? cas1@cs.cmu.edu github/craigastewart/qe_sim_interp"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 200,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Background\\n- Traditional Event Extraction based on predefined event schema and rich features encoded from annotated events.\\n\\nPros: extract high quality events for predefined types.\\n\\nCons: require large amount of human annotations and cannot extract event mentions for new event types.\\n\\nTraditional Event Extraction Pipeline\\n\\nConsumer 1: I want an event extractor for \"Transport.\" The resources for existing event types cannot be reused.\\n\\nSystem Developer: I'll train a classifier used for new types; not to mention we have 1000+ event types.\\n\\nConsumer 2: I want an event extractor for \"Attack.\"\\n\\nAnnotators: We will annotate 500 documents.\\n\\nSystem Developer: I'll train a classifier."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Background\\n- Zero Shot Transfer Learning\\n\\nLearning a regression function between object (e.g., image, entity) semantic space and label semantic space based on annotated data for seen labels.\\nThe regression model can be used to predict the unseen labels for any given image.\\n\\nVisual Representation | Shared Semantic Space\\n- Pretrained Word\\n- Visual Model\\n- Talzaon Visual Model (Embedding Lookup)\\n\\nRepresentation\\n\\nImage 1\\n\\nSeen/Unseen Label\\n\\nAndrea Frome, Greg S.\\nCorrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc Aurelio Ranzato, Tomas Mikolov, DeViSE: A Deep Visual-Semantic Embedding Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Motivation\\n- Zero Shot Learning for Event Extraction\\n\\nBoth event mentions and types have rich semantics and structures, which can specify their consistency and connections.\\n\\nEvent Mention Structure\\n- dispatch-01\\n- conflict-01\\n\\nE1. The Government of China has ruled Tibet since 1951 after dispatching troops to the Himalayas in\\n1950.\\n\\nARG\\n- year\\n- location: China\\n- troop: Himalayas\\n- 1950\\n\\nE2.\\nIranian state television stated that the conflict between the Iranian police and the drug smugglers took place near the town of Mirjaveh.\\n\\nEvent Type Structure\\n- Transport\\n- Person Attacks\\n\\nAgent\\nTime\\nAttacker\\nTime\\nPerson\\nDestination\\nTarget\\nPlace\\nInstrument\\nOrigin\\nInstrument"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Arrest Sees Transport-Person Test Event Mentions\\n\\nObjective Attack Grounding \"ARGO \"ARG Semantic Space \"Veeee\"\\n\\nQuestions\\n\\nKuwaitis \"ARG! conflict-01\\n\\nDousiion Q = asrpo Gh Tings loss (open, mention)\\n\\nPooling & Concatenation\\nPooling & Concatenation\\n\\nConvolution Layer Shared CNN\\nConvolution Layer\\n\\nStructure Composition Layer\\nStructure Composition Layer\\n\\nUnseen Types\\nSeen Types\\n\\ndispatch-01\\nconflict-01\\n\\nRecipient Instrument = Agent\\nPerson\\n\\ntime 'ARGO \"ARG!\\nDonor\\n\\nTheme\\nTarget\\nOrigin\\nTime\\ndate-entity\\npolic person\\n\\nARG!\\nARG2 year\\nmodf\\nlocation\\n<ARGO-of\\nPlace\\nTime\\nDestination\\n\\nDonation Attack Transport_Person troop\\nHimalayas\\nTran Mirjaveh\\nsmuggle-01\\n\\nTarget Event Ontology\\nTraining Event Mentions\\nJelsoy 5/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Approach Details\\n- Trigger and Argument Identification:\\n- Trigger Identification\\n- AMR parsing and FrameNet verbs/nominal lexical units\\n- Argument Identification\\n- Subset of AMR relations\\n- Event and Type Structure Construction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Approach Details\\n- Structure Composition and Representation\\n\\nEvent Mention Structure\\n- We use a matrix M, to represent each AMR relation A, and compose its semantics with two concepts for each tuple: U = <W, A, w> e.g., <dispatch-01, ARGO, China> v = f(V, 3V, 1-M).\\n\\nEvent Type Structure\\n- Similarly, we assume an implicit relation exists between any pair of type and argument, and use a tensor U'' to represent it, and compose its semantics with each pair of type and argument role u = <y, r> e.g., <Transport_Person, Person> V = f(U, V, U, e, V)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Approach Details = Joint Event Mention and Type Label Embedding\\n\\nRepresentation learning for each event mention structure and type structure: Take each structure (a sequence of tuples) as input, and encode each event mention and type structure into a vector representation using a weight-sharing Convolutional Neural Network (CNN).\\n\\nAlign the vector representations of each event mention structure with its corresponding event type structure.\\n\\nMinimize their distance within a shared vector space.\\n- Over-fitting to seen types: seen types are usually very limited.\\n- oF 8/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Approach Details= Joint Event Mention and Type Label Embedding: To avoid overfitting for seen types, add negative event mentions into training.\\n- Negative event mentions: the mentions that are not annotated with any seen types, namely other.\\nExtracted from the event mention clusters generated by Huang et al. (2016).\\n\\nLoss function: max{0, m\\n- C; + C;}, y = Other\\n\\nJY is the positive event type for the candidate trigger t, Y is the typeset of the event ontology, y' is the seen type set.\\n)' is the type which ranks the highest among all event types for event mention\\n- KSoy 9/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Approach Details\\n- Joint Event Argument and Role Embedding: Mapping between argument and role path\\n- Argument path: e.g., dispatch0O1 -> :Arg0 -> China\\n- Role path: Transport_person -> Agent\\n- Learn path representations using two weight-sharing CNNs\\n- Loss function: max max{0, m\\n- C., + Cua;}\\n- Other terms: r # OtherL4 _ j€RyjFr9(4,\\nr)\\n- a max max{0, m\\n- & It Coat rly = OtherGER, i\\n- r'\\n\\nwhere ' is the positive argument role for the candidate argument @, R, and Ry are the set of argument roles which are predefined for trigger type V and all seen types y.\\n\\n/' is argument role which ranks the highest for a when @ or V is annotated as Other."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Evaluation = Zero-Shot Classification for ACE Events\\n- Given trigger and argument boundaries, use a subset of ACE types for training, and remaining types for testing.\\n\\nSeen types for each experiment setting:\\n\\nSeen Types for Training / Dev:\\n- Attack\\n- Transport\\n- Die\\n- Meet\\n- Arrest\\n- Jail\\n- Transfer\\n- Money\\n- Sentence\\n- Elect\\n- Transfer\\n- Ownership\\n- End\\n- Positionals"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Evaluation\\n- Zero-Shot Classification for ACE Events\\n\\nStatistics for Positive/Negative instances on Training, Development, and Test sets for each experiment setting\\n\\nNegative instances are sampled from the trigger and argument clustering output of (Huang et al.,\\n2016)\\n- Training\\n- Development\\n- Test\\n\\nIndex    # of        #0          #0        # of        # of        # of        # of        # of\\nA         1/5      953/900   894/1,097   105/105   86/130\\nB         3/14   1,803/1,500  2,035/1,791   200/200   191/237\\nC         5/18     2,033/1,300  2,281/1,503   225/225   233/241   23/99   793   879\\nD         10/37   2,537/700   2,816/879   281/281   322/365\\nE         12/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Evaluation = Zero-Shot Classification for ACE Events\\n- Hit@K performance on trigger and argument classification\\n- Hit@K Accuracy: the correct label occurs within the top K ranked output labels\\n- WSD-Embedding: directly map event triggers and arguments to event types and argument roles according to their cosine similarity of word sense embeddings\\n\\n| Transfer  | A      | B      | C      | D      |\\n|-----------|--------|--------|--------|--------|\\n| Argument Typing (%) | 3.98   | 7.04   | 20.05  | 33.47  |\\n| Accuracy (%)        | 23.77  | 12.48  | 34.66  | 51.40  |\\n| F1 Score           | 32.54  | 36.79  | 46.48  | 68.26  |\\n| Precision          | 1.25   | 3.53   | 9.56   | 14.68  |\\n| Recall             | 3.41   | 6.03   | 14.68  | 26.51  |\\n| Normalized F1     | 3.64   | 6.26   | 15.70  | 27.65  |\\n\\nelsoy 13/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Evaluation\\n- Zero-Shot Classification for ACE Events:\\n\\nTraining subtypes of Justice:\\n- Arrest-Jail\\n- Convict\\n- Charge-Indict\\n- Execute\\n\\nPerformance on Various Unseen Types\\n\\nType Subtype Hit@k bd eer\\nJustice Sentence 68.29 68.29 69.51\\nJustice Appeal 67.50 97.50 97.50\\nJustice Release-Parole 73.91 91 73.91\\nConflict Attack 26.47 44.52 46.69\\nTransaction Transfer-Money 48.36 68.85 79.51\\nBusiness Start-Org 0 33.33 66.67\\nMovement Transport 2.60 al 7.81\\nPersonnel End-Position 9.09 50.41 33.12\\nLife Injure 87.64 91.01 91.01\\nContact Phone-Write 60.78 88.24 90.20\\n\\nelsoe 14/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Evaluation\\n- Event Extraction for ACE Types\\n\\nTarget Event Ontology: ACE (33 types) + FrameNet (1161 frames)\\n\\nSeen types for training: 10 ACE types\\n\\nPerformance on ACE types\\n\\nSetting Method | Tyseer | Target Event | Agent\\n\\nLSTM 59.3 54.3 56.7 55.1 50.4 52.6 47.8 22.6 30.6 28.9 13.7 18.6 16.1 15.6 15.8\\n\\nErrors: misclassification within the same scenario\\n- e.g., Being-Born vs. Giving-Birth\\n\\nAbby was a true water birth (3kg\\n- normal) and with Fiona I was dragged out of the pool after the head crowned."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Discussion- Impact of AMR\\n\\nParsing= AMR is used to identify candidate triggers and arguments, as well as construct event structures.\\n\\nCompare AMR with Semantic Role Labeling (SRL) on a subset of ERE corpus with perfect AMR annotations.\\n\\nTrain on top-6 most popular seen (training) types: Arrest-Jail, Execute, Die, Meet, Sentence, Charge-Indict, and test on 200 sentences, with 128 attack event mentions and 40 convict event mentions.\\n\\nTrigger Argument\\n- Lattin\\n- PPT RTA | PTR IS\\n\\nPerfect AMR\\n- 79.1 | 47.1 | 59.1 | 25.4 | 21.4 | 23.2\\n\\nPerfect AMR with Core Roles only (SRL)\\n- 77.1 | 47.0 | 58.4 | 19.7 | 16.9 | 18.2\\n\\nSystem AMR\\n- 85.7 | 32.0 | 46.7 | 22.6 | 15.8 | 18.6\\n\\nelsoe 16/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Discussion\\n- Transfer Learning vs. Supervised Model\\n- Target Event Ontology: ACE (33 types) + FrameNet (1161 frames)\\n- Seen types for training: 10 most popular ACE types\\n- Unseen type: 23 remaining ACE types\\n- LSTM: 20\\n- TransferF: 200 400 600 800 1000 # of Event Mentions for Training\\n- 17/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Conclusion and Future Work\\n- We model event extraction as a generic grounding problem, instead of classification.\\nBy leveraging existing human constructed event schemas and manual annotations for a small set of seen types, the zero shot framework can improve the scalability of event extraction and save human effort.\\nIn the future, we will extend this framework to other Information Extraction problems.\\n- os 18/19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "O&A Thank You! 6 19/19"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 365,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Bush to Stress Domestic Issues in Speech."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Bush to Stress Domestic Issues in Speech. (Year\\n1989) George W. Bush"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Bush to Stress Domestic Issues in Speech. (Year\\n1989)\\n\\nGeorge W. Bush\\n\\nGeorge H. W. Bush"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "1. Introduction\\n2. Temporal NED Model\\n3. Time-Aware Start-of-the-Arts\\n4. Evaluation\\n5. Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Introduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Problem Description\\n\\nGiven: a set of entity mentions M in a document.\\n\\nEntities: entries in a Knowledge Base (KB).\\n\\nTask: Link each m, where m ∈ M, to its correct entry in KB, if available.\\n\\nPredict as an OOKBE, otherwise."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Named Entity Disambiguation\\n\\nIn 1959, David Pearson exhibited as part of the Young Contemporaries exhibition in London.\\n\\nIn 1981, with a small number of BNR colleagues, David Pearson left to found Orcatech Inc.\\n\\nDavid Pearson raced for Hoss Ellington during the 1980 season."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Named Entity Disambiguation (en.wikipedia.org/wiki/Dave_Pearson_(painter))\\n\\nIn 1959, David Pearson exhibited as part of the Young Contemporaries exhibition in London.\\n\\n(en.wikipedia.org/wiki/David_Pearson_(computer_scientist))\\n\\nIn 1981, with a small number of BNR colleagues, David Pearson left to found Orcatech Inc.\\n\\nDavid Pearson raced for Hoss Ellington during the 1980 season.\\n\\n(en.wikipedia.org/wiki/David_Pearson_(racing_driver))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Context Evolution\\n\\nPopularity-based Models Mihalcea and Csomai, 2007 [7]\\n- Entity popularity and mention-entity prior probabilities.\\n- Leverages anchor links structure.\\n\\nDavid Pearson\\nDave Pearson (painter) | 0.1\\nDavid Pearson\\nDavid Pearson (computer scientist) | 9 4"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Context Evolution\\n\\nPopularity-based Models\\nMihalcea and Csomai, 2007 [7]\\nEntity popularity and mention-entity prior probabilities.\\nLeverages anchor links structure.\\nDavid Pearson Dave Pearson (painter) | 0.1\\nDavid Pearson David Pearson (computer scientist) | 9 4\\n\\nLocal Models\\nBunescu and Pasca, 2006 [2]; Cucerzan, 2007 [3]; Milne and Witten, 2008 [8]\\nSimilarity with immediate context words.\\nIndependent disambiguation.\\n1959, exhibited, exhibition, David Pearson Dave Pearson (painter) SES VEE, SE london\\nDavid Pearson David Pearson (computer scientist) | 1981, bnr, colleagues, found, orcatech5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Context Evolution = Global Models\\nKulkarni et al., 2007\\nHoffart et al., 2011\\n\\nEntities mentioned in a document are related.\\nCollectively disambiguate entities.\\nDavid Pearson\\nDave Pearson (painter) | London\\nDavid Pearson | ooo Beezeen (computer scientist)\\nBNR, Orcatech Inc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Context Evolution\\n\\nGlobal Models\\n\\nKulkarni et al., 2007 [6], Hoffart et al., 2011 [4]\\n\\nEntities mentioned in a document are related. Collectively disambiguate entities.\\n\\nDavid Pearson Dave Pearson (painter) | London David Pearson | ooo Beezeen (computer scientist) @ Representation Learning and Context Attention\\n\\nBlanco et al., 2015 [1], Hu et al. [5], 2015, Yamada et al., 2016 [10]\\n\\nUse of distributed vector representations. Trained using the anchor links structure of KB.\\nRemove noisy words from the context.\\n\\nDavid Pearson Dave Pearson (painter) Vondon: Vestibition\\n\\nDavid Pearson David Pearson (computer scientist)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Context Evolutiono Temporal Context"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Motivation for Temporal Modeling Deduction\\n\\nPrevious works fail to factor in temporal semantics.\\n- Single value for entity popularity.\\n- Bias towards frequently occurring entities in KB and recent news.\\n\\nYear 1989: Bush to Stress Domestic Issues in Speech.\\nYear 1521: Martin Luther confronts the emperor Charles V, refusing to retract the views which led to his excommunication.\\n\\nFigure 1: Entity Annotated Sample Texts. (Image source: Wikipedia)\\n\\nThe values in the brackets indicate the entity popularity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Motivation for Temporal Modeling\\n\\nDeduction\\n\\nPrevious works fail to factor in temporal semantics.\\nSingle value for entity popularity.\\nBias towards frequently occurring entities in KB and recent news.\\n\\n(4.21 x 10⁻⁴) (3.70 x 10⁻⁵)\\nYear 1989: Gail; Bush to stress domestic issues in speech.\\n(4.85 x 10⁻⁵)\\nYear 1521: Martin Luther confronts the emperor Charles V, refusing to retract the views which led to his excommunication.\\n(1.28 x 10⁻⁴) (2.67 x 10⁻⁸) TAR (5.21 x 10⁻⁵)\\n\\nFigure 1: Entity Annotated Sample Texts. (Image source: Wikipedia)\\n\\nThe values in the brackets indicate the entity popularity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "o Temporal Context\\n\\nFactor-in temporal semantics. Distributed popularity. Independent of anchor link structure.\\nUnbiased towards document creation time. 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Temporal NED Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Vector Space Modeling\\n- George H.W. Bush (1989)\\n\\nGeorge W. Bush\\n\\nFigure 2: Temporal Vector Space Modeling\\n\\nRepresentations: Entity as <entity signature> and mention as (mention, year)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Temporal Signatures of KB Entities\\n\\nMartin Luther\\n\\n---- a HeidelTime\\n\\nMartin Luther (10 November 1483\\n- 18 February\\n1546) was a German avis, (ithe: pense 1483-11-10, 1546-02-18, 1517, 1520, Ninety-five Theses of 1517, Leo 1521, 1484, 1492, 1497, 1498, 1505 (multi-set of temporal expressions) X in 1520 and Diet of Worms one year later.\\nHis family moved to Mansfeld in 1484, served as town councilor in 1492, in Magdeburg in 1497, and in Eisenach in\\n1498.\\n\\nIn 1501, he received his master's degree in\\n1508.\\n\\n(signature)\\n\\nFigure 3: Extraction of Temporal Signatures from Wikipedia Article Content."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "1. Document Creation Time (DCT): The mention is represented as One-Hot Vector. Applicable for news articles.\\nAll values in the vector are 0, except a single 1 at the index position corresponding to DCT.\\n2. In-context Temporal Information: In-context expressions can be extracted using a temporal tagger.\\nApplicable for narrative documents.\\nThere are 1s at index positions corresponding to the set of date values T(m) extracted by the temporal tagger.\\n3. Combined Contexts: The context similarity scores can also be aggregated."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Disambiguation Example\\n- George H. W. Bush\\n- Martin Luther King Jr.\\n- Barbara Bush\\n- Martin Luther (diplomat)\\n- Alan Bush\\n- Martin Luther McCoy\\n- Lawrence Bush\\n- Martin Luther\\n- George W. Bush\\n- Lynn J. Bush\\n- Kate Bush\\n\\nFigure 4: Temporal signatures of entity candidates for mentions (Bush,\\n1989) and (Martin Luther, 1521)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Time-Aware Start-of-the-Arts"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Making NEDs Time-aware\\n\\ndiaNED-1, extension of [Hoffart et al.: Robust Disambiguation of Named Entities in Text, EMNLP 2011]\\nDocument as a graph with mentions and entities as nodes.\\nMention-entity priors, mention entity similarity, and entity coherence used as edge weights.\\nDisambiguation: A one-to-one mapping between each mention and entity node.\\n\\ndiaNED-2, extension of [Yamada et al.: Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation, SIGNLL 2016]\\nRepresentation of context words and entities in a single vector space using skip gram model.\\nDisambiguation: A learning-to-rank model using prior stats, string similarity, mention-entity, and coherence similarity as features."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Standard NED Datasets\\n- CoNLL-AIDA 1996\\n- TAC 2010\\n- 2004-2007\\n- Microposts 2014\\n- 2011\\n\\nShortcomings\\n- Minimal improvements with time-aware models.\\n- Not suitable to demonstrate/evaluate power of time-awareness."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "A Diachronic Dataset: diaNEDHistoryNet Historynet.com: online resource of major historical events.\\n\\nManually annotated 865 mentions in 350 randomly selected documents.\\n\\nNew York Times NYT headlines published between 1987 and\\n2007.\\n\\nManually annotated 368 mentions in 300 randomly selected headlines.\\n\\nThe named entities were identified using the 3 class Stanford NER tagger."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Results: diaNED-1 History Net New York Times Feature set\\n- w/o time\\n- w/ time\\n\\nPrior\\n(2.26 80.48* 38.14 54.24*\\n\\nContext\\n63.63 66.10* 48.31 62.71\\n\\nTable 1: Micro-accuracy of diaNED-1 with and without time-awareness feature.\\n* significant over w/o time (Welch's t-test at level of 0.01)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Results: diaNED-2 HistoryNet New York Times Feature set\\n\\nw/o time    w/ time\\nBase        89.44      90.23*\\nString      89.40      90.00*\\nContext     91.10      91.81*\\nCoherence   91.16      91.98*\\n\\nTable 2: Micro-accuracy of diaNED-2 with and without time-awareness feature.\\n* significant over w/o time (Welch's t-test at level of 0.01)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Results:\\n\\ndiaNED system HistoryNet | New York Times x Lisa\\n- NGRAM [Zhang and Rettinger, 2014] 87.07 66.30\\n\\nx Lisa\\n- NER [Zhang and Rettinger, 2014] 83.32 60.25\\n\\nWAT [Ferragina and Scaiella, 2012] 82.26 70.95\\n\\nPBOH [Ganea et al., 2016] 90.26\\n\\nTASFREME NER [Dojchinovski and Kliegr, 2013] 48.50 45.27\\n\\nFRED [Consoli and Recupero, 2015] 23.18 15.44\\n\\nFOX [Speck and Ngomo, 2014] 77.85 54.25\\n\\nDexter [Ceccarelli et al., 2013] 69.88 49.12\\n\\nDBpedia Spotlight [Mendes et al., 2011] 56.92 61.91\\n\\nAIDA [Hoffart et al, 2011] 82.68 70.14\\n\\nAGDISTIS [usbeck et al, 2014] 70.77 50.14\\n\\nGupta et al., 2017 62.82 43.33\\n\\nre-impl. of [Yamada et al., 2016] 90.87 255\\n\\ndiaNED\\n- 2 91.68 76.09\\n\\nTable 3: Micro\\n- fl scores on the HistoryNet and New York Times datasets of diaNED\\n- 2 (trained on CoNLL\\n- AIDA [4]) and other tools available on GERBIL [9]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Summary\\n- Wikipedia\\n\\nEntity Relations\\n\\nTemporal Tagger\\n\\nNamed Entity Signatures\\n\\nTemporal Contexts\\n\\nEntity Repository\\n\\nDictionary\\n- xts with Time"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "The annotated diaNED Corpora and Entity Temporal Signatures are available at: https://www.mpi-inf.mpg.de/yago-naga/dianed/21"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Future Work\\n- Study how temporal affinity can be used for identifying out-of-KB entities.\\n- Large scale experiments using data-sets generated using semi-supervised methods.\\n- Adding multilingual support for the temporal signatures."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Thank you! Questions?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "R. Blanco, G. Ottaviano, and E. Meij. Fast and space-efficient entity linking for queries.\\nIn Proceedings of the 8th ACM International Conference on Web Search and Data Mining, WSDM '15, pages 179-188. ACM,\\n2015.\\n\\nR. C. Bunescu and M. Pasca. Using encyclopedic knowledge for named entity disambiguation.\\nIn Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, EACL '06, pages 9-16, 2006."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "S. Cucerzan. Large-scale named entity disambiguation based on Wikipedia data.\\n\\nIn Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL '07, pages 708-716.\\nAssociation for Computational Linguistics, June\\n2007.\\n\\nJ. Hoffart, M. A. Yosef, I. Bordino, H. Fürstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum.\\nRobust disambiguation of named entities in text.\\n\\nIn Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP '11, pages 782-792.\\nAssociation for Computational Linguistics, 2011."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Z. Hu, P. Huang, Y. Deng, Y. Gao, and E. Xing. Entity hierarchy embedding.\\nIn Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1292-1300, Beijing, China, July\\n2015. Association for Computational Linguistics.\\n\\nS. Kulkarni, A. Singh, G. Ramakrishnan, and S. Chakrabarti. Collective annotation of Wikipedia entities in web text.\\nIn Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '09, pages 457-466.\\nACM, 2009."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "R. Mihalcea and A. Csomai. Wikify!: Linking documents to encyclopedic knowledge.\\nIn Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM '07, pages 233-242.\\nACM,\\n2007.\\n\\nD. Milne and J. H. Witten. Learning to link with Wikipedia.\\nIn Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08, pages 509-518. ACM, 2008."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "R. Usbeck, M. Réder, A.-C. Ngonga Ngomo, C. Baron, A. Both, M. Brümmer, D. Ceccarelli, M. Cornolti, D. Cherix, B.\\nEickmann, P. Ferragina, C. Lemke, A. Moro, R. Navigli, F. Piccinno, G. Rizzo, H. Sack, R. Speck, R. Troncy, J.\\nWaitelonis, and L. Wesemann.\\n\\nGerbil: General entity annotator benchmarking framework.\\nIn Proceedings of the 24th International Conference on World Wide Web, WWW '15, pages 1133-1143.\\nInternational World Wide Web Conferences Steering Committee,\\n2015.\\n\\nY. Yamada, H. Shindo, H. Takeda, and Y. Takefuji.\\n\\nJoint learning of the embedding of words and entities for named entity disambiguation.\\nIn Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, CoNLL '15, pages 250-259.\\nAssociation for Computational Linguistics, August 2016."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 367,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Query Auto-Completion\\n\\nSearch engine suggests queries as the user types.\\n\\nGoogle Idea from Park & Chiba (2017):\\n\\nUse an LSTM to generate completions.\\n- Why does ice float?\\n- Why does water expand when it freezes?\\n- Why does my stomach hurt?\\n- Why does my chest hurt?\\n- Why does my cat lick me?\\n- Why does my back hurt?\\n- Why does my head hurt?\\n- Why does my lower back hurt?\\n- Why does my jaw hurt?\\n\\nCan we do better by adapting the LM to provide personalized suggestions?\\n\\nGoogle Search: I'm Feeling Lucky."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "RNN Language Model Adaptation\\n\\nLearn an embedding, c, for each user and use it to adapt the predictions.\\n\\nMethod #1: Concatenate the user embedding with the input at each step.\\n\\n* A = o(W[h_{t-1}, e] +\\nb)\\n\\n* Same as applying a constant linear shift to the bias vector (in recurrent & output layers)\\n\\n* W = [W_Y, V]\\n\\n* b_c\\n\\n* Leaves most of the recurrent model parameters unchanged.\\n\\nMethod #2: Low-rank adaptation of embedding is the same as shifting the bias.\\n\\n* Adjust b and W!\\n\\n* Referred to here as ConcatCell (Mikolov & Zweig, 2012)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Factor Cell Model Adapted weights Generic weights Low-rank adaptation (e +\\nh) x h (e +\\nh) x h 1 x k k x (e +\\nh) x r r x h x k k x 1 e\\n\\nThe adaptation matrix is formed from a product of the context embedding with left and right bases.\\nThe two bases tensors (L and\\nR) hold k different rank r matrices, each the same size as W. Context vectors give a weighted combination."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Learning user embeddings, recurrent layer weights and {L, R} tensor learned jointly.\\n\\nNeed online learning to adapt to users that were not previously seen.\\n\\nIn joint training, learn a cold-start embedding for a set of infrequent users.\\n\\nDuring evaluation, initialize each user's embedding with the learned cold-start vector.\\n\\nMake query suggestions.\\n\\nAfter the user selects a query, back-propagate and only update the user embedding."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "© Welcome, Xianndc! ORF Lo. Search: MVE ACen AEs oe ESS 4 -j AOL @ |e Using Query Log data:\\n\\nusers and 12 million queries for training now\\n\\nNew Poll Lists Love Bites! Vote for Top '07 Romantic Restaurants\\n\\npatrons.\\n\\nUser embedding size =\\n32. LSTM size = 600\\n\\nCompare Before-and-After Photos\\n\\nOn-Demand News Videos\\n\\nVictim Pursues Rapist for 29 Years\\n\\nGifts for them. Triple Points for you.\\n\\nFeedback (See Smallest Horse in the World)\\n\\nMore News: U.S. Won't Quit Iraq, Bush Vows:\\n\\nRun Your Own Basketball Team for Free!\\n\\nLet Them Select (RED) Products\\n\\nGift Cards:\\n- Gaming Systems\\n\\nHappy Christmas.\\n\\nDiet & Fitness\\n\\nLove@AOL\\n\\nPictures\\n\\nVideo\\n\\nFood & Home\\n\\nMapQuest\\n\\nReal Estate\\n\\nYellow Pages\\n\\nCelebrate the Holidays by Sending Free E-Cards\\n\\nVideo 'The Source for Mean Reciprocal Rank (MRR) as a metric\\n\\nChange This Screen\\n\\nHigh-Speed Options\\n\\nDecrease Screen Size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Benefit improves over time!\\n\\n0.305\\n- FactorCell\\n- ConcatCell\\n- Unpersonalized ConcatCell\\n- FactorCell\\n\\nPerformance for users with > 50 queries\\nQueries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Qualitative Comparison\\n\\nWhat queries are boosted the most after searching for \"high school softball\" and \"math homework help\"?\\n\\nFactor Cell\\n\\nConcat Cell\\n\\nhigh school musical\\nhoroscope\\nchris brown\\nhigh school musical\\nfunny junk com\\nhomes for sale\\nfunbrain.com\\nmodular home\\nchat room\\nhair styles\\n\\nQueries that most decrease in likelihood with the Factor Cell include travel agencies and plane tickets."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Recent Related Work:\\n\\nFlorini & Lu, NAACL 2018\\n- Also personalized LSTM for query prediction\\n- ConcatCell adaptation framework\\n- User embedding learned separately\\n- No online learning. Assessed on two datasets, but different split of AOL data\\n- Confirms benefit of adapted LM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Conclusion\\n\\nPersonalization helps and the benefit increases as more queries are seen.\\nStronger adaptation of the recurrent layer (FactorCell) gives better results than concatenating a user vector.\\nNo extra latency/computation due to caching of adapted weight matrix.\\n\\nTry out the FactorCell on your data:\\nhttp://github.com/ajaech/query_completion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "THANKS!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Qualitative Comparison\\n\\nWhat queries are boosted the most after searching for \"pradahandbags\" and \"versace eyewear\"?\\n\\nFactor\\n\\nCell Concat\\n\\nCell\\n\\nneiman marcus\\n\\nCraigslist\\n\\nnyc\\n\\npottery barn\\n\\nmyspace\\n\\nlayours\\n\\nJc penny\\n\\nverizon wireless\\n\\nverizon wireless\\n\\njensen ackles\\n\\nbed bath and\\n\\nwebster dictionary\\n\\nbeyond"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Backup Slides"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "FactorCell Model Adapted weights Generic weights Low-rank adaptation The adapted weight matrix is a drop-in replacement for WAesy = O((Wo + We) [he ee] +\\nb) Much larger change in recurrent THE YELLOW box layer than what ConcatCell does"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Prefix and query length\\n- Longer queries are more difficult.\\n- Suggestion quality improves as prefix length increases.\\n- 0.9\\n- 0.6\\n- 0.4\\n- 0.3\\n- Factor Cell °F ~ 4 7 10 13 16 19\\n\\nPrefix Length 15"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 187,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Sentence extraction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Sentence extraction and document modeling is essential to many NLP tasks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Sentence extraction and document modeling is essential to many NLP tasks apparent in problems where capturing long range dependencies is important"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Sentence extraction and document modeling is essential to many NLP tasks apparent in problems where capturing long range dependencies is important.\\nSentence extraction is the selection of specific sentences from documents, with an end goal in mind."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Sentence extraction document modeling is essential to many NLP tasks apparent in problems where capturing long range dependencies is important.\\nSentence extraction is the selection of specific sentences from documents, with an end goal in mind.\\nExtractive Summarization and Question Answer Selection are two examples of sentence extraction problems."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "South Korean Prime Minister Lee Wan-Koo offers to resign\\n\\nSeoul (CNN) -- South Korea's Prime Minister Lee Wan-Koo offered to resign on Monday amid a growing political scandal.\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\n\\nPark heard about the resignation.\\nCalls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging.\\nSung, who was under investigation for fraud and bribery, left a note listing names and amounts of cash given to top officials, including those who work for the President.\\nLee and seven other politicians ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "South Korean Prime Minister Lee Wan-Koo offers to resign\\n\\nSeoul (CNN) -- South Korea's Prime Minister Lee Wan-koo offered to resign on Monday amid a growing political scandal.\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\nPark heard about the resignation...\\n\\nCalls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging.\\nSung, who was under investigation for fraud and bribery, left a note listing names and amounts of cash given to top officials, including those who work for the President.\\nLee and seven other politicians ...\\n\\nStory highlights:\\n- Calls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging from a tree in Seoul.\\n- Sung, who was under investigation for fraud and bribery, left a note listing names and amounts of cash given to top officials."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "South Korean Prime Minister Lee Wan-Koo offers to resign\\n\\nSeoul (CNN) -- South Korea's Prime Minister Lee Wan-Koo offered to resign on Monday amid a growing political scandal.\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\n\\nCalls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging.\\nSung, who was under investigation for fraud and bribery, left a note listing names and amounts of cash given to top officials, including those who work for the President.\\n\\nStory highlights:\\n- Calls for Lee to resign began after South Korean tycoon Sung Woan-jong was found hanging from a tree in Seoul.\\n- Sung, who was under investigation for fraud and bribery, left a note listing names and amounts of cash given to top officials."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Documents are more than plaintext chunks\\n\\nSeoul (CNN) South Korea's Prime Minister Lee Wan-koo offered to resign on Monday amid a growing political scandal.\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\nHe has transferred his..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "South Korean Prime Minister Lee Wan-koo offered to resign on Monday amid a growing political scandal.\\n\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\nHe has transferred his..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "South Korean Prime Minister Lee Wan-koo offers to resign more than plain text chunks.\\n\\nThey can also contain titles.\\n\\nSeoul (CNN) South Korea's Prime Minister Lee Wan-koo offered to resign on Monday amid a growing political scandal.\\nLee will stay in his official role until South Korean President Park Geun-hye accepts his resignation.\\nHe has transferred his..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Main ideas of this work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Main ideas of this work: external information can be useful to sentence selection (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Main ideas of this work: external information can be useful to sentence selection (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001).\\n\\nDocument modeling with richer content: read whole document before starting to extract sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Main ideas of this work: external information can be useful to sentence selection (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001).\\nDocument modeling with richer content: read whole document before starting to extract sentences.\\nDo not rely on similarity metrics to extract sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Main ideas of this work:\\n- External information can be useful to sentence selection (Edmundson, 1969; Kupiec et al., 1995; Mani, 2001).\\n- Document modeling with richer content: read whole document before starting to extract sentences.\\n- Do not rely on similarity metrics to extract sentences.\\n- Neural architecture for sentence extraction (XNet)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "XNet: Document Encoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Convolutional Sentence Encoder\\nDocument Encoder\\nNorth Korea; fired a T missle $5 $4 $3 $2\\nSy over [convolution] [max pooling]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "XNet: Document Encoder\\n\\nConvolutional Sentence Encoder\\n\\nDocument Encoder\\n\\nMissile 85 S4 83 So S1=a\\n\\nConvolution\\n\\nMax pooling\\n\\nHierarchical (two-level) encoder\\n\\nSentences are encoded by a convolutional encoder (Kim, 2014).\\n\\nLSTM Document Encoder\\n\\nGet a document embedding before extraction begins."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "XNet: Sentence Extractor"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "XNet: Sentence Extractor\\n\\nSentence Extractor\\n\\nY1 Y2 ¥3 Ya Y5 ae) lllior) | lhCUttC«*dTdoc S1 82 83 S4 S59"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "XNet: Sentence Extractor\\n\\nSentence Extractor\\n\\nFire RNN extractor takes document embedding aset Edoc Si S82 83 SA S5a,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "XNet: Sentence Extractor\\n\\nSentence Extractor\\n\\nY1 Y2 U3 Ya U5 moro; tt ft e RNN extractor i e takes document embedding as er) nedoc si 82] s3 sa 85 e instead of attending to text, attends over external ya: information IE = sentence embeddings = other information be 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "XNet: Sentence Extractor\\n\\nSentence Extractor\\n\\nY1 Y2 U3 Ya U5 i e RNN extractor takes document embedding as input instead of attending to text, attends over external information.\\n\\nIE =» sentence embeddings = other information.\\n\\nSoftmax over the output external produces binary labels."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "XNet for Extractive Summarization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "XNet for Extractive Summarization attention over external information = title = image captions sentences encoded with the convolutional sentence encoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "XNet for Extractive Summarization\\n\\nSentence Extractor\\n- attention over external information\\n- title\\n- image captions\\n- sentences encoded with the convolutional sentence encoder\\n- External attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "XNet for Extractive Summarization\\n\\nSentence Extractor\\n\\n0 il 0 1e attention over external information\\n- i\\n- n\\n- nea title T 7 te) on doc $1 §2 83 S4 S5 = image captions\\n\\nsentences encoded with the convolutional sentence encoder C1 C2\\n\\nExternal attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "XNet for Extractive Summarization\\nSentence Extractor\\n0 1 0 1 0\\ne attention over external information = title T\\n7_ (| idoc $1 82 83 S84 85 = image captions\\ne sentences encoded with the convolutional sentence encoder C1 C2\\nExternal attention\\n10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Extractive Summarization Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "E + + S + E | Mosquito-borne virus. Chikungunya worries CDCe CNN part of CNN/DailyMail dataset\\n\\nUpdated 11:20 GMT (19:20 HKT) June 13, 2014\\n\\nDangerous mosquito illness on the rise\\n\\n01:16\\n\\nStory highlights\\n\\nNorth Carolina reports first case of mosquito-borne virus called chikungunya.\\n\\nChikungunya is primarily found in Africa, East Asia and the Caribbean islands.\\n\\nVirus is not deadly, but it can be painful, with symptoms lasting for weeks.\\n\\nA debilitating, mosquito-borne virus called chikungunya has made its way to North Carolina, health officials say.\\nIt's the state's first reported case of the virus.\\nThe patient was likely infected in the Caribbean, according to the Forsyth."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Extractive Summarization Experiments\\n\\nMosquito-borne virus. Chikungunya worries CDC.\\n\\nCNN is part of the CNN/DailyMail dataset.\\n1. Preprocess:\\n- Extract titles (each article has a title) and image captions (avg 3 captions per article; 40% articles have at least one).\\n2. Oracle summaries:\\n- Select sentences that collectively give a high ROUGE score with respect to the gold summary (Nallapati et al., 2017).\\n\\nA debilitating, mosquito-borne virus called chikungunya has made its way to North Carolina, health officials say.\\nIt's the state's first reported case of the virus.\\nThe patient was likely infected in the Caribbean, according to the Forsyth."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Extractive Summarization Experiments\\n\\nMosquito-borne virus. Chikungunya worries CDC\\n\\nCNN part of CNN/DailyMail dataset\\n- preprocess C6608 = extract titles (each article has a title) and image captions (avg 3 captions per article; 40% articles have at least one) = oracle summaries: select sentences that collectively give high ROUGE score with respect to the gold summary (Nallapati et al.,\\n2017)\\n- summary: 3 top-scoring sentences according to the extractor can say.\\nIt's the state's first reported case of the virus.\\nThe patient was likely infected in the Caribbean, according to the Forsyth."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "External info helps extractive summarization\\n\\nAblation results on validation set (ROUGE recall scores)\\n\\nPointerNet is Cheng and Lapata (2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Results model | ROUGE1 | ROUGE2 | ROUGE_L | LEAD | XNet is XNet + title + caption, PointerNet is Cheng and Lapata (2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Human evaluation confirms the quality of generated summaries"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Human evaluation confirms the quality of generated summaries.\\nModel, AST, and ORDA annotators ranked systems from best (1st) to worst (4th)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "XNet for OA Selection Sentence Extractor attention over the question\\nExternal attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "XNet for OA Selection\\n\\nSentence Extractor attention over the question word overlap info inverse document frequency (IDF) inverse sentence frequency (ISF; Trischler et al.,\\n2016) local ISF (ISF considering number of sentences in article) External attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "XNet for OA Selection Sentence Extractor attention over a.\\nThe question = word overlap information | inverse document frequency (IDF) | local ISF (ISF considering number of sentences ISF IDF in article) External attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "XNet for OA Selection\\nSentence Extractor attention over -.\\nCae=» the question= word overlap info\\ninverse document age\\nfrequency (IDF)\\ninverse sentence frequency (ISF; Trischler et al.,\\n2016)\\nlocal ISF (ISF with considering no of sents q ISF IDF in article)\\nExternal attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "XNet for OA Selection\\n\\nSentence Extractor attention over -.\\n\\nPea hl=» the question= word overlap info T 7 Ti°o inverse document doc 81 82 83 sa] 85 frequency (IDF) o inverse sentence ya frequency (ISF; Trischler 40 et al.,\\n2016) © local ISF (ISF with considering no of sents q ISF IDF in article) External attention 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "OA Selection Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "OA Selection Experiments four datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "OA Selection Experiments four datasets: NewsQA, SQUAD, WikiQA, MSMarco"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "OA Selection Experiments four datasets: NewsQA, SQUAD, WikiQA, MSMarco leave out unanswered questions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "OA Selection Experiments four datasets: NewsQA, SQUAD, WikiQA, MSMarco leave out unanswered questions; report scores for accuracy, Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "XNet variants___model___|_SQuad | WikiQa | NewsQA | MSMarco comparison of XNet variants reporting accuracy, similar patterns for MRR and MAP\\n\\nXNet: only considering qe\\n\\nXNet+: considers q, IDF, ISF, LocalSFe\\n\\nXNetTopk: choose top k sentences based on ISF and then XNet\\n\\nLRXNet: ensemble <XNet, CompAger (Wang et al., 2017), classifier considering word overlap scores>"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Results for NewsQA show consistent behavior on SQUAD, WikiQA, and MS Marco with consistent behavior on all metrics."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Results for NewsQA consistent behavior on SQUAD, WikiQA and MSMarco consistent behavior on all metrics.\\nWrd Cnt: word count\\n- Wrd Cnt: weighted word Wrd Cnt 44.67 count\\n0 10 20 30 40 50 60\\naccuracy 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Results for NewsQA consistent behavior on SQUAD, WikiQA and MSMarco CompAggr 54.54.\\n\\nConsistent behavior PairCNN 25.67; on all metrics.\\n\\nWrd Cnt: word count.\\n\\nWet Wrd Cnt: weighted word count.\\n\\nWrd Cnt 44.67 count.\\n\\nPairCNN: encode (question, candidate sent) isolated.\\n\\nCompAggr (Wang et al.,\\n2017) 18."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Results\\nLRXNet 55.17\\nNewsQAXNet+ 47.23\\nconsistent behavior\\nXNetTopK 29.41 on SQuAD, WikiQA, and MSMarco\\nCompAggr 54.54.\\nconsistent behavior\\nPairCNN 25.67 on all metrics\\nWrd Cnt: word count\\nWrd Cnt 45.24\\nWrd Cnt: weighted word count\\nWrd Cnt 44.67\\nPairCNN: encode (question, candidate sent) isolated\\nCompAggr (Wang et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Summary: A robust neural model for sentence extraction that hierarchically encodes documents, reads whole documents before extraction, and attends to external information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Summary: A robust neural model for sentence extraction that hierarchically encodes documents, reads the whole document before extraction, and attends to external information.\\nAttending to external information (title and caption) helps create better extractive summaries."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Summary: A robust neural model for sentence extraction that hierarchically encodes documents, reads the whole document before extraction, and attends to external information.\\nAttending to external information (title and caption) helps create better extractive summaries.\\nAttending to question and word overlap metrics helps with question-answer selection.\\nConsidering external information helps."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Sm3 Edinburgh), code and datasets available Nan! Langue Pecos NLP https://git.io/fbpl3Ws HUAWEI20"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 12,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Motivation\\n- Our Method\\n- Training Procedures\\n- Experiments and Results\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Outline\\n- Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Textual Media\\nPeople spend 12 hours everyday consuming media in\\n2018.\\n- eMarketer\\nhttps://www.emarketer.com/topics/topic/time-spent-with-media"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "consuming media in 2018\\n\\nJapan floods leave at least 55 dead; 2 million flee homes\\n\\nPompeo dismisses North Korea's 'gangster' comments\\n\\nCroatia eliminate host Russia in Cup\\n\\nExtraction of 12 boys and their soccer coach\\n\\nUS citizens warned to shelter amid Haiti\\n\\nFull story: 13 divers descend into caves to bring out soccer team\\n\\nHeartbreaking letter: Youngest boy dreams of fried chicken\\n\\nSoybean farmers say that China tariffs could do 'serious damage'\\n\\nHero: Former Thai navy SEAL diver dies in cave\\n\\nUS candidate: 'Outside of Western civilization there is only barbarism'\\n\\nWatch: A virtual look inside what cave rescue could look like\\n\\nWashington Post: Trump's personal calls to\\n\\nHealth: How a lack of oxygen is affecting the Thai soccer team\\n\\nUS destroyers sail through Taiwan Strait"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Overview\\n\\nTextual Media\\n\\nThai cave rescue begins\\n\\nIn\\n2018.\\n- Live updates on the situation: Pompeo.\\n\\nExtraction of 12 boys and their soccer coach could take days, officials say.\\n\\nPhotos: Thai soccer team trapped in cave.\\n\\nHero: Former Thai navy SEAL diver dies in cave.\\n\\nWatch: A virtual look inside what cave rescue could look like.\\n\\nHealth: How a lack of oxygen is affecting the Thai soccer team."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "ACL 2018 Conference\\n\\nIf you're still looking for accommodation during ACL 2018, the excellent reviewing performance of the following Melbourne sods will check out their gigs @acl2018 reviewers.\\nThey were recognized by the area chairs as outstanding reviewers who have turned in exceptionally well-written and constructive reviews.\\n\\nAbout actively engaged themselves in the post-rebuttal photos.\\nThis is a public Google group to help match roommates for NLP conferences.\\nBelow is the ACL 2018 Top Reviewer template for posting.\\n\\nOnce you have found a place, please let us know if you are attending @aci2018 and would like to volunteer.\\n\\nThanks to all the volunteers! We still need more mentors.\\nIt basically entails reading one paper and attending one poster session.\\n\\nPlease let me know if you are attending @aci2018 and would like to volunteer.\\n\\nKorea's extraction of 12 boys and their soccer coach could take days, officials say.\\n\\nWe are recruiting more mentors!\\nIf you are an experienced researcher (not a student) and you are attending @acl2018, let us know if you can help by providing feedback to one student before and during the workshop.\\n\\nReply photos: Thai soccer team trapped in a cave.\\n\\nHero: Former Thai navy SEAL diver dies in cave.\\n\\nHealth: How a lack of oxygen is affecting the Thai soccer team."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Text Summarization\\n- To condense a piece of text to a shorter version while maintaining the important points\\n\\nLong Articles\\n\\nSSS Summary\\n\\nSSS eoEE OO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Overview\\n\\nExamples of Text Summarization\\n- Article headlines\\n- Meeting minutes\\n- Movie/book reviews\\n- Bulletins (weather forecasts/stock market reports)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Overview\\n\\nExamples of Text Summarization\\n- Article headlines\\n- Attending [Name 1]’s [Name 2]’s Meeting minutes\\n- Announcements.\\n\\n[List all announcements made at the meeting. For example, new members, change of event, and so on.]\\n- Movie/book reviews\\n\\n[Need a heading? On the Home tab, in the Styles gallery, just tap the heading style you want.]\\n- Weather forecasts/stock market reports\\n\\nDiscussion\\n\\n[Summarize the discussion for each issue, state the outcome, and assign any action items.]\\n\\nRoundtable\\n\\n[Summarize the status of each area/department.]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Overview\\n\\nCast & Crew\\n- Lee Unkrich\\n- Benjamin Bratt\\n- Gael Garcia Bernal\\n- Renee Victor\\n\\nMeeting minutes\\n\\nMovie/book reviews\\nNell Soans, Updated: Nov 24, 2017, 03:48 PM\\nCritic's Rating: 4.5/5\\n\\nCoco Story: A multi-generational story by Disney-Pixar about the power of family relationships.\\n\\nCoco Review: Disney-Pixar has repeatedly raised the bar of animated movies by telling stories that would appeal to children and adults alike.\\nBut their past couple of films seemed to miss that crucial element of storytelling, leading to some sub-parentheses in their otherwise impressive catalogue.\\n'Coco' is an original tale, and a highly imaginative one at that, by writer/co-director Adrian Molina.\\nBased in Mexico, it introduces us to the Rivera family who makes shoes for a living and everyone absolutely despises anything related to music.\\nExcept for little Miguel Rivera, who shines shoes but aspires to be a musician.\\nThrough the course of the film, Miguel enters the Land of the Dead and learns the truth about who his family really is."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Automatic Text Summarization\\n- To condense a piece of text to a shorter version while maintaining the important points.\\n\\nExtractive Summarization\\n\\nAbstractive Summarization\\n- Select text from the article\\n- Generate the summary word-by-word"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Overview\\n- Select phrases or sentences from the source document\\n\\nLong Article Representation\\n\\nEEE Summar\\n-\\n- sentence 1 ARR ¥ yenema\\n- sentence 2 ERIGENEA\\n- sentence 3 EREUESEN V\\n- Shen, D.; Sun, J.-T.; Li, H.; Yang, Q.; and Chen, Z.\\n2007. Document summarization using conditional random fields. IJCAI\\n2007.\\n- Kageback, M., Mogren, O., Tahmasebi, N., & Dubhashi, D. Extractive Summarization using Continuous Vector Space Models.\\nEACL\\n2014.\\n- Cheng, J., and Lapata, M. Neural summarization by extracting sentences and words. ACL\\n2016.\\n- Ramesh Nallapati, Feifei Zhai, and Bowen Zhou.\\nSummarunner: A recurrent neural network based sequence model for extractivesummarization of documents. AAAI 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Overview\\n- Select phrases or sentences from the source document\\n\\nLong Article Summary\\n- Alexander M Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization.\\nEMNLP\\n2015.\\n- Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Caglar Gulcehre, and Bing Xiang.\\nAbstractive text summarization using sequence-to-sequence RNNs and beyond. CoNLL\\n2016.\\n- Abigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointer-generator networks.\\nACL\\n2017.\\n- Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. ICLR\\n2018.\\n- Fan, Angela, David Grangier, and Michael Auli. Controllable abstractive summarization.\\narXiv preprint arXiv:1711.05217 (2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Overview not concise\\n- Extractive summary _(select sentences): Italian artist Johannes Stoetter has painted two naked women to look like a chameleon.\\nImportant, correct incoherent or not concise The 37-year-old has previously transformed his models into frogs and parrots but this may be his most intricate and impressive artwork to date."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Overview not concise\\n- Extractive summary _(select sentences): Italian artist Johannes Stoetter has painted two naked women to look like a chameleon.\\n\\nImportant, correct incoherent or not concise.\\nThe 37-year-old has previously transformed his models into frogs and parrots but this may be his most intricate and impressive artwork to date.\\n\\nAbstractive summary P (generate word-by-word): readable, concise, concise may lose or mistake some facts.\\nJohannes Stoetter has previously transformed his models into frogs and parrots but this chameleon may be his most impressive artwork to date."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Overview not concise\\n- Extractive summary _(select sentences): Italian artist Johannes Stoetter has painted two naked women to look like a chameleon.\\n\\nImportant, correct * incoherent or not concise.\\nThe 37-year-old has previously transformed his models into frogs and parrots but this may be his most intricate and impressive artwork to date.\\n- Abstractive summary P(generate word-by-word): readable, concise * may lose or mistake some facts.\\nJustin BieberJohann@>€foetter has previously transformed his models into frogs and parrots but this chameleon may be his most\\n- Unified summary: impressive artwork to date. * important, correct * readable, concise."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Outline\\n- Our Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "static sentence Extractor attention\\n\\nSentence-Level (6.9) I (0.2) 1 (05) attention\\n\\nSentence-level\\n\\nRNN\\n\\nWord-level\\n\\nRNN\\n\\nRamesh Nallapati, Feifei Zhai, and Bowen Zhou.\\nSummarunner: A recurrent neural network based sequence model for extractive summarization of documents. AAAI 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "static sentence Extractor Abstracter attention Final Distribution \"Argentina\" Cont See Sgt as So ee ma\\n5. m= s Sentence-Level (6.9) I (0.2) 1 (05) g1...\\nne eee ee Sasi init 4 i =7 ir Context Vector ke Sentence-level 2 2 2 Aeon ES gRNN am am © Mh.\\n= I I 5 3 onl ae eS = ten A 3 I I = a ven ae\\n- a Be Paena 2 gat gl j wan 91 Ss 3 I I\\n- @353% mm 2 Word level FP. ee. ee | ee ee ee ee ee Beet \" | zRNN © © OBB o © OBB o co o gra Js! l a| I\\n\\nGermany emerge victorious in 20 win against Argentina on Saturday... <START> Germany beat\\n\\n1 1 ®Wy W2 W3 | W4 Ws We | W7 Wg Wo Y Yi I\\n\\nSource Text Partial Summary Ramesh Nallapati, Feifei Zhai, and Bowen Zhou.\\nSummarunner: A recurrent neural Abigail See, Peter J Liu, and Christopher D Manning.\\nGet to the point: summarization network based sequence model for extractive summarization of documents.\\nAAAI 2017 with pointer-generator networks. ACL 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "static sentence Extractor dynamic word Abstracter attention \"Argentina\" Sentence-Level (6.9) (0.2) (0.5)\\n\\nContext Vector\\n\\nSentence-level\\n\\nWord-level\\n\\nGermany emerge victorious in 2-0 win against Argentina on Saturday...\\n\\n<START> Germany beat\\n\\nSource Text Partial Summary Ramesh Nallapati, Feifei Zhai, and Bowen Zhou.\\nSummarunner: A recurrent neural network based sequence model for extractive summarization of documents.\\nAAAI 2017 with pointer-generator networks. ACL 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Method static sentence Extractor dynamic word Abstracter attention\\nFinal Distribution \"Argentina\"\\n2S Sees erg Sees Se ee;\\nSentence-Level (6.9) I (0.2) 1 (0.5) I | X(L = Pgen)\\nAttention\\nContext Vector\\nSentence-level 2 2 P Q a pgenarinceaane aa g! I eg age | ote O g52 get:\\nWord-level 2\\nGermany emerged victorious in 20 win against Argentina on Saturday...\\n- Germany beat\\n\\nSource Text Partial Summary:\\n- m: word index at Qm\\n- Bn(m)\\n- Am = --\\n- tv,n.\\n- n: sentence index\\n- 5 im Of, Bim)\\n- t: generated word index"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Method static sentence Extractor dynamic word Abstracter attention\\n\\n1 Context Vector Sentence-Level (6.9) I (0.2) 1 (0.5) Attention\\n\\nei on, 1 26 ee Si -level = 2 P 23 Ap Agi 6 Fs Me, a... :.\\n\\nCindy is lucky. She won $1000. She is going to...\\n\\nSource Text: word index nt _ Om x Bn(m) Qn = n: sentence index Yom Of, Bim) t: generated word index 27"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Method static sentence Extractor dynamic word Abstracter attention attention B 1 B 2 Context Vector Sentence-Level (6.9) I (0.2) i (0.5) Attention et me it.\\nmn 7 7 Fe[m aes tats 6 yf| \" | ' <8 aI I oc a1 2 3 2 voce fA eo os oO baat RNN © © om | eC o cm | 6c o o Cindy is lucky.\\nShe won $1000. She is going to... $$a We Wa ! \" aS We !\\nis TMs id Source Text t m: word index nt _ Om x Bn(m) nd Qn = = n: sentence index Yom Of, Bim) t: generated word index 28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Method static sentence Extractor dynamic word Abstracter attention attention B 1 B 2 B 3 Context Vector Sentence-Level (6.9) I (0.2) i (0.5) Attention et me it.\\nsentence-level 3!\\n3, 2: 5 {4 82 3 4 Gs % Q@, G9 am Pgen | \" | ' <8 a: ' Gow 1 2 3 2 voce fA eo os oO baat RNN © © om | eC o cm | 6c o o Cindy is lucky.\\nShe won $1000. She is going to... $$ Wt We Wa! We Ws Ws! Wr We Wa Source Text: m: word index at Qm * Bn(m).\\nAn = = n: sentence index Yom Of, Bim) t: generated word index 29"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Method: Combined Attention at, = 0m * Paton)ym Am * Bn(m)\\n- Our unified model combines sentence-level and word-level attentions to take advantage of both extractive and abstractive summarization approaches.\\nSentence Attention (transparent bars) and Word Attention (solid bars) Updated Word Attention 1.0\\n-\\n\\nMultiplying and Renormalizing Inconsistent Attenuated as | Ee Sentence and Word Attentions |"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Method: Combined Attention at = 0m\\nUpdated word attention is used for calculating the context vector and final word distribution.\\n\\nFinal Word Distribution: P(i)\\n\\nUpdated Word Attention: a > Word Distribution P\\n\\nEncoder Hidden States: {h_f, ..., h_f} | Context Vector: h*(a')\\n\\nDecoder Hidden State: h"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Encourage Consistency\\n- We propose a novel inconsistency loss function to ensure our unified model to be mutually beneficial to both extractive and abstractive summarization.\\nMultiplied attention of top K attended words\\n-\\n1. tLine = op > loe(ag S Am * Bn(m))t=1 mek maximize f where K is the set of top K attended words."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Method Encourage Consistency of the top K attended words at each decode time step.\\n\\n1.0 a consistent K = 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Outline\\n- Training Procedures"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Training Procedures\\n- Extractive Summarization: select sentences from the article\\n- Abstractive Summarization: generate the summary word-by-word"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Training Procedures\\n- 3 types of loss functions:\\n1. extractor loss\\n2. abstracter loss + coverage loss\\n3. inconsistency loss"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Training Procedures\\n\\nSentence-Level (6.9)\\n1 (0.2)\\n1 (0.5)\\n\\nAttention\\n\\n* 3 types of loss functions:\\n- Sentence-level\\n1. extractor loss\\n- Word-level\\n2. abstracter loss\\n- coverage loss\\n\\nwhere gy, € {0, 1} is the ground-truth label for the sentence and N is the number of sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Training Procedures\\n\\nGround Truth\\n1. Sentence-Level (6.9)\\n\\n1 (0.2)\\n\\n1 (0.5)\\n\\nAttention*\\n\\n3 types of loss functions:\\n1. extractor loss\\n2. abstracter loss\\n3. inconsistency loss\\n\\nwhere gy, € {0, 1} is the ground-truth label for the sentence and N is the number of sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Training Procedures\\n\\nGround Truth\\n1. Sentence-Level (6.9)\\n2. (0.2)\\n3. (0.5) = Attention\\n\\nThree types of loss functions:\\n- Sentence-level extractor loss\\n- Word-level abstracter loss\\n- Coverage loss\\n- Inconsistency loss\\n\\nwhere \\( g_y \\) ∈ {0, 1} is the ground-truth label for the sentence and N is the number of sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Training Procedures\\n\\nExtractor Target\\n\\nTo extract sentences with high informativity: the extracted sentences should contain information that is needed to generate an abstractive summary as much as possible.\\n1.\\nMeasure the informativity of each sentence in the article by computing the ROUGE-L recall score between the sentence and the reference abstractive summary.\\n2.\\nSelect the sentence in the order of high to low informativity and add one sentence at a time if the new sentence can increase the informativity of all the selected sentences.\\n\\nRamesh Nallapati, Feifei Zhai, and Bowen Zhou.\\nSummarunner: A recurrent neural network based sequence model for extractive summarization of documents. AAAI 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Training Procedures static sentence Extractor Abstracter attention dynamic word Final Distribution\\n\\nattention Argentina\\n\\nSentence-level: Context Vector\\n\\nRNN\\n\\nGermany beat\\n\\nSource Text Partial Summary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Training Procedures\\n\\nFinal Distribution\\n\\nContext Vector\\n\\n3 types of loss functions:\\n- extractor loss\\n- abstracter loss\\n- coverage loss\\n\\nAbigail See, Peter J Liu, and Christopher D Manning. Get to the point: Summarization with pointer-generator networks.\\nACL 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Training Procedures, T- 3 types of loss functions:\\n1. extractor loss where XK is the set of top K attended words\\n2. abstracter loss\\n3. inconsistency loss\\n\\nGermany emerged victorious in Argentina on Saturday."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Training Procedures\\n1. Two-stages training\\n2. End-to-end training without inconsistency loss\\n3. End-to-end training with inconsistency loss"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Training Procedures\\n1. Two-stages training\\n- The extractor is used as a classifier to select sentences with high informativity and output only those sentences.\\n- Hard attention on the original article.\\n- Simply combine the extractor and abstracter by feeding the extracted sentences to the abstracter.\\n- Extracted article | Abstracter summary sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Training Procedures\\n2. End-to-end training without inconsistency loss\\n- The sentence-level attention is soft attention and will be combined with the word-level attention.\\n- Minimize extractor loss and abstracter loss."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Training Procedures\\n3. End-to-end training with inconsistency loss\\n- The sentence-level attention is soft attention and will be combined with the word-level attention.\\n- Minimize extractor loss, abstracter loss and inconsistency loss:\\n\\nLede = ALext + Labs + Leooft"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Outline\\n- Experiments and Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Experiment Summary\\n- 53 words\\nArticle-summary pairs 287,113\\n13,368\\n11,490 cos] politics 45\\n\\nCONGRESS SECURITY THE NINE TRUMP AMERICA\\n- STATE STORY HIGHLIGHTS\\n\\nWashington (CNN)\\n- The House Intelligence Committee has agreed to give former White House chief strategist Steve Bannon until the end of the month to return to the panel and finish his closed-door interview, according to the postponement follows an exchange of terse letters by the House panel and multiple sources with knowledge of the matter.\\n\\nBannon's attorney, in a letter to the committee shared with CNN, said the committee asked that his legal team (...)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Experiment Summary ~ 53 words\\n\\nArticle-summary pairs 287,113 13,368 11,490 ea politics 45\\n\\nCONGRESS SECURITY THE NINE TRUMP AMERICA STATE\\n\\n(Washington (CNN)\\n- The House Intelligence Committee has agreed to give former White House chief strategist Steve Bannon until the end of the month to return to the panel and finish his closed-door interview, according to multiple sources with knowledge of the matter.\\nThe postponement follows an exchange of terse letters by the House panel and Bannon's attorney.\\nBannon's attorney, in a letter to the committee shared with CNN, said the committee asked that his legal team..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Experiment Results\\n- Abstractive Summarization\\n\\nROUGE-I | ROUGE-2 | ROUGE:\\n- HierAttn (Nallapati et al., 2016b) * 32.75 12.21 29.01\\n- DeepRL (Paulus et al.,\\n2017) * 39.87 15.82 36.90\\n- pointer-generator (See et al.,\\n2017) 39.53 17.28 36.38\\n- GAN (Liu et al.,\\n2017) 39.92 17.65 36.71\\n- two-stage (ours) 39.97 17.43 36.34\\n- end2end w/o inconsistency loss (ours) 40.19 17.67 36.68\\n- end2end w/ inconsistency loss (ours) 40.68 17.97 37.13\\n- lead-3 (See et al.,\\n2017) 40.34 17.70 36.57\\n\\nTable 2: ROUGE F-1 scores of the generated abstractive summaries on the CNN/Daily Mail test set.\\nOur two-stage model outperforms pointer-generator model on ROUGE-1 and ROUGE-2.\\nIn addition, our model trained end-to-end with inconsistency loss exceeds the lead-3 baseline.\\nAll our ROUGE scores have a 95% confidence interval with at most +0.24.\\n'*' indicates the model is trained and evaluated on the anonymized dataset and thus is not strictly comparable with ours."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Experiment Results\\n- Inconsistency Rate\\n\\nInconsistency step tjy: inconsistency rate: Pa(aremex(ev*)) x mean() Count (time) Rine = T_e Inconsistent where T is the length of the summary.\\n\\n0.5\\n\\nw/o incon. loss 0.1987\\n\\nw/ incon. loss 0.042\\n- Table 3: Inconsistency rate of our end-to-end trained model with and without inconsistency loss.\\nSentence attention and word attention in time step t54"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Experiment Results\\n- Inconsistency Rate\\nInconsistency step: inconsistency rate:\\n\\nCount (time) IRine = --- 1:\\nInconsistent where 7' is the length of the summary.\\n0.5\\n\\nw/o incon. loss 0.1987\\nw/ incon. loss 0.042\\n\\nTable 3: Inconsistency rate of our end-to-end, non-trained model with and without inconsistency loss, sentence attention and word attention in time step t55."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Experiment Results\\n- Inconsistency Rate\\n\\nInconsistency step t: inconsistency rate: 0\\nPa(aremex(ev*)) x mean() Count (time) 1 t Tee Inconsistent where T is the length of the summary.\\n\\n0.5\\n\\nw/o incon. loss 0.1987\\nw/ incon. loss 0.042\\n- Table 3: Inconsistency rate of our end-to-end model trained with and without inconsistency loss, sentence attention and word attention in time step t."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Experiment Results\\n- Inconsistency Rate\\n\\nInconsistency step: inconsistency rate: Pa(aremex(ev*)) x mean() Count (time) Rine = 1\\n\\nInconsistent where T is the length of the summary.\\n\\n| 0.5 |\\n| Pe CS} !1 w/o incon. loss 0.198\\n| w/ incon. loss 0.042\\n- Table 3: Inconsistency rate of our end-to-end sentence attention and word attention in time step t.\\n- Featured models without inconsistency."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "R It H Evaluation on MTurk\\n\\nHenrik Larsson was forced to play his 42-year-old kit man in goal.\\nThe emergency stopper kept a clean sheet as Helsinborg drew 0-0. Helsinborg played in the season opener against Kalmar.\\nHenrik Matt Pyzdrowski was out injured.\\nThe emergency stopper kept a clean sheet as Helsinborg drew 0-0 against Kalmar in the Allsvenskan season opener.\\n\\nHelsinborg manager Henrik Larsson was forced to play Daniel Andersson with goalkeepers Par Hansson and Matt Pyzdrowski out injured.\\nThe former goalkeeper earned one cap for Sweden back in\\n2001.\\n\\nA new survey found seven in 10 people end up injured while doing DIY.\\nA poll of 2,000 people found 68% say they or their partner have ended up hurt.\\nTwo in five said they injured their back and one in five had cut themselves."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Experiment Results\\n- Human Evaluation\\n- Informativity: how well does the summary capture the important parts of the article?\\n- Conciseness: is the summary clear enough to explain everything without being redundant?\\n- Readability: how well-written (fluent and grammatical) the summary is?\\n\\nreadability\\n\\nDeepRL (Paulus et al.,\\n2017) 2.97 2.85\\npointer-generator (See et al.,\\n2017) 3.18 3.36 3.47\\nGAN (Liu et al.,\\n2017) 3.52 3.51\\n\\nTable 3: Comparing human evaluation results with state-of-the-art methods."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Outline\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Conclusion and Future work\\n\\nConclusion\\n- We propose a unified model combining the strength of extractive and abstractive summarization.\\n- A novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions.\\nThe inconsistency loss enables extractive and abstractive summarization to be mutually beneficial.\\n- By end-to-end training of our model, we achieve the best ROUGE scores while being the most informative and readable summarization on the CNN/Daily Mail dataset in a solid human evaluation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Acknowledgements\\n\\nWen-Ting Tsu\\nChieh-Kai Lin\\nMing-Ying Lee\\nKerui Min\\nJing Tang"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "LF.Oo red I Oo Project page Be mm. ° CodeL- : sae ET = ° Test output o mah oO a\\n- Supplementary material | ee https://hsuwanting.github.io/unified_summ/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 177,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n\\nBackground / Motivation\\n- Machine Reading Comprehension (MRC)\\n- Why Multi-Passage MRC is Challenging?\\n- Model Architecture\\n- Answer Boundary Prediction\\n- Answer Content Modeling\\n- Cross-Passage Answer Verification\\n- Joint Training and Prediction\\n\\nExperiments\\n- Results on MS-MARCO and DuReader\\n- Ablation Study\\n- Quantitative Analysis\\n\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Machine Reading Comprehension (MRC) Passage: ...\\nTesla later approached Morgan to ask for more funds to build a more powerful transmitter.\\nWhen asked where all the money had gone, Tesla responded by saying that he was affected by the Panic of 1901, which he (Morgan) had caused.\\nMorgan was shocked by the reminder of his part in the stock market ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Machine Reading Comprehension (MRC) Passage:\\n\\nQuestion: On what did Tesla blame for the loss of the initial money?\\n\\nWhen asked where all the money had gone, Tesla responded by saying that he was affected by the Panic of\\n1901.\\n\\nAnswer: Panic of 1901 [from SQUAD v1.1!1]\\nSingle-passage MRC 5:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Machine Reading Comprehension (MRC)\\n\\nPassage:\\n\\nQuestion: On what did Tesla blame for the loss of the initial money?\\n\\nWhen asked where all the money had gone, Tesla responded by saying that he was affected by the Panic of\\n1901.\\n\\nAnswer: Panic of 1901\\n\\n[from SQUAD v1.1]\\n\\nSingle-passage MRC\\n- Different types: cloze test, entity extraction, span extraction, multiple-choice\\n- Various models: Match-LSTM, BiDAF, R-Net, QANet\\n- Very impressive performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Reading the Web to Answer Questions?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Applying MRC to the Web.\\n\\nSearch engine is employed.\\n\\nHow many teams will be in the 2022 World Cup?\\n\\n4 Q- Multiple passages are retrieved.\\n\\n2022 FIFA World Cup\\n- Wikipedia\\nhttps://en.wikipedia.org/wiki/2022_FIFA_World_Cup\\n\\nIn the end, there were five bids for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea and the United States.\\n\\nTeams: 32 (from 5 or 6 confederations)\\nDates: 21 November\\n- 18 December\\nHost country: Qatar\\nVenue(s): 8 or 12 (in 5 or & host cities)\\n\\n2018 FIFA World Cup qualification\\n- Wikipedia\\nhttps://en.wikipedia.org/wiki/2018_FIFA_World_Cup_qualification\\n\\nUnited Arab Emirates Ahmed Khalil (16 goals each).\\n- 2014\\n- 2022\\n-\\nThe 2018 FIFA World Cup qualification process was a series of tournaments organised by the six FIFA confederations to decide 31 of the 32 teams which will play in the 2018 FIFA World Cup, with the suspension of their football association by FIFA on 30 May\\n2015.\\n\\nTeams: 210 (from 6 confederations)\\nGoals scored: 2,454 (2.81 per match)\\nMatches played: 872\\n\\nQataris considering a 48-team option for 2022 World Cup\\n- The ...\\nhttps://www.washingtonpost.com/...team...2022-world-cup/.../64dae0e6-8214-11€8-b3b...\\n\\n5 days ago\\n- The organizers of the 2022 World Cup in Qatar are open to talks about a ...\\npower it apparently gained is key to any progress on the tournament expansion. ...\\n32 nations from which 16 winners would join 16 seeded teams in a ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Applying MRC to the Web.\\n\\nSearch engine is employed.\\n\\nHow many teams will be in the 2022 World Cup?\\n- Multiple passages are retrieved.\\n\\n2022 FIFA World Cup\\n- Wikipedia\\nhttps://en.wikipedia.org/wiki/2022_FIFA_World_Cup\\n\\nIn the end, there were five bids for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea, and the United States.\\n\\nTeams: 32 (from 5 or 6 confederations)\\nDates: 21 November\\n- 18 December\\nHost country: Qatar\\nVenue(s): 8 or 12 (in 5 or 8 host cities)\\n\\n2018 FIFA World Cup qualification\\nWikipedia\\nhttps://en.wikipedia.org/wiki/2018_FIFA_World_Cup_qualification\\n\\nUnited Arab Emirates: Ahmed Khalil (16 goals each).\\n- 2014\\n- 2022\\n-\\n\\nThe 2018 FIFA World Cup qualification process was a series of tournaments organised by the six FIFA confederations to decide 31 of the 32 teams which will play in the 2018 FIFA World Cup, with the suspension of their football association by FIFA on 30 May\\n2015.\\n\\nTeams: 210 (from 6 confederations)\\nGoals scored: 2,454 (2.81 per match)\\nMatches played: 872\\n\\nQataris considering a 48-team option for 2022 World Cup.\\nThe organizers of the 2022 World Cup in Qatar are open to talks about a tournament expansion.\\n\\nThe power it apparently gained is key to any progress on the tournament expansion.\\n\\n32 nations from which 16 winners would join 16 seeded teams in a ..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Applying MRC to the Web\\n\\nSearch engine is employed.\\n\\nHow many teams will be in the 2022 World Cup?\\n\\nQ- Multiple passages are retrieved.\\n\\n2022 FIFA World Cup\\n- Wikipedia\\nhttps://en.wikipedia.org/wiki/2022_FIFA_World_Cup\\n\\nIn the end, there were five bids for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea, and the United States.\\n\\nDates: 21 November\\n- 18 December\\nHost country: Qatar\\nVenue(s): 8 or 12 (in 5 or 8 host cities)\\n\\nBut they give different answers!\\n\\n2018 FIFA World Cup qualification\\n- Wikipedia\\nhttps://en.wikipedia.org/wiki/2018_FIFA_World_Cup_qualification\\n\\nThe 2018 FIFA World Cup qualification process was a series of tournaments organized by the six FIFA confederations to decide 31 of the 32 teams which will play in the 2018 FIFA World Cup, with the suspension of their football association by FIFA on 30 May\\n2015.\\n\\nGoals scored: 2,454 (2.81 per match)\\nMatches played: 872\\n\\nQatar is considering a 48-team option for the 2022 World Cup.\\nThe organizers of the 2022 World Cup in Qatar are open to talks about a tournament expansion."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "An Example from MS-MARCOF! Dataset\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nPassages:\\n1) A culture is a society's total way of living and a society is a group that live in a defined territory and participate in common culture.\\nWhile the answer given is...\\n2) The mixed economy is a balance between socialism and capitalism.\\nAs a result, some institutions are owned and maintained by...\\n3) A pure culture is one in which only one kind of microbial species is found whereas in mixed culture two or more microbial species formed colonies.\\nCulture on the...\\n4) A pure culture comprises a single species or strains.\\nA mixed culture is taken from a source and may contain multiple strains or species. A contaminated...\\n5) It will be at that time when we can truly obtain a pure culture.\\nA pure culture is a culture consisting of only one strain. You can obtain a pure culture by picking...\\n6) A pure culture is one in which only one kind of microbial species is found whereas in mixed culture two or more microbial species formed colonies.\\nA pure culture..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "An Example from MS-MARCO I! Dataset\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nPassages:\\n- A pure culture is one in which only one kind of microbial species is found whereas in mixed culture two or more microbial species formed colonies.\\n- A pure culture is one in which only one kind of microbial species is found whereas in mixed culture two or more microbial species formed colonies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "An Example from MS-MARCO I! Dataset\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nPassages:\\n\\nA pure culture comprises a single species or strains.\\nA mixed culture is taken from a source and may contain multiple strains or species. A contaminated culture ...\\nIt will be at that time when we can truly obtain a pure culture.\\nA pure culture is a culture consisting of only one strain. You can obtain a pure culture by picking..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "An Example from MS-MARCO I! Dataset\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nPassages:\\n- A culture is a society's total way of living and a society is a group that live in a defined territory and participate in common culture.\\nWhile the answer given is...\\n- The mixed economy is a balance between socialism and capitalism.\\nAs a result, some institutions are owned and maintained by..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "An Example from MS-MARCO I! Dataset\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nPassages:\\n- A pure culture is one in which only one kind of microbial species is found whereas\\nin a mixed culture two or more microbial species formed colonies.\\n- A pure culture comprises a single species or strains. A mixed culture is taken\\nfrom a source and may contain multiple strains or species.\\n- It will be at that time when we can truly obtain a pure culture. A pure culture is\\na culture consisting of only one strain. You can obtain a pure culture by picking...\\n- A pure culture is one in which only one kind of microbial species is found whereas\\nin a mixed culture two or more microbial species formed colonies.\\n\\nCorrect Answer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Question Passage | Passage 2\\n\\nPassage ny Y Y Y Encoding Q-P Matching- ToS A TES: TS Sa ga cma na meen a | dhe adh | | (hi. aod cll, lla |\\n\\nAnswer Boundary ' !\\nPrediction 2 eee) ret re) iar ee)t 1Sf Amswerdr |] Answerz [| Answerdn | !(fo wsighted | weiattea [weighted arum sum um ina\\n\\nAnswer Content ( ih > oe ot) me) all. +> ®\\n- An Modeling j P(content) P(content) P(content) ; Swen2... 2... 2 }. . i Attention.\\n; Answer Verification ' oet -r ' re! i-T1 oa! ; (MBB sect EB se oes | 18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Question Passage | Passage 2\\n\\nPassage n- a\\n\\nY Y Y Y\\n\\nEncoding\\n\\nQ-P Matching\\n\\nAnswer Boundary\\n\\nPrediction\\n\\nP(start) | P(end)\\n\\nAnswerdr\\n\\nAnswerz\\n\\nAnswerdn\\n\\nAnswer Content\\n\\nAnswer Modeling\\n\\nAttention\\n\\nAnswer Verification"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Question Passage | Passage 2\\n\\nPassage nY Y Y Y Encoding Q-P Matching- iL iL a fh.\\n_all as TL Lt Ty Answer- Boundary P P (start) P (end) P (start) P (end) } Prediction (start) i P (end) | en oe | eSf Answer an |] Answer dy |__| Answer dn |!\\necccccccsTNy (fo wsighted | weiattea [weighted .5 sum um Finalt Answer Content 1 { ih. > ® ot)\\n- @ oll.\\n+> ® > AnI Modeling I j P (content) P (content) P (content) ; Swen1 = [4 )l I secceeeeeed Meccceceeelll reeecsseeesee llZ Z I Attention }{| Answer Verification ' _ a _\\n- _ 1' ae Tra 'allelsoc set see sos20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Question Passage | Passage 2\\n- Passage\\n\\nAnswer Boundary\\n\\nPrediction\\n\\nAnswer A, Answer B, Answer C\\n\\nFinal = Answer Content\\n\\nModeling P(content) P(content) P(content)\\n\\nAttention Answer Verification"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Input Question Passage | Passage 2 os Passage n22"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Question and Passage Encoding\\n\\nQuestion Passage | Passage 2 os Passage n\\n\\nEncoding with Bi-LSTM:\\nuy' = BiLSTMa(u);\\nult = BiLSTMp(u, ey, c)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Question-Passage Matching\\n\\nQuestion Passage | Passage 2 \"Passy.\\n\\nBi-directional Attention Flow (Seo et al.,\\n2016)\\n\\nDot attention matrix: Sin = ue! il24"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Answer Boundary Prediction Question Passage | Passage 2 os Passage n' t ' 'ao\\n- Start and end pointer: pees oy af, = wf tanh(W3 {vf ) oh = einlal bres =\\n- eialal obs = | HI | P | avi = exp(gk) / D7, exPCG5) [P | ct = it atvph? = LSTM(h?_, cr) 25"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Answer Content Modeling Question Passage 1 Passage 2 a Passage\\n\\nAnswer A, Answer A Answer An\\n\\nContent score for each (wrested {| ciated cist sn = sip moid (w°TReLU(Wév\"sum sum sum 1 Pk sigmol (w € ( S ))di +e iH] +e al, \"oe ) : ak{ P(content) P(content) P(content) ; R .\\nf Ai[4] | [rq | [*q '\\n- Representation for A':aia aii aii eee 1 IPil .$i = Pi] et plex', ef]26"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Cross-Passage Answer Verification\\n\\nQuestion Passage | Passage 2\\n\\nAnswer to Answer Attention:\\n\\nSig = rit, otherwise\\n\\nAnswer A\\n\\nQj = exp(si)/ Σ exp(si)\\n\\nweighted\\n\\nVerification score:\\n\\nScore 1\\n\\nScore 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Joint Training and Prediction\\n\\nThree objectives:\\n- Finding the boundary of the answer\\n- Predicting whether each word should be included in the answer\\n\\nSelecting the best answer from all the candidates\\n\\nTraining Loss: Ljoint = Lboundary + Lcontent + Lverify\\n\\nPrediction: Score = Sboundary X Scontent X Sverify"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Experiments Setup\\n\\nDatasets: MS-MARCO and DuReader:\\n- MS-MARCO\\n- English\\n- Bing\\n- 100K+\\n- 9.93%\\n- 40.00%\\n- DuReader\\n- Chinese\\n- Baidu\\n- 200K+\\n- 67.28%\\n- 56.38%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Experiments Setup\\n\\nDatasets: MS-MARCO and DuReader\\n- Search Questions with Multi Annotated Answers\\n- Multi Answer Spans\\n\\nMS-MARCO\\n- English\\n- Bing 100K+: 9.93%, 40.00%\\n\\nDuReader\\n- Chinese\\n- Baidu 200K+: 67.28%, 56.38%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Experiments Setup\\n\\nDatasets:\\n- MS-MARCO\\n- DuReader\\n\\nSearch Questions with Multi Annotated Answers\\nMulti Answer Spans\\n\\nMS-MARCO\\nEnglish\\nBing\\n100K+\\n9.93%\\n40.00%\\n\\nDuReader\\nChinese\\nBaidu\\n200K+\\n67.28%\\n56.38%\\n\\nHyper-parameters (tuned on the dev set):\\nWord Character z 7\\n- 20:0\\n- 150\\n- 3e-4\\n- Adam\\n- 4e-4\\n- 32\\n- 0.5\\n- 0.5\\n- Glove\\n- Random 31"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Main Results\\n\\nROUGE-L | BLEU-1     ROUGE-L | BLEU-4\\nFastQA_Ext            33.67         33.93\\nMatch-LSTM            39.0          31.8\\nwacvisa               31.2          +Bi 41.7\\nR-Net                 42.89         42.22\\nPR+BIDAF              37.65\\nS-Net                 45.23         43.78\\nOur Model             44.2          41.0\\nOur Model (Ensemble)  46.15         44.47\\nS-Net (Ensemble)      46.65         44.78\\n\\nTab\\n1. Performance on MS-MARCO test set\\n\\nTab\\n2. Performance on DuReader test set\\nOur Model (Ensemble)  46.66         45.41"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Ablation Study on MS-MARCO Dev Set\\n\\nComplete Model 45.65\\n- Answer Verification 44.38 -1.27\\n- Content Modeling 44.27 -1.38\\n- Joint Training 44.12 -1.53\\n- Yes/No Classification 41.87 -3.78\\n- Boundary Baseline 38.95 -6.70"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Quantitative Analysis: the Predicted Scores\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nScores\\n\\nAnswer Candidates: Boundary Content Verification\\n\\nA culture is a society's total way of living and a society is a group ... 1.0 x 10^7? 10 x 10^7* 1.1 x 10^7?\\n\\nThe mixed economy is a balance between socialism and capitalism.\\n\\nLox 10-* £08 107? 3 e<107\\n\\nA pure culture is one in which only one kind of microbial species is...\\n\\n5.5 x 10^7? = 7.7 x 10^7? 1.2 x 10^7?\\n\\nA pure culture comprises a single species or strains. A mixed...\\n\\n27 x 10 81 x 10^7 L310\\n\\nA pure culture is a culture consisting of only one strain.\\n\\n5.8 x 10^7* 799 x 10^7? 5.1 x 10^7?\\n\\nA pure culture is one in which only one kind of microbial species...\\n\\n5.8 x 10^7% 9.1 x 10^7? 2.7 x 10^7?34"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Question: What is the difference between a mixed and pure culture\\n\\nScoresAnswer Candidates: Boundary Content Verification\\n\\nA culture is a society's total way of living and a society is a group\\n\\nThe mixed economy is a balance between socialism and capitalism.\\n\\nA pure culture is one in which only one kind of microbial species is present.\\n\\nA pure culture comprises a single species or strains.\\n\\nA pure culture is a culture consisting of only one strain.\\n\\nA pure culture is one in which only one kind of microbial species is present.\\n\\nBoundary / content / verification scores are usually positively relevant."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Quantitative Analysis: the Predicted Scores\\n\\nQuestion: What is the difference between a mixed and pure culture\\n\\nScores\\n\\nAnswer Candidates: Boundary Content Verification\\n\\nA culture is a society's total way of living and a society is a group ... 1.00 x 10^7? 10 x 10^7* 11 x 10^7?\\n\\nThe mixed economy is a balance between socialism and capitalism. 10 x 10^7 40 x 10^7? 3.2 x 10^7?\\n\\nA pure culture is one in which only one kind of microbial species is... 5.5 x 10^7? 7.7 x 10^7?\\n\\nA pure culture comprises a single species or strains. A mixed... 27 x 10^8 = 8.1 x 10^7\\n\\nA pure culture is a culture consisting of only one strain. 5.8 x 10^7* 7.9 x 10^7 5.1 x 10^-2\\n\\nA pure culture is one in which only one kind of microbial species ... 58 x 10^7 9.1\\n\\nMore commonality --> larger verification score"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Quantitative Analysis: the Predicted Scores\\n\\nQuestion: What is the difference between a mixed and pure culture?\\n\\nScores\\n\\nAnswer Candidates:\\n- A culture is a society's total way of living and a society is a group.\\n- The mixed economy is a balance between socialism and capitalism.\\n- A pure culture is one in which only one kind of microbial species is present.\\n- A pure culture comprises a single species or strains.\\n- A pure culture is a culture consisting of only one strain.\\n\\nCorrect answer is selected by considering verification!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Necessity of the Content Model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "N ity of the Content Model\\n- start probability 0.35 0.30 0.25 0.20 0.15 0.10 0.05"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "Necessity of the Content Model\\n- start probability\\n- end probability\\n\\n0.35\\n0.30\\n0.25\\n0.20\\n0.15\\n0.10\\n0.05"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Visualization of the Probability Distribution\\n\\nstart probability\\nend probability\\n- content probability 0.35\\n0.3\\nft 0.25\\ni hh 0.2\\n1) HY\\n0.15\\n-\\n0.1\\nt.\\n-\\n0.05\\nf\\n-\\n4\\n10\\nBade aahiivg\\n- \"gee ged Ftp PEEieateTM is g2 BEER CEESs s 3 gg\"\\ns E = F 53\\n& 41"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Necessity of the Content Model\\n- start probability\\n- end probability\\n- content probability 0.35\\n- 0.30\\n- 0.25\\n- 0.20\\n- -0.15\\n- SS 0.1\\n- -0\\n\\nWhen the answer is long, boundary words carry little information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Necessity of the Content Model\\n\\nstart probability end probability\\n- content probability 0.35 0.3 i 0.25 L i 0.2 i} + 0.15 f_ 40.1 } }\\n- 10.050 e oer S$. S$ AAA OE! _ EK | Bigg ZEkPE \"gE \"CESS t eg TSZEtSZEEZ EEE\" 23 ES\" REysc et ge:g° Fe REC\" 8 q 2 e8\\n- 2 EE°\"#\" 22 S£ BFE FE€ = 2 s 3 vo = Content words reflect the real semantics of this answer. 43"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Conclusion\\n- Multi-passage MRC: much more misleading answers\\n- End-to-end model for multi-passage MRC:\\n- Find the answer boundary\\n- Model the answer content\\n- Cross-passage answer verification\\n- Joint training and prediction\\n- SOTA performance on two datasets created from real-world web data:\\n- MS-MARCO (English)\\n- DuReader (Chinese)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "References\\n1) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.\\n2016. Squad: 100,000+ questions for machine comprehension of text.\\n2) Shuohang Wang and Jing Jiang.\\n2016. Machine comprehension using Match-Istm and AnswerPointer.\\n3) Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi.\\n2016. Bidirectional attention flow for machine comprehension.\\n4) Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou.\\n2017. Gated self-matching networks for reading comprehension and question answering.\\n5) Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V Le.\\nQANet: Combining local convolution with global self-attention for reading comprehension.\\n6) Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.\\n2016. MS MARCO: A human generated machine reading comprehension dataset.\\n7) Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang.\\n2017. Dureader: A Chinese machine reading comprehension dataset from real-world applications."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Thank you!\\n\\nQ&A\\nContact: yizhong@pku.edu.cn"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 358,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Table of contents\\n1. Motivation\\n2. Method\\n3. Experiment\\n4. Demo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Commonsense Property Comparison Task\\n\\nIs an elephant bigger or smaller than a mouse?\\n\\nIs Ferrari more expensive or cheaper than beer?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Problem Definition\\n\\nThree-way task: P(L|O₁, O₂, Property), L € {[<], [>], [=]}.\\n\\nFour-way task: P(L|O₁, O₂, Property), L € {[<], [>]} {N/a}."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Learning Commonsense Knowledge from Text?\\nChallenges:\\n- Reporting bias [Gordon and Van Durme 2013]: Commonsense knowledge is rarely explicitly stated.\\n- Large knowledge dimensions: Property specified by adjectives: large, heavy, fast, rigid, etc.\\nCreating training examples and building separate models on each type of property requires expensive labeling efforts.\\nHandling unseen properties during the test phase (zero-shot prediction)?\\n- Language variation: An ideal model should be able to take flexible natural language inputs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Learning Commonsense Knowledge from Text?\\nCan we build an efficient commonsense comparison model with word embedding inputs only?\\n- carry a dog around.\\n- carry an elephant around."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Method"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Categorical Linear Regressions\\n- Size Model\\n- Weight Model\\n- Speed Model\\n- Strength Model\\n\\nFigure 1: Creating a softmax regression model for each property."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Our PCE model Big Compare (dot product) Breakable Fast / Slow"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Experiment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "VERB PHYSICS (5 physical properties) [Forbes and Choi 2017]\\nPROPERTY COMMON SENSE (32 commonsense properties)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Results: Supervised Performance Test\\n\\nSo size weight stren rigid speed overall\\n- Majority 0.51 0.55 0.52 0.49 0.50 0.51\\n- F&C 0.75 0.76 0.72 0.65 0.61 0.70\\n- PCE (LSTM) 0.80 0.79 0.76 0.71 0.71 0.76\\n- PCE (GloVe) 0.76 0.75 0.71 0.68 0.68 0.72\\n- PCE (Word2vec) 0.76 0.76 0.73 0.68 0.66 0.72\\n\\nTable 1: Supervised accuracy on the VERB PHYSICS data set. PCE outperforms the F&C model from previous work."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Results: Zero-shot Prediction Model = = least\\n- size weight strength rigid speed\\n\\nRandom 0.33 0.33 0.33 0.33 0.33\\n\\nEmb-Similarity | 0.37 0.53 0.48 0.43 0.35\\n\\nPCE 0.74 0.73 0.70 0.62 0.58\\n\\nTable 2: Accuracy of zero-shot learning on the VERB PHYSICS data set (using LSTM embeddings)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Results Model Test Random 0.25\\nMajority Class 0.51\\nPCE (GloVe) 0.63\\nPCE (Word2vec) 0.67\\nPCE (LSTM) 0.67\\n\\nTable 3: Accuracy on the four-way task on the PROPERTY COMMON SENSE data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Synthesis Active Learning\\n\\nWant further reduce labeling effort?\\n\\n0.700\\n0.675\\n0.650\\n0.625\\n0.600\\n0.575\\n- Random\\n0.550\\n- Lc\\n0.525\\n200\\n400\\n600\\n800\\n1000\\n1200\\n1400\\n1600\\n2 training examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Active Learning\\n- Random\\n- EMC.\\n\\nSynthesis 0.6\\n\\ntraining examples 200 400 600 800 1000 1200 1400 1600"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Demo"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "http://thor.cs.northwestern.edu:1959/14"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 376,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "- Introduction\\n- The proposed method\\n- Experiments\\n- Summary and future work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Aone 2 = 'CEyh ereey Tsinghua University\\n\\nTask Description\\n- Sentence-level Sentiment Classification.\\n- Positive/negative/neutral\\n\\nGiven a sentence, mam ian {ovary\\n- More fine-grained classes\\n\\nExamples:\\n- The food is very delicious. → Positive\\n- The movie is so boring. → Negative\\n\\n2018/7/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "(Go) id 4Aey Tsinghua University@\\n\\nEarly Methods-\\n\\nMachine learning based- SVM (Pang et al., 2002)*\\n\\nLinguistic knowledge based-\\nSentiment lexicon [Turney, 2002; Taboada et al., 2011]@\\n\\nNeural Networks-\\n\\nRecursive Neural Network [Socher et al., 2011]*\\n\\nConvolutional Neural Network [Kim, 2014]-\\n\\nRecurrent Neural Network/LSTM [Hochreiter and Schmidhuber, 1997]@\\n\\nIncorporating Linguistic Knowledge with Neural Networks-\\n\\nLinguistically regularized LSTM [Qian et al., 2017]-\\n\\nLexicon integrated CNN models with attention [Bonggun et al., 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "ea (4 x 42 sears pa' Sere a Tsinghua University\\n\\nMotivation\\n\\nSentiment linguistic knowledge (e.g.\\nsentiment words, intensity words, negation words) play important roles in sentiment detection.\\nBy attention mechanism, we can integrate various sentiment resource information into neural networks to boost the performance.\\n\\n2018/7/28 6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "(FAG Outline\\n\\nIntroduction\\n\\nThe proposed method\\n\\nExperiments and analysis\\n\\nSummary and future work\\n\\n2018/7/28 7eee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "- OOOO\\n- aa CTAETT\\n- [ [ ax '' / [ '-- VH_O\"E $RBhi \"OOEOR9 ? EORERE SSS OS S.00 ? 0 ?\\n0)\\n- 66 N0N0NNNNN eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS ew wNToEe SET-T ---- SEEM °AB EER yce) ia x a 4Rae ee Tsinghua University OOur Modelee ee ee ee\\n- Coupled Word Embedding: Multi-sentiment-resource Attention Module\\n- Sentiment word Attention\\n1. sentiment (< M |, tle at ji: I' words jy» emmy!\\n- Correlation module\\n- Intensity\\n\\n\" = H Intensity-Context oh. = Sey Se ARTS\\n\\n9: words 1, mmm\\n- Correlation module\\n1. ul {ji er a Softmax\\n- Classifier\\n\\n| ctContext \"i Sa\\n- TY: a 2J words | uf emis 1 0, I |I | G\\n- Negation word Attention\\n1. Negation \"'!\\n- St Negation-Context Ro i\\n-\\n-\\n-\\n- > ® ->\\n0. I words jn od 1\\n- Correlation module\\n\\nul } | AY om: i * Fr: I ee\\n\\nThe overall framework of our model\\n\\n2018/7/28 8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "AE 2M ee esey Tsinghua University\\nCoupled word Embedding\\nWord-level\\nCharacter-level Embedding\\nEmbedding\\nGLOVE\\nChar-CNN\\nCharacter-level Embedding\\n1x1 Conv\\nOne-hot\\nMulti-gram\\nConv\\nChar-CNN\\n2018/7/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "- Tsinghua University\\n- Multi-sentiment-resource attention module\\n- Coupled Word Embedding\\n- Multi-sentiment-resource Attention Module\\n- Sentiment word Attention\\n- Sentiment-Context\\n- Intensity\\n- Intensity-Context\\n- Correlation module\\n- Classifier\\n- Context\\n- Negation word Attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "LEZ > (id 4Aey Tsinghua University)\\nContext-sentiment correlation modeling with myWords = a\\n\\nContext-sentiment correlation matrix\\n\\nSentiment | Smita fat X® = W°M®, X = W8(M®)?\\nWords |\\n\\nSentiment-Context Correlation module\\n\\nThe implementation of context-intensity correlation modeling and context-negation correlation modeling are the same as the context-sentiment correlation modeling.\\n\\nWe note that in the preceding version, there are some typos in this part.\\nThe updated version can be obtained via arxiv.org: https://arxiv.org/abs/1807.049902018/7/28\\n\\nAll"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "AEA\\nTsinghua University\\n\\nMulti-sentiment-resource\\nattention\\n\\nSentiment word attention\\n= GRU(X°)\\n= GRU(X\")\\nm01 = d aghf,g°\\n= S_he/mi=1\\ni=1\\nB([h§; qs]) = us tanh(W.[h§; gs])\\n\\nIntensity attention and Negation attention are computed via the similar methods with the sentiment word attention.\\n\\nFinally, the multi-sentiment-resource enhanced sentence representation: o = (01, 02,\\n03)\\n\\n2018/7/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "KE SM, 'CAELeee Tsinghua University Training\\n\\nThe predicted sentiment polarity distribution can be obtained via a fully connected layer with softmax.\\n\\nT\\n\\nj = exp(W, 6 + bo) = eee eSar exp(W, o + bo)\\n\\nLoss function:\\n\\nN CL(9,\\ny) =\\n- 95 > yf log(@) + (D5 6?) t = 1 j = 1 6 EO(17) + ||OOT\\n- p1|| FO = [01; 09; 03]\\n(18)\\n\\n2018/7/28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "(Go) id 4Aey Tsinghua University\\n\\nExperiments @ Datasets\\n\\nMovie Review (MR)\\n- 5331 positive/ 5331 negative, training/validation/test split is the same as (Qian et al., 2017);\\n\\nStanford Sentiment Treebank (SST)\\n- 8545 training/1101 validation/ 2210 test\\n\\n@ Sentiment Resources\\n\\nSentiment words\\n- combined from (Hu and Liu,\\n2004) and (Qian et al., 2017), containing 10899 words;\\n\\nIntensity words and Negation words\\n- manually collected due to the limited number."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "LEE, s(=) if x zx ¥ Wey Tsinghua University\\n\\nExperiments ---- Results Methods\\n- MR SSTRNTN 75.9%\\n- LSTM 74%\\n- BiLSTM 79.3%\\n- Tree-LSTM 80.7%\\n- CNN 81.5%\\n- NSCL 82.9%\\n- LR-Bi-LSTM 82.1%\\n- Self-attention 81.7%\\n- ID-LSTM 81.6%\\n- MEAN (our model) 84.5%\\n- MEAN w/o CharCNN 83.2%\\n- MEAN w/o sentiment words 82.1%\\n- MEAN w/o negation words 82.9%\\n- MEAN w/o intensity words 83.5%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "(aes | Zz\\nFAG\\nOutline\\n- Introduction\\n- The proposed method\\n- Experiments and analysis\\n- Summary and future work\\n2018/7/28\\nlgeee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "BY Sere a Tsinghua University\\n\\nSummary and Future Work\\n\\nIntegrating sentiment resources into neural networks is effective to improve the performance of sentence-level sentiment classification.\\n\\nHow to design more effective information-fusion methods is still challenging, such as regularization, attention, etc.\\n\\nIn future work, we can consider employing position embedding to automatically detect various sentiment resource words."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "LEZ >LN it x 42 (aera? eey Tsinghua University\\n\\nThanks for your attention!\\n\\nSupplementary Materials: https://drive.google.com/open?id=1KNBy50IBD7CMjack_9--M4N7EzeRmJDI 2018/7/28 19eee"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 323,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Task, challenges, and ideas\\n- Our approach\\n- A new learning method for matching models\\n- Experiment\\n- Datasets\\n- Evaluation and analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Task: retrieval-based chatbots\\n- Given a message, find most suitable responses\\n- Large repository of message-response pairs\\n- Take it as a search problem\\n\\nContext | Responses\\n\\nRetrieval potentials Ranking generation\\n\\nLearning to:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Related Work\\n\\nPrevious works focus on network architectures.\\n\\nSingle Turn\\n- CNN, RNN, syntactic based neural networks\\n\\nMultiple Turn\\n- CNN, RNN, attention mechanism\\n\\nThese models are data hungry,\\n\\nUtterance-Response Matching\\n- Matching\\n- Accumulation\\n- Prediction\\n\\nSo they are trained on large scale negative sampled dataset.\\n\\nState-of-the-art multi-turn architecture (Wu et al. ACL 2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Background\\n- Loss Function\\n- Cross Entropy Loss (Pointwise loss)\\n- Hinge Loss (Pairwise loss)\\n\\nL = -∑(p_i log(i))\\nCoss\\n- ENTROPY\\ncL = max(α, S(-)\\n- S(+) + ε)\\na = α (@ aE α, 9 Se ~ Ye, \"e ;j (S,L) =\\n- a\" foa(S:) 0.0\\nD(L,S) 0.0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Background: traditional training method\\n\\nGiven a (Q,R) pair, update the designed test model on one first randomly model with the use of human annotations.\\nSampled N instances of point-wise cross data {(Q, Rj)} y-entropy loss.\\n\\nTwo problems:\\n1. Most of the randomly sampled responses are far from the semantics of the messages or the contexts.\\n2. Some of the randomly sampled responses are false negatives which pollute the training data as noise."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Challenges of Response Selection in Chatbots\\n- Negative sampling oversimplifies the response selection task in the training phase.\\n- Train: Given an utterance, positive responses are collected from human conversations, but negative ones are negative sampled.\\n- Test: Given an utterance, a bunch of responses are returned by a search engine.\\nHuman annotators are asked to label these responses.\\n- Human labeling is expensive and exhausting; one cannot have large scale labeled data for model training."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Our training process. The margin in our loss is dynamic. R: R 4 Hinge loss R' 9 S(Q,\\nR)\\n- S(Q, R') + C4\\n- S(Q,\\nR)\\n- S(Q, R'2) + C2 optimization.\\n\\nR'3 S(Q,\\nR)\\n- S(Q, R'3) + g R'_N S(Q,\\nR)\\n- S(Q, R'N) + c_NR is the ground-truth response, C_i is a confidence score for each instance and R'_i is a retrieved instance.\\nOur method encourages the model to be more confident to classify a response with a high c_i as a negative one."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "How to calculate the dynamic margin?\\n- We employ a Seq2Seq model to compute c.\\n- Seq2Seq model is an unsupervised model.\\nIt is able to compute a conditional probability likelihood P(R|Q) without human annotation.\\n\\ns2s(Q,R)\\nLSTM Encoder\\nLSTM Decoder\\nCc; = max(0, s2s(0,R) 1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Pre-train the given (Q,\\nR) pair: (Q) p update the matching model to retrieve N. Test the model on...\\n\\ndesigned model with negative instances; human annotation with the dynamic sampling and cross {(Q, R;)} y from a da...\\nhinge loss, entropy loss, pre-defined index.\\n\\nThe pre-training process\\n1.\\nOversimplification problem of the negative sampling enables the matching model approach can be partially mitigated to distinguish semantically far away responses.\\n2. We can avoid false negative examples and true negative examples are treated equally during training."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Dataset\\n- STC data set (Wang et al.,\\n2013)\\n- Single-turn response selection\\n- Over 4 million post-response pairs (true response) in Weibo for training.\\n- The test set consists of 422 posts with each one associated with around 30 responses labeled by human annotators in \"good\" and \"bad\".\\n\\nDouban Conversation Corpus (Wu et al.,\\n2017)\\n- Multi-turn response selection\\n- 0.5 million context-response (true response) pairs for training\\n- In the test set, every context has 10 response candidates, and each of the response has a label \"good\" or \"bad\" judged by human annotators."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Evaluation Results\\n- Pet P@!TFIDF (Wang et al.,\\n2013) 0.574\\n- TFIDF 0.331 | 0.359 | 0.180\\n- Translation (Wang et al.,\\n2013) 0.587\\n- RNN 0.390 | 0.422 | 0.208\\n- WordEmbedding 0.579\\n- CNN 0.417 | 0.440 | 0.226\\n- DeepMatch topic (Lu and Li,\\n2013) 0.587\\n- DeepMatch (Wang et al.,\\n2015) 0.608\\n- DL2R (Yan et al.,\\n2016) 0.488 | 0.527 | 0.330\\n- LSTM (Lowe et al.,\\n2015) 0.485 | 0.527 | 0.320\\n- LSTM (Lowe et al.,\\n2015) 0.592\\n- LSTM+WS 0.616\\n- Multi-View (Zhou et al.,\\n2016) 0.505 | 0.543 | 0.342\\n- CNN (Hu et al.,\\n2014) 0.585\\n- Multi-View+WS 0.378\\n- CNN+WS 0.604\\n- SMN (Wu et al.,\\n2017) 0.393\\n- SMN+WS 0.565 | 0.609 | 0.421\\n\\nTable 1: Results on STC\\n\\nTable 2: Results on Douban Conversation Corpus"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Ablation Test\\n- WSrand: negative samples are Douban randomly generated.\\n- P@l CNN + WSrand 0.590\\n- CNN + const 0.598\\n- CNN + WS 0.604\\n- LSTM + WSrand 0.598 | 0.501 | 0.532 | 0.323*\\n- const: the marginal in the loss function is a static number.\\n- LSTM + const 0.607 | 0.510 | 0.545 | 0.331\\n- LSTM + WS 0.616 | 0.519 | 0.559 | 0.359\\n- Multi-View + WSrand 0.515 | 0.549 | 0.357\\n- Multi-View + const 0.528 | 0.564 | 0.370\\n- Multi-View + WS 0.534 | 0.575 | 0.378\\n- SMN + WSrand 0.536 | 0.574 | 0.377*\\n- WS: Our full model\\n- SMN + const 0.558 | 0.603 | 0.417\\n- SMN + WS 0.565 | 0.609 | 0.421\\n\\nTable 3: Ablation results."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "More Findings\\n- Updating the Seq2Seq model is not beneficial to the SSE NMUnaEOr [STMPGI 0.616 SMNoo: MAP 0.567.\\n- The number of negative MRR 0.609 instances is an important hyper-parameter for our model.\\n\\nTable 4: The effect of instance number"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Conclusion\\n- We study a less explored problem in retrieval-based chatbots.\\n- We propose a new method that can leverage unlabeled data to learn matching models for retrieval-based chatbots.\\n- We empirically verify the effectiveness of the method on public data sets."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 363,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "sam= Outline\\nBackground & Motivation\\nMethod\\nExperiments & Analysis\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nSemantic Parsing\\n\\nGoal: Map natural languages into semantic representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nTECHNOLOGY AND DESIGN\\n\\nGoal: Map natural languages into semantic representations.\\n\\nNatural Language English: What states have no bordering state?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nTECHNOLOGY AND DESIGN\\n\\nGoal: Map natural languages into semantic representations.\\nNatural Language English: what states have no bordering state?\\n\\nAnswer (exclude(state(all), next_to(state(all))))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nTECHNOLOGY AND DESIGN\\n\\nGoal: Map natural languages into semantic representations.\\n\\nNatural Language English: what states have no bordering state?\\n\\nQUERY: answer (STATE)\\n\\n| Semantic STATE: exclude (STATE, STATE)\\n\\nTree\\n\\n| STATE: state (all)\\n\\nSTATE: next_to (STATE)\\n\\n| STATE: state (all)\\n\\nanswer (exclude(state(a/l), next_to(state(all))))\\n\\nForm 3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nSinz 'sel Joint Representations\\n\\nProposed in previous works:\\n- Synchronous CFG derivation trees Wong and Mooney (2006,\\n2007)\\n- CCG derivation trees Zettlemoyer and Collins (2005,\\n2007)\\n- Bayesian tree transducers Jones, Goldwater and Johnson (2012)\\n- Hybrid Trees Lu, Ng, Lee, Zettlemoyer (2008) A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Lu et al.,\\n2008)\\nHybrid Tree\\nInput: what states have no bordering states?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Lu et al.,\\n2008)\\n\\nHybrid Tree Input: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\n\\nSTATE: exclude (STATE, STATE)?\\n\\nSTATE: state (all) have no\\n\\nSTATE: next_to (STATE) | oO what states bordering\\n\\nSTATE: state (all)\\n\\nstates"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Lue et al.,\\n2008)\\n\\nHybrid Tree\\n\\nInput: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\n\\n_STATE: exclude (STATE, STATE)?\\n\\n---\\n\\nf ~STATE: state (all) have no STATE: next_to (STATE) > what states bordering STATE: state (all)\\n\\nOutput: answer(exclude(state(all), next_to(state(all))))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Lu et al.,\\n2008)\\n\\nGenerative Hybrid Tree\\n\\nInput: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\n_STATE: exclude (STATE, STATE)\\n_STATE: state (all) have no\\n_STATE: next_to (STATE)\\nwhat states bordering STATE: state (all)\\nstates p(m,n) = > p(m,h,n)\\nhe H (n,m)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Lu, 2014,\\n2015)\\n\\nInput: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\n\\n_STATE: exclude (STATE, STATE)\\n\\nfaSTATE: state (all) have no\\n\\nSTATE: next_to (STATE)\\n\\nwhat states bordering STATE: state (all)\\n\\nstatesp(m|n)= > p(m, h in) hEeH(n,m)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Susanto and Lu,\\n2017)\\n\\nNeural Hybrid Tree\\n\\nInput: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\n\\n_STATE: exclude (STATE, STATE)\\n\\n?OoSTATE: state (all) have no STATE: next_to (STATE)\\n\\nwhat states bordering STATE: state (all)\\n\\nNeural hybrid tree is an extension of discriminative hybrid tree."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Susanto and Lu,\\n2017)\\nNeural Hybrid Tree\\n\\nInput: what states have no bordering states?\\n\\nQUERY: answer (STATE)\\nSTATE: exclude (STATE, STATE)\\nSTATE: state (all) have no\\nSTATE: next_to (STATE)\\nwhat states bordering STATE: state (all)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion (Susanto and Lu,\\n2017)\\nNeural Hybrid Tree\\nScore vector\\nHidden layer\\nInput layer\\nSTATE.\\nnext_to (STATE)\\nDiscriminative =\\nSTATE : state (all)\\nhybrid tree"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nWhat do we have?\\n\\nEnglish Sentences:\\n\\nSemantic Parser: 3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nWhat do we have?\\n\\nSemantic Parser → For English: Structured language for German Sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nWhat do we have?\\n\\nGelisaestaiciecsy\\n\\nSemantic Parser: 3 --S > For English: Indonesian Sentences: TGiiitecuscincuecsy10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nWhat do we have?\\n\\nEnglish Sentences:\\n\\nSemantic Parser:\\n\\nFor English:\\n\\nIndonesian Sentences:\\n\\nChinese Sentences:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nSetup\\n\\nTarget Language: (Sere eae): Semantic Parser: ===> For English\\nAuxiliary Languages:\\n- German\\n- Indonesian\\n- Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nSetup\\n\\nTarget Language: (E.g., English)\\n\\nSemantic Parser:\\n- For English\\n- Cross-lingual\\n- Auxiliary Languages\\n- German\\n- Indonesian\\n- Chinese"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nTarget Language: Semantic Parser: For English, we learn distributed representations of semantic auxiliary languages where such cross-lingual information is captured."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nSetups: Target Language: (Series) : Semantic Parser:\\n\\nFor English, we learn distributed auxiliary languages => representations of semantic criteria units where such cross-lingual information is captured."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nStep 1: Cross-lingual Representations\\n\\nWe construct a Semantics Word-Lectocourrencel matrix Ce RTM* based on auxiliary languages and semantic trees.\\n\\nCi1: Auxiliary Languages\\n- German, Indonesian, Chinese."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nCross-lingual Representations\\n\\nThe singular value decomposition (SVD) is then applied to the co-occurrence matrix, leading to C = UxV* We truncate the diagonal matrix and left multiply it with U: R = U"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions Results Data: Multilingual Geoquery"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nResults without Neural Features\\n\\nData: Multilingual Geoquery\\n\\nBaselines: (Lu et al.,\\n2008) (Lu,\\n2015)\\n- Acc.: 76.8\\n- F: 81.0\\n- Acc.: 73.6\\n- F: 76.7\\n- Acc.: 62.1\\n- F: 68.5\\n- Acc.: 69.3\\n- F: 74.6\\n- Acc.: 56.1\\n- Acc.: 53.4\\n- Acc.: 66.4\\n- F: 72.8\\n- Acc.: 61.4\\n- F: 70.5\\n- Acc.: 01.9\\n- Acc.: 58.6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions | Results without Neural Features Data: Multilingual Geoquery Baselines: (Lu et al.,\\n2008) (Lu,\\n2015) (+0): models with distributed representations of semantic units. Acc. | Acc. | Acc. | Acc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nResults with Neural Technology and Design\\n\\nData: Multilingual Geoquery\\n\\nBaselines:\\n- (Lu et al.,\\n2008)\\n- (Lu,\\n2015)\\n- (Susanto and Lu,\\n2017)\\n\\nModels with distributed representations of semantic units.\\n\\nAcc. F. | Acc. F. | Acc. F. | Acc. F.\\n\\n76.8 | 81.0 | 73.6 | 76.7 |\\n62.1 | 68.5 | 69.3 | 74.6 |\\n56.1 | 58.4 | 66.4 | 72.8 |\\n61.4 | 70.5 | 51.8 | 58.6 |\\n\\n96.8 | 80.7 | 80.7 | 75.7 |\\n75.7 | 79.3 | 79.3 | 76.1 |\\n76.1 | 75.0 | 79.3 | 79.3 |\\n73.9 | 73.9 |\\n\\nHT-D (NN) J=2\\n90.0 | 90.0 | 82.1 | 82.1 |\\n73.9 | 73.9 |\\n80.7 | 80.7 |\\n81.1 | 81.1 |\\n81.8 | 81.8 |\\n83.9 | 83.9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nResults with Neural Features\\n\\nTECHNOLOGY AND DESIGN\\n\\nData: Multilingual Geoquery\\n\\nBaselines: (Lu et al.,\\n2008) (Lu,\\n2015) (Susanto and Lu,\\n2017)\\n\\n(+0): models with distributed representations of semantic units.\\n\\nAcc.! F | Acc.! F | Acc.: F | Acc.: F | Acc.: FE | Acc.: F | Acc.! F | Acc.! F | HED\\n\\n86.8 | 86.8 | 80.7 | 80.7 | 75.7 | 75.7 | 79.3 | 79.3 | 76.1\\n\\n76.1 | 75.0 | 75.0 | 79.3 | 79.3 | 73.9 | 73.9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nResults with Neural Features\\n\\nData: Multilingual Geoquery\\n\\nBaselines: (Lu et al.,\\n2008) (Lu,\\n2015) (Susanto and Lu,\\n2017)\\n- models with distributed representations of semantic units.\\n- improved 5 out of 8 languages get imp"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusions\\n\\nCross-Lingual Representations; Meeks UPI\\n\\nRiver: loc (State)\\nCity: loc (State)\\nState: loc (Place)\\nQuery: answer (Nt)\\nRiver: loc (City)\\nPlace: loc (Country)\\n\\nCity: loc (Country)\\nState: largest (SHARE)\\nPopulation (State)\\nState: lonatd Comaiyst (State)\\nPopulation_2 (City)\\n\\nRiver: ShortesCoiiney\\nPlace: place (all)\\nCity: major (River)\\nCity: smallest (City)\\nNum: count (stares)\\nCount (River)\\n\\nState: smallest (density (State))\\nNum: len (River)\\nCity: smallest (density (State))\\nCity: smallest (population (City))\\nState: fewest (State)\\n- Semantic units with similar meanings gather together.\\n- Occasionally, semantic units conveying opposite meanings are grouped together."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nPresented a novel method to learning distributed representations of semantic units containing cross-lingual information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n\\nConclusions\\n\\nPresented a novel method to learning distributed representations of semantic units containing cross-lingual information.\\n\\nFuture work\\n\\nLearn representations and semantic parsers in a joint manner."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Background | Method | Experiments & Analysis | Conclusion\\n- Presented a novel method to learning distributed representations of semantic units containing cross-lingual information.\\n\\nFuture work\\n- Learn representations and semantic parsers in a joint manner.\\n- Investigate which languages from auxiliary corpus are the leading sources of performance gains."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Code available at: http://statnlo.org/research/sp/Zt At oF L| C} oaneeWbanke Evxaptoties Dalu & N Kész6ném\\n- Thank You Tack & (5 Cnacn6o Dank eracias a ® SeéEY Merc suxes Questions?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 208,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Artificial Intelligence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Sentiment and Emotion Analysis\\n\\nSpeaker's behaviors\\n\\nSentiment Intensity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Multimodal Sentiment and Emotion Analysis\\n\\nSpeaker's behaviors\\n\\nSentiment Intensity\\n- Smile (S)\\n- Loud time\\n\\nIntra-modal Interactions\\n\\nCross-modal Interactions\\n\\nMultimodal Representation\\n- Computational Efficiency (Multimodal Fusion)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Multimodal Fusion using Tensor Representation\\n\\nBimodal Visual\\n\\nMultimodal Representation\\n\\nUnimodal\\n\\nIntra-modal interactions\\n\\nCross-modal interactions\\n\\nComputational efficiency\\n\\n\"Tensor Fusion Network for Multimodal Sentiment Analysis\" by Zadeh, A., et al. (2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Computational Complexity\\n- Tensor Product\\nComputational Complexity = O(d, x d, x d^3) O(d, x d^2)\\nNumber of Modalities"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "CONTE SORT ONise Fusion mr"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "From Tensor Representation to Low-rank Fusion: A Low-rank Multimodal Fusion\\n\\nRearrange the computation of h.wD w wo?\\n\\nDecomposition of input tensor Z.\\n\\nDecomposition of weight W.\\n\\nTensor Fusion Networks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Canonical Polyadic (CP) Decomposition of tensors\\n- Rank of tensor W: minimum number of vector tuples needed for exact reconstruction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Canonical Polyadic (CP) Decomposition of 3D tensors"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Modality-specific Decomposition\\n\\n(1) (2) WG Wy Wy + + «6.@ i\" ®1 2wt\\nw) => Retain the dimension for the multimodal representation h during decomposition"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "() Decomposition of weight tensor WQS s = lJhZ|"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "( ) Decomposition of weight tensor WZy wi Na Ww (2)? + + eee\\n- h® WwW) &® W,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "(2) Decomposition of ZBy Wy? Wy\"X) e + + eee =- h"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "@) Rearranging computation forse + |° + foee| = |ww wo) 2, ww) wo) 7,"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Low-rank Multimodal Fusion Visual XYZ Multimodal Language Low-rank Representation Multimodal Prediction Task output Fusion Low-rank factors Low-rank factors"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Easily scales to more modalities\\n\\nIntra-modal interactions\\n\\nVisual\\n\\nCross-modal interactions\\n\\nComputational complexity\\n\\nLow-rank Multimodal Language Representation\\n\\nMultimodal Prediction Task output\\n\\nFusion\\n\\nAudio\\n\\nLow-rank factors\\n\\nLow-rank factors\\n\\nLow-rank factors"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "EXPERIMENTS AND RESULTS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "CMU-MOSI\\nPOM\\nIEMOCAP\\n\\n\"Sentiment Analysis\\nSpeaker Trait Recognition\\nEmotion Recognition\\n\\n2199 video segments\\n1000 full video clips\\n10039 video segments\\n- Single-speaker\\n- Dyadic interaction\\n- From 93 Movie reviews\\n- From 302 videos\\n\\nSegment level annotations\\nVideo level annotations\\nSegment level annotations\\n- Sentiment\\n- 16 types of speaker traits\\n- 10 classes of emotions\\n- Real-valued\\n- Categorical annotations\\n- Categorical annotations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Compare to full rank tensor fusion\\n\\nCMU-MOSI\\n\\nLow-rank Multimodal Fusion\\n- LMFe (Our Model)\\n- OOM Tensor Fusion Networks (Zadeh, et al.,\\n2017)\\n\\n0.98 0.97 0.67 0.987 76.5 76.4 33.5 75.7 32.8 73.9 0.91 0.63 73.4 32.1 0.88 0.60 71.5 31.6\\n\\nMAE Correlation Acc\\n- 2t Fit Acc\\n- 7-20"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Compare to full rank tensor fusion\\n\\nCMU-MOSI POM\\n\\nlEMOCAP\\n\\n0.98 0.97 0.90 0.89 1.0\\n86.0 58 85.9\\n0.40 68.8 0.63 0.80 82.8\\n0.09 0.88 0.60 0.75 0.0 81.0\\n\\nMAE  Correlation\\n\\nMAE  Correlation\\n\\nF1-Happy\\n\\nF1-Sad"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Compare with State-of-the-Art Approaches\\n\\nCMU-MOSI\\n- Low-rank Multimodal Fusion [ij LMFs} (our model)\\n- Memory Fusion Networks [7] MFN (Zadeh, et al.,\\n2018)\\n- Multi-attention Recurrent Networks [J] MARN (Zadeh, et al.,\\n2018)\\n- Tensor Fusion Networks TEN (Zadeh, et al.,\\n2017)\\n- Multi-view LSTM [| MV-LSTM (Rajagopalan, et al.,\\n2016)\\n- Deep Fusion\\n\\nMean Average Error {MAE} (Nojavanasghari, et al., 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Compare with Top 2 State-of-the-Art Approaches\\n\\nCMU-MOSI    POM      IEMOCAP\\n- MARNI: 0.965\\n- 0.968\\n- 0.886\\n- 0.912\\n- 0.668\\n\\nTFN: 0.396\\n- 0.855\\n- 0.270\\n- 82.8\\n- 0.796\\n- 0.60\\n- 0.75\\n- 81.0\\n\\nCorrelation t   MAE  Correlation f\\n- F1-Angry\\n- F1-Sad"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Efficiency Improvement TM LMF (Ours) CMU-MOSI TFN (Zadeh, et al.,\\n2017)\\n\\nEfficiency Metric: Number of data samples processed per second\\n\\nTraining Efficiency\\n\\nTesting Efficiency\\n- Training\\n- samples/s\\n- Testing\\n- samples/s"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Conclusions on interactions of Cross-modal interactions. Visuality:\\n- Computational complexity.\\n- Low-rank factors.\\n- State-of-the-art results in Audio: Representation.\\n- Multimodal Prediction Task output.\\n- Fusion."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Code: https://github.com/Justin1904/Low-rank-Multimodal-Fusion\\n\\n* MultiComp Lab http://multicomp.cs.cmu.edu/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 212,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Inferring Character State\\n\\nThe band instructor told the band to start playing. He often stopped the music when players were off-tone.\\n\\nThey grew tired and started playing worse after a while.\\n\\nThe instructor was furious and threw this chair. He cancelled practice and expected us to perform tomorrow."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Reasoning about Naive Psychology\\n\\nNew Story Commonsense Dataset:\\n- Open text + psychology theory\\n- Complete chains of mental states of characters\\n- Implied changes to characters\\n\\nContextualized reasoning\\n\\nhttps://uwnlp.github.io/storycommonsense/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "How do we represent naive psychology?\\n\\nThe band instructor told the band to start playing. He often stopped the music when players were off-tone.\\n\\nPsychology Natural Theories | Language\\n\\nInstructor wants to create a good harmony.\\n\\nFeels frustrated."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Naive Psychology Annotations\\n\\nMotivation:\\n- Causal source to actions\\n- Motivational theories\\n\\nEmotional Reaction:\\n- Causal effect of actions\\n- Theories of emotion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Motivation: Maslow Hierarchy of Needs (1943)\\n\\nShe sat down on the couch and instantly fell asleep.\\n\\nShe sat down to eat for lunch."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Motivation: Reiss Categories (2004)\\n\\nSpiritual curiosity, serenity,\\nGrowth idealism, independence\\nEsteem: approval, power, status;\\nromance, belonging, love, family, social contact\\n& material health, savings,\\naesthetic order, safety\\n\\nFood: physiological food, rest\\n\\nShe sat down to eat lunch."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Emotional Reaction: Plutchik (1980) Plutchik's Wheel 8 \"main\" emotions: Their favorite uncle died.\\n\\nfeel Sadness\\n\\nSuddenly, they heard a loud noise.\\n\\nfeel Fear, Surprise"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Implicit Mental State Changes\\n\\nThe band instructor told the band to start playing. He often stopped the music when players were off-tone.\\nThey grew tired and started playing worse after a while. The instructor was furious and threw his chair.\\nHow are players affected? Implicitly involved inference in these cases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Tracking Mental States\\n\\nThe band instructor told the band to start playing. He often stopped the music when players were off-tone.\\nThey grew tired and started playing worse after a while. The instructor was furious and threw his chair.\\nHe cancelled practice and expected us to perform tomorrow. Why does the instructor cancel practice?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Related Work\\n\\nReasoning about narratives (Mostafazadeh et al. 2016); Detecting emotional content (Mohammad et al.\\n2013) or stimuli (Gui et al.\\n2017) of a statement.\\n\\nOur work: Both motivation and emotion for a character's outlook.\\nLeverage psychology theories and natural language explanations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Full Annotation Chain\\n\\nMaslow, Reiss motivations + open text: Action Motivation\\n\\nL--- + & = Emotional Plutchik emotions + open text"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Action = Motivation\\na = Full Annotation Chain\\naa Lf Egy Reaction\\n\\nSarah is swimming.\\nSarah gets attacked by a shark.\\nSarah fights off the shark.\\nSarah escapes the attack.\\nSarah lost her eye battling the shark.\\n\\n7\\nSarah: (1, 2, 3, 4,\\n5)\\nA Shark: {2, 3, 5}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Full Annotation Chain Characters Affect + tone -> Sarah is swimming. Sarah gets attacked by a shark.\\nSarah fights off the shark.\\n\\nIs Sarah taking Stability action: Yes \"to escape to safety\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Full Annotation Chain\\n\\nPharacie's Reaction\\n\\nSarah is swimming.\\nSarah gets attacked by a shark.\\nSarah fights off the shark.\\n\\nEmotional\\n\\nDoes the Shark have a reaction?\\n- Anger\\n- Yes \"aggressive\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Data Collection Summary\\n\\nOver 300k low-level annotations for 15k stories from ROC training set\\n\\nOpen-text Open-text + categories\\n\\ntrain dev test\\n\\n# character-line pairs 200k 25k 23k\\n\\n7 m. w/ motivation\\n\\nAOk 9k 7k >50k motiv. change changes\\n\\na ... w/ emotional 77k 15k 44k > 100k emotion reaction change changes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Annotated Data Distributions (Motivation)\\n\\nA fair amount of diversity in the open-text: ~1/3 have positive motivation change.\\n\\nSeniesa Opie\\n\\n% Annotations where selected explanations become experienced\\n\\nSpiritual growth\\n- meet goal; to look nice\\n\\nEsteem\\n- to support his friends\\n\\nLove\\n- to be employed; stay dry\\n\\nStability\\n- rest more; food\\n\\nPhysical"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Annotated Data Distributions (Emotion)\\n\\nLots of happy stories ~2/3 have positive emotion change:\\n\\nSampled Open-text Explanations\\n\\n% Annotations where selected\\n- outraged\\n- disgust\\n- dismayed\\n- surprise\\n- enraged\\n- anger\\n- touched\\n- trust\\n- excluded\\n- sadness\\n- future oriented\\n- anticipation\\n- happier\\n- joy\\n- frozen in fear\\n- fear"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "New Tasks\\n\\nGiven a story excerpt and a character, can we explain the mental state:\\n- Explanation Generation: Generate open-text explanation of motivation/emotional reaction\\n- State Classification: Predict Maslow/Reiss/Plutchik category"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Task 1\\n- Explanation Generation\\n\\nExplain mental state of character using natural language\\n\\nInput Output\\n\\nThe band instructor told the band to start playing."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Modeling (AS iStory Text + Character Using encoder-decoder framework with Encoders\\n- LSTM, CNN, REN, NPN.\\n\\nh = fenc(s, char)\\n\\ne Decoder for generation: single layer LSTM\\n\\nDecoder expl = fgen(h)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Encoding Modules\\n\\nGiven entity e; and line x* (and entity-specific context sentences x'|e;)\\n\\nh = Fenclx*, x'le;|)\\n\\nEncoding functions:\\n- e CNN, LSTM: encode last line and context -- concatenate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Entity Modeling\\n\\nRecurrent Entity Networks (Henaff et al., 2017):\\n- Store separate memory cells for each story character.\\n- Update after each sentence with sentence-based hidden states.\\n\\nNeural Process Networks (Bosselut et al., 2018):\\n- Also has separate representations for each character.\\n- Updates after each sentence using learned action embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Explanation Generation Set-up\\n\\nEvaluation: Cosine similarity of generated response to reference\\n\\nRandom baseline: Select random answer from dev set\\n\\nResponses are short/formulaic\\n\\nWords for describing intent/emotion are close in embedding space"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Explanation Generation Results\\nCos. Similarity to Reference\\n\\n90\\n80\\n70\\n60\\n51\\n8\\n53.950\\n45.840\\n0.030\\n\\nMotivation (VE)\\nEmotion (VE)\\n\\nmM\\nRandom SLSTM\\n@CNN\\n@®REN\\n@NPN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Task 2\\n- Mental State Classification\\n\\nPredicting psychological categories for mental state\\n\\nInput Output\\n\\nThe band instructor told the band to start playing.\\n\\nStory Text Excerpt + Character Theory categories"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Modeling (AS Story Text + Characters) Using encoder-decoder framework\\n\\nSet Encoders\\n- LSTM, CNN, RNN, f = fenc(s, char)\\n\\nDecoder for categorization: Dete logistic regression cat = phrase(h)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "State Classification Results © CNN and F1 Performance\\n\\nLSTM perform 40 best on 35 motivation 30 categories\\n\\n20\\n- Entity\\n\\n15 modeling has 10 slight > gmene\\n\\nA Maslow = Reiss\\n\\n€8 Plutchik\\n\\nM Random @LSTM @CNN @REN @NPN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Further Improvement F1 Performance 90\\nBest F1 Bpat ~35% 605040\\n\\nMaslow = Reiss €8 Plutchik\\nRandom = LSTM #CNN @REN @&NPN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Effect of Entity Specific Context\\n\\nIncluding previous lines F1 w/ and w/o context from context that include entity specific context:\\n- improves all models F1 by about 3-5%\\n- MASLOW REISS PLUTCHIK = CNN\\n- CNN w/ context"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Pre-training Encoders\\n\\nStory Text + Character\\n\\nWe have more open-text explanations than categorical annotations:\\n1. Pre-train encoders on open-text explanations\\n2. Fine-tune with the categorical labels\\n\\nDecoder\\nexpl = fgen(h)\\ncat = fotass(h)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Effect of Pretrained Encoders F1 w/ and w/o Pretrained Encoders\\n\\n4035305 Improves: 20 1-2% 151050 Maslow Reiss Plutchik = CNN- @ & CNN + pre-training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Performance Per Category\\n\\nHighest performance:\\n- Frequent classes (eg. \"joy\" F1: 38.9%)\\n- Very concrete sets of actions (\"physiological\" F1: 40%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Future Work\\n\\nOutside Knowledge: Help with infrequent classes and subtle implied changes.\\n\\nSocial Commonsense: Help with inferring mental state especially in more contextual cases.\\n\\nPotential Applications: Improving language models, chat systems, natural language understanding."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Conclusions\\n\\nNew Dataset:\\n- 15k roc stories annotated per character\\n- >50k motivation changes\\n- >100k emotions changes\\n\\nhttps://uwnlp.github.io/storycommonsense/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 127,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "I want to be... State of the art\\n- my new algorithm\\n\\nApply algorithm on current SOTA\\n\\nApply algorithm on algorithm\\n\\nTest if\\n\\nData\\n- Evaluation measure"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "This is not enough!\\n- The difference between the performance of the algorithm and could be coincidental!\\n- We need to make sure that the probability of making a false claim is very small.\\n- We can do so by... Testing Statistical Significance!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "NLP & Hypothesis Testing\\n- Survey ACL 2017\\n- 180 experimental long papers\\n- 63 checked statistical significance\\n- Only 42 mentioned the name of the statistical test\\n- Only 36 used the correct statistical test of all papers!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "simple Guide\\n\\nDoes the test statistic come from a known distribution?\\nYes\\nNo\\n\\nUse a parametric test\\n\\nIs the data metric?\\nYes\\nNo\\n\\nUse bootstrap\\nUse sampling or random-free non-parametric test"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "statistical Significance Hypothesis Testing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "statistical Significance Hypothesis Testing\\n- The smaller the p-value is, the higher the indication that the null hypothesis does not hold.\\n- We reject the null hypothesis if"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "statistical Significance Hypothesis Testing\\n- Type I error\\n- rejecting the null hypothesis when it is true\\n- Type II error\\n- not rejecting the null hypothesis when the alternative is true\\n- Significance level\\n- probability of making Type I error\\n- Significance power\\n- probability of not making Type II error"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "90... Let's all test for statistical significance! Why not?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "NLP & Hypothesis Testing\\n- Problems? Both algorithms are applied on the same data. What is the distribution of data samples?\\nData samples are not independent."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Paired Statistical Tests\\n- Both algorithms are applied on the same data\\n- dependent\\n-\\n\\nPaired sample: sample selected from the first population is related to the corresponding sample from the second population\\n-\\n\\nSolution: apply paired version of statistical test\\n- Paired t-test\\n- Wilcoxon signed-rank test\\n- paired bootstrap..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Parametric Tests\\n\\nFirst case: the distribution is Normal\\n\\nParametric tests make assumptions about the test statistic distribution, particularly\\n- normal distribution. When the parametric test meets assumptions it has high statistical power.\\n- Linear regression analyses\\n- T-tests and analyses of variance on the difference of means\\n- Normal curve Z-tests of the differences of means and proportions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Parametric Tests\\n- Check for Normality\\n- Shapiro-Wilk: tests if a sample comes from a normally distributed population\\nscipy.stats.shapiro([a-b for a, b in zip(res_A, res_B)])\\n- Anderson-Darling: tests if a sample is drawn from a given distribution\\nscipy.stats.anderson([a-b for a, b in zip(res_A, res_B)], 'norm')\\n- Kolmogorov-Smirnov: goodness of fit test. Samples are standardized and compared with a standard normal distribution.\\nscipy.stats.kstest([a-b for a, b in zip(res_A, res_B)], 'norm')"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Non-Parametric Tests\\n\\nSecond case: the distribution is unknown/not normal.\\n\\nNon-parametric tests do not assume anything about the test statistic distribution.\\n\\nTwo types:\\n- sampling-free tests\\n- sampling-based tests"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Sampling-Free Non-Parametric Tests\\nOQ ere Not Normal\\n8f© rouge-red bleu-bue"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "sampling-Based Non-Parametric Tests\\n- Permutation tests: resamples drawn at random from the original data. Without replacements.\\n- Paired design\\n- consider all possible choices of signs to attach to each difference.\\n- Bootstrap: resamples drawn at random from the original data. With replacements.\\n- Paired design\\n- sample with repetitions from the set of all differences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "NLP Data and Assumption\\n- Many NLP datasets have dependent samples.\\n- All statistical tests assume independency => all tests are invalid, impact hard to quantify.\\n- Solution: come up with statistical tests that allow dependencies."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Thank You for Listening\\n\\nQuestions?\\n\\nhttps://github.com/rtmdrr/testSignificanceNLP"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 98,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Time Critical Events\\n\\nUrgent needs for affected people\\n- Food, water\\n- Medical assistance\\n- Service and utilities\\n\\nInformation gathering in real-time is the most challenging part.\\nHumanitarian organizations and local administration need information to help launch responses."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Artificial Intelligence for Digital Response (AIDR)\\nResponse time-line today\\nResponse time-line our target\\n\\nDisaster Event.\\n- Community\\n- Untimely harm.\\n- Response:\\n- Reduced wasted effort\\n- Decisions\\n- Delayed decision-making\\n- Early decision-making\\n- Delayed crisis response\\n- Rapid crisis response"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "- WAIDR Artificial Intelligence for Digital Response\\n- MicroMappers (CrowdExpert/User/Crisis Volunteers)\\n- Model data\\n- Collection Classifier(s)\\n\\nFacilitates decision context\\n\\nYes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "WA IDR Artificial Intelligence fortang Digital Response\\n\\nMicroMappers (CrowdExpert/User/Crisis Volunteers)\\n\\n$ 30k/min\\n\\nCollection"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "WAIDR Artificial intelligence for digital response\\n\\nMicroMappers (Crowd4 Volunteers)\\n-\\n- Small amount of labeled data and large amount of unlabeled data at the beginning of the event\\n- Labeled data from the past event. Can we use them? What about domain shift?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Our Solutions/Contributions\\n- How to use large amount of unlabeled data and small amount of labeled data from the same event?\\n- Graph-based semi-supervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Our Solutions/Contributions\\n- How to use large amount of unlabeled data and small amount of labeled data from the same event?\\n- Graph-based semi-supervised\\n- How to transfer knowledge from the past events => Adversarial domain adaptions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Domain Adaptation with Adversarial Training and Graph Embeddings\\n\\nShared Components\\n- Dense (Z.)\\n- Convolution Dense (Z)\\n\\nClass label\\n- ERY:\\n- Domain adversary\\n- Feature map"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Supervised Learning\\n\\nShared Components\\n\\nInput Dense (Z)\\n- Convolution Dense (Z)\\n\\nClass label £o(A, ®)\\n\\nSupervised O E X \\/ loss L\\n- S Wax:\\n\\nFeature map\\n\\nPre-trained Word Max\\n\\nEmbeddings pooling QcRI"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Semi-Supervised Learning\\n- Semi-Supervised component\\n\\nShared Components\\n- Dense (Z.)\\n- Convolution Dense (2)\\n\\nSemi-Supervised\\n- loss LgWry (Z).\\n- Feature map\\n- Pre-trained Word Max\\n- Baheiiey pooling"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Semi-Supervised Learning\\n\\nL: number of labeled instances (%, Yi.)\\nU: number of unlabeled instances (X.41.14u)\\n- Design a classifier f: x\\n- y"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Graph based Semi-Supervised Learning\\n\\nPositive Negative\\n\\nSimilarity\\n\\nAssumption: If two instances are similar according to the graph, then class labels should be similar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Graph based Semi-Supervised Learning\\n\\nPositive Negative\\n\\nSimilarity 0.7 0.3\\n\\nTwo Steps:\\n- Graph Construction\\n- Classification"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Graph based Semi-Supervised Learning\\n- Graph Representation\\n- Nodes: Instances (labeled and unlabeled)\\n- Edges: n x n similarity matrix\\n- Each entry aij indicates a similarity between instance i j and /"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Graph based Semi-Supervised Learning\\n\\nGraph Construction\\n\\nWe construct the graph using k-nearest neighbor (k=10).\\n\\nEuclidean distance\\n- Requires n(n-1)/2 distance computation\\n- K-d tree data structure to reduce the computational complexity O(log\\nN)\\n- Feature Vector: taking the averaging of the word2vec vectors"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Graph based Semi-Supervised Learning\\n\\nSemi-Supervised component:\\n\\nLoss function L(A, ®,\\nQ) = Lo(A, ®) + AgLla(A,\\n2)\\n\\nGraph context loss\\n\\nLet Us_La(A,\\nQ) = \"Ton. 2 E(;,7) logo (CF z,(i)) (Yang et al.,\\n2016)\\n\\nLearns the internal representations (embedding) by predicting a node in the graph context"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Graph based Semi-Supervised Learning\\n- Semi-Supervised component: Loss function Lst + UsLoao(A,\\nQ) = \"Tov, 2 E(;,7) logo (CP 29(i)) (Yang et al.,\\n2016)\\n\\nTwo types of context:\\n1. Context is based on the graph to encode structural (distributional) information"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Graph based Semi-Supervised Learning\\n- Semi-Supervised component: Loss function Lst + Us; Lao(A,\\nQ) =\\n- Lav. 2 E(;,y) logo (C} 2, (i)) (Yang et al.,\\n2016)\\n\\nTwo types of context:\\n- Context is based on the graph to encode structural (distributional) information.\\n- Context is based on the labels to inject label information into the embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Graph based Semi-Supervised Learning\\n- Semi-Supervised component: Loss function L(A, ®,\\nQ) = Lo (A, ®) + AgLe (A,\\nQ) A={U, V} Convolution filters and dense layer parameters ©={V, W} Parameters specific to the supervised part Q={V, C} Parameters specific to the semi-supervised part"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Domain Adaptation with Adversarial Training and Graph Embeddings\\n\\nShared Components\\n- Dense (Z)\\n- Convolution Dense (Z)\\n- Class label (ALF)\\n- FDS\\n- Semi-Supervised\\n- Dense (s)\\n- Graph context loss\\n- Domain adversary\\n- Feature map"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Domain Adaptation with Adversarial Training\\n\\nDomain discriminator is defined by:\\n6 = p(d = 1|t, A,\\nV) = sigm(wi z,)\\n\\nNegative log probability of the discriminator loss:\\nINA, WV) = -d; log 5\\n- (1\\n- d;) log (1\\n-\\n5)\\n\\nDomain adversary loss is defined by:\\nl Ls + Us 1 Ut£Lp(A,¥) = -----\\n9) IA, ¥)\\n-\\n- SFA.)\\n\\nLs + Us i=1 Ut f-4d € {0,1} represents the domain of the input tweet tA={U,V}\\n\\nConvolution filters and dense layer parameters={V,.w,}\\n\\nParameters specific to the domain discriminator"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Domain Adaptation with Adversarial Training and Graph Embeddings;\\n\\nCombined loss\\nDomain Supervised adversarial loss L(A, ®, 2,\\nV) = EclA, @)' + Agla (A, ny) + AaLp(A, ¥)\\n\\nSemi-Supervised We seek parameters that minimize the classification loss of the class labels and maximize domain discriminator loss\\n\\n6° = argmin max L(A, ®, 2, WV)\\nAQA={U,V}\\n\\nConvolution filters and dense layer parameters ®={V., W}\\nParameters specific to the supervised part 2={V..C}\\nParameters specific to the semi-supervised part={V,, w.}\\nParameters specific to the domain discriminator part"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Model Training\\n\\nAlgorithm 1: Model Training with SGD\\n\\nInput: data DL, Du, Dy; graph G\\nOutput: learned parameters Θ = {A, ...}\\n1. Initialize model parameters {F, A, ..., 2, V};\\n2. repeat\\n// Semi-supervised\\nfor each batch sampled from p(j, y | i, Dk, Dé,\\nG) do\\na) Compute loss £Le(A, ...);\\nb) Take a gradient step for Le(A, ...);\\nend\\n\\n// Supervised & domain adversary\\nfor each batch sampled from D' do\\na) Compute £-(A, ... ) and Lp(A, ...);\\nb) Take gradient steps for £-(A, ...) and Lp(A, ...);\\nend\\n\\n// Domain adversary\\nfor each batch sampled from D7 do\\na) Compute £p(A, ...);\\nb) Take a gradient step for Lp(A, ...);\\nend\\n\\nuntil convergence:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Corpus collected during:\\n- 2015 Nepal earthquake\\n- 2013 Queensland flood\\n\\nA small part of the tweets has been annotated using CrowdFlower.\\n\\nRelevant: injured or dead people, infrastructure damage, urgent needs of affected people, donation requests.\\n\\nIrrelevant: otherwise\\n\\nDataset Relevant | Irrelevant | Train | Dev | Test (60%) | (20%) | (20%)\\n\\nNepal earthquake 5,527 6,141 7,000 1,167 3,503\\n\\nQueensland flood 5,414 4,619 6,019 1,003 3,011\\n\\nUnlabeled Instances\\n\\nNepal earthquake: 50K\\n\\nQueensland flood: 21K"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Experiments and Results\\n- Supervised baseline:\\n- Model trained using Convolution Neural Network (CNN)\\n- Semi-Supervised baseline (Self-training):\\n- Model trained using CNN was used to automatically label unlabeled data\\n- Instances with classifier confidence >= 0.75 were used to retrain a new model\\n\\nUnlabeled data\\n\\nTraining at Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Experiments and Results\\n- Semi-Supervised baseline (Self-training) | 61.15 | 61.53 | 61.53 | 61.26\\n- Semi-Supervised (Graph-based) | 64.81 | 64.58 | 64.63 | 65.11\\n- Supervised | 80.81 | 80.84 | 81.08\\n- Semi-Supervised (Self-training) | 81.04 | 80.78 | 80.84 | 81.08\\n- Semi-Supervised (Graph-based) | 92.20 | 92.60 | 94.49 | 93.54"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Experiments and Results\\n- Domain Adaptation Baseline (Transfer Baseline): Trained CNN model on source (an event) and tested on target (another event)\\n- Source | Target | AUC | P | R | F1\\n\\nIn-Domain Supervised Model\\n- Nepal | Nepal | 01.22 | 02.42 | 62.31 | 60.89\\n- Queensland | Queensland | 80.14 | 80.08 | 80.16 | 80.16\\n\\nTransfer Baseline\\n- Nepal | Queensland | 58.99 | 59.62 | 60.03 | 59.10\\n- Queensland | Nepal | 54.86 | 56.00 | 56.2 | 53.63"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Experiments and Results\\n- Domain Adaptation\\n- Source\\n- Target\\n- AUC\\n- P\\n- R\\n- F1\\n\\nIn-Domain Supervised Model 60.89\\n\\nTransfer Baseline 59.10\\n\\n53.63 (60.15 60.6: Al) 71"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Experiments and Results\\n\\nCombining all the components of the network\\n\\nSource | Target | AUC | P | R | F1\\n\\nNepal Nepal | 612 | 2.49 | 2.31 | 60.89\\n\\nQueensland Queensland | 80.14 | 80.05 | 80.16\\n\\nNepal Queensland | 585 | sm | soa\\n\\nQueensland Nepal | 548 | 56.00 | 50.21 | 58.68\\n\\nNepal Queensland | 80.94\\n\\nQueensland Nepal | 8\\n\\nNepal Queensland | 582\\n\\nQueensland Nepal | 80"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Summary\\n- We have seen how graph-embedding based semi-supervised approach can be useful for small labeled data scenario.\\n- How can we use existing data and apply domain adaptation technique?\\n- We propose how both techniques can be combined."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Limitation and Future Study\\n\\nLimitations:\\n- Graph embedding is computationally expensive\\n- Graph constructed using averaged vector from word2vec\\n- Explored binary class problem\\n\\nFuture Study:\\n- Convoluted feature for graph construction\\n- Hyper-parameter tuning\\n- Domain adaptation: labeled and unlabeled data from target"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Thank you! To get the data: http://crisisnlp.qcri.org/ Please follow us @aidr_qcri\\n\\nFiroj Alam, Shafiq Joty, Muhammad Imran. Domain Adaptation with Adversarial Training and Graph Embeddings.\\nACL, 2018, Melbourne, Australia."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 254,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Google YAHOO! bing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Natural Language Understanding Google YAHOO! bing CO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Natural Language Understanding\\n\\nGive me a recipe\\n\\nGoogle\\nYAHOO!\\nbing\\n\\nPlease bring me my coffee mug from the kitchen"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Natural Language Understanding\\n\\nGive me a recipe\\n\\nGoogle\\n\\nYahoo!\\n\\nBing\\n\\nHow long does it take to get a PhD?\\n\\nPlease bring me my coffee mug from the kitchen.\\n\\nWhat can I help you with?\\n- Seema\\n\\nWhich phone number for Tom Ribbins?\\n\\n(212) 555-13134"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "ruman interactions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "ab > & CLA )|ae CAN LULLyERSIPx BioG:Is564 JLSS OSARYL NY8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Teach Machines to Ask Clarification Questions\\n\\nGoogle\\nYAHOO!\\nbing\\n\\nHow long does it take to get a PhD?\\n\\nGive me a recipe for lasagna.\\n\\nIn which field? Any dietary restrictions?\\n\\nPlease bring me my coffee mug from the kitchen. What color is your coffee mug?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Teach Machines to Ask Clarification Questions\\n\\nGoogle Context-aware questions about \"YAHOO! missing information\\n\\nHow long does it take to get a PhD?\\n\\nGive me a recipe for lasagna.\\n\\nIn which field?\\n\\nAny dietary restrictions?\\n\\nPlease bring me my coffee mug from the kitchen.\\n\\nWhat color is your coffee mug?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Reading Comprehension Question Generation\\n\\nMy class is going to the movies on a field trip next week. We have to get permission slips signed before we go.\\n\\nWe are going to see a movie that tells the story from a understanding of the textbook we read.\\n\\nQ: What do the students need to do before going to the movies?\\n- Heilman. \"Automatic factual question generation from text\" Ph.D. thesis 2011\\n- Vasile, et al. \"The first question generation shared task evaluation challenge.\" NLG 2010\\n- Olney, Graesser, and Person. \"Question generation from concept maps.\" Dialogue & Discourse 2012\\n- Chali and Hasan. \"Towards Topic-to-Question Generation.\" ACL 2015\\n- Serban, et al. \"Generating Factoid Questions With Recurrent Neural Networks\" ACL 2016\\n- Du, Shao & Cardie \"Learning to ask: Neural question generation for reading comprehension\" ACL 2017\\n- Tang et al. \"Learning to Collaborate for Question Answering and Asking.\" NAACL 2018\\n- Mrinmaya and Xing. \"Self-Training for Jointly Learning to Ask and Answer Questions.\" NAACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Question Generation for Slot Filling\\n\\nSLOTS\\n\\nUSER: I want to go to Melbourne on July 14: <origin city>\\n\\nSYSTEM: What time do you want to leave? <origin time>\\n\\nUSER: I must be in Melbourne by 11 am.\\n\\nSYSTEM: Would you like a Delta flight that arrives at 10:15 am? <departure time>\\n\\nUSER: Sure. <airline>\\n\\nSYSTEM: In what name should I make the reservation?\\n\\no Goddeau, et al. \"A form-based dialogue manager for spoken language applications.\" 1996\\n\\no Bobrow, et al. \"GUS, a frame-driven dialog system.\" Artificial Intelligence 1977\\n\\no Lemon, et al.\\n\"An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the TALK in-car system.\" EACL 2006\\n\\no Williams, et al. \"The Dialog State Tracking Challenge.\" SIGDIAL 2013\\n\\no Young, et al. \"POMDP-based statistical spoken dialog systems: A review.\" IEEE 2013\\n\\no Dhingra, et al. \"Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access.\" ACL 2017\\n\\no Bordes, et al. \"Learning end-to-end goal-oriented dialog.\" ICLR 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Other types of Question Generation\\n- Liu, et al.\\n\"Automatic question generation for literature review writing support.\" International Conference on Intelligent Tutoring Systems.\\n2010\\n- Penas and Hovy, \"Filling knowledge gaps in text for machine reading.\" International Conference on Computational Linguistics: Posters ACL 2010\\n- Artzi & Zettlemoyer, \"Bootstrapping semantic parsers from conversations.\" EMNLP 2011\\n- Labutov, et al. \"Deep questions without deep understanding.\" ACL 2015\\n- Mostafazadeh et al. \"Generating natural questions about an image.\" ACL 2016\\n- Mostafazadeh et al. \"Multimodal Context for Natural Question and Response Generation.\" IJCNLP 2017\\n- Rothe, Lake and Gureckis. \"Question asking as program generation.\" NIPS 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "- Clarification Questions\\n- Dataset\\n- Problem Formulation: Question Ranking\\n- Expected Value of Perfect Information (EVPI)\\n- Inspired Model Evaluation\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "See Problem Formulation: Question Ranking\\nExpected Value of Perfect Information (EVPI) inspired model\\nEvaluation\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Clarification Questions Dataset\\nStackExchange Question-Answer Forum\\nStack Overflow\\nAsk Ubuntu\\nLanguage & Usage\\nUnix & Linux"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Clarification Questions Dataset\\n\\nEmel CT signup login tour help pQSearch a@AQyeountue\\n\\nQuestions Tags Users Badges Unanswered Ask Question\\n\\nHow to configure path or set environment variables for installation?\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\nAny help? Thanks in advance!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Clarification Questions Dataset\\n\\nme eT signup login tour help pQSearch a@ AQyeountue Questions Tags Users Badges Unanswered Ask Question\\n\\nHow to configure path or set environment variables for installation?\\n\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\nAny help? Thanks in advance!\\n\\nFinding: Questions go unanswered for a long time if they are not clear enough\\n\\nAsaduzzaman, Muhammad, et al.\\n\"Answering questions about unanswered questions of stack overflow.\" Working Conference on Mining Software Repositories.\\nIEEE Press, 2013."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Clarification Questions Dataset\\n\\nsignup login tour help\\n\\nSearch a@Account\\n\\nQuestions Tags Users Badges Unanswered\\n\\nAsk Question\\n\\nHow to configure path or set environment variables for installation?\\n\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\n\\nQuestion\\n\\nAny help? Thanks in advance!\\n\\ncomment\\n\\nWhat version of ubuntu do you have?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Clarification Questions Dataset\\n\\nme eT signup login tour help\\n\\nSearch a@AQyeountue\\n\\nQuestions\\n\\nTags\\n\\nUsers\\n\\nBadges\\n\\nUnanswered\\n\\nAsk Question\\n\\nHow to configure path or set environment variables for installation?\\n\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\n\\nI'm having this error message while running ./configure\\n\\nInitial Post\\n\\n<error message>\\n\\nSo I have the library but the program installation isn't finding it.\\n\\nQuestion\\n\\nAny help? Thanks in advance!\\n\\ncomment\\n\\nWhat version of ubuntu do you have?\\n\\nI'm aiming to install ape in Ubuntu 14.04 LTS, a simple code for pseudopotential generation.\\n\\nto the question\\n\\nI'm having this error message while running ./configure\\n\\n<error message>\\n\\nUpdated Post\\n\\nSo I have the library but the program installation isn't finding it.\\n\\nAny help? Thanks in advance!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Clarification Questions Dataset\\n\\nDataset Creation (Gent), (auenion), (Gaver)\\n\\nOriginal post\\n\\nClarification question posted in comments\\n\\nEdit made to the post in response to the question or author's reply to the question comment\\n\\nDataset Size: ~77 K triples\\n\\nDomains: Askubuntu, Unix, Superuser\\n\\nNote: We identify a question using the question mark (?) token.\\nWe match the edit to the answer using timestamp & word embedding similarity based heuristics."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "(Talk Outline\\n\\nClarification Questions\\n\\nDataset\\n\\nExpected Value of Perfect Information (EVPI) inspired model\\n\\nEvaluation\\n\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Problem Formulation: Question Ranking\\n\\nHow to configure path or set environment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Problem Formulation: Question Ranking\\n\\nGenerate Question Candidates\\n\\nWhat is the make of your wifi card?\\n\\nHow to configure path or set environment variables?\\n\\nWhat version of Ubuntu do you have?\\n\\nWhat OS are you using?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Problem Formulation: Question Ranking\\n\\nGenerate Question Rank the question Candidates\\n\\nWhat is the make of your wifi card?\\n\\nWhat version of Ubuntu do you have?\\n\\nHow to configure path or set environment variables?\\n\\nWhat OS are you using?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Problem Formulation: Question Ranking\\n\\nHow to configure path or set environment variables for installation?\\n\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\nAny help? Thanks in advance!\\n\\nWhat version of Ubuntu do you have?\\n- Shortlist of useful questions\\n- How are you installing ape?\\n- Do you have GSL installed?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "- Clarification Questions\\n- Dataset\\n- Problem Formulation\\n- Question Ranking\\n- Evaluation\\n- Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nKey Idea\\n\\nHow to configure path or set environment variables for installation?\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\nAny help? Thanks in advance!\\n\\nPossible questions\\n\\n(a) What version of Ubuntu do you have? > Just right\\n\\n(b) What is the make of your wifi card? > Not useful\\n\\nAG ye 36"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nKey Idea\\n\\nHow to configure path or set environment variables for installation?\\n\\nI'm aiming to install ape, a simple code for pseudopotential generation.\\nI'm having this error message while running ./configure <error message> So I have the library but the program installation isn't finding it.\\nAny help? Thanks in advance!\\n\\nPossible questions\\n\\n(a) What version of Ubuntu do you have? > Just right\\n\\n(b) What is the make of your wifi card? > Not useful\\n\\n(c) Are you running Ubuntu 14.10 kernel 4.4.0-59-generic on an x86 64 architecture? > Unlikely to add value\\n\\na: stIRyyD"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nUse EVPI to identify questions that add the most value to the given post.\\n\\nAvriel, Mordecai, and A. C. Williams.\\n\"The value of information and stochastic programming.\" Operations Research 18.5 (1970)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nUse EVPI to identify questions that add the most value to the given post.\\n\\nDefinition: Value of Perfect Information VPI (x)\\n\\nHow much value does x add to a given information content c?\\n\\nSince we have not acquired x, we define its value in expectation.\\n\\nLikelihood of x given c\\n\\nEVPI (x|c) = P (x|c) Utility(x, c)x\\n\\nValue of updating c with x\\n\\nAvriel, Mordecai, and A. C. Williams.\\n\"The value of information and stochastic programming.\" Operations Research 18.5 (1970)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nEVPI formulation for our problem"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem ever ((@) (5) [e | : given post: question from set of question candidates Q"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\nLikelihood of a; being the answer to q; on post p\\n\\nEver ((aji(p))= P((aji(e).(s))[e | : given post: question from set of question candidates Q"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\nLikelihood of a; being the answer to q; on post prior\\n\\nP((sji(e).(e))\\n\\nUtility of updating the post p with answer a; given post: question from set of question candidates QAG ye 45"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\nLikelihood of a being the answer to q on post p\\nUtility of updating the post p with answer a given post: question from set of question candidates Q: answer from set of answer candidates A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\nWe rank questions based on their EVPI value\\n\\nLikelihood of a being the answer to q on post pever P((s)i(2)(@)) 1((e} + (3)Gea\\ni)\\n\\nUtility of updating the post p with answer a, given post: question from set of question candidates Q: answer from set of answer candidates AIRyyD"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\n(2) Likelihood of a being the answer to q on post pever ((a)i(e)) => ? ((s)i(2).(@)) we) +\\n\\n(3) Gea\\ni) Utility of updating the post p with answer a; [e | : given post: question from set of question candidates O: answer from set of answer candidates A a&."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem\\n\\n© ever ((a) i (e)) => ? ((s) i (2).\\n(@)) we) + (3) Gea t@[e | : given post: question from set of question candidates O: answer from set of answer candidates A @ '- 81"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nEVPI formulation for our problem:\\n\\nGiven post: question from set of question candidates O: answer from set of answer candidates A."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nDataset of ten posts similar to given post."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nDataset of ten posts similar questions paired (post, question, answer) to given post p with those posts."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nAnswer Modeling EvPI\\n\\nP((a, || (p}, [a}) u((p}+{a]) CA"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nAnswer Modeling P((a)i(b).(@))i 60"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nAnswer Modeling P (Ls Ji (2), (a) Embaa\\n\\nA KRPost Question\\n\\nLSTM\\n\\nLSTM Word embedding module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nAnswer Modeling P((aJ1 [pe], ) = cosine_sim(Emb, ((p }, ); [a,))\\nA KRPost Question\\nLSTM\\nLSTM\\nWord embedding module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nAnswer Modeling P((aJ1 [pe], ) = cosine_sim(Emb,,,,((p}, ); [a,))3 a\\n3. Embans((P | , [ai | )\\n\\nTraining a K1\\n- xI |i Ii I:\\n\\nPost Question I I LSTM LSTM1 Ii I;\\n\\nWord embedding module l Ii I! ' fe) ly [J! | Cie|&."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nAnswer Modeling P ((aJ1 [pe], ) = cosine_sim(Emb,,,,((p }, ); [a,))\\n\\n3 =\\n3. Emb,n<((P | , [a | )\\n\\nTraining a K- x| ' Close to true a; I! paired with p| | a,: Ubuntu 14.04 LTS\\n\\nPost Question1\\n\\n4: Which version of LSTM Ubuntu do you have?\\n\\nWord embedding module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nAnswer Modeling\\n\\nP ({a, |1 [p], ) = cosine_sim(Emb, ((p }, ); [a,))\\n\\nTraining a K\\n- sI\\n\\nClose to true a I! paired with p\\n\\nClose to a, paired with q,\\n\\nPost Question 1\\n\\na: Which version of LSTM Ubuntu do you have?\\n\\nWord embedding module: a,\\n\\nUbuntu 11.10i\\n\\nWhat OS are you using?\\n\\na: 69IRyyD"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model (3) Utility Calculator u((J+(a))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nUtility Calculator Value between 0 and 1\\n\\nlearning: Feedforward\\nPost Question Answer\\nLSTM LSTM LSTM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\nUtility Calculator\\nValue between 0 and 1\\n\\nWhich version of Ubuntu do you have?\\nUbuntu 14.04 LTS\\n\\nPost Question Answer\\nLSTM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nUtility Calculator\\n\\nValue between 0 and 1\\n\\nWhich version of Ubuntu do you have?\\n\\nUbuntu 14.04 LTS\\n\\nWhat OS are you using?\\n\\nUbuntu 11.10\\n\\nWhat is the make of your wifi card?\\n\\nTP-Link TL-WDN4800"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nUtility Calculator\\n\\nValue between 0 and 1\\n\\nMinimize binary cross-entropy (Y Py): Feedforward\\n\\nLabeling\\n\\nWhich version of Ubuntu do you have?\\n\\nUbuntu 14.04 LTS\\n\\nWhat OS are you using?\\n\\nUbuntu 11.10\\n\\nWhat is the make of your wifi card?\\n\\nTP-Link TL-WDN4800"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model. Answer Utility Modeling\\n- Calculator"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nQuestion & Answer\\n\\nAnswer Utility\\n\\nCandidate Generator\\n\\nModeling Calculator\\n\\nTrain time behavior: For each (p, q,\\na) in our train set\\n1. Generate question candidates (Q) and answer candidates (A)\\n2. Train Answer Model and Utility Calculator using joint loss function: loss(Pp, q, a,\\nQ) + loss(y; p, q, a)dye"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nQuestion & Answer\\n\\nAnswer Utility\\n\\nCandidate Generator\\n\\nModeling Calculator\\n\\nTrain time behavior: For each (p, q,\\na) in our train set\\n1. Generate question candidates (Q) and answer candidates (A)\\n2. Train Answer Model and Utility Calculator using joint loss function: loss(Pp, q, a,\\nQ) + loss(y; p, q,\\na)\\n\\nTest time behavior: Given a post from our test set\\n1. Generate question candidates (Q) and answer candidates (A)\\n2. Calculate P(a; |p, q;) for each q ∈ Q using Answer Model\\n3. Calculate U(p + a,) for each a ∈ A using Utility Calculator\\n4. Rank questions by EVPI (q; |\\np) = > P(a; | p,\\nq) U(p +\\na) ∀ a ∈ A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Evaluation\\n\\nToo much disk read/write when launching an application\\n\\nI have Xubuntu 13.04 on an old Dell Inspiron.\\nWhen I launch an application it takes a pretty long time to be launched and I see a lot of disk read/write.\\nIf the system was short on memory, this would be understandable as the system would use swap.\\nBut that's not the case in my situation (i.e. I have this problem even when the RAM is almost empty).\\n1. How much RAM do you have installed? And what size is the swap disk partition?\\n2. If you do not have any problem with getting a little techy, then may I suggest a method?\\n3. How is it slow exactly? Boot time? HDD read/write? CPU time? Graphics rendering?\\n4. What is the longest time you have let it run?\\n5. This may be a silly question but ... did you make your USB stick bootable?\\n6. Do your system updates were recently applied?\\n7. Why not have two SSDs in RAID 1 for redundancy?\\n8. Is that a 'parted --list' on the Synology device?\\n9. Can you tell us a little about your configuration?\\n10. Did you turn hardware virtualization on in BIOS/EFI?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Evaluation set creation process\\n\\nWe recruited 10 Unix admin experts using UpWork. Given a post and the set of ten questions, candidates:\\n- Mark the one best question.\\n- Mark any other valid questions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Evaluation\\n\\nEvaluation set creation process\\n\\nWe recruited 10 Unix admin experts using UpWork.\\nGiven a post and the set of ten questions, candidates mark the one best question and mark any other valid questions.\\nWe annotated a total of 500 posts from our test set. Each post is annotated by two experts."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Evaluation set creation process\\n\\nWe recruit 10 Unix admin experts using UpWork. Given a post and the set of ten questions:\\n- \"Mark the one best question\"\\n- \"Mark any other valid questions\"\\n\\nWe annotate a total of 500 posts from our test set. Each post is annotated by two experts.\\n\\nUnion of Bests: Questions marked as best by either of the annotators.\\n\\nIntersection of Valids: Questions marked as valid by both annotators.\\n\\nUnion of Bests: {Q2, Q3}\\n\\nIntersection of Valids: {Q1, Q3, Q5}"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Evaluation Baseline Models\\n1. Random: Randomly permute the 10 candidate questions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Evaluation Baseline Models\\n1. Random: Randomly permute the 10 candidate questions\\n2. Bag-of-ngrams: Train linear classifier using bag-of-ngrams of p, q and a"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Evaluation Baseline Models\\n1. Random: Randomly permute the 10 candidate questions\\n2. Bag-of-ngrams: Train linear classifier using bag-of-ngrams of p, q, a and a\\n3. Community QA (Nakov et al., 2017):\\n- SemEval Task: Rank comments by relevance to post on Qatar Living\\n- Winning model: Logistic regression trained with string similarity & word embedding based features (Nandi et al.,\\n2017)\\n- Our baseline: We retrain this model on our dataset\\n4. Neural (p,\\nq) Value between\\n5. Neural (p, q,\\na)\\nBoth Neural (p, q,\\na) and EVPI (q | p,\\na) have similar number of parameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Evaluation RESULTS = Union of Best EVPI Neural (p, q,\\na) Neural (p,\\nq) Community QA Bag-of-ngrams Random 0 Precision @1\\n- 89"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Evaluation RESULTS = Union of Best EVP INeural (p, q,\\na) Neural (p,\\nq) Non-linear vs linear Community QA Bag-of-ngrams Random 0 5 10 15 20 25 30 35 40 Precision @1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Evaluation RESULTS TM Union of Best EVP INeural (p, q,\\na) Explicitly modeling Neural (p,\\nq) \"answer\" is useful Community QA Bag-of-ngrams Random 0 5 10 15 20 25 30 35 40 Precision @1 ce 92 Agyi Re"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Evaluation RESULTS = Union of Best EVPI Neural (p, q,\\na) Neural (p,\\nq) ~| Both use only (p,\\nq) Community QA\\n- Bag-of-ngrams Random 0 5 10 15 20 25 30 35 40 Precision @1' &\\n- 93\" AR AK"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Evaluation RESULTS TM\\n\\nUnion of Best\\n\\nEVPI Neural (p, q,\\na)\\n\\nNeural (p,\\nq)\\n\\nCommunity QA\\n\\nBag-of-ngrams\\n\\nRandom\\n\\n0  5  10  15  20  25  30  35  40\\n\\nPrecision @1\\n\\nNote: Difference between EVPI and all baselines is statistically significant with p < 0.05"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "Evaluation RESULTS = Union of Best EVPI | Mainly differ in their function Neural (p, q,\\na) | loss function Neural (p,\\nq) Community QA Bag-of-ngrams Random 0 5 10 15 20 25 30 35 40 Precision @1 so, Note: Difference between EVPI and all baselines is statistically significant with p < 0.05"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Evaluation RESULTS\\n\\n\"Intersection of Valids\"\\n\\n\"Union of Best\"\\n\\nEVPI\\n\\nNeural (p, q,\\na)\\n\\nNeural (p,\\nq)\\n\\nCommunity QA\\n\\nBag-of-ngrams\\n\\nRandom\\n\\n0 5 10 15 20 25 30 35 40\\n\\nPrecision @1\\n\\nST, Note: Difference between EVPI and all baselines is statistically significant with p < 0.05\\n\\n@ &\\n- *"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Evaluation RESULTS \"Intersection of Valids\" \"Union of Best EVPI\"\\nNeural (p, q, a(Pda) Not statistically significant\\nNeural (p,\\nq)\\nCommunity QA\\nBag-of-ngrams\\nRandom\\n0 5 10 15 20 25 30 35\\n\\nPrecision @3 &\\n- 97"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "o Clarification Questions Dataset\\n\\no Problem Formulation: Question Ranking\\n\\no Expected Value of Perfect Information (EVPI) inspired model\\n\\no Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "CONCLUSIONS\\n\\nKey Contributions:\\n- Create a dataset of ~77K clarification questions (and answers) with context.\\n- Introduce a novel model that integrates deep learning with the classic notion of expected value of perfect information.\\n- Create an evaluation set of size 500 with expert human annotations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "CONCLUSION\\n\\nKey Contributions\\n- Create a dataset of ~77K clarification questions (and answers) with context\\n- Introduce novel model that integrates deep learning with classic notion of expected value of perfect information\\n- Create an evaluation set of size 500 with expert human annotations\\n\\nKey Findings\\n- A context can have multiple good clarification questions\\n- Explicitly modeling the answer helps in identifying good questions\\n- EVPI formalism provides leverage over similarly expressive feedforward network"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "CONCLUSION\\n\\nKey Contributions\\n- Create a dataset of ~77K clarification questions (and answers) with context\\n- Introduce novel model that integrates deep learning with classic notion of expected value of perfect information\\n- Create an evaluation set of size 500 with expert human annotations\\n\\nKey findings\\n- A context can have multiple good clarification questions\\n- Explicitly modeling the answer helps in identifying good questions\\n- EVPI formalism provides leverage over similarly expressive feedforward networks\\n\\nFuture work\\n- Sequence-to-sequence based question generation model\\n- Multi-turn question generation\\n- How to automatically evaluate performance?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "Backup Slides"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "Evaluation RESULTS\\n\\nPrecision @3\\n\"Intersection of Valids\"\\n\"Union of Best\"\\n\\nEVPI\\nNeural (p, q,\\na)\\nNeural (p,\\na)\\nNeural (p,\\nq)\\nCommunity QA\\nBag-of-ngrams\\nRandom\\n\\n0 5 10 15 20 25 30 35\\n- 105"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "Evaluation RESULTS\\n\\nMean Average Precision\\n\\nIntersection of Valid's Union of Best\\n\\nEVPI\\n\\nNeural (p, q,\\na)\\nNeural (p,\\na)\\nNeural (p,\\nq)\\nCommunity QA\\nBag-of-ngrams\\n\\nRandom 0 10 20 30 40 50 60\\n- 106"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "Evaluation RESULTS\\n\\n\"True Question EVPI Neural (p, q,\\na) Neural (p,\\nq) Community QA Bag-of-ngrams Random\\n\\n0 5 10 15 20 25 30 35 40 Precision SET\\n\\nNote: Difference between EVPI and all baselines is statistically significant with p < 0.05"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 83,
        "texts": [
          "Evaluation RESULTS = Union of Best (with true removed) EVPI\\n\\n\"Neural (p, q,\\na) Not statistically significant\\n\\nNeural (p,\\na) significant\\n\\nNeural (p,\\nq)\\n\\nCommunity QA\\n\\nBag-of-ngrams\\n\\nRandom\\n\\n0 5 10 15 20 25 30\\n\\nPrecision @1 &\\n- 108\" Ry"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 84,
        "texts": [
          "SAMPLE OUTPUT\\n\\nToo much disk read/write when launching an application\\n\\nI have Xubuntu 13.04 on an old Dell Inspiron.\\nWhen I launch an application it takes a pretty long time to be launched and I see a lot of disk read/write.\\nIf the system was short on memory, this would be understandable as the system would use swap.\\nBut that's not the case in my situation (i.e. I have this problem even when the RAM is almost empty).\\n\\nEVPT value Ranking of Question Candidates\\n- 0.21 How much RAM do you have installed? and what size is the swap disk partition\\n- 0.18 Can you tell us a little about your configuration?\\n- 0.17 What is the longest time you have let it run?\\n- 0.11 How is it slow exactly? boot time? hdd read/write? cpu time?\\n- 0.00 If you do not have any problem with getting a little techy may I suggest a method?\\n- 0.00 This may be a silly question but... did you make your USB stick bootable?\\n- 0.00 Did your system recently update?\\n- 0.00 Why not have two SSDs in RAID 1 for redundancy?\\n- 0.00 Is that a 'parted --list' on the Synology device?\\n- 0.00 Did you turn hardware virtualization on in BIOS/EFI?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 85,
        "texts": [
          "SAMPLE OUTPUT\\n\\nNo wifi after restart in Ubuntu 16.04\\n\\nAfter upgrading to 16.04, there is no wifi whenever I restart the system.\\nMy wireless interface of Ubuntu is RT3290 Wireless 802.11n 1T/1R Pcie.\\n\\nOn iwconfig I got the following:\\n\\neth0 no wireless extensions...\\n\\nCurrently to start wifi again I have to shutdown, then boot the system again. How to fix the problem?\\n\\nEVPI value Ranking of Question Candidates\\n- @ Best@ Valid 0.24 © I doubt it, shutdown and reboot are exactly identical! Are you really rebooting?\\n- 0.13 © Be clear about the problem. Is Ubuntu not showing them even though they are present?\\n- 0.11 What is 4g wifi connection?\\n- 0.09 © Can you type 'iwconfig' in terminal and paste what it returns here?\\n- 0.09 What does this tell us?\\n- 0.08 If I post it as an answer, would you kindly mark as such?\\n- 0.06 Which Ubuntu 15?\\n- 0.06 What exactly do you mean by make fails?\\n- 0.05 © Welcome to Ask Ubuntu! ; -) Is the wireless LAN disabled in the BIOS?\\n- 0.00 O Is Ubuntu detecting your wireless card? **iwconfig** does list your card?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 86,
        "texts": [
          "Expected Value of Perfect Information (EVPI) inspired model\\n\\nLONG SHORT TERM MEMORY (LSTM)\\n\\nDi = -a > k = 0\\noutput layer\\n\\nhidden layer\\nword embeddings\\n\\nPost pi: How to configure ... advance\\n\\nSepp Hochreiter and Jurgen Schmidhuber.\\n1997. Long short-term memory. Neural Computation, 9(8): 1735-1780.\\n\\nJeffrey Pennington, Richard Socher, and Christopher D. Manning.\\n2014. \"GloVe: Global Vectors for Word Representation.\" In Empirical Methods on Natural Language Processing."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 191,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Semantic Role Labeling (SRL) is a shallow semantic parsing task: recognize the predicate-argument structure, such as who did what to whom, where and when, etc.\\n\\nFour subtasks:\\n- Predicate identification and disambiguation\\n- Argument identification and classification\\n\\nApplications:\\n- Machine Translation\\n- Information Extraction\\n- Question Answering, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "SRL\\n- Example Two formulizations of predicate-argument structure:\\n- Span-based (i.e., phrase or constituent)\\nMarry borrowed 2 books from John last week.\\n- Dependency-based: head of arguments\\nMarry borrowed 2 books from John last week."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Related Work\\n\\nPrevious methods\\n- Traditional Neural network\\n- Zhou and Xu (2015) introduced deep bi-\\n- Pradhan et al. (2005) utilized a SVM classifier.\\n- Roth and Yih (2005) employed CRF with\\n- Roth and Lapata (2016) proposed PathLSTM.\\n- Punyakanok et al. (2008) enforced global\\n- Teia et al. (2017) used deep highway BiCSTM with constrained decoding.\\n- Marcheggiani et al. (2017) presented a\\n- Zhao et al. (2009) proposed a huge feature.\\n- Marcheggiani and Titov (2017) proposed a GCN-based SRL model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Focus\\n- Dependency SRL\\n\\nnc\\n\\nor TMP syntactic ADV SBJ\\n\\nBJee Marry borrowed a book from John last week.\\n\\nborrow.01 ee AO A2 ae semantic\\n\\nSyntax-aware:\\n- Maximum entropy model (Zhao et al.,\\n2009)\\n- Path embedding (Roth and Lapata,\\n2016)\\n- Graph convolutional network (Marcheggiani and Titov,\\n2017)\\n\\nSyntax-agnostic:\\n- (The simple BiLSTM {Marcheggiani et al., 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Method\\n- Overview. (Softmax) Pipeline t_4, Predicate Disambiguation & Argument Labeling:\\n\\nHidden Layer: >\\n\\nSequence labeling: BILSTM\\n- MLP\\n\\nEnhanced representation: ELMo\\n\\nArgument Labeling Model\\n\\nRepresentation Preprocessing: k-order pruning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "k-order argument pruning\\n\\nInitialization: Set the marked predicate as the current node;\\n1.\\nCollect all its descendant nodes as argument candidates, which are at most k syntactically distant from the current node.\\n2. Reset the current node to its syntactic head and repeat step 1 until the root is reached.\\n3. Collect the root and stop.\\n\\nReference: Zhao et al., 2009\\n- 1st-order\\n- 2nd-order\\n- 3rd-order"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "syntax-aware = syntax-agnostic\\n\\nCoverage 88\\n\\nReduction ~ 60\\n\\nCoNLL-2009 English training set\\n\\nCoNLL-2009 English development set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "CoNLL-2009 Results Models\\n- English: 86.2\\n- Chinese: 77.7\\n- OOD: 74.6\\nZhao et al., 2009\\n- English: 85.8\\n- Chinese: 78.6\\n- OOD: 73.9\\nBjorkelund et al., 2010\\n- English: 86.6\\n- OOD: 75.6\\nNN: FitzGerald et al., 2015\\n- English: 86.7\\n- OOD: 75.2\\nRoth and Lapata, 2016\\n- English: 86.7\\n- Chinese: 79.4\\n- OOD: 75.3\\nsyntax-aware: Marcheggiani and Titov, 2017\\n- English: 88.0\\n- Chinese: 82.5\\n- OOD: 72\\nOurs: 89.5\\n- Chinese: 82.8\\n- OOD: 79.3\\nNN: Marcheggiani et al., 2017\\n- English: 87.7\\n- Chinese: 81.2\\n- OOD: 77.7\\nsyntax-agnostic: Ours\\n- English: 88.7\\n- Chinese: 81.8\\n- OOD: 78.8\\nResults on CoNLL-2009 English, Chinese and out-of-domain (OOD) test set."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "End-to-end SRLe Integrate predicate disambiguation and argument labeling\\n\\n02A2YO RSNA,\\n\\nSomeone makes you happy\\n\\nCoNLL-2009 results\\n\\nModels\\n- F1 end-to-end 88.4\\n- syntax-agnostic pipeline 88.7\\n- end-to-end 89.0\\n- syntax-aware pipeline 89.5\\n\\nResults of end-to-end model on the CoNLL-2009 data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "CoNLL-2008 Results\\n\\nIndispensable task: predicate identification\\n\\nModels                    LAS      Sem-F1\\nJohansson and Nugues, 2008     90.13   81.75\\nZhao and Kit, 2008           87.52   77.67\\nZhao et al, 2009             88.39   82.18\\nZhao et al, 2013             88.39   82.58\\nOurs (syntax-agnostic)\\n-       82.9\\nOurs (syntax-aware)          86.0    83.3\\n\\nResults on the CoNLL-2008 in-domain test set."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Syntactic Roles\\n\\nDifferent syntax-aware SRL models may adopt different syntactic parsers:\\n- PathLSTM SRL (Roth and Lapata,\\n2016)\\n- GCN-based SRL (Marcheggiani and Titov,\\n2017)\\n- BIST Parser\\n\\nHow to quantitatively evaluate the syntactic contribution to SRL?\\n\\nEvaluation Measure: the Sem-F / LAS ratio\\n- Sem-F: the labeled F score for semantic dependencies\\n- LAS: the labeled attachment score for syntactic dependencies\\n\\nReference: Surdeanu et al., CoNLL-2008 Shared Task"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Performance Comparison\\n\\nModels                   LAS        Sem-F1         Sem-F1/LAS\\n\\nZhao et al, 2009 [CoNLL SRL-only]        86.0      85.4            99.3\\nZhao et al, 2009 [CoNLL Joint]           89.2      86.2            96.6\\nBjorkelund et al, 2010                       89.8      85.8            95.6\\nLei et al, 2015                                  90.4      86.6            95.8\\nRoth and Lapata, 2016                      89.8      86.7            96.5\\nMarcheggiani and Titov, 2017            90.3      88.0            275\\nOurs + CoNLL-2009 predicted            86.0      89.5            104.0\\nOurs + Auto syntax                           90.0      89.9            99.9\\nOurs + Gold syntax                          100.0    90.3            90.3\\n\\nSem-F1/LAS ratio on CoNLL-2009 English test set."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Faulty Syntactic Tree Generator\\n\\nHow to obtain syntactic input of different quality?\\n\\nA Faulty Syntactic Tree Generator (STG) produces random errors in the output parse tree.\\n\\nSTG implementation:\\n\\nGiven an input error probability distribution, modify the syntactic heads of nodes."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Sem-F1\\n- LAS Curve92e\\n\\nSyntactic inputs generated from STG\\n\\n10th-order SRL\\n- GCN\\n\\nThe 10th-order SRL gives quite stable results regardless of syntactic quality.\\nThe 1st-order SRL model yields overall lower performance. Better syntax could result in better SRL.\\n\\n1st and 10th-order SRL on CoNLL-2009 English test set."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusion and Future Work\\n\\nWe present an effective model for dependency SRL with extended k-order pruning.\\nThe gap between syntax-enhanced and -agnostic SRL has been greatly reduced, from as high as 10% to only 1-2% performance loss.\\nHigh-quality syntactic parses indeed enhance SRL.\\n\\nFuture work:\\n- Develop a more effective syntax-agnostic SRL system.\\n- Explore syntactic integration method based on high-quality syntax."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Thank You!\\n\\n{heshexia, charlee}@sjtu.edu.cn\\n\\nCode is publicly available at: https://github.com/bcmi220/srl_syn_pruning"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 112,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n1. Introduction\\n2. Methodology\\n- Word embedding\\n- Framework\\n- Machine Translation\\n3. Experiments and Results\\n4. Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nNovelty.\\n1. Identify and paraphrase metaphors in whole sentences from unrestricted domains.\\n2. Using word embedding input and output vectors to model a word and its context—co-occurrence.\\n3. Metaphor processing for Machine Translation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n1. Introduction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nThe definition of metaphor.\\nLinguistically, metaphor is defined as a language expression that uses one or several words to represent another concept, rather than taking their literal meanings of the given words in the context (Lagerwerf and Meijers, 2008)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nMetaphors are widespread in natural language. One third of sentences in typical corpora contain metaphors.\\n\\naLiterals N (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova 2016)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "a UNIVERSITY OF ABERDEEN\\n\\nContexts help to find anomalies and identify metaphors.\\n\\nShe devoured his sandwiches.\\n\\nShe devoured his novels.\\n\\n\"I devoured\" means \"enjoyed avidly.\"\\n\\n--- devoured and \"enjoyed\" are different concepts literally.\\n\\n\"Devoured\" is metaphorical."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nMany previous metaphor processing methods are domain dependent.\\n\\nMany works simply use input vectors.\\n\\nMetaphor processing has rarely been applied to a real-world NLP task, instead mostly reporting accuracy on metaphor identification or interpretation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nContribution.\\n1. Metaphor detection and interpretation in sentences from unrestricted domains.\\n2. Investigate the effectiveness of input and output vectors of word embedding.\\n3. Apply metaphor detection and interpretation to improve Machine Translation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n1. Metaphor detection and interpretation in whole sentence from unrestricted domains.\\n\\nShe devoured his novels, i.e., enjoyed.\\n\\nInterpretation of metaphorical identification."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n1. Metaphor detection and interpretation in whole sentence from unrestricted domains.\\n\\nSentence level\\nPhrase level\\n\\nThis young man knows how to climb the social ladder.\\ni ladder\\nMetaphorical\\nLiteral"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n2. Investigate the effectiveness of input and output vectors of word embedding.\\n\\nOutput vector\\n\\nInput vector of enjoyed\\n\\nInput vector of novels"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n3. Apply metaphor detection and interpretation to improve Machine Translation.\\n\\nWithout metaphor processing\\n\\nWith metaphor processing\\n- Google Translate\\n- Chinese (Simplified)\\n- English\\n- Spanish\\n\\nShe devoured his novels.\\n\\nShe enjoyed his novels."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n2. Methodology"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nOne of the novelties of our work is to model co-occurrence between words with input and output vectors.\\n\\nCBOW word2vec\\n\\nInput  Hidden  Output (Mikolov et al,\\n2013)\\n- HsC,1 \" oe 1C SKS T. ontext words\\n- C, Te T arget words\\n- Cc, O; + pa Output vector\\n- Abandoned Input vector\\n- ON BOOM (e.g., gensim word2vec)\\n- fi § Sa (Rehurek and Sojka,\\n2010)\\n- Input vec\\n- Output vec\\n- on NEGATIVE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "a UNIVERSITY OF ABERDEEN\\n\\nThe interaction between input and output vectors represents the co-occurrence of words and contexts.\\n\\nTraining corpus\\n\\nInput vec\\nOutput vec\\n\\ndrink\\napple juice\\n\\ndrink\\norange juice\\n\\njuice,\\n\\n500 iterations on wevi\\n\\nhttps://ronxin.github.io/wevi/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nThe interaction between input and output vectors represents the co-occurrence of words and contexts.\\n\\nInput vec\\nOutput vec\\napple a § apple\\ninput vec\\ndrink close\\njuice\\norange\\ninput vec\\n- E"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nThe interaction between input and output vectors represents the co-occurrence of words and contexts.\\n\\nInput vec\\n\\nOutput vec\\n\\napple\\n\\ninput vec\\n\\njuice\\n\\norange drink\\n\\ninput vec"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nThe interaction between input and output vectors represents the co-occurrence of words and contexts.\\nInput vec Output vec apple input vec or los drink im | drink distant output vec juice orange drink input vec"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n- Input vectors can better model the similarity between words with similar semantics and syntax.\\n- Output vectors can better model the co-occurrence between words with different Part-of-Speech."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nThe co-occurrence between a target word and its context is measured by score = cos(v, v_i) cooccur\\n\\ncontext =\\n- V_on_m J_n=1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "1 UNIVERSITY OF ABERDEEN\\n\\nHypotheses.\\n\\nH1. Literal sense is more common than metaphorical.\\n\\nDetect the (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova,\\n2016) One third of sentences in typical corpora contain metaphors.\\n\\nH2.\\nA metaphorical word can be identified, if the sense the word takes within its context and its literal sense come from metaphorical eaters.\\n(Wilks, 1975, 1978)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "By UNIVERSITY OF Framework. Wiki Word Embedding\\n\\nContext words: Target word: Look up.\\nSynonyms: {s, S} || {Wet, Wea, We3} | {w}\\nWordNet | Hypernyms: {hy, hp}\\n\\nCandidate word set\\n- cos(w;, context)\\n- cos(s, context)\\n- argmax cos(S2, context)\\n- best fit word literal, if S > threshold\\n- S = cos(w*, w), metaphoric, otherwise"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "a UNIVERSITY OF ABERDEEN\\n\\nStep 1: training word embedding models on Wikipedia, so that we can model the common expressions.\\n\\nW1 O AO Wy Train W2 O SSS POSS, 70 We Wikipedia W3 Om 908 90 WG Word Embedding AK 1 KSw, O \"O w,\\n- Wikipedia's language could be more literal.\\n- We model the literal so that we can identify the anomalies in metaphor in next steps. (H1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nStep 2: look up WordNet to list all possible senses of a target word.\\n\\nContext words:\\nTarget word:\\nLookup\\nSynonyms: {s, S, ...}\\n{Wer Wea, Weg eed {w,}\\nWordNet\\nHypernyms: {hy, h, ..}\\n\\nCandidate word set W\\n- Separate context words and a target word.\\n- A candidate word set consists of hypernyms and synonyms of the target word, which represents all possible senses of the target word."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nStep 3: identify the most likely sense from the candidate set.\\n\\nCandidate word set W\\nContext words:\\nSynonyms: {s, S5 ...}\\nHypernyms: {h, h, ...}\\n\\nBest fit word*\\nCompute the most likely word appearing in the context.\\n- The best fit word is interpreted as the sense that metaphor takes. (H1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nStep 4: identify the metaphoricity of a target word.\\n' literal, if S > threshold\\nS = cos(w%, w,)\\nmetaphoric, otherwise\\n- A metaphor could be identified as the real sense and its literal sense come from different domains. (H2)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nAn example in Step\\n2.\\n\\nShe devoured his novels.\\n\\nContext words: {She, his, novels}\\n\\nTarget word: {devoured}\\n\\nCandidate word set: { SS{devour, devoured, devours, devouring}\\n\\nWordNet Sense 1: {destroy, ruin, ...}\\n\\nSense 2: {enjoy, bask, ...}\\n\\n(Fellbaum,\\n1998) | Sense 3: {demolish, down, ..., eat up, finish}\\n\\nHYPERNYMS\\n\\nSYNONYMS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nAn example in Step\\n3.\\n\\nml _ 1 it 1 i L l\\n\\nVeontext = m Von = 3 (Use + Unis + Vnoveis) n = 1\\n\\nCOS(Vgevoured: Uroncaxt) = -0.01\\n\\ncos(Vgestroyed Veontext) = -0.04\\n\\narg Max [ _8 cos(VPxinea Veontext) = -0.01\\n\\nCOS(Vén joyear Veontext) = 0.02\\n\\nBest fit word = enjoyed"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nAn example in Step 4.s vi: {ent if S > threshold = COS(Van inv, Venjoy?\\n\"devour metaphoric, otherwise Best fit word Target word § = -0.04 < threshold = 0.6 Metaphoric"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "39 ABERDEEN\\n(1) SIM-CBOW, = cos(Vi, chow) Veontext, cbow\\n(2) SIM-CBOW, 49 = cos(VR, chow) Veontext, chow\\n(3) SIM-SG, = cos(Vi, sq) Veontext, sg\\n(4) SIM-SG; 49 = COS(UE oo Peonteat.ca)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nExamine on Machine Translation (before paraphrasing).\\n\\nGoogle # 0 @Translate Tum off instant translation | @ | Chinese English Spanish English-detected ~ Chinese (Simplified) English Spanish ~ } translate |\\n\\nShe devoured his novels.\\n- She (physically) swallowed his novels.\\n- She voraciously wrote novels."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "By UNIVERSITY OF ABERDEEN Examine on Machine Translation (after paraphrasing).\\nGoogle x 0 @Translate Turn off instant translation Chinese English Spanish English\\n- detected ~ 5 [Chinese (Simplified) English Spanish ~ Ea. . She enjoyed his novels. * SRA) * She enjoyed his novels. ®\\n- 2300 KOM < 7 | HE Microsoft b p | She enjoyed his novels. PES RA) ibe p * She enjoyed his novels."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "si 1 UNIVERSITY OF ABERDEEN\\n3. Experiments and Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nExperiment setup.\\n\\nMetaphor identification:\\n- Sentence level: inputs are original sentences\\n- Phrase level: inputs are parsed phrases\\n\\nMetaphor interpretation:\\n- Machine Translation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nDataset and baselines.\\n\\nPhrase evaluation baselines:\\n\\nMammae et al. (2016)\\n- Shutova et al. (2016) used Skip-gram input vectors to model the similarity between two component words.\\n- 1,230 literals\\n- Rei et al.\\n(2017) used sigmoid function, projecting Skip-gram input vectors into another space, then training a deep neural network based classifier.\\n\\nSentence evaluation baseline:\\n- 212 meta.\\n- 316 meta.\\n- 212 lite.\\n\\nMelamud et al. (2016) used LSTM trained context embeddings to predict the center word. Mao et al. (2018) Shutova et al.\\n(2016), Rei et al. (2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nMethod P R FlShutova et al. (2016) 0.67 0.76 0.71\\nRei et al. (2017) 0.74 0.76 0.74\\nSIM-CBOW/+0 0.66 0.78 0.72\\nSIM-SG/+0 0.68 0.82 0.74\\n*Melamud et al. (2016) 0.60 0.80 0.69\\nSIM-SG; 0.56 0.95 0.70\\nSent. SIM-SG/+0 0.62 0.89 0.73\\nSIM-CBOW, 0.59 0.91 0.72\\nSIM-CBOW/+0 0.66 0.88 0.75\\n\\n*Table 1: Metaphor identification results.\\nNB: * denotes that our model outperforms the baseline significantly, based on two-tailed paired t-test with p < 0.001."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nEvaluation with different thresholds.\\n\\nP R F1\\n0.4 | 0.69 0.75 0.72 0.65 0.63\\n0.5 | 0.67 0.82 0.74 0.71 0.72\\n0.6 | 0.66 0.88 0.75 0.72 0.74\\n0.7 | 0.64 0.88 0.74 0.72 0.73\\n0.8 | 0.63 0.89 0.74 0.72 0.73\\n0.9 | 0.63 0.89 0.74 0.71 0.73\\n1.0 | 0.65 0.65\\n\\nTable 2: Model performance vs. different threshold settings.\\nNB: the sentence level results are based on SIM-CBOW/0."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "By UNIVERSITY OF ABERDEEN\\n\\nExperiment design for Machine Translation evaluation.\\n\\nSample Questionnaire\\n\\nThe ex-boxer's job is to bounce people who want to enter this private club.\\nbounce: eject from the premises Good / Bad\\n1. Google translation on the original sentence.\\n2. Bing Translation on the original sentence.\\n3. Google translation on our model paraphrased sentence.\\n4. Bing Translation on our model paraphrased sentence.\\n5. Google translation on Context2Vec paraphrased sentence.\\n6. Bing Translation on Context2Vec paraphrased sentence."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "ws UNIVERSITY OF ABERDEEN\\n\\nMetaphor interpretation results.\\n\\nOriginal sentence\\nParaphrased by our model\\nParaphrased by the baseline (Melamud et al.\\n2016)\\n\\n0.85 0.7\\n0.6 6 of\\n- 8\\nA + 0.11\\nX + 0.24 = 0.5\\nA x 8 + 0.26\\nZ 04 x = 0.3\\n\\nLiteral\\nMetaphoric\\nOverall\\nLiteral\\nMetaphoric\\nOverall\\nGoogle\\nBing"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n4. Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nAnovel model for metaphor identification and interpretation on sentence level.\\n\\nA metaphor could be identified by its interpretation.\\n\\nInput and output vectors could better model the co-occurrence between two words.\\n\\nEffective paraphrasing of metaphors could improve Machine Translation."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "UNIVERSITY OF ABERDEEN\\n\\nChristiane Fellbaum.\\n1998. WordNet: An Electronic Lexical Database. Bradford Books.\\n\\nEkaterina Shutova, Douwe Kiela, and Jean Maillard.\\n2016. Black holes and white rabbits: Metaphor identification with visual features.\\nProceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT\\n2016) pages 160-170.\\n\\nIlana Heintz, Ryan Gabbard, Mahesh Srinivasan, David Barner, Donald S Black, Marjorie Freedman, and Ralph Weischedel.\\n2013. Automatic extraction of linguistic metaphor with LDA topic modelling.\\nIn Proceedings of the First Workshop on Metaphor in NLP (ACL 2013). pages 58-66.\\n\\nLuuk Lagerwerf and Anoe Meijers.\\n2008. Openness in metaphorical and straightforward advertisements: Appreciation effects.\\nJournal of Advertising 37(2): 19-30.\\n\\nMarek Rei, Luana Bulat, Douwe Kiela, and Ekaterina Shutova.\\n2017. Grasping the finer point: A supervised similarity network for metaphor detection.\\nProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP\\n2017) pages 1537-1546.\\n\\nMeshberger, F. L. (1990). An interpretation of Michelangelo's Creation of Adam based on neuroanatomy.\\nJaMa, 264(14), 1837-1841.\\n\\nOren Melamud, Jacob Goldberger, and Ido Dagan.\\n2016. context2vec: Learning generic context embedding with bidirectional LSTM.\\nIn Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL 2016). pages 51-61.\\n\\nSaif M Mohammad, Ekaterina Shutova, and Peter D Turney.\\n2016. Metaphor as a medium for emotion: An empirical study.\\nProceedings of the Joint Conference on Lexical and Computational Semantics (\"SEM\\n2016) page\\n23.\\n\\nShutova, E. (2015). Design and evaluation of metaphor processing systems. Computational Linguistics, 41(4), 579-623.\\n\\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.\\n2013. Efficient estimation of word representations in vector space.\\nProceedings of International Conference on Learning Representations (ICLR 2013).\\n\\nTomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Samira Shaikh, Ting Liu, Boris Yamrom, Kit Cho, Umit Boz, Ignacio Cases, et al.\\n2013. Robust extraction of metaphor from novel data. In Proceedings of the First Workshop on Metaphor in NLP (ACL 2013).\\npages 67-76.\\n\\nWilks, Y. (1978). 'Making preferences more active', Artificial Intelligence 11(3), 197-223.\\n\\nYulia Tsvetkov, Leonid Boytsov, Anatole Gershman, Eric Nyberg, and Chris Dyer.\\n2014. Metaphor detection with cross-lingual model transfer.\\nProceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL\\n2014) pages 248-258."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Rui Mao\\nDepartment of Computing Science, University of Aberdeen, UK\\nrO3rm16@abdn.ac.uk\\n\\nThis work is supported by the award made by the UK Engineering and Physical Sciences Research Council (Grant number: EP/P005810/1)."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 322,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction\\nMotivation\\nContent\\nAven\\nSaad\\nSummary"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "= Introduction\\n- Event Detection\\n- subtask of event extraction: given a document, extract event triggers from individual sentences and further identifies the (pre-defined) type of events.\\n- Event Trigger\\n- words in sentences that most clearly express the occurrence of events. They have been married for three years.\\n- Event Trigger is \"married\", which represents a marry event."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Motivation FA... | Knew it was time to leave.\\n\\nTransport event\\n- End-Position event.\\n\\nKnew it was time to leave. Is not that a great argument for term limits?\\n\\nMela ace. More confident for classifying."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "= Motivation\\n\\nSome shortcomings of existing works:\\n- Manually designed document-level features (Ji and Grishman, ACL, 2008; Liao and Grishman, ACL, 2010; Huang and Riloff, AAAI, 2012).\\n- Learning document embedding without supervision cannot specifically capture event-related information (Duan et al., ICNLP, 2017)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "= DEEB-RNN: The Proposed Model\\n\\nEvent Trigger Type:\\n- Encoder: B-GRUe1\\n- B-GRUerlattention\\n- Document: embedding\\n- Entity type: embedding\\n- Document-level Enhanced Embedding Learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "=\\n- 7 -= Model\\n- ED Oriented Document Embedding Learning\\n- Word encoder\\n- Bi-GRUs\\n- Word attention\\n- Bi-GRU\\n- Document embedding\\n- Entity type representation\\n\\nED Oriented Document Embeddings Learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Model\\n- ED Oriented Document Embedding Learning\\n\\nGold word-level attention signal: Joy Fenter was by the grand Jury.\\n\"Indicated\" is an event trigger and is set as 1, other words are set as\\n0.\\n\\nLoss function: The square error is the general loss of the attention at word level to supervise the learning process."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Model\\n- ED Oriented Document Embedding Learning\\n'sentence Bi + X Bi\\n- X BL -> XeuarGinu > Sentence encoder qi qi qL; ae Bi\\n- GRUs i |» -+-[ Bi\\n- GRUs i |-+-->[ Bi\\n- GRUs 1 q; = ose GRU, (s;,) encoder.\\nSi(6e -- Sil@@) -- SLIGO ia eee Vaal ame Lak aleceyaji XX Ait > Gir XX word | _ attention | hit hit | t = tanh(W, q 2»| || [Bi\\n- GRUw: |» -+-[ Bi\\n- GRUwt |-++-> [Bi\\n- GRUwr I document yey = males word wes gir git gir ves embedding 4 pos encoder | | word A| _ .\\n, embedding > Document representation | | ate ty1 eal el Eating L| Wil Wit Wit l Pe > PED Oriented Document Embeddings Learning ye li = l3)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "= Model\\n- ED Oriented Document Embedding Learning\\n\\nGold sentence-level attention signal:\\n- $1, S3 and SL are sentences with event triggers and is set as 1, other sentences are set as\\n0.\\n\\nLoss function:\\n- The square error is the general loss of the attention at sentence level to supervise the learning process."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "= Model\\n- Document-level Enhanced Event Detector\\n\\nEvent Trigger Type: Sf, = Bi-GRU, ([d, w])y, softmax output layer to get the predicted probability for each word\\n\\ndocument LT Kembedding (k) word J(y,0) a\\nk) log aTembedding TM TM j=1 t=1 k=1\\n\\nEntity\\n\\ncross-entropy error\\n\\nDocument-level Enhanced Event Detector for Sj10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Model\\n- Joint Training\\n\\nJoint Loss Function: J(O) = D(I(y, 0), HE, (a\", @) + HE, (B\", B))\\n\\n@ denotes all parameters used in DEEB-RNN\\n- is the training document set\\n\\nA and u are hyper-parameters for striking a balance im"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "= Experiments\\n\\nEnglish words files\\n\\nACE 2005\\n\\n1P DUAL ADJ NORM\\n\\n33 categories\\n\\n57807 33459 48309 128 124 a1 106 BN 59239 58144 52444 55067 239 234 217 226 ae BC 46612 46110 33874 40415\\n\\n599 documents we 45210 43648 35529 37807 127 122 114 119\\n\\n5349 labeled events\\n\\nUN 45161 44473 26371 37366 58 57 37 49 cTS 47003 47003 34868 30845\\n\\nTotal 303833 297185 216545 250880 666 650 535 1 599"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "= Experiments\\n- Configuration\\n\\nPartitions #Documents\\n\\nTraining set 2042\\n\\nValidation set 30\\n\\nParameters Setting\\n\\nGRU, GRU, GRU, 300, 200, 300, 600, 400\\n\\nentity type embeddings 50 (randomly initialized)\\n\\nword embeddings 300 (Google pre-trained)\\n\\ndropout rate 0.5\\n\\ntraining SGD"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "= Experiments\\n- Model analysis\\n\\nModel Variants:\\n- DEEB-RNN computes attentions without supervision\\n- DEEB-RNN1 uses only the gold word-level attention signal\\n- DEEB-RNN2 uses only the gold sentence-level attention signal\\n- DEEB-RNN3 employs the gold attention signals at both word and sentence levels\\n- BiGRU |\\n- |\\n- | 662 | 723 | 69.1\\n- DEEB-RNN | 0 | 0 | 693 | 752 | 721\\n- DEEB-RNN1 | 1 | 0 | 70.9 | 76.7 | 73.7\\n- DEEB-RNN2 | 0 | 1 | 72.3 | 74.5 | 73.4\\n\\nModels with document embeddings outperform the pure Bi-GRU method.\\n\\nThe model with both gold attention signals at word and sentence levels performs best."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "= Experiments\\n- Baselines\\n- Feature-based methods without document-level information:\\n- Sentence-level (2011)\\n- Joint Local (2013)\\n- Representation-based methods without document-level information:\\n- JRNN (2016)\\n- Skip-CNN (2016)\\n- ANN-S2 (2017)\\n- Feature-based methods using document-level information:\\n- Cross-event (2010)\\n- PSL (2016)\\n- Representation-based methods using document-level information:\\n- DLRNN (2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "4 el-1a lpn 10s ACI Alene\\n\\nFeature-based Sentence-level (2011) | 67.6 | 53.5 | 59.7\\n\\nwithout Document-level\\n\\nTraditional, JRNN (2016) | 66.0 | 73.0 | 69.3\\n\\nEvent Detection\\n\\nRepresentation-based Skip-CNN (2016) | N/A | N/A | 71.3\\n\\nModels without Document-level\\n\\nANN-S2 (2017) | 78.0 | 66.3 | 71.7\\n\\nCross-event (2010) | 68.7 | 68.9 | 68.8\\n\\nDLRNN (2017) | 77.2 | 64.9 | 70.5\\n\\nDEEB-RNN1 | 70.9 | 76.7 | 73.7\\n\\nDEEB-RNN? | 72.3 | 74.5 | 73.4\\n\\nMtoe TST 1 DEEB-RNN3+ | 72.3 | 75.8 | 74.0\\n\\nOur models consistently out-perform the existing state-of-the-art methods in terms of both recall and F1-measure."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "= Summary\\n\\nConclusions\\n- We proposed a hierarchical and supervised attention based and document embedding enhanced Bi-RNN method.\\n- We explored different strategies to construct gold word- and sentence-level attentions to focus on event information.\\n- We also showed this method achieves best performance in terms of both recall and F1-measure.\\n- Automatically determine the weights of sentence and document embeddings.\\n- Use the architecture for another text task."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Thank you for your attention!\\n\\nQ&A\\n\\nName: Yue Zhaon\\nMMer Age: Ton0(-1 Coan) (eM [am-lenarn"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 183,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n\\nIntroduction\\n\\nRelated Work\\n\\nProblem Statement\\n\\nRvNN-based Rumor Detection\\n\\nEvaluation\\n\\nConclusion and Future Work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Introduction\\n\\nWhat are rumors?\\n\\nMark Zuckerberg Is Giving Away Money!\\n\\nAnti-Trump protestors are not as organic as they seem. Here are the reasons they thank you message came in.\\n\\n#fakeprotests #trump2016 #austin\\n\\nCLAIM: Mark Zuckerberg is giving $4.5 million to 100 Facebook users who share a specific message.\\n\\n[FAKE NEWS] A story or statement whose truth value is unverified or deliberately false."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction: How the fake news propagated? morpe @morpc\\n- 30 Dec 2015 v. \"pemore ODOT riffs on a slew of Facebook posts about Mark Zuckerberg giving away money to users.\\ns.cleveland.com/6IQISAR\\n- sfey 2 is known as false. (Zubiaga et al., 2016b)\\n\\nPrevious studies focused on text mining KP Kelly i= @KP_Kelly «30 Dec 2015 v ' 3@ lol RT @adhutchinson: No, Mark Zuckerberg is not giving away $45m to random Facebook users ow/.!y/WpvXm.\\n\\nLY Sohail Ahmed @lamAhmedSohail\\n- 29 Dec\\n2015. Sorry, #MarkZuckerberg is not giving $4.5 billion to 1,000 random #Facebook users.\\n#Tech #News #Donate pic.twitter.com ae EFrictucker lowers VNAWEnlyRq\\n\\nAnti-Trump protestors in Austin today are not as organic as they seem. Here Gateway Pundit > 44k shares.\\n\\nFigures. Anti-Trump protests in Austin #FakeProtests.\\n\\nRedman @gingermeister21\\n- 27 Dec 2015 v. You're high if you think Mark Zuckerberg is going to donate $45 million to Facebook users.\\nStop being naive & looking for handouts.\\n\\nBREAKING: They found the buses! Just had a very open and successful lineup from the Austin protests.\\nThe media are protesting, very newt.\\n\\n#VisitNepal @nepalbot\\n- 22 Dec 2015 v. Free Republic $307k shares.\\n\\nDozen: Is Mark Zuckerberg donating so many $$ for Facebook users?\\n\\nI did not see loading or unloading than in pics, quite near protests.\\n\\nJoshua Mission Team Nepal @JonahYonjan\\n- 22 Dec 2015 v. Time @----2 0 eo -_$§$ oosig Mark Zuckerberg donate so many $$ for Facebook users!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Motivation = \"We generally are not good at distinguishing rumors.\\nIt is crucial to track and debunk rumors early to minimize their harmful effects.\\n- Online fact-checking services have limited topical coverage and long delay.\\n- Existing models use feature engineering\\n- oversimplistic; or recently deep neural networks\\n- ignore propagation structures.\\n- Kernel-based method\\n- develop based on tree structure but cannot learn high-level feature representations automatically.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Observation & Hypothesis = Existing works: Consider post representation or propagation structure\\n\\n1:5h Support @ 10h eV, Osh 4\\n\\nDoubt\\n- RNN-based model\\n- Tree kernel-based model (Ma et al. 2016, Ma et al.\\n2017)\\n\\nIDEA: Combining the two models, leveraging propagation structure by representation learning algorithm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Observation & Hypothesis\\n\\nWhy such model do better?\\n- Polarity stances\\n(a) False rumor\\n(b) True rumor\\n\\nLocal characteristic: A reply usually responds to its immediate ancestor rather than the root tweet.\\nRepliers tend to disagree with (or question) who support a false rumor or deny a true rumor; repliers tend to agree with who deny a false rumor or support a true rumor."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Contributions: The first study that deeply integrates both structure and content semantics based on tree-structured recursive neural networks for detecting rumors from microblog posts.\\n\\nProposes two variants of RVNN models based on bottom-up and top-down tree structures to generate better integrated representations for a claim by capturing both structural and textural properties signaling rumors.\\n\\nOur experiments based on two real-world Twitter datasets achieve superior improvements over state-of-the-art baselines on both rumor classification and early detection tasks.\\n\\nWe make the source codes in our experiments publicly accessible at https://github.com/majingCUHK/Rumor_RvNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Related Work\\n- Systems based on common sense and investigative journalism, e.g., snopes.com, factcheck.org\\n- Learning-based models for rumor detection\\n- Information credibility: Castillo et al. (2011), Yang et al. (2012)\\n- Using handcrafted and temporal features: Liu et al. (2015), Ma et al. (2015), Kwon et al. (2013,\\n2017)\\n- Using cue terms: Zhao et al. (2015)\\n- Using recurrent neural networks: Ma et al. (2016,\\n2018)\\n- Tree-kernel-based model: crafted features, Ma et al. (2017), Wu et al. (2015)\\n- RVNN-based works\\n- Images segmentation (Socher et al,\\n2011)\\n- Phrase representation from word vectors (Socher et al,\\n2012)\\n- Sentiment analysis (Socher et al,\\n2013)\\n- etc"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Problem Statement: Given a set of microblog posts R = {r}, model each source tweet as a tree structure T(r) = <V, E>, where each node v provides the text content of each post.\\nAnd F is directed edges corresponding to response relation.\\n- Task 1: finer-grained classification for each source post: false rumor, true rumor, non-rumor, unverified rumor\\n- Task 2: detect rumor as early as possible"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Tweet Structure\\n\\n1: #Walmart donates $10,000 to #DarrenWilson\\nWalmart donates $10,000 to support Darren Wilson and the ongoing racist bottom-up tree fund to continue police racial profiling...\\npolice murders #Ferguson #BoycottWalmart\\n\\n4: \"I have a feeling this is just hearsay...\"\\n\\n2: \"I don't think I am hearing this all day but Walmart would let everyone know this if they did!!\"\\n\\nAnnie Mae @000\\n- 19 Oct 2014\\n\\n1: #Walmart donates $10,000 to #DarrenWilson\\ntop-down tree fund to continue police racial profiling...\\n\\n5: \"I think they support protecting their store from…\"\\n\\n1:30 \"Idc if they killed x3: NEED SOURCE.\"\\nMelanie @19 Oct 2014\\n\"foreal. Ima always have a feeling this is just hearsay...\"\\n\\nAnnie Mae @anniemae1000\\n- 19 Oct 2014\\n\"Exactly, I don't think I am hearing this all day but Walmart would let everyone know this if they did!!\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Standard Recursive Neural Networks (RNNs) utilize sentence parse trees: the representation associated with each node of a parse tree is computed from its direct children, computed by\\n\\np = f(W * [c1; c2] +\\nb) = p: the feature vector of a parent node whose children are c1 and c2.\\nThe computation is done recursively over all tree nodes."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Bottom-up RvNN\\nInput: bottom-up tree (node: a post represented as a vector of words)\\nGRU equation at node j;\\n\\ntj = UE\\nStructure: recursively visit every node from the leaves at the bottom;\\nChildren nodeto the root at the top (a natural extension to the original RvNN)\\n\\nOwn input\\nIntuition: local rumor indicative features are aggregated along\\nrj = a (W, #; + U-hs) different branches (e.g., subtrees having a denial parent and a set of supportive children)\\n(generate a feature vector for each subtree)\\n\\nhj = tanh (WZ; + Up(hs ©1;))\\nhj = (1-2) Ohs + 2; Oh;x\\n\\n# Walmart donates $10,000 to #DarrenWilson\\nSoftmax fund to continue police racial profiling...\\n\\n1:30 Ide if they killed\\nNEED SOURCE. a mf foreal. Ima always have a feeling this shop with @Walmart. I'm just bein honest\\n\\n0:00 Lagree. I have been\\nExactly, I don't think\\nhearing this all day but Wal-Mart would let everyone know this if they did!!\\n\\n16 Jing Ma (CUHK) 2018/7/15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "SKeyemrelen. sem ean nny>\\n\\nInput: top-down tree\\n\\nGRU transition equation at node j.\\n\\nOwn input Parent node>\\n\\nStructure: recursively visit from the root node to its children until reaching all leaf nodes. (reverse Bottom-up RvNN)\\n\\nrj = (W,#; + U,hp(yy))\\n\\nIntuition: rumor-indicative features are aggregated along the propagation path (e.g., if a post agree with its parent's stance, the parent's stance should be reinforced) (models how information flows from source post to the current node)\\n\\nhy = tanh (Wp&; + Un(hprj))\\n\\nhj = (1-2;)® hp) + 2 © h j\\n\\nrx: #Walmart donates $10,000 to #DarrenWilsonfund to continue police racial profiling...\\n\\n(OO\\nO)\\n\\na Ry |OOOX2: 1:30\\n\\nIde if they killed\\n\\nx3: NEED SOURCE.\\n\\nx OOQ\\n\\nx.a mf foreal. Ima always have a feeling this is just hearsay ...\\n\\nfact ee gene\\n\\n©6D COOx4: Lagree. I have been\\n\\nxs: Exactly, I don't think\\n\\nPooling:\\n\\nhearing this all day but Wal-Mart would let everyone know this if they did!!\\n\\nSoftmaxF\\n\\nAlyyJing Ma (CUHK) 2018/7/15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Model Training\\n\\nComparison: both of the two RVNN models aim to capture the structural properties by recursively visiting all nodes.\\n\\nBottom-up RvNN: the state of root node (i.e., source tweet) can be regarded as the representation of the whole tree (can be used for supervised classification).\\n\\nTop-down RvNN: the representation of each path is eventually embedded into the hidden vector of all the leaf nodes.\\n\\nlearned vector of root node\\n\\nOutput Layer\\n\\nBottom-up RvNN: y = Softmax(Vhy +\\nb)\\n\\nTop-down RvNN: y = Softmax(Vh +\\nb)\\n\\nthe pooling vector over all leaf nodes\\n\\nObjective Function: L = YN_, 14 (ve\\n- Je)? + AllOll3 prediction Ground truth\\n\\nTraining Procedure\\n\\nparameters are updated using efficient back-propagation through structure (Goller and Kuchler, 1996; Socher et al., 2013)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Data Collection = Use two reference Tree datasets:\\n- Statistic\\n- Twitter15\\n- # of users: 276,663\\n- # of source tweets: 1,490\\n- # of threads: 331,612\\n- # of non-rumors: 374\\n- # of false rumors: 370\\n- # of true rumors: 372\\n- # of unverified rumors: 374\\n- Avg. time length / tree: 1,337 Hours\\n- Avg. # of posts / tree: 223\\n- Max # of posts / tree: 1,768\\n- Min # of posts / tree: 55\\n- Twitter16\\n- # of users: 173,487\\n- # of source tweets: 818\\n- # of threads: 204,820\\n- # of non-rumors: 205\\n- # of false rumors: 205\\n- # of true rumors: 205\\n- # of unverified rumors: 203\\n- Avg. time length / tree: 848 Hours\\n- Avg. # of posts / tree: 201\\n- Max # of posts / tree: 2,705\\n- Min # of posts / tree: 81\\n\\nURL of the datasets: https://www.dropbox.com/s/Ojhsfwep3ywvpca/rumdetect2017.zip?dl=0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Approaches to compare with:\\n- DTR: Decision tree-based ranking model using enquiry phrases to identify trending rumors (Zhao et al., 2015).\\n- DTC: Twitter information credibility model using Decision Tree Classifier (Castillo et al., 2011).\\n- RFC: Random Forest Classifier using three parameters to fit the temporal tweets volume curve (Kwon et al., 2013).\\n- SVM-TS: Linear SVM classifier using time-series structures to model the variation of social context features (Ma et al., 2015).\\n- SVM-BOW: Linear SVM classifier using bag-of-words.\\n- SVM-TK and SVM-HK: SVM classifier uses a Tree Kernel (oo et al.,\\n2017) and that uses a Hybrid Kernel (Wu et al., 2015), both model propagation structures with kernels.\\n- RNN-based rumor detection model (Ma et al.).\\n- Ours (BU-RVNN and TD-RvNN): Our bottom-up and top-down recursive models."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Results on Twitter\\n\\n15 NR: Non-Rumor;\\nFR: False Rumor;\\nTR: True Rumor;\\nUR: Unverified Rumor;\\n\\nhand-crafted features (e.g., 0.454 0.733 0.355 0.317 0.415 vs others)\\n0.565 0.810 0.422 0.401 0.543\\n0.544 0.796 0.472 0.404 0.483\\n0.548 0.564 0.524 0.582 0.512\\n0.493 0.650 0.439 0.342 0.336\\n\\n5 clint\\n0.667 0.619 0.669 0.772 0.645\\nFi scroller\\n0.641 0.684 0.634 0.688 0.571\\n\\nP\\n0.708 0.695 0.728 0.759 0.653\\n\\nMore info loss\\n0.723 0.682.\\n- 0.758 0.821 0.654"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Results on Twitter\\n\\n16NR: Non-Rumor;\\nFR: False Rumor;\\nTR: True Rumor;\\nUR: Unverified Rumor;\\n\\n0.414 0.394 0.273 0.630 0.344\\n0.465 0.643\\n- 0.393 0.419 0.403\\n0.585 0.752 0.415 0.547 0.563\\n0.574 0.755 0.420 0.571 0.526\\n- 0.585 0.553 0.556\\n0.655 0.0578\\n| OEM TOu\\n0.511 0.648 0.434 0.473 0.451\\n= \"a\\n0.662 0.643\\n- 0.623 0.783 0.655\\n0.633\\n0.617\\n0.715 0.577 0.527\\n0.718 0.723\\n- 0.712 0.779 0.659\\n0.737 0.662\\n- 0.743 0.835 0.708"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "7S: eee == «QI the first few hours, the accuracy of the RvNN-wt FOO\\n- Py based methods climbs more rapidly and stabilizes more quickly.\\nIt becomes challenging to compare the performance of TD-RvNN and BU-RVNN.\\n- SVM-TKK\\n- DTR 0987\\n- TD-RVNN\\n- SVM-TK\\n\\nDIR RvNN only needs around Elapsed time (hours) to achieve comparable performance of the best baselines:\\n- BU-RVNN\\n- GRU-RNN\\n- RFC\\n\\nElapsed time (hours)\\n- TM Tweets count\\n\\n(b) Twitter16 DATASET: pyTC UEReuleLs aes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Example subtree of a rumor captured by the algorithm at early stage of propagation\\n\\nSupport.\\n\\nuser2:user 1: @user1 Thank you! Good to know. I undid that rt. @user0 This is a \"satirical\" website\\n\\nuser4: aserti Deny Support\\n\\n@user1 Exactly! Charleston Church Shooter / Support\\n\\nuser2: 0 Amerikkka RT: Deny\\n\\nuser5: Support\\n\\nuser6: Dylann Roof Receives ave aire mses\\n\\n@user2 Fake website, fake story\\n\\n@user5 Shit you might be right $4 Million in Donations\\n\\nYlann TOOL RECEIVES.\\n\\n-- user7: etait Supporicis {guescicat Support /\\n\\n@user3 Pretty sure it is fake, page just posts music links and news headlines\\n\\nuser a firm if Support\\n\\nuser8: Support\\n\\nuser10: ee ag lace ou\\n\\n@user3 Yeah it is all satire news\\n\\n@user8 That makes me happy.\\n\\nSupport\\n\\nuser9: @user3 Its a fake site. They got articles like this http://... and this http://...\\n\\nBottom-up RvNN: a set of responses supporting the parent posts that deny or question the source post.\\n\\nTop-down RvNN: some patterns of propagation from the root to leaf nodes like \"support-deny-support\"\\n\\nBaselines: sequential models may be confused because the supportive key terms such as \"be right\", \"yeah\", \"exactly!\" dominate the responses, and the SVM-TK may miss similar subtrees by just comparing the surface words.\\n\\nJing Ma (CUHK) 2018/7/15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusion and future work:\\n- Propose a bottom-up and a top-down tree-structured model based on recursive neural networks for rumor detection on Twitter.\\n- Using propagation tree to guide the learning of representations from tweets content, such as embedding various indicative signals hidden in the structure, for better identifying rumors.\\n- Results on two public Twitter datasets show that our method improves rumor detection performance in very large margins as compared to state-of-the-art baselines.\\n\\nFuture work:\\n- Integrate other types of information such as user properties into the structured neural models to further enhance representation learning.\\n- Develop unsupervised models due to massive unlabeled data from social media."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Pah dg7 é' extSa\\n7. A a. it ie j t i\" . }Pe gy aS Y / Z fee He i S5gprsa Af if i (ey a,YY UY SO\" L a4TCRUER Gules a Or ares"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 169,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Matthias Lindemann: Saarland University\\nMeaghan Fowlie: Saarland University\\nMark Johnson: Macquarie University\\nAlexander Koller: Saarland University"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Abstract Meaning Representation (AMR)\\nBanarescu et al. 2013\\nO-2 | Parsing\\nThe witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "camel mulisentence root ARGO ARG 1 sntl gnt2 ARG2 /ARG1 condition ARG 1 polarity ppl op2oo Gents) CD ra ARG1 possible-01 ARG1 condition Cen) /anon Claei 0 ONfoe RGI ARGO /ARG2 RGI RGO opl ARG2 <= Con) Ce) Cos) Con) ator Cree) od ARGI mod |A ARG2 RGI Cam) COS ema) mon GS Gea fem /rver Cre) quant = compared-to /ARGI ARGO AR5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Classic AMR parser (e.g. JAMR\\n2014)\\n\\nStep 1: Predict nodes\\n\\nStep 2: Predict edges\\n\\nThe witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Not just nodes and edges"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Not just nodes and edges\\n\\nControl verb\\nNoun\\nTransitive verb"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Hidden compositional structure\\n\\nPrinciple of compositionality: the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them.\\n\\nAPPs\\n\\n\"APPoreQ . TMé O[S] oe\"\\n\\n\"The witch tried to cast a spell\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Hidden compositional structure\\n\\nPrinciple of compositionality: the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them.\\n\\nAPPs\\n\\n\"APPoreQ. TMé O[S] oe\"\\n\\nThe witch tried to cast a spell\\n\\nWidely accepted in linguistics, long history (Frege 1800s)\\n\\nUse this knowledge to guide machine learning!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "APPsa Cy)---oo sep,8 Ve, 2 (~=\")$s O[s] (on) The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "APPsa N Cv)ooAPPoS oS ts):\\n- The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "APPsa ©ooAPPoQD oN (wen -{ cast:| caivain AppoPeoOTM Appoey\\n6. dependencies!: (eS)| easy (easier) The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "APPga OooAPPooTM (np\\n- cost of S] Part 1 | caivain AppoPeoOTM. Appoey\\n6. dependencies! Celis) easy (easier) Part 2 The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "| &Apply-Modify (AM) Algebra G. et al, IWCS 2017 (i) cat)*HR algebra, Courcelle & Engelfriet 2012 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Apply-Modify (AM) Algebra G. et al, IWCS 2017\\n(i) cat) Empty argument slots are labeled with sources S, O,... (Subject, object,...)\\n\\nO*HR algebra, Courcelle & Engelfriet 2012 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Apply-Modify (AM) Algebra G. et al, IWCS 2017\\n\\n(i) Category: Empty argument slots are labeled with sources S, O,... (Subject, object,...)\\n\\nHave 'apply' operation for each source, e.g. APPof: © : Sp\\n- 48G0 (casthead argument HR algebra, Courcelle & Engelfriet 2012)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Typed AM Algebra Sin\\n- Has type [S|]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Typed AM Algebra %Object must have type [S] i ARGO (cesHas type [S]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Typed AM Algebra 'ApPpo& oN 7\" oO ¥© o, 2 %, 5 Object must have type [S] 5& Matching sources automatically merge ARGO' ao Has type [S|] 11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Apply-Modify Algebra ' |A ©oN\\n- %, -< <Cw) \", Cowtch neo cast < <(> ARGO cast The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Types control reentrancies Appo XxKN\\n- ft2 oS csSs ARGO (cast) @Has type [S] 'cast to sleep"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Types control reentrancies Appo XxoN = fovee)eo 88 TY): DD 4RG0 (cast) MD _aRGo (cast) @Has type [S] 'cast to sleep Object must have type [ |13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Types control reentrancies\\n\\n1 Appoi S ¥3 oN -_- 2 6, Object must have type [S] tied to witch Has type | | 14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "AM Dependency Trees dependencies define operations, but not their order\\n\\nApps\\n\\nAppoontood The witch cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "AM Dependency Trees dependencies define operations, but not their order\\n\\nApps Appoontood The witch cast a spell here: order does not matter"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "AM Dependency Trees\\n\\nThe witch tried to cast a spell here: need APPo before APPs to get reentrancies"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "AM Dependency TreesApporw AppoTr e }5 as aEThe witch tried to cast a spell here: need APPo before APPs to get reentrancies.\\nAlways need to resolve reentrancies first. Types encode reentrancies. TM use type system to determine operation order."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "AM Dependency Trees\\nApporw\\nAppor\\n\\nThe witch tried to cast a spell\\n\\nBuilding instructions for an AMR that we know how to predict"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "APPsAPPo C)--APPoQ oTM Co {mt )1 en Part 1 caivainAppoPo oTM Appo5 lo)s}} easy (easier) Part 2 The witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Model\\n1. Supertagging: score graph fragments for each word\\n2. Dependency model: score operations\\n3. Decoding: find highest-scoring well-typed tree\\n\\nThe witch tried to cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "1. Supertagging\\nE.g. Lewis et al. (2014) for CCGtrain to predict probability distribution over graph lexicon = bidirectional LSTM\\nThe witch tried\\n- spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "2. Dependency Model\\n\\nKiperwasser & Goldberg (2016) for syntactic dependencies\\n\\nAppstraint to predict\\n- WWJ witch\\n- Tried probability distribution over operations\\n- A bidirectional LSTM\\n\\nThe witch tried\\n- spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "AMR Corpus Required training data. The witch cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "AMR Corpus Required training data\\n\\nApps\\n\\nAppoono Oe\\n\\nThe witch cast a spell\\n\\nHeuristics: Alignments\\n\\nAttaching edges\\n\\nSource names\\n\\nSource annotations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "AMR Corpus Required training data Apps Appo- determine i(wen (eas) dS.\\n\\nThe witch cast a spell.\\n\\nThe witch cast a spell.\\n\\nHeuristics jo>e Alignments.\\n\\nAttaching edges\\n\\nThe witch cast a spell.\\n\\nSource names\\n\\nSource annotations"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "3. Decoding Find the best well-typed dependency tree"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "3. Decoding\\n\\nFind the best well-typed dependency trees.\\nIll-typed trees do not evaluate to AMRs; ill-typed trees do not match our linguistic intuitions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "3. Decoding\\n\\nFind the best well-typed dependency trees. Ill-typed trees do not evaluate to AMRs.\\nIll-typed trees do not match our linguistic intuitions. Exact typed decoding is NP-hard.\\nUntyped decoding: 74% of trees are ill-typed."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Approximate decoders A: Fixed tree The fv. The\\n- witch cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Approximate decoders\\n\\nA: Fixed tree\\n1. Fix unlabeled tree\\n2. Label tree, with type checking\\n\\nThe witch cast a spell\\nSo The\\n- witch cast a spell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Approximate decoders\\n\\nA: Fixed tree\\n1. Fix unlabeled tree\\n2. Label tree, with type checking\\n\\nThe witch cast a spell.\\n\\nSo the witch cast a spell.\\n\\nB: Projective: can only combine adjacent constituents\\n\\n\"CKY parsing with types as nonterminals\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Classic AMR parser (graph decoder)\\n\\nStep 1: Predict nodes\\n\\nStep 2: Predict edges"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Results poset | Mattos | StetSere) JAMR (Flanigan et al.\\n2016) graph decoder 67\\nFoland & Martin 2017 graph decoder 70.7\\nvan Noord & Bos 2017 neural seq2seq 68.5\\nLyu & Titov (ACL\\n2018) graph decoder 73.7\\nOur baseline graph decoder 66.1\\n\\nDataset: LDC2015E8626"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Conclusione\\n\\nWe built a competitive compositional AMR parser.\\n\\nClear avenues to improvement:\\n- Update to recent advancements in training regimen (e.g. Lyu & Tivov 2018).\\n- Look into specific phenomena, e.g. anaphora, ellipsis.\\n\\nFuture work: extend method to other formalisms."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 357,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Lexical Relations\\n\\nTask: Graded lexical entailment\\n\\nTo what degree is X a type of Y?\\n- girl\\n- person 9.85/10\\n- guest\\n- person 7.22/10\\n- person\\n- guest 2.88/10\\n\\nUseful for query expansion, natural language inference, paraphrasing, machine translation, etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Lexical Relations\\n\\nDistributional vectors are not great for directional lexical relations:\\n- carrot ~ vegetable\\n- new ~ old\\n\\nRetro-fitting (Faruqui et al.,\\n2015)\\nCounter-fitting (Mrksic et al.,\\n2016)\\n\\nBUT these mostly affect words that are in the training data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Main Idea\\nSpecialized network for directional lexical relations\\n- Off-the-shelf pre-trained embeddings\\n- Train the network to discover task-specific regularities in the embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Supervised Directional Similarity Network\\nFixed pre-trained word embeddings as input\\nPredict a score indicating the strength of a specific lexical relation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "SDSN: Gating Conditioning each word based on the other\\nod91 = O(Way w1 + Bg)\\n92 = a(Wy, we + bgp)\\nW1 = W1 © ge W2 = W2 © 1 un\\nGls 6/13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "SDSN: Mapping the representations to new spaces"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "SDSN: Sparse Features based on sparse distributional representations (Rei & Briscoe,\\n2014) to ratio of shared contexts (Ca 2)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "SDSN: Scoring Mapping the representations to a score Optimize the network with labeled examples.\\n\\n-d = m, Omega g tb = tanh(Wy d + W ar + b\\ns)\\n\\nGo\\na) y = S\\n- o(a(W,h + b y))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "HyperLex: Graded Lexical Entailment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "HypeNet: Hyponym Detection"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Conclusion\\n- Can train a neural network to find specific regularities in off-the-shelf word embeddings.\\n- Traditional sparse embeddings still provide complementary information.\\n- Achieves state-of-the-art on graded lexical entailment."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Thank you! Any questions?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Examples\\n\\nPremise                     Hypothesis               Gold    Predicted\\n\\ncaptain                    officer                       8.22    8.17\\n\\ncelery                      food                           9.3      9.43\\n\\nhorn                       bull                            1.12    0.94\\n\\nwing                      airplane                     1.03    0.84\\n\\nprince                     royalty                       9.85    4.71\\n\\nautumn                   season                       9.77    3.69\\n\\nkid                          parent                        0.52    8.00\\n\\ndiscipline               punishment              view    3.21    4/13"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 364,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction\\n- Our target problem is the extraction of drug-drug interactions (DDIs) from biomedical texts.\\n\\nMechanism\\n- Grepafloxacin inhibits the metabolism of Theophylline."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Introduction\\n\\nOur target problem is the extraction of drug-drug interactions (DDIs) from biomedical texts.\\nWe investigate the use of external drug database (DrugBank) information in extracting DDIs from texts.\\nWe especially focus on molecular structure information.\\n\\nMechanism\\n\\nGrepafloxacin inhibits the metabolism of Theophylline."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Method Overview\\n- We obtain the representations of textual drug pairs using convolutional neural networks (CNNs) and molecular drug pairs using graph convolutional networks (GCNs).\\n- We concatenate text-based and molecule-based vectors.\\n- Grepafloxacin inhibits the metabolism of Theophylline.\\n\\nDDI types concat Molecular structure:\\n- Grepafloxacin\\n- Theophylline"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Method DDI extraction from texts using molecular structures\\n- Text-based DDI representation\\n- Molecular structure-based DDI representation\\n- Word + position embeddings\\n- Grepafloxacin inhibits metabolism\\n\\nDDI types\\nTheophylline concat \"ieS (HCc NO Grepafloxacin\\nDrugBank\\nTheophylline Molecular vector"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Method DDI extraction from texts using molecular structures\\n- Text-based DDI representation word + position embeddings Grepafloxacin CLLL]\\n- inhibits CLL] Textual vector Text C the LLIT) metabolism CLLL] CNN of LLLT) Ps. Theophylline [LLLU] J \"i,6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Method: Text-based DDI Representation\\n\\nword + position embeddings\\n\\nGrepafloxacin inhibits CLL\\n\\nText Corpus the metabolism\\n\\nTheophylline\\n\\nOur model for representing textual DDIs is based on the CNN model by Zeng et al. (2014).\\nWe use word and position embeddings as the input to the convolution layer.\\nWe convert the output of the convolution layer into a fixed-size textual vector."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Method DDI extraction from texts using molecular structures\\n- Molecular structure-based DDI representation C NO Grepafloxacin GCN DrugBank ° Database TO : Theophylline Molecular vector"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Method: Molecular Structure-based DDI Representation\\n- We represent drug pairs in molecular graph structures using GCNs.\\n- We pre-train GCNs using interacting (positive) pairs mentioned in the DrugBank and not mentioned (pseudo negative) pairs in the DrugBank.\\n\\nGrewafloxanin Molecular vector A G: prediction GCN interact Theophylline not mentioned CH, at 5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Method: Molecular Structure-based DDI Representation Graph Convolutional Network (GCN) [Li et al. 2016]\\n\\nWe use GCNs to convert a drug molecule graph into a fixed size vector by aggregating node vectors h?, graph structure molecular vector Hs NHSS\\n- [een]\\n- J N hé, : node vector bes os\\n\\nNode w N(v) : neighbors of v\\n\\nNode v ~ * 9g GRU : gated Recurrent Unit\\n\\nEdge C@yy Logi,j : linear layer mi? = DEN) Ao, hy © : element-wise product hot?\\n= GRU((h5; m5*1)) [...; ...] : concatenation A: learned weight 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Method: Molecular Structure-based DDI Representation Graph Convolutional Network (GCN) [Li et al. 2016]\\n\\nWe use GCNs to convert a drug molecule graph into a fixed size vector by aggregating node vectors h?.\\ngraph structure molecular vector Hs NH\\n- [een]\\n- J N hé, : node vector bes os\\n\\nNode w N(v) : neighbors of v\\n\\nNode v ~ * 9g GRU : gated Recurrent Unit\\n\\nEdge C@yy Logi,j : linear layer mi** = Dwe N(v) Ae, tw © : element-wise product hit? = GRU((hE; m5*1]) [...\\n...] : concatenation 9 = XvaCi(thy; hp])) © GChe; hy)) a; leaned Walght11"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Method: DDI Extraction from Texts Using Molecular Structures word + position embeddings Grepafloxacin LLL textual inhibits CLO erethe CITT CNN metabolism CLIT of CLT Theophylline CIT 12"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Method: DDI Extraction from Texts Using Molecular Structures\\n- Link mentions in text corpus to drug database entries by relaxed string matching word + position embeddings\\n- Grepafloxacin (CLO) an relaxed inhibits CLO\\n- relaxed string the CNN marshing metabolism of CL Theophylline\\n- Grepafloxacin WK[drugBank Bank a_e_ Theophylline SOs13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Method: DDI Extraction from Texts Using Molecular Structures\\n- Link mentions in text corpus to drug database entries by relaxed string matching\\n- Obtain molecular vectors via GCNs with fixed parameters word + position embeddings\\n- Grepafloxacin (CLLO) an aeinhibits CLO -'sting the FEED CNNvnatting metabolism Cit) of CL\\n- Theophylline (CITT)\\n- > Grepafloxacin MU cTheophylline\\n\\nSOs | molecular vector 14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Method: DDI Extraction from Texts Using Molecular Structures\\n- Link mentions in text corpus to drug database entries by relaxed string matching\\n- Obtain molecular vectors via GCNs with fixed parameters\\n- Predict DDIs from concatenated textual and molecular vectors word + position embeddings\\n\\nGrepafloxacin (CLLO) inhibits CLIO vector matching. The Theophylline (CITT) is\\n5. Grepafloxacin is concatenated with Theophylline."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Task Settings\\n\\nSemEval2013 shared task 9.2\\n\\nThe data set is composed of documents annotated with drug mentions and their 4 types of interactions (Mechanism, Effect, Advice and Interaction) or no interaction.\\n\\nDDI type\\n\\nPositive\\n- Mechanism 1,319 302\\n- Effect 1,687 360\\n- Advice 826 221\\n- Int 189 96\\n- Total 4,021 879\\n\\nNegative\\n- 23,771 4,737\\n- Total 27,792 5,716\\n\\nStatistics of the DDI SemEval2013 shared task"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Data for Pre-training GCNs\\n- We extracted 255,229 interacting (positive) pairs from DrugBank and generated the same number of pseudonegative pairs by randomly pairing DrugBank drugs.\\n\\nWe deleted drug pairs mentioned in the test set of the text corpus."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Molecular Structure Features\\n- To obtain the graph of a drug molecule, we took as input the SMILES string encoding of the molecule from DrugBank and then converted it into the 2D graph structure using RDKit.\\n- For the initial atom (node) vectors, we used randomly embedded vectors for atoms, i.e., C, O, N, ...\\n- We also used 4 bond (edge) types: single, double, triple, and aromatic."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Differences of Labels in Text and Database\\n\\nTasks interacting drug pairs in database may not appear as positive instances in the text task.\\n\\nText task defines 4 detailed types, while database task has one positive type.\\n\\nMechanism\\n\\nGrepafloxacin inhibits the metabolism of Theophylline\\n\\nNo relation\\n\\nWhile the effect of Grepafloxacin on the metabolism of C.P.A substrates is not evaluated, in vitro data suggested similar effects of Grepafloxacin in Theophylline metabolism.\\n\\nNo relation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Training Settings\\n- Mini-batch training using the Adam optimizer with L2 regularization\\n- Word embeddings trained by the word2vec tool on the 2014 MEDLINE/PubMed baseline distribution\\n- Skip-gram\\n- Vocabulary size: 215k"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Training Settings\\n\\nHyper-parameters\\n- Parameter Value\\n- Word embedding size 200\\n- Word position embedding size 20\\n- Molecular vector size 50\\n- Convolution window size [3, 5, 7]\\n- Number of steps 4\\n- Convolution filter size 100\\n- Hidden layer size 1,000\\n- Hidden layer size 500\\n- Initial learning rate 0.001\\n- Mini-batch size 100\\n- Mini-batch size 50\\n- Hidden layer size of NFP 50\\n- L2 regularization parameter 0.0001\\n- GRU unit size of GGNN 50\\n\\nHyper-parameters for text-based model\\n\\nHyper-parameters for molecule-based model"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Evaluation on Relaxed String Matching\\n- How much of drug mentions in texts are linked to DrugBank entries by relaxed string matching?\\n- We lowercased the mentions and the names in the entries and chose the entries with the most overlaps.\\n- As a result, 92.15% and 93.09% of drug mentions in train and test SemEval 2013 data set matched the DrugBank entries."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Evaluation on DDI Extraction from Texts (SemEval 2013 Shared Task)\\n- We observe the increase of micro F-score by using molecular structures.\\n\\nText\\n- Only 2.39 pp Text + Molecular Structure\\n\\nZheng et al. 2017\\n\\nLim et al. 2018\\n\\nmicro F-score (%)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Analysis Can molecular structures alone represent DDIs in texts?\\nA interact CNS Grepafloxacin | GCN concat H not interact DrugBank ae\\n- Theophylline\\n\\nMolecular vector\\n- Low F-score (23.90%)\\n- This might be because the drug pairs that interact can appear in the textual context that does not describe their interactions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Conclusions\\n- We proposed a novel neural method for DDI extraction using both textual and molecular information.\\nThe molecular information has improved DDI extraction performance.\\nAs future work, we will investigate the use of other information in DrugBank."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 118,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "GOAL: Geolocation of text.\\nGeoparsing Pipeline:\\n- NER\\n- NEL\\n- WSD\\n- GEOTAGGING\\n\\nDocument Geocoding"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "South Patrick Shores\\n\\nSatellite Beach.\\n\\nIncident\\n- Wickham Park.\\n\\nBeach Oceanfront\\n\\nBeachfront hotel with... Melbourne's\\n\\nHampton Inn Melbourne\\n\\nFairfield Inn & Suites\\n\\nby Marriott Melbourne...\\n\\nModern hotel with free...\\n\\nAndretti Thrill Parks\\n\\nCounty Jail.\\n\\nPalm Bay"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Ps Geocoding similar to WSD but...\\n- Ambiguity of toponyms greater Background (e.g. 10+ Melbournes in the world)\\n\\nGeoparsing\\n- Contextual clues not adequate\\n- RSees or missing for small (local) places\\n- Often difficult for humans to judge\\n- 50%\\n- 75% resolved by population"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "1 TEXT DOCUMENT, ~ vag = wows.\\n\\n2 SETS OF FEATURES\\n- SMe\\n- SF\\n- LED\\n- B\\n- 6#\\n- SSS\\n- ESEPPPS\\n\\nLONGITUDE Mateo\\n- [° Peo (pepops|o |e | saos BB |6 [(pzps[m]o[o pelo | gGo |e\\n- [° Pale | palo [ole | &sor | EEEEPEEEO (reshape to)\\n- 1D Map Vector\\n- 360 DEGREES\\n- Bag of locations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "CONTEXT WORDS CONVOLUTIONS POOLING DENSE pyramid complex, archaeological site near Giza, Egypt, at Giza Plateau.\\n\\nTARGET ENTITY: CAIRO\\n\\nDENSE PREDICTION:\\n- SOFTMAX"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "» LOCAL GLOBAL LEXICON (LGL) by Lieberman et al. 2010\\n- packaged with our code.\\n588 local news articles from global sources\\n4460 annotated places, Medium Difficulty Test\\n\\n» WIKIPEDIA TOPONYM RETRIEVAL (WikToR) by Gritta et al. 2017\\n- also packaged with our code.\\nEvaluation\\nWikipedia-based geoparsing of 5,000 articles\\nHigh Difficulty Test, 25,000+ locations in total\\n\\nDatasets\\nOther corpora available (De Lozier et al. 2010), (Wallgrun et al. 2017), (Buscaldi and Rosso 2008), (DeOliveira et al.\\n2017), (Mani et al. 2010), (Eisenstein et al.\\n2010) but issues with cost, scope, annotation, size, type of task, completeness, etc.\\n\\n» OR RESOURCES NOT PUBLISHED WITH PAPER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Ae? (x) Freeasin Freedom WIK| (@v=Yo VAiablseaagl = 229 articles (August, September 2017).\\nNER/Geotagging and Geocoding I =\\\\iqDychecls{s\\au =.\\n\\nKEYWORDS: Ebola, Bird Flu, Swine Flu, AIDS, Mad Cow Disease, many more. (Medisys JRC).\\n\\nLocations: 2,167, Word Count: 638,205 | DOWNLOAD. https://github.com/milangritta"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "OVERALL PERFORMANCE COMPARISON\\n\\nGeocoder System configuration\\n\\nDataset Average\\n\\nLanguage Features + MapVec Features\\n\\nLGL WIK GEOCamCoder CNN MLP\\n0.22 0.33 0.31 0.29\\n\\nLexical Only CNN\\n- 0.23 0.39 0.33 0.32\\n\\nMapVec Only MLP\\n0.25 0.41 0.32 0.33\\n\\nContext2vec LSTM MLP\\n0.24 0.38 0.33 0.32\\n\\nContext2vec LSTM\\n- 0.27 0.47 0.39 0.38\\n\\nRandom Forest MapVec features only, no lexical input\\n0.26 0.36 0.33 0.32\\n\\nNaive Bayes MapVec features only, no lexical input\\n0.28 0.56 0.36 0.40\\n\\nPopulation\\n- 0.27 0.68 0.32 0.42\\n\\nContext2vec LSTM\\n- 0.27 0.47 0.39 0.38\\n\\nRandom Forest MapVec features only, no lexical input\\n0.26 0.36 0.33 0.32\\n\\nNaive Bayes MapVec features only, no lexical input\\n0.28 0.56 0.36 0.40\\n\\nPopulation\\n- 0.27 0.68 0.32 0.42"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Melbourne + Perth + NewcastleeaGeoVirus.xml\\n- \"a CONTEXT WORDS CONVOLUTIONS PC__.\\n- pyramid complex, A wy :=] ;outskirts SE, LOCATION MENTIONS well,\\n- Giza, Egypt,\\n- The Map Vector TARGET ENTITY W | K | Ps @ DENSE CAIRO is rs SOFTMAX@ (LOCATION a MAP VEC FF FF PREDICTION) Geocoder Area Under Curve!\\nAverage Error? Accuracy @ 161km S DENSE Ie MN LGL WIK GEO LGL WIK GEO LGL WIK GEOpS\\n- Wiel i ) nO eesssneeeeeaaaee oeeoooeeeeoeeeea SEOE eeemn: eS,\\n- CamCoder 22(18) 33(37) 31(32) 7(5)\\n119) 3(3) 76(83) 65(57) 82(80)\\n- Edinburgh 25(22) 53(58) 33(34) 8(8) 31(30) 5(4) 76(80) 42(36) 78(78)\\n- Yahoo! 34(35) 44(53) 40(44) 6(5) 23(25) 3(3) 72(75) 52(39) 70(65)\\n- Population 27(22) 68(71) 32(32) 12(10) R45(42(3 OW9) )\\n- CLAVIN 26(20) 70(69) 32(33) 13(9)\\n- GeoTxt 29(21) 70(71) 33(34) 14(9) 47(45) 6(5) 68(80) 18(14) 79(79)\\n- Topocluster 38(36) 63(66) NA 12(8)\\n- GO AO CO é er NA Santos et al. NA NA NA 8 NA"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "www.DREAM-CDT.ac.uk\\nTie, Mate Wee | ae ThA Sya os b1004 Ve Sl\\n\\npascaiges ex ez007 paxosSe 22 QA AAS\\n\\n& Money enables DATA, RISK & ENVIRONMENTAL ANALYTICAL METHODS much Scientific Research.\\n\\nThank You!\\n\\nR ECONOMIC\\n\\n& SOCIAL RESEARCH NERC COUNCIL\\nwww.NERC.ac.uk\\nhttps://ESRC.ukri.org/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "OOD OOEDOO HABO OOUNIVERSITY OF CAMBRIDGE"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 174,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Machine learning can help you! If you have enough training data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Example Tom Brady was spotted in New York City on Monday with his wife Gisele Bündchen amid rumors of Brady's alleged role in Deflategate.\\n\\nLabel Is person 1 married to person 2?\\n\\nTime Spent if Bi Reading/Understanding BM Clicking Y/N"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Example Tom Brady was spotted in New York City on Monday with his wife Gisele Bündchen amid rumors of Brady's alleged role in Deflategate.\\n\\nLabel Is person 1 married to person 2?\\n1) Explanation Why do you think so? Because the words \"his wife\" are right before person 2."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Explanations Encode Labeling Heuristics\\n\\nExplanation\\n\\nWhy did you label True?\\n\\nBecause the words \"his wife\" are right before person\\n2.\\n\\n4\\n\\nFREE\\n\\nLabel Example\\n\\nTrue \"Barack batted back tears as he thanked his wife, Michelle, for all her help.\"\\n\\nTrue = \"Both Bill and his wife Hillary smiled and waved at reporters as they rode by.\"\\n\\nTrue \"George attended the event with his wife, Laura, and their two daughters.\"\\n\\nBig Idea: Instead of collecting labels, collect labeling heuristics (in the form of explanations) that can be used to label more examples for free."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "A framework for generating large training sets from natural language explanations and unlabeled data\\n\\nResult: classifiers trained with Babble Labble and explanations achieved the same F1 score as ones trained with traditional labels while requiring 5-100x fewer user inputs as"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "babblex labble | SEMANTIC PARSER UNLABELED!\\nEANAR ON EXAMPLES} ARGLIST IS EQUAL > Bos; ~ ae RG AND ARG IS EQUAL 1 eye) FUT Lt Fl\\n- 1 X and Y are the same gg fenteane | EXPLANATIONS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Explanations Encode Heuristics | Explanation\\n\\nWhy did you label True? | Labeling Function\\n\\ndef f(x):\\nreturn 1 if (\"his wife\" in left(x.person2, dist==1)) else 0 # abstain"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "LFCONDITIONS BOOL ARGLIST ISEQUAL; I| et, ge me, 1\\n\\nSTART LABEL FALSE BECAUSE ARG AND ARG IS 1 EQUAL: STOP\\n\\n<START> label false because X and Y are the same person <STOP>\\n\\nLexical Rules\\n\\nUnary Rules\\n\\nCompositional Rules\\n\\nIgnored token\\n\\n<START> START FALSE BOOL START LABEL BOOL BECAUSE CONDITION STOP.\\n- LFlabel > LABEL TRUE > BOOL ARGLIST ISEQUAL\\n- CONDITION false\\n- FALSE INT\\n- NUM ARG AND ARG\\n- ARGLIST Labeling Function Template: def LF(x): return [label] if [condition] else [abstain]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Predicate | Description\\n\\nbool, string, Standard primitive data types\\n\\nint, float, tuple, win O DA, spt list, set\\n\\nLogical & Comparison and, or, not, any, Standard logic operators\\n\\nall, none = Standard comparison operators\\n\\nlower, upper, Return True for strings of the corresponding case\\n\\ncapital, all_caps\\n\\nString Matching\\n\\nstarts_with, Return True if the first string ends_with, starts/ends with or contains the substring\\n\\nsecond\\n\\nperson, location, Return True if a string has the corresponding NER tag\\n\\ndate, number, organizational\\n\\nalias A frequently used list of words may be predefined and referred to with an alias\\n\\ncount, contains, Operators for checking size,\\n\\nSets & Mapping\\n\\nintersection membership, or common elements of a list/set\\n\\nmap, filter Apply a functional primitive to each member of list/set to transform or filter the elements\\n\\nword distance, Return the distance between\\n\\ncharacter_distance two strings by words or characters\\n\\nRelative Positioning\\n\\nleft, right, Return as a string the text that is between, within left/right/within some distance of a string or between two designated strings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "1 Explanation\\n1 Parse Typical aaele Goal: produce the correct parse\\n\\n1 Explanation\\nMany Parses ole Tslo Goal: produce useful parses (whether they're correct or not)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "babble labble | SEMANTIC PARSER FILTER BANK UNLABELED!\\nEXAMPLES ARGLIST IS EQUAL> Bos = i, AND ARG IS EQUAL; few mee) | TT | fp- 1 X and Y are the same 'gg fenteane- | EXPLANATIONS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "(Filtered) Explanations Labeling Functions Labeling Functions Filter Bank def f(x): return 1 if...\\ndef f(x): return 1 if... def f(x): return 1 if... Semantic def f(x): return 1 if... xel atols def f(x): return 1 if...\\nx def f(x): return 1 if... an def f(x): return 1 if... def f(x): return 1 if... LU def f(x): return 1 if...\\nx Semantic Filter x Pragmatic Filter"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Example X1: Tom Brady was spotted in New York City on Monday with Gisele Bündchen amid rumors of Brady's alleged role in Deflategate.\\n\\nExplanation True, because the words \"his wife\" are right before person\\n2.\\n\\nCandidate Labeling Functions\\n\\n\"right before\" = \"to the right of\"\\n\"right before\" = \"immediately before\"\\n\\ndef LF_1b(x):\\ndef LF_1la(x):\\nreturn (1 if \"his wife\" in right(x.person2) else\\n0)\\nreturn (1 if \"his wife\" in left(x.person2, dist==1) else\\n0)\\n\\nLF_1b(x1) == 0\\nX\\nLF_1la(x1) == 1\\n\\n\"If \"his wife\" is not to the right of person 2\"\\n(\"his wife\" is, in fact, 1 word to the left of person 2)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "-- Pragmatic Filters\\n\\nHow does the LF label our unlabeled data?\\n\\nUniform labeling \"| XN signature LFF: @@0000000600000\\n\\nDuplicate labeling LF: @OOCOOOOOOOO signature Fes @OOSOCOOOOOOOO"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "babble labble | SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR UNLABELED!\\n\\nEXAMPLES\\nARG LIST IS EQUAL\\n- TM soles Seles = i ~ ARG AND ARG IS EQUAL\\n\\nX and Y are the same\\n\\nEXPLANATIONS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "-- LF1: @@@@eeeeo\\nPositive\\n\\nLF2: @@@@@eOeOOO\\nNegative\\n\\nInput:\\n\\nLF3: @@@@@CeGC80@ © Abstain\\n\\nLF4: @@OOOOOO®\\n\\nOLF5: OO@@OOCO0CO0O\\n\\nOutput: y ©000000060\\n\\nTraining Data (x1, ¥1) (X21V2) (x3,\\n93) (X47 Va)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "ope OOO OOOO. High correlation; not independent?\\n\\nInput:\\n\\nLF2: @@@@O@OO@OOO\\n\\nLF3: @@@@O00080\\n\\nLF4: O @ O O @ @ @ O @ <- High conflict; low accuracy?\\n\\nLF5: O O @ O O O O O O « Low coverage, high accuracy?\\n\\nOutput: yy ©00000000\\n\\nHow should I break this tie?\\n\\nData Programming: (Ratner, et al. NIPS\\n2016) As implemented in: snorkel Snorkel.stanford.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "babblex labble | SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR ! DISC.\\nMODEL UNLABELED CONDITION EXAMPLES ARGLIST ISEQUAL OS: z= Wy,ee ,® ad > @OC@oe) | LES OreI an are the same .eframam) | !\\nOFSEXPLANATIONS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "- Discriminative Classifier\\n- Input: Labeling Functions, Label Discriminative\\n- Unlabeled data Aggregator Model\\n- Labeling functions Resolve conflicts, Generalize beyond the labeling functions\\n- Generate noisy, re-weight & combine conflicting votes"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "-- Task: identify disease-causing chemicals\\n\\nKeywords mentioned in LFs: \"treats\", \"causes\", \"induces\", \"prevents\", ...\\n\\nHighly relevant features learned by discriminative model: \"could produce a\", \"support diagnosis of\", ...\\n\\nTraining a discriminative model that can take advantage of additional useful features not specified in labeling functions boosted performance by 4.3 F1 points on average (10%)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "SSName # Unlabeled Sample Explanations\\n\\nSpouse 22k Label true because \"and\" occurs between X and Y and \"marriage\" occurs one word after person1.\\n\\nDisease 6.7k Label true because the disease is immediately after the chemical and \"induc\" or \"assoc\" is in the chemical name.\\n\\nProtein 5.5k Label true because \"Ser\" or \"Tyr\" are within 10 characters of the protein."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "- Task F1\\n- Babble Labble\\n- Traditional Labels\\n- Reduction in Score\\n- Padded # Labels\\n- User Inputs\\n\\nSpouse 50.1 30 3000+ 100x\\nDisease 42.3 30 1000+ 33x\\nProtein 47.3 30 150+ 5x\\n\\nClassifiers trained with Babble Labble and explanations achieved the same F1 score as ones trained with traditional labels while requiring 5-100x fewer user inputs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "0.45 0.40 Y 0.35 °Oa 0.30 caLL 0.25\\n\\n=== Spouse (BL) === Disease (BL) =-- Protein (BL)\\n\\n0.15 1000 2000 3000 4000 5000\\n\\nUnlabeled Examples\\n\\nWith labeling functions, training set size (and often performance) scales with the amount of unlabeled data we have."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Task Babble Labble Babble Labble\\n\\n% Incorrected (Nom a ict) Parses Filtered\\n\\nSpouse 15.7 50.1 97.8%\\n\\nDisease 39.8 42.3 96.0%\\n\\nProtein 38.2 47.3 97.0%\\n\\nAVERAGE 31.2 46.6 96.9%\\n\\nThe filters removed almost 97% of incorrect parses.\\nWithout the filters removing bad parses, F1 drops by 15 F1 points on average."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "- Perfect Parsers Need Not Apply\\n- BET Babble Labble Babble Labble\\n- (Perfect Parses)\\n- Spouse 50.1 49.8\\n- Disease 42.3 43.2\\n- Protein 47.3 46.8\\n- AVERAGE 46.6 46.8\\n\\nUsing perfect parses yielded negligible improvements.\\nIn this framework, for this task, a naive semantic parser is good enough!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "-- \"Alice beat Bob in the annual office pool tournament.\"\\n\\nDo you think person 1 is the spouse of person 2? Why?\\n\\nNo, because it sounds like they’re just co-workers.\\n\\nWhat’s B co-worker? (e.g., keywords, word distance, capitalization, etc.)\\n\\nUsers' reasons for labeling are sometimes high-level concepts that are hard to parse."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "- Related Work: Data Programming\\nCommon theme: Use weak supervision (e.g., labeling functions) to generate training sets\\n- Snorkel (Ratner et al., VLDB\\n2018)\\nFlagship platform for dataset creation from weak supervision\\n- Structure Learning (Bach et al., ICML\\n2017)\\nLearning dependencies between correlated labeling functions\\n- Reef (Varma and Ré, In Submission)\\nAuto-generating labeling functions from a small labeled set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "--- Related Work: Explanations as Features (Srivastava et al.,\\n2017)\\n\\nWhat if we use our explanations to make features instead of training labels?\\n\\nDISC. MODEL\\n\\nUse as features for classifier\\n\\nUse as labels for training set\\n\\nUsing the parses to label training data instead of as features boosts 4.5 F1 points."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Highlight key phrases in text: (Zaidan and Eisner, 2008), (Arora and Nyberg,\\n2009)\\n\\nMark key regions in images: (Ahn et al.,\\n2006)\\n\\nLabel key features directly: (Druck et al., 2009), (Raghavan et al., 2005), (Liang et al.,\\n2009)\\n\\nTom Brady dotted in New York City on Monday amid rumors of Brady's alleged role in Deflategate.\\n\\nBenefits of natural language approach:\\n- more options: e.g., \"X is not in the sentence\", \"X or Y is in the sentence\"\\n- more direct credit assignment (compared to highlighting)\\n- no feature set required a priori"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "We need more efficient ways to collect supervision.\\nWe can collect labeling heuristics instead of labels.\\nUsing this approach, training set size grows with the amount of unlabeled data we have."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "- EXTRA SLIDES"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Dataset Statistics\\n\\nTask           Train   Dev     Test\\n9% Pos. Spouse     22195   2796   2697\\n8% Disease         6667    773    4101\\n20% Protein        5546    1011   1058\\n22%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Unlabeled Examples + Explanations\\n\\nLabeling Functions\\n\\nFilters\\n\\nLabel Matrix\\n\\nLabel whether person 1 is married to person 2\\n\\ndef LF_1a(x):\\nreturn (1 if \"his wife\" in x.person2 else\\n0)\\n\\ndef LF_1b(x):\\nreturn (1 if \"his wife\" in x.person2 else\\n0)\\n\\nDeflategate.\\n\\ndef LF_2a(x):\\nreturn (-1 if x.person1 in x.person2 else\\n0)\\n\\ndef LF_2b(x):\\nreturn (-1 if x.person1 == x.person2 else\\n0)\\n\\nNoisy Labels Classifier\\n\\ndef LF_3b(x):\\nreturn (-1 if x.person1.tokens[-1] != x.person2.tokens[-1] else 0)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "babblelabble (INPUT ' SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR | _ DISC.\\nMODEL Xq CONDITION ' OX3 pee | oOi X and Y are the same\\n\\nNOUN LABELED | :EXAMPLES c> > [>> @ i. bt1 rel ies) | Um Gx) m4 Xa Ms\\n\\n:@ [Rrer because.} LF is @) LF is 1/0 1 _ 1 2%F. Geo Y Geliea] | Fw Cf) «0 -1-\\n\\n!EXPLANATIONS { LABELING FUNCTIONS\\n- LABEL MATRIX\\n- PROBABILISTIC LABELS | TRAINED MODEL\\n\\nIMPORTANT: No Babble Labble components require no labeled training data!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Example Label Matrix\\n\\nTom Brady was spotted in New York City on Monday with his wife Gisele Bündchen amid rumors of Brady's alleged role in Deflategate.\\n\\nLabel 1\\nIs person 1 married to person 2?\\n\\nExplanation\\nWhy do you think so?\\n\\nAggregated Labels\\nBecause the words \"his wife\" are right before person\\n2.\\n\\nClassifier\\nLabeling Function\\nOnn @def LF1(x):\\nreturn (1 if \"his wife\" in left(x) else -1)"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 195,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Numeracy the Ying.mat 9.0/ * 2000 314.F dog Words for 7 14 sleeping brown 7 1 R5 three jumped four 9-008 numbers V2jumpe are ww 5 numerals 4 N 0.9 142ione 5 146 1 Cmoiv 2 QV-12018 3 44 B 5/82/3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Literate Language Models rsPry (text) (semantically, grammatically, etc.)\\n\\n'A apple eats'\\n\\n'leats an apple'\\n\\n'An apple eats me'\\n\\n'I eat an apple'"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Numerate Language Models rsPry (text) = Q1.4 15 1.6 1.8 1.9 2 2.1 22\\n\\nJohn is 1.7 m tall\\n\\nJohn is 2 m tall\\n\\nJohn is 999 m tall"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Numeracy Matters\\n\\n'Unemployment of the US is 5%'\\n\\n'Patient's temperature is 36.6 degrees'\\n\\n'Our model is 10 times better than the baseline'"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Q1: Are existing LMs numerate?\\n\\nQ2: How to improve the numeracy of LMs?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "A Neural Language Model rsp(w; |hz) Dh i he; Wr-1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "A Neural Language Model Ap(w;|h;) = softmax(w;)i ny | an 3 petrichoré a unothrorgaphy Spithourakis\\n- we Ap\\n- 4; Vt\\n- $\\n- Input Ct 1 |\\n- 17 9,846,321 2018 oft sores Wt\\n- 1 UNKNUM"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Evaluation: Adjusted Perplexity rsPerplexity John is 2.1 m tall p(2.1) = pC UNKNUM) BUT 4p(0.731) 2.1 + 0.731p(9,846,321) | 9 ga6 321 + 2018.3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Evaluation: Adjusted Perplexity\\n\\nAdjusted Perplexity [Ueberla, 1994] John is 2.1 m tall\\n- p | UNKNUM | p(2.1) = pi) P21) = Fret ow BUT 4 : | (0.731) 21 from test data + 0.731 p(9,846,321) | 9 ga6 321 a.k.a.\\nUnknown\\n- Penalised Perplexity r meaias [Ahn et al., 2016]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Datasets\\n- Clinical Dataset: 16,015 clinical patient reports\\n- Scientific Dataset: 20,962 paragraphs from scientific papers\\n\\nSource: London Chest Hospital\\nSource: ARXIV"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Results: Adjusted Perplexity ts (Lower is better) So 80.62: i010 8.910 all tokens"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Results: Adjusted Perplexity ts (Lower is better) 3,505,856.25 © 100 30.625 i 51.83 © 50° | 058,443.72 10 8.91 ee 8 5.99 © 5° all tokens words numerals"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Results: Adjusted Perplexity tsL 3,505,856.25 (Lower is better) softmax 5 100 80.62 Assumptions Reality (?) € 21.83 large Seo large 5 e% e 58,443.72 10 8.91 small small 5,992 50 all tokens words numerals all..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Strategy: Softmax & Hierarchical Softmax"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Strategy: Softmax & Hierarchical Softmax\\n- softmax\\n- softmax\\n- softmax\\n- types\\n- words\\n- numerals"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Strategy: Softmax & Hierarchical Softmax\\n- softmax\\n- softmax\\n- softmax\\n- words\\n- eV\\n- p(numeral|h;)\\n- h-softmax\\n- digit-by-digit\\n- from PDF\\n- vopiyaiinan\\n- etc."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Strategy: Digit-by-Digit Composition rypP2.1) = p@ yp [2)pC\\n12. pls |2.1)d-RNN2 . 1 EOSPPESOS\\n2. 1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Strategy: Digit-by-Digit Composition\\n1) p@)pC\\n2) p G2. pos\\n2.1) NOBusid-RNN2\\n1 EOS1.99he : Ly\\n196 1.97 aSoS\\n1 +73\\n94\\n2.00"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Strategy: from continuous PDF ap(numeral = 2.1) = ppy-(2.05 < number < 2.15 | precision =\\n1) X p(precision =\\n1) 2.521g 15o10.50"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Strategy: from continuous PDF ap(numeral = 2.1) = ppy-(2.05 < number < 2.15 | precision =\\n1) x p(precision =\\n1) a MoG Frozen ps2 and ossoftmax1.5 componento1 hy0.5 precision° PRP RPPRPRPRPRPP NNNNNNNNNNN W W W W W W W W p(precision) = ranw (dddd cos) BNWAUDYUOO BNWAUONOO BNWAU"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Overview of Strategies"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Overview of Strategies\\nrssoftmaxcombination\\n21.7° \"Y \"WHEN = 20/1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Results: Language Modelling\\n\\n(1) rya 10 8.91\\naesClinical 6.05 5.88 5.88 i 5.82\\n\\nAI Tokens\\n\\nWords ; lI 4.96 4.95 4.99 4.9625\\nZH2 @ 058,443.721000\\n\\nNumerals\\n\\n04 495.95\\n263.22 226.46\\n197.59\\n\\n(lower is better) softmax h-softmax d-RNN MoG combination"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Results: Language Modelling\\n\\nScientific 100 80.62\\nFi 54.8 53.7 54.37 ; 53.03 | 50\\n\\nNote ee 0 Lt...\\n\\n100 se 51.83 49.81 48.89 48.97 48.25\\n\\n\"Billi\" 3 ota 3,505,856.25\\n\\nPay poss parenvy 550.98 | sigg | P98 sa 95\\n\\nI 1 Ivee im ie om0 Se oa oansoftmax h-softmax d-RNN MoG combination (lower is better)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Results: Number Prediction\\n- targetLa ay MAPE = 100%\\n- Baki targetClinical 2353.11747800\\n- 622600\\n- 514 Sees\\n- 552426\\n- 34g\\n- 400o\\n- lower\\n- mean\\n- median\\n- softmax\\n- h-softmax\\n- d-RNN\\n- MoG combination better"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Results: Number Prediction aScientific 1-23 30392500 1947 17777 23332000 1652 kl1500 1287: I1000 590500 I0 1IClinical 2353.11 1I800 747 1 I622 I600 514 ' 1 55200 426 1 348 |4I200 10.: Ilower is .( ower © mean median softmax h-softmax d-RNN !\\nMoG combination better) caer some genege!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Softmax versus Hierarchical Softmax\\n\\n0.7523:\\n\\nBee can\\n\\nseparnee\\n\\ninef\\n\\npeaks\\n\\ncosine similarities\\n\\nsoftmax\\n\\nh-softmax"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Analysis: d-RNN and Benford's Law\\ncosine similarities d-RNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Analysis: d-RNN and Benford's Law\\n- First digit\\n- Fourth digit\\n\\ncosine similarities\\n\\nd-RNN\\nBenford"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "1. Analysis: Model Predictions\\n- target=27.00 pred=59.00 r=0.030\\n- target=27.00 pred=53.00 r=0.020\\n- target=27.00 pred=61.00 r=0.020\\n\\nejective fraction: %"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Analysis: Strategy Selection\\n\\nry4 out of 17 segments\\n\\nSmall integers, Enhancement > 25 % percentiles, softmax Li et al.\\n2003 years strategies | i = measured 32 x 31 mm 2-digit integers.\\n\\nNGC 6334 stars some ids\\n\\nEjective fraction: 27.00 % reals, Ejective fraction: 35.00 % some ids HIP 12961 and GL6/6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Conclusion (1) Are existing LMs numerate? softmax --> 23.44"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Conclusion\\n\\n(1) Are existing LMs numerate? John's height is 'oRsoftmax K,ee {Ny 0the ai 1 2 5999 3he UNKNUM 3.14an 201850"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Conclusion (2) How to improve the numeracy of LMs? combination strategies"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Conclusion (2) How to improve the numeracy of LMs? John's height is ____'combinations of man | man 2.1 18 .oe 1.73 5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "0 2002 3.14 Ou 24 1.83 14 XK 9 G2018 V2 | 1.73 aps 50 o N 95 ' 142 i OS s. _ sje NI wor"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 17,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Adpositions are Pervasive\\n- Adpositions: prepositions or postpositions.\\n\\nOrder of Adposition and Noun Phrase\\n- WALS / Dryer and Haspelmath"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Prepositions are some of the most frequent words in English to with ste_ |ow a = SF am hafin': for-.\\nql aget ren that Wat. Landi: Dehave ps: BM tro tis were ==] dori"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "We know prepositions are challenging for syntactic parsing—a talk at the conference on prepositions.\\n\\nBut what about the meaning beyond linking governor and object?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Prepositions are highly polysemous in for- in the box\\n- leave for Paris\\n- in the afternoon\\n- ate for hours\\n- in love, in trouble\\n- a gift for mother\\n- in fact\\n- raise money for the party"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Translations are Many-to-Many for raise money for the church a gift for mother at for hours pour pendant dQ give the gift to mother go to Paris raise money to buy a house to"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Potential Applications\\n- Machine Translation\\n- MT into English: mistranslation of prepositions among the most common errors (Hashemi and Hwa, 2014; Popovic,\\n2017)\\n- Grammatical Error Correction\\n- Semantic Parsing / SRL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Goal: Disambiguation\\n\\nDescriptive theory (annotation scheme)\\n\\nLexical resource\\n\\nAnnotated Dataset\\n\\nDisambiguation system (classifier)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Our Approach\\n1. Coarse-grained supersenses\\n2. Comprehensive with respect to naturally occurring text\\n3. Unified scheme for prepositions and possessives\\n4. Scene role and preposition's lexical contribution are distinguished\\n\\nIn this paper: English"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Senses vs. Supersenses\\n\\nover\\n- preposition\\n1. extending directly upwards from: I saw flames over Berlin | cook the sauce over a moderate heat.\\n2. so as to cover or protect: an oxygen tent over the bed | ladle this sauce over fresh temporal.\\n3. extending above (an area) from a vantage point: views over Hyde Park.\\n4. at a higher level or layer than: his flat was over the shop.\\n5. higher in rank than: over him is the financial director.\\n6. expressing authority or control: editorial control over what is included.\\n7. expressing preference: I'd choose the well-known brand over that one.\\n8. expressing majority: the predominance of Asian over African managers in the sample.\\n9. higher in volume or pitch than: he shouted over the noise of the taxis.\\n10. higher or more than (a specified number or quantity): over 40 degrees C | they've been married for over a year.\\n11. expressing passage or trajectory across: she trudged over the lawn.\\n12. beyond and falling or hanging from: he toppled over the side of the boat.\\n13. at the other side of; beyond: over the hill is a small village.\\n14. expressing duration: you've given us a lot of heartache over the years | she told me over coffee.\\n15. expressing the medium by which something is done; by means of: a voice came over the interval loudspeaker.\\n16. on the subject of: a heated debate over unemployment.\\n\\nSenses (e.g., Over-15-1) Supersenses (e.g., Frequency)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Challenges for Comprehensiveness\\n\\nWhat counts as a preposition/possessive marker?\\n- Prepositional multi-word expressions (\"of course\")\\n- Phrasal verbs (\"give up\")\\n- Rare senses (RateUnit, \"40 miles per gallon\")\\n- Rare prepositions (\"in keeping with\")\\n- Wicked polysemy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Supersense Inventory\\n- Semantic Network of Adposition and Case Supersenses (SNACS)\\n- 50 supersenses, 4 levels of depth\\n- Simpler than its predecessor (Schneider et al.,\\n2016) * Fewer categories, smaller hierarchy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "- Participant\\n- Identity\\n- Usually core semantic roles\\n- Co-Agent\\n- Gestalt\\n- EndTime\\n- Theme\\n- Possessor\\n- Frequency\\n- Co-Theme\\n- Whole\\n- Circumstance\\n- Duration\\n- Topic\\n- Characteristic\\n- Interval\\n- Stimulus\\n- Possession\\n- Usually non-core semantic roles\\n- Experiencer\\n- Part/Portion\\n- Originator\\n- Accompaniere\\n- InsteadOf?\\n- Configuration\\n- Direction\\n- RefExtent\\n- Beneficiary\\n- Non-spatiotemporal information\\n- Means\\n- Instrument\\n- Quantity\\n- Static relations\\n- Approximator\\n- Purpose\\n- SocialRel\\n- OrgRole"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Construal- Challenge: the preposition itself and the verb may suggest different labels.\\n\\nSimilar meanings: the same label?\\n1. Vernon works at Grunnings\\n- \"at Grunnings\": Locus or OrgRole?\\n2. Vernon works for Grunnings\\n- \"for Grunnings\": Beneficiary or OrgRole?\\n- Approach: distinguish scene role and preposition function."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Construal\\n- Scene role and preposition function may diverge: Locus > OrgRole\\n1. Vernon works at Grunnings\\n2. Vernon works for Grunnings\\n\\nBeneficiary > OrgRole\\n- Function # Scene Role in 1/3 of instances"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Documentation\\n- Large number of labels, prepositions, constructions and ultimately languages; careful documentation is imperative\\n- Extensive guidelines\\n- 450 examples * 80 pages\\n- Xposition: (under development)\\n- A web-app and repository of prepositions/supersenses\\n- Standardized format and querying tools to retrieve relevant examples/guidelines"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Re-annotated Dataset\\nSTREUSLE is a corpus annotated with (preposition) supersenses.\\n\\nText: review section of the English Web Treebank.\\n\\nComplete revision of STREUSLE: version 4.0.\\n\\nhttps://github.com/nert-gu/streusle.\\n- 5,455 target prepositions, including 1,104 possessives.\\n- 80:10:10% train:dev:test split.\\n\\nSee Blodgett and Schneider, LREC 2018 for details."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Preposition Distribution* 249 prepositions\\n- 10 account for 2/3 of the mass"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Supersense Distribution\\n- 47 attested supersenses\\n- Frequencies:\\n- 10% are spatial\\n- 10% are temporal\\n- 8% involve possession"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Inter-Annotator Agreement\\n- Annotated a small sample of The Little Prince\\n216 preposition tokens\\n\\n5 annotators, varied familiarity with scheme\\n\\nExact agreement (pairwise avg.):\\n74.4% on scene roles, 81.3% on functions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Disambiguation Models\\n- Most Frequent (MF) baseline: most frequent label for the preposition in training\\n- Neural: BiLSTM over sentence + multilayer perceptron per preposition\\n- Feature-rich linear: SVM per preposition, with features based on previous work (Srikumar & Roth\\n2013)\\n- Lexicon-based features: WordNet, Roget thesaurus to detect governor and object"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Target Identification\\n- Main challenges:\\n- Multi-word prepositions, especially rare ones (e.g., \"after the fashion of\")\\n- Idiomatic PPs (e.g., \"in action\", \"by far\")\\n- Approach: rule-based\\n- Results: A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Disambiguation Results\\n\\nWith gold standard syntax & target identification:\\n\\nQO anne erect teteteeeetetnenntntntntnetetntentnentnntntntntnetetntntiststninntntnteinetceeB75 we sescenenentne sesceenentn\\n- AB wre\\n- seventeen\\n- 0 Role\\n- Acc Fxn\\n- Acc Full\\n- Acc «Most Frequent\\n- Neural s\\n- Feature-rich linear"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Results: Summary\\n- Predicting function label is more difficult than role label\\n- ~8% gap in F-score in both settings\\n- This mirrors a similar effect in IAA, and is probably due to:\\n- Less ambiguity in function labels (given a preposition)\\n- The more literal nature of function labels\\n- Syntax plays an important role\\n- 4-7% difference in performance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Results: Summary\\n- Neural and feature-rich approach are not far off in terms of performance.\\n- Feature-rich is marginally better.\\n- They agree on about 2/3 of cases; agreement area is 5% more accurate."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Multi-Lingual Perspective\\n\\nWork is underway in Chinese, Korean, Hebrew and German.\\n- Parallel Text: The Little Prince\\n\\nChallenges:\\n- Complex interaction with morphology (e.g., via case)\\n- How do prepositions change in translation?\\n- How do role/function labels change in translation?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Conclusione\\n\\nA new approach to comprehensive analysis of the semantics of prepositions and possessives in English.\\n- Simpler and more concise than previous version.\\n- Good inter-annotator agreement.\\n- Extensive documentation.\\n- Encouraging initial disambiguation results."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Ongoing Work\\n\\nFocus on:\\n- Multi-lingual extensions to four languages\\n- Streamlining the documentation and annotation processes\\n- Semi-supervised and multi-lingual disambiguation systems\\n- Integrating the scheme with a structural scheme (UCCA)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Acknowledgments\\n\\nCU annotators\\n\\nDiscussion and Support\\n\\nSpecial Thanks\\n- Evan Coles-Harris\\n- Oliver Richardson\\n- Noah Smith\\n- Audrey Farber\\n- Na-Rae Han\\n- Mark Steedman\\n- Nicole Gordiyenko\\n- Archna Bhatia\\n- Claire Bonial\\n- Megan Hutto\\n- Tim O'Gorman\\n- Tim Baldwin\\n- Celeste Smitz\\n- Ken Litkowski\\n- Miriam Butt\\n- Tim Watervoort\\n- Bill Croft\\n- Chris Dyer\\n- Martha Palmer\\n- Ed Hovy\\n\\nCMU pilot annotators\\n- Lingpeng Kong\\n- Lori Levin\\n- Archna Bhatia\\n- Ken Litkowski\\n- Carlos Ramirez\\n- Orin Hargraves\\n- Yulia Tsvetkov\\n- Michael Ellsworth\\n- Michael Mordowanec\\n- Dipanjan Das & Google\\n- Matt Gardner\\n- Spencer Onuffer\\n- Nora Kazour"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 378,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Agenda\\nIssue of false-alarm self-labeled data\\nDataset\\nDisambiguation of hashtag usage\\nIrony Detection\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Self-Labeled Data\\n\\nA large amount of self-labeled data available on the Internet are popular research materials in many NLP areas.\\nMetadata such as tags and emoticons given by users are considered as labels for training and testing learning-based models.\\nThe tweets with certain types of hashtags are collected as self-labeled data in a variety of research works.\\n- Sentiment analysis\\n- Stance detection\\n- Financial opinion mining\\n- Irony detection"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "It is impractical to manually annotate the ironic sentences from randomly sampled data due to the relatively low occurrences of irony.\\n\\nAlternatively, collecting the tweets with the hashtags like #sarcasm, #irony, and #not becomes the mainstream approach.\\n\\n@Anonymous doing a great job... #not What do I pay my extortionate council taxes for?\\n#Disgrace #OngoingProblem http://t.co/FQZUUwWKSoN\\n\\n@Anonymous doing a great job... What do I pay my extortionate council taxes for?\\n#Disgrace #OngoingProblem http://t.co/FQZUUWKSoN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "The reliability of the self-labeled data is an important issue.\\n\\nMisused Hashtag\\n\\nNot all tweet writers know the definition of irony.\\n\\nBest Pro Advice @Anonymous\\n\\nMore clean or cleaner, never more cleaner. #irony"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Hashtags Functioning as Content Words\\n\\nA hashtag in a tweet may also function as a content word.\\nIn its word form, the removal of the hashtag can change the meaning of the tweet, or even make the tweet grammatically incomplete.\\nThe #irony of taking a break from reading about #socialmedia to check my social media."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Two kinds of unreliable data are our targets to remove from the training data for irony detection.\\n- The tweets with a misused hashtag.\\n- The tweets in which the hashtag serves as a content word.\\n\\nCompared to general training data cleaning approaches, our work leverages the characteristics of hashtag usages in tweets.\\n\\nWith a small amount of golden labeled data, we propose a neural network classifier for pruning the self-labeled tweets, and train an ironic detector on the less but cleaner instances."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "The ground-truth is based on the dataset released for SemEval 2018 Task\\n3. The hashtag itself has been removed in the SemEval dataset.\\nThe hashtag information, the position and the word form of the hashtag (i.e., not, irony, or sarcasm), is missing.\\nWe recover the original tweets by using Twitter search.\\n\\nHashtag: False-Alarm: Irony: Total\\n\\nTotal 276 1,083 1,359"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "- Sigmoid\\n- Word sequences of the context preceding and following the targeting\\n- Serence\\n- Sentence\\n- ReLU\\n- Hashtag are separately encoded by neural network\\n- Encoder\\n- Sentence encoders.\\n- (Word embeddings\\n- Features LM\\n- CNN such as Hirony. You still have to #praisehim.\\n- e GRU JJ PRPRB VBPTO # NN :)\\n- e Attentive GRU vy JJ #NN PRPRB VBPTO # NN :)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Di biguat f Hasht | Sigmoid\\n- Handcrafted features\\n- ReLU\\n- Lengths of the tweet in words and in characters.\\n- Sentence Type of the target hashtag\\n- Encoder GRU\\n- Embeddings\\n- If the targeting hashtag is the first/last token in the tweet.\\n- If the targeting hashtag is the first/last hashtag in the tweet\\n- Position of the targeting hashtag"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Di biguati f Hasht| Sigmoid\\n- A tweet will be more grammatical complete with only the hash symbol.\\nReLU removed if the hashtag is also a content word.\\nOn the other hand, the tweet will be more grammatical complete with the whole anus.\\n\\nEncoder\\n- GRU-based language model on the level.\\n\\nFeatures\\n- POS tagging is used to measure the grammatical completeness of the tweet with and without the hashtag.\\n- Remove the whole hashtag removed.\\n- Remove the hash symbol # only.\\n- The original tweet."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Results of Hashtag Disambiguation\\n\\nBy integrating various kinds of information, our method outperforms all baseline models no matter which encoder is used.\\nThe best model is the one integrating the attentive GRU encoder, which is significantly superior to all baseline models (p < 0.05), achieving an F-score of 88.49%.\\nThe addition of language model significantly improves the performance (p < 0.05).\\n\\nModel : Encoder | Precision | Recall | F-score\\nWithout LM At.GRU | 88.17% | 80.52% | 84.17%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Training Data Pruning for Detection\\n\\nWe employ our model to prune self-labeled data for irony detection.\\n- A set of tweets that contain indication hashtags as (pseudo) positive instances.\\n- A set of tweets that do not contain indication hashtags as negative instances.\\n\\nOur model is performed to predict whether it is a real ironic tweet or false-alarm ones, and the false-alarm ones are discarded.\\n\\nPrior-Pruning\\n\\nPost-Pruning\\n- Positive Instances\\n- Negative Instances\\n- Tweets without Indication Hashtags\\n\\nTest Data\\n- Human-verified Positive Ironic Tweets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "We implement a state-of-the-art irony detector, which is based on an attentive-RNN classifier, and train it on the prior- and the post-pruned training data.\\n\\nThe irony detection model trained on the less, but cleaner instances significantly outperforms the model that is trained on all data (p < 0.05).\\n\\nThe irony detector trained on the small genuine data does not compete with the models that are trained on a larger amount of self-labeled data.\\n\\nData: Size: Precision | Recall | F-score\\nPost-Pruning | 9,234 80.88% 85.35% 83.08%\\nHuman Verified | 2,166 86.35% | 66.70% = 75.26%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "We can sort all self-labeled data by their calibrated confidence and control the size of the training set by adjusting the threshold.\\n\\nThe higher the threshold value is set, the less the training instances remain.\\n\\nThe best result achieved by the irony detector trained on the 9,234 data filtered by our model with the default threshold value (0.5).\\n\\nThis confirms that our model is able to strict data, and the bar indicates the F-score achieved by LENSE TVET the irony detector trained on those data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusions\\n\\nWe make an empirical study on an issue that is potentially inherited in a number of research topics based on self-labeled data.\\nWe propose a model for hashtag disambiguation. For this task, the human-verified ground-truth is quite limited.\\n\\nTo address the issue of sparsity, a novel neural network model for hashtag disambiguation is proposed.\\nThe data pruning method is capable of improving the performance of irony detection, and can be applied to other work relied on self-labeled data."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 99,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Outline\\n- Background\\n- Method\\n- Experiments\\n- Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "What is Automated Essay Scoring (AES)?\\n- Computer produces summative assessment for evaluation.\\n- Aim: reduce human workload.\\n\\nAES has been put into practical use by ETS from 1999."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Prompt-specific and -Independent AES\\n- Most existing AES approaches are prompt-specific\\n- Require human labels for each prompt to train\\n- Can achieve satisfying human-machine agreement. Quadratic weighted kappa (QWK) > 0.75 [Taghipour & Ng, EMNLP 2016]\\n- Inter-human agreement: QWK = 0.754\\n- Prompt-independent AES remains a challenge\\n- Only non-target human labels are available"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Challenges in Prompt-independent AES\\n\\nSource Prompts\\n\\nTarget Prompt\\n\\nPrompt 1: Winter Olympics\\n\\nPrompt 3: Australian Open"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Challenges in Prompt-independent AES\\n\\nSource Prompts\\n\\nTarget Prompt\\n\\nPrompt 1: Winter Olympics\\n\\nUnavailability of\\n\\nPrompt 2: Ri Waa iaol e for the World Cup\\n\\n2 Australian Open"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Challenges in Prompt-independent AES\\n\\nSource Prompts Target Prompt\\n\\nPrompt 1: Winter Olympics\\nLearn Predict\\n\\nWorld Cup\\n- World Cup\\n- Australian Open.\\n\\nPrevious approaches learn on source prompts:\\n- Domain adaptation (Phandi et al., EMNLP\\n2015)\\n- Cross-domain learning (Dong & Zhang, EMNLP\\n2016)\\n\\nAchieved Avg. QWK = 0.6395 at best with up to 100 labeled target essays."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Challenges in Prompt-independent AES\\n\\nSource Prompts\\n\\nTarget Prompt\\n\\nPrompt 1:\\n\\neee Learn Predict\\n\\nWorld Cup\\n- TA ola (oO) AONE)\\n\\nPrompt 3:\\n\\nOff-topic: essays written for source prompts are mostly irrelevant"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Outline\\n\\nBackground\\n\\nMethod\\n\\nExperiments\\n\\nConclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "TDNN: A Two-stage Deep Neural Network for Prompt-independent AES\\n\\nBased on the idea of transductive transfer learning\\n- Learn on target essays\\n- Utilize the content of target essays to rate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "The Two-stage Architecture\\n\\nNon-target Prompt\\n\\nPrompt-dependent independent stage:\\n- Train RankSVM\\n\\nPredict prompt\\n\\nHybrid Model\\n- Prompt-independent stage: train a shallow model to create pseudo labels on the target prompt"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "The Two-stage Architecture\\n\\nNon-target Prompt\\n\\nPrompt-dependent independent stage\\n- Train Rank SVM\\n- Predict\\n\\nTarget\\n\\nPseudo Hybrid Model\\n\\nPrompt examples\\n\\nTrain\\n\\nPrompt-dependent stage: learn an end-to-end model to predict essay ratings for the target prompts"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Prompt-independent stage\\n- Train a robust prompt-independent AES model\\n- Using non-target prompts\\n- Learning algorithm: RankS VM\\n- Pre-defined prompt-independent features\\n- Select confident essays written for the target prompt\\n\\nPredicted Scores Cn0 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Prompt-independent stage\\n- Train a robust prompt-independent AES model\\n- Using non-target prompts\\n- Learning algorithm: RankSVM\\n- Pre-defined prompt-independent features\\n- Select confident essays written for the target prompt\\n\\nPredicted Scores\\n0 4 10\\nPredicted ratings in [0, 4] as negative examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Prompt-independent stage\\n- Train a robust prompt-independent AES model\\n- Using non-target prompts\\n- Learning algorithm: RankSVM\\n- Pre-defined prompt-independent features\\n- Select confident essays written for the target prompt\\n- Common sense: >8 is good, <5 is bad\\n- Enlarge sample size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Prompt-dependent stage\\n- Train a hybrid deep model for a prompt-dependent assessment\\n- An end-to-end neural network with three parts of inputs:\\n- Word semantic embeddings\\n- Part-of-speech (POS) taggings\\n- Syntactic taggings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Architecture of the hybrid deep model\\n- Multi-layer structure: Words\\n- (phrases)\\n- Sentences\\n- Essay"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Architecture of the hybrid deep model\\n\\nConcatenate sem pos es nt\\n\\nEssay\\n\\nLayer never\\n\\nSentence\\n\\nLayer\\n\\nPhrase\\n\\nSemantic Network\\n\\nPOS Network\\n\\nSyntactic Network\\n\\nGlove word embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Architecture of the hybrid deep model\\n- Concatenate\\n- Sentence\\n- Layer\\n- Phrase\\n- Semantic Network\\n- POS Network\\n- Syntactic Network\\n- Part-of-speech taggings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Architecture of the hybrid deep model\\n\\nConcatenate semi-positions\\n\\nEssay Layer never. S1, S2, S3, S8, S0\\n5155250.\\n\\nSentence Layer\\n\\nPhrase Layer\\n\\nSemantic Network\\n\\nPOS Network\\n\\nSyntactic Network\\n\\nSyntactic taggings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Architecture of the hybrid deep model\\n\\nConcatenate\\n\\nEssay\\n\\nSentence\\n\\nLayer\\n\\nSemantic Network\\n\\nPOS Network\\n\\nSyntactic Network\\n\\nMulti-layer structure: Words\\n- (phrases)\\n- Sentences\\n- Essay"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Architecture of the hybrid deep model\\n\\nEssay\\n\\nLayer S1, S2, S3\\n\\nSentence\\n\\nLayer\\n\\nPhrase\\n\\nLayer W1, W2, W3\\n\\nSemantic Network\\n\\nPOS Network\\n\\nSyntactic Network"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Model Training\\n- Training loss: MSE on 0/1 pseudo labels\\n- Validation metric: Kappa on 30% non-target essays\\n- Select the model that can best rate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Dataset & Metrics\\n- We use the standard ASAP corpus\\n- 8 prompts with >10K essays in total\\n- Prompt-independent AES: 7 prompts are used for training, 1 for testing\\n- Report on common human-machine agreement metrics\\n- Pearson's correlation coefficient (PCC)\\n- Spearman's correlation coefficient (SCC)\\n- Quadratic weighted Kappa (QWK)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Baselines\\n- RankSVM based on prompt-independent handcrafted features\\n- Also used in the prompt-independent stage in TDNN.\\n- 2L-LSTM [Alikaniotis et al., ACL 2016]\\n- Two LSTM layers + linear layer\\n- CNN-LSTM [Taghipour & Ng, EMNLP 2016]\\n- CNN + LSTM + linear layer\\n- CNN-LSTM-ATT [Dong et al., CoNLL 2017]\\n- CNN-LSTM + attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "RankSVM is the most robust baseline QWK of the baselines on the 8 prompts 0.750 0.70 0.65 0.6 0.55 0.45 0.4 0.35 0.25\\n- High variance of DNN models' performance on all 8 prompts\\n- Possibly caused by learning on non-target prompts\\n- RankSVM appears to be the most stable baseline\\n- Justifies the use of RankSVM in the first stage of TDNN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Comparison to the best baseline\\n\\nPerformance of TDNN variants\\n\\n0.80\\n0.75\\n0.7\\n0.65\\n0.55\\n0.5\\n0.45\\n0.41\\n- TDNN outperforms the best baseline on 7 out of 8 prompts.\\n- Performance improvements gained by learning on the target prompt."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Average performance on 8 prompts\\n\\nCCB\\n\\nBaselines Rank\\n\\nSVM 5462 .6072 5976\\n\\nL-LSTM 4687 6548 6214\\n\\nCNN-LSTM 5362 .6569 .6139\\n\\nCNN-LSTM-ATT S0a7 6535 .6368\\n\\nTDNN\\n\\nTDNN(Sem) 3875 ogo 9 6795\\n\\nTDNN(Sem+POS) 6582 .7103 .7130\\n\\nTDNN(POS+Synt) .6784 7189 7322\\n\\nTDNN(ALL) .6682 .7176 7258"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Average performance on 8 prompts\\n\\nCCBaselines\\n\\nRank\\n\\nSVM 5462 .6072 5976\\n\\nL-LSTM 4687 6548 6214\\n\\nCNN-LSTM 5362 .6569 .6139\\n\\nCNN-LSTM-ATT 507 6535 .6368\\n\\nTDNN\\n\\nTDNN(Sem) 3875 6909 6795\\n\\nTDNN(Sem+POS) 6582 .7103 .7130\\n\\nTDNN(Sem+Synt) .6856 7244 .7365\\n\\nTDNN(POS+Synt) .6784 7189 7322"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Sanity Check: Relative Precision\\n\\nHow the quality of pseudo examples affects the performance of TDNN?\\nThe sanctity of the selected essays, namely, the number of positive (negative) essays that are better (worse) than all negative (positive) essays.\\n\\nSuch relative precision is at least 80% and mostly beyond 90% on different prompts.\\n\\nTDNN can at least learn from correct 0/1 labels."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Conclusions\\n- It is beneficial to learn an AES model on the target prompt.\\n\\nSyntactic features are a useful addition to the widely used Word2Vec embeddings.\\n- Sanity check: small overlap between pos/neg examples.\\n- Prompt-independent AES remains an open problem.\\n- ETS wants Kappa > 0.70.\\n- TDNN can achieve 0.68 at best."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Thank you!\\n\\nISGAS POWER INSTITUTE OF SOFTWARE\\n\\nCHINESE ACADEMY OF SCIENCES\\n\\nUniversity of Chinese Academy of Sciences"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 88,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "- Getting manually labeled data in each domain for sentiment analysis is always an expensive and a time-consuming task; cross-domain sentiment analysis provides a solution.\\n- However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another.\\n- Changing Significance: \"Entertaining, boring, one-note, etc.\" are significant for classification in the movie domain.\\n- Changing Polarity: \"Unpredictable plot of a movie\" // Positive sentiment \"Unpredictable behaviour of a machine\" // Negative sentiment"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "- Significant Consistent Polarity (SCP) words represent the transferable (usable) information across domains.\\n- We present an approach based on y' test and cosine similarity between context vector of words to identify polarity preserving significant words across domains.\\n- Furthermore, we show that a weighted ensemble of the classifiers enhances the cross-domain classification performance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Technique: Find SCPSignificant Consistent Polarity (SCP): SOT\\n\\nTransferable information from the source (S) to the target (T) for cross-domain SA.\\n\\nS: Significant words with their polarity orientation in the labeled source domain:\\n\\n72 test: 'unpredictable' has equal distribution in the positive and negative corpora.\\n\\n'Unpredictable' has significantly different count in either positive or negative corpus.\\n\\nIf X?\\nscore is greater than 3.85 => p-value < 0.05 => Probability of the observed value given null hypothesis is true is less than 0.05 => Reject the Null hypothesis => 'unpredictable' has occurred significantly more often in one of the classes with a v2 score of 4.5.\\n\\nHence, 'unpredictable' is positive."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Technique: Find SCP (2)\\nT: Significant words with their polarity orientation in the unlabeled target domain:\\n\\nSignificance: Normalized Count (Significant (w)) > 6 > Significant, (w)\\n\\nPolarity:\\nIf (cosine(conVec(w), conVec(pos-pivot)) > cosine(conVec(w), conVec(neg-pivot))) => Positive\\nIf (cosine(conVec(w), conVec(pos-pivot)) < cosine(conVec(w), conVec(neg-pivot))) => Negative\\n\\nNote: We construct a 100 dimensional vector for each candidate word from the unlabeled target domain data.\\n\\nSignificant Consistent Polarity (SCP): S NT\\nTransferable information from the source to the target for cross-domain SA.\\nraksha.sharma@tcs.com"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Example: Inferred polarity orientation in the Target Domain Word Great Bad Polarity (Pos-pivot) (Neg-pivot)\\n\\nCosine-similarity score with the Pos-pivot (great) and Neg-pivot (bad), and inferred polarity orientation of words in the movie domain.\\nraksha.sharma | @tes.com"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "The F-score for SCP words identification task: Electronics\\nAvailable at: Gold standard SCP words: Application of y? test in\\nBooks http://www.cs.jhu.edu/~mdredze/datasets/sentiment/ind both the domains considering target domain is also\\nKitchen ex2.html labeled gives us gold standard SCP words from the\\nDVD corpus. No manual annotation.\\n\\nSCL: Structured Correspondence Learning (Bhatt et al.,\\n2015)\\n\\nOur Approach\\nTM SCL Common Unigram\\n80 70 60 = 50 = 'a 40\\n- S 30 = 20\\n\\nFigure 1: F-score for SCP words identification task (source -> target) with respect to gold standard SCP words.\\nraksha.sharmal1@tcs.com"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Domain Adaptation Algorithm\\n\\nInput: D_i = {r_s) r' f watt} ! C(exampleDoc) = -0.07 (wrong prediction, negative)\\ni = {r, tt, ri, wlth, C(exampleDoc) = 0.33 (correct prediction, positive)\\nV_s = {ts 5%, oolWeta Lise\\n\\nOutput: Sentiment Classifier in the Target Domain.\\n\\n-0.07 * 0.765 + 0.33 * 0.712\\n\\nStep-1: SCP = sigPol(D_i) 1 sigPol(D')\\n\\nStep-2: C_i = Train-SVM(D_i), where f = SCP a\\n\\nStep-3: Predict Label: (,(D_i') + D_i)\\n\\nStep-4: Select: R?'| Y_r € D_i', C_i(r) > 4, where i € {1, 2....k} and n <= hk\\n\\nStep-5: C_i = Train-SVM(R_i'), where f = {unigrams(R_i')}\\n\\nStep-6: WSM = (C_i * W_a + C_i * W_b) / (W_a + W_b)\\n\\nStep-7: Sentiment Classifier in the Target Domain = WSM\\n\\nrash.sharmal@tcs.com"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Cross-domain Results\\n\\nJon oe Jon Jor oe\\n\\nSystem Name: Transferred Info\\n\\nSystem-2: SCL (Bhatt et al,\\n2015)\\n\\nSystem-4: System-1 + iterations\\n\\nSystem-6: System-3 + iterations\\n\\nCorrelation (r) of 0.78 between KopFscoe (Miguel) and nor wwwross-domain (system-3)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Conclusion\\n- Significant Consistent Polarity (SCP) words show a strong positive correlation of 0.78 with the sentiment classification accuracy achieved in the unlabeled target domain.\\n\\nEssentially, a set of less erroneous transferable features leads to a more accurate classification system in the unlabeled target domain.\\n\\nraksha.sharmal @tcs.com 10"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 4,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "A caine Background @ The proposed model\\n\\nContents\\n\\nExperiments and results\\n\\nRelated and future work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "9) BELA R apaacs lise. BipesesBz ie EFL A www.ia.ac.cn CASIA INSTITUTE OF AUTOMATION\\n\\nBackground\\n\\nAssumption: different languages can be mapped into one shared-latent space\\n- Shared encoder (L1/L2)\\n- decoder\\n- resource sentences\\n- latent space target sentences\\n- latent space source sentences\\n- encoder\\n- decoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Techniques based on\\n\\nInitialize the model with inferred bilingual dictionary\\n\\nUnsupervised word embedding mapping\\n\\nLearn strong language model\\n\\nDe-noising Auto-Encoding\\n\\nConvert unsupervised setting into a supervised one\\n\\nBack-translation\\n\\nConstrain the latent representation produced by encoders to a shared space\\n\\nfully-shared encoder fixed mapped embedding GAN"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "A caine We find\\n\\nThe shared encoder is a bottleneck for unsupervised NMT.\\nThe shared encoder is weak in keeping the unique and internal characteristics of each language, such as the style, terminology and sentence structure.\\nSince each language has its own characteristics, the source and target language should be encoded and learned independently.\\n\\nFixed word embedding also weakens the performance (not included in the paper).\\nIf you are interested in this part, you can find some discussions in our GitHub code: https://github.com/Zhen Yang IACAS/unsupervised-NMT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "The proposed model:\\n- Enc, Dec, -3 Base Networks\\n- Roles:\\n- 3 mags {Enc, Dec} AE for source language\\n- {Enc, Dec} AE for target language\\n- {Enc, Dec} translation source > target\\n- {Enc, Dec} translation target > source\\n- 1st local GAN (GAN1)\\n- 2nd local GAN (GAN2)\\n- 1st global GAN (GAN1)\\n- 2nd global GAN (GAN2)\\n\\nThe local GAN is utilized to constrain the source and target latent representations to have the same distribution (embedding-reinforced encoder is also designed for this purpose, see our paper for detail).\\n\\nThe global GAN is utilized to fine-tune the whole model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Experiment setup:\\n- Training sets: WMT 16 En-de, WMT 14 En-Fr, LDC Zn-En\\nNote: The monolingual data is built by selecting the front half of the source language and the back half of the target language.\\n- Test sets: newstest2016 En-de, newstest2014 En-Fr, NIST O2 En-Zh\\n- Model Architecture: 4 self-attention layers for encoder and decoder\\n- Word Embedding: applying the Word2vec to pre-train the word embedding utilizing Vecmap to map these embedding to a shared-latent space"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "A cata\\n\\nExperimental results: The effects of the weight-sharing layer number Layers for 7\\nmechanism sharing 26: 0 10.23 16.02 13.75 14 fi= &1 10.86 16.97 14.52 122 10.56 16.73 14.07\\n\\nEn2De3 10.63 16.50 13.92\\n\\nZh2En4 10.01 16.44 12.86\\n\\nSharing one layer achieves the best translation performance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "A caine\\n\\nExperimental results:\\n\\nThe BLEU results of the proposed model:\\n- en-de: 24.07\\n- de-en: 26.99\\n- en-fr: 30.50\\n- fr-en: 30.21\\n- zh-en: 40.02\\n\\nSupervised: 24.07\\nWord-by-word: 5.85\\nLample et al. (2017): 9.64\\nThe proposed approach: 10.86\\nBaseline 1: the word-by-word translation according to the similarity of the word embedding\\nBaseline 2: \"unsupervised NMT with monolingual corpora only\" proposed by Facebook.\\nUpper Bound: the supervised translation on the same model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "% HHA Experimental results:\\n\\nAblation study\\n- de-en: 10.23 13.84 16.02 14.82 13.75\\n- en-fr: 10.45 14.17 16.55 15.27 14.10\\n- fr-en: 10.60 14.21 16.82 15.30 14.29\\n- zh-en: 10.51 14.35 16.40 15.07 14.12\\n- Without Global GANs: 10.34 14.05 16.19 15.21 14.09\\n- Full model: 10.86 14.62 16.97 15.58 14.52\\n\\nWe perform an ablation study by training multiple versions of our model with some missing components: the local GAN, global GAN, the directional self-attention, the weight-sharing, and the embedding-reinforced encoder.\\n\\nWe do not test the importance of the auto-encoding, back-translation, and the pre-trained embeddings since they have been widely tested in previous works."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "A cataGA Baemsee\\n\\nSemi-supervised NMT (with 0.2M parallel data)\\n\\nContinue training the model after unsupervised training on the parallel data\\n\\nFrom scratch, training the model on monolingual data for one epoch, and then on parallel data for one epoch, and another one on monolingual data, on and on...\\n- Only with parallel data 11.59\\n- Fully unsupervised training 10.48\\n- Continuing training on supervised data 14.51\\n- Jointly training on monolingual and parallel data 15.79"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Acaine\\n\\nRelated works:\\n- G. Lample, A. Conneau, L. Denoyer, and M. Ranzato.\\n2018. Unsupervised machine translation using monolingual corpora only.\\nIn International Conference on Learning Representations (ICLR).\\n- Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho.\\n2018. Unsupervised neural machine translation. In International Conference on Learning Representations (ICLR).\\n- G. Lample, A. Conneau, L. Denoyer, and M. Ranzato.\\n2018. Phrase-Based & Neural Unsupervised Machine Translation (arxiv).\\nThe newest paper (third one) proposes the shared BPE method for unsupervised NMT, its effectiveness is to be verified (around +10 BLEU points improvement is presented)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "A future work:\\n- Continuing testing the unsupervised NMT and seeking to find its optimal configurations.\\n- Testing the performance of semi-supervised NMT with a little amount of bilingual data.\\n- Investigating more effective approaches for utilizing the monolingual data in the framework of unsupervised NMT."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "A caterCode and new results can be found at: https://github.com/ZhenYangIACAS/unsupervised-NMT"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 1,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "ACL 2018 Motivations\\n\\nDistributed representations for words/text have had lots of successes in NLP (language models, machine translation, text classification)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "ACL 2018\\n\\nMotivations\\n\\nDistributed representations for words/text have had lots of successes in NLP (language models, machine translation, text classification).\\n\\nMotivations for our work:\\n- Can we induce embeddings for all kinds of features, especially those with very few occurrences (e.g.\\nngrams, rare words)?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "ACL 2018\\n\\nMotivations\\n\\nDistributed representations for words/text have had lots of successes in NLP (language models, machine translation, text classification).\\n\\nMotivations for our work:\\n- Can we induce embeddings for all kinds of features, especially those with very few occurrences (e.g.\\nn-grams, rare words)\\n- Can we develop simple methods for unsupervised text embedding that compete well with state-of-the-art LSTM methods"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "ACL 2018\\n\\nMotivations\\n\\nWe make progress on both problems.\\n- Simple and efficient method for embedding features (ngrams, rare words, synsets).\\n- Simple text embeddings using ngram embeddings which perform well on classification tasks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "ACL 2018\\n\\nWord embeddings\\n- Core idea: Co-occurring words are trained to have high inner product. E.g. LSA, word2vec, GloVe and variants."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "ACL 2018\\n\\nWord embeddings\\n- Core idea: Cooccurring words are trained to have high inner product. E.g. LSA, word2vec, GloVe and variants\\n- Require few passes over a very large text corpus and do non-convex optimization."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "ACL 2018\\n\\nWord embeddings\\n- Core idea: Co-occurring words are trained to have high inner product. E.g. LSA, word2vec, GloVe and variants.\\n- Require few passes over a very large text corpus and do non-convex optimization.\\n\\nOptimizing word embeddings\\n- Used for solving analogies, language models, machine translation, text classification."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "ACL 2018\\n\\nFeature embeddings\\n- Capturing meaning of other natural language features\\n- E.g. n-grams, phrases, sentences, annotated words, synsets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "ACL 2018\\n\\nFeature embeddings\\n- Capturing meaning of other natural language features\\n- E.g. ngrams, phrases, sentences, annotated words, synsets\\n- Interesting setting: features with zero or few occurrences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "ACL 2018\\n\\nFeature embeddings\\n- Capturing meaning of other natural language features\\n- E.g. ngrams, phrases, sentences, annotated words, synsets\\n- Interesting setting: features with zero or few occurrences\\n- One approach (extension of word embeddings): Learn embeddings for all features in a text corpus | Optimizing | d feature corpus Ss = -) | i embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "ACL 2018\\n\\nFeature embeddings\\n\\nIssues\\n- Usually need to learn embeddings for all features together\\n- Need to learn many parameters\\n- Computation cost paid is prix fixe rather than a la carte\\n- Bad quality for rare features"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "ACL 2018\\nFeature embeddings\\nFirth revisited: Feature derives meaning from words around it"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "ACL 2018\\nFeature embeddings\\nFirth revisited: Feature derives meaning from words around it\\n\\nGiven a feature f and one (few) context(s) of words around it, can we find a reliable embedding for f efficiently?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "ACL 2018\\n\\nFeature embeddings\\n\\nFirth revisited: Feature derives meaning from words around it\\n\\nGiven a feature f and one (few) context(s) of words around it, can we find a reliable embedding for f efficiently?\\n\\nScientists attending ACL work on cutting edge research in NLP\\n\\nPetrichor: the earthy scent produced when rain falls on dry soil\\n\\nRoger Federer won the first set of the match"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "ACL 2018\\n\\nProblem setup\\n\\nGiven: Text corpus and high quality word embeddings trained on it\\n- Input: A feature in context(s)\\n- Output: Good quality embedding for the feature"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "ACL 2018\\n\\nLinear approach\\n- Given a feature f and words in a context c around it\\n\\n1 avg __WwEc"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "ACL 2018\\n\\nLinear approach\\n- Given a feature f and words in a context c around it\\n\\n1 avgVv =\\n- V,f Ic|\\n\\nIssues\\n- Stop words (\"is\", \"the\") are frequent but are less informative.\\n- Word vectors tend to share common components which will be amplified."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "ACL 2018 Potential Tixes\\n- Ignore stop words"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ACL 2018\\n\\nPotential fixes\\n- Ignore stop words\\n- SIF weights!: Down-weight frequent words (similar to tf-idf)\\n\\na, = --Ue = Ic] Aw Vw at Dywee Pw is frequency of w in corpus\\n\\n1: Arora et al. '17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "ACL 2018\\n\\nPotential fixes\\n- Ignore stop words\\n- SIF weights!: Down-weight frequent words (similar to tf-idf)\\n\\n1 aky =\\n- \"Fig Dah eaWec Pw is frequency of w in corpus\\n- All-but-the-top?: Remove the component of top direction from word vectors\\n\\n1 u = top_direction({v,,}) vp =\\n- > vy, = I\\n- uul) vy\"9[c| ee Vy = remove_component(vy,\\nU)\\n\\n1: Arora et al. '17, 2: Mu et al. '18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "ACL 2018\\n\\nOur more general approach\\n- Down-weighting and removing directions can be achieved by matrix multiplication\\n\\n1 avg ;Vp &\\nA) Vy = Av;\\n\\nInduced Embedding\\n\\nIC| WEC fInduction Matrix"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "ACL 2018\\n\\nOur more general approach\\n- Down-weighting and removing directions can be achieved by matrix multiplication.\\n\\n1 avg\\n- Induced Embedding\\n\\nwy = Avy Wwec\\n\\nInduction Matrix\\n- Learn A by using words as features\\n\\nA* = argmin luy\\n- Avy 7/2Ww\\n- Learn A by linear regression and is unsupervised"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "ACL 2018\\n\\nTheoretical justification\\n- [Arora et al.\\nTACL'18] prove that under a generative model for text, there exists a matrix A which satisfies Vw © Avy 2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "ACL 2018\\n\\nTheoretical justification\\n- [Arora et al. TACL'18] prove that under a generative model for text, there exists a matrix A which satisfies vy = A vy\\n\\n2\\n- Empirically we find that the best A* recovers the original word vectors cosine(vy, A* vy, \") = 0.9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "ACL 2018 A la carte embeddings\\n1. Learn induction matrix S * | ~ | A* = argmin, ». | Yy\\n- Avy \"13 Linear"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "ACL 2018 A la carte embeddings = an1. Learn induction matrix iA* = argmin, ». lu, -Av,, 7 |3 Smearnt\\n2. A la carte embeddings Gy) Jn O1 oi aang ae (EY oy) OoWwEc :"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "ACL 2018 A la carte embeddings pone, Only once!\\n1. Learn induction matrix A* = argmin, lu, -Av\\n2. A la carte embeddings Gy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "ACL 2018\\n\\nAdvantages\\n- ala carte: Compute embedding only for given feature\\n- Simple optimization: Linear regression\\n- Computational efficiency: One pass over corpus and contexts\\n- Sample efficiency: Learn only d parameters for A (rather than Vd)\\n- Versatility: Works for any feature which has at least 1 context"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Effect of induction matrix\\n- We plot the extent to which A* down-weights words against frequency of words compared to all-but-the-top"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Effect of induction matrix\\n- We plot the extent to which A* down-weights words against frequency of words compared to all-but-the-top.\\n\\nChange in Embedding Norm under Transform 7 = .\\ntt A* mainly down-weights words with very high significance, and very low frequency.\\nAll-but-the-top mainly down-weights frequent words.\\n\\nAll-but-the-Top log(count)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "ACL 2018\\n\\nEffect of number of contexts\\n\\nContextual Rare Words (CRW) dataset? Providing contexts for rare words.\\n- Task: Predict human-rated similarity scores for pairs of words.\\n- Evaluation: Spearman's rank coefficient between inner product and score.\\n\\n1: Subset of RW dataset [Luong et al. '13]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "ACL 2018 Contextual Rare Words (CRW) dataset? Providing contexts for rare words.\\n\\nTask: Predict human-rated similarity scores for pairs of words.\\n\\nEvaluation: Spearman's rank coefficient between inner product and score.\\n\\nCRW Similarity Task.\\n\\nAverage Compare to the following methods:\\n- Average, all-but-the-top: 0.35\\n- EVETaRE: no stop words\\n- Average of words in context: 0.30\\n- A la carte: Average of non stop words\\n- SIF weighted average all-but-the-top: 0.20\\n\\n1 2 4 8 16 32 64 128 Number of Contexts\\n\\nSubset of RW dataset [Luong et al. '13]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "ACL\\n2018.\\n\\nNonce definitional task\\n\\nTask: Find embedding for unseen word/concept given its definition.\\n\\nEvaluation: Rank of word/concept based on cosine similarity with true embedding.\\n\\nIodine: is a chemical element with symbol I and atomic number\\n53.\\n\\nHerbelot and Baroni '17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "ACL 2018\\n\\nNonce definitional task\\n\\nTask: Find embedding for unseen word/concept given its definition\\n\\nEvaluation: Rank of word/concept based on cosine similarity with true embedding\\n\\niodine: is a chemical element with symbol I and atomic number 53\\n\\nMethod\\n\\nMean Reciprocal Rank  Median Rank\\n\\nword2vec  0.00007  111012\\n\\napdiited version average  0.00945  3381\\n\\nof word2vec it average, no stop words  0.03686  861\\n\\nnonce2vec!  0.04907  623\\n\\na la carte  0.07058  165\\n\\n51: Herbelot and Baroni '17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "ACL 2018\\n\\nInduce embeddings for n-grams using contexts from a text corpus.\\nWe evaluate the quality of embedding for a bigram f = (Ww, Wz) by looking at closest words to this embedding by cosine similarity.\\n\\nMethod\\n- beef up\\n- cutting edge\\n- harry potter\\n- tight lipped\\n- veda = vy\\n- Ww\\n- meat\\n- out cut\\n- edges\\n- deathly\\n- azkaban\\n- loose\\n- fitting\\n- ve! | but\\n- however which\\n- both which\\n- but\\n- but\\n- however\\n- ECO! | meats\\n- meat\\n- weft\\n- edges\\n- robards\\n- keach\\n- scaly\\n- bristly\\n- Sent2Vec? | add\\n- reallocate\\n- science\\n- multidisciplinary\\n- naruto\\n- pokemon\\n- wintel\\n- codebase\\n- alacarte (A*ve\") | need\\n- improve\\n- innovative\\n- technology\\n- deathly\\n- hallows\\n- worried\\n- very\\n\\n1: Poliak '17\\n2: Pagliardini et al. '18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "ACL 2018 Unsupervised text embeddings This great!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "ACL 2018\\n\\nUnsupervised text embeddings\\n\\nThis a movie\\n\\nGreat! Sparse LSTM Linear Bag-of-words, Bag-of-ngrams\\n- Predict surrounding words/sentences\\n- Sum of word/ngram embeddings\\n\\nGood performance SOTA on some tasks\\nCompete with Bag-of-ngrams and LSTMs on some tasks"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "ACL 2018\\n\\nA la carte text embeddings\\n\\nLinear schemes are typically weighted sums of n-gram embeddings"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "ACL 2018\\n\\nA la carte text embeddings\\n\\nLinear schemes are typically weighted sums of n-gram embeddings\\n\\nTypes of n-gram embeddings\\n\\nSent2Vec\\n\\nA La Carte\\n\\nCompositional Learned\\n\\nFlexible High quality"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "ACL 2018\\n\\nA la carte text embeddings\\n\\nLinear schemes are typically weighted sums of n-gram embeddings.\\n\\nTypes of n-grams:\\n\\nA La Carte text embeddings are concatenations of embeddings, sum of a la carte n-gram embeddings (as in DisC).\\n\\nSent2Vec\\n- ats IV\\n- document\\n- word\\n- oigram prey\\n- unigram\\n\\nA La Carte\\n- Compositional\\n- Learned\\n- Flexible\\n- High quality"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "ACL 2018\\n\\ndocument = y\\n\\nMethod              dimension  MR   CR   SUBJ   MPQA  TREC  SST (+1)  SST  IMDB\\nSparse + Bag-of-ngrams     100K-1M  77.8  78.3  91.8   85.8  90.0  80.9  42.3  89.8\\n\\nSkip-thoughts?            4800    80.3  83.8  94.2   88.9  93.0  85.1  45.8\\n\\nSDAE2                     2400    74.6  78.0  90.8   86.9  78.4\\n\\nLSTM-CNN-LSTM?           4800    77.8  82.0  93.6   89.4  92.6\\n\\nMc-QT*                   4800    82.4  86.0  94.8   90.2  92.4  87.6\\n\\nDisC> 2-3 <              4800    80.1  81.5  92.6   87.9  90.0  85.5  46.7  89.6\\n\\nSent2Vec®                700     76.3  79.1  91.2   87.2  85.8  80.2  31.0  85.5\\n\\nLinear                   2400    81.3  83.7  93.5   87.6  89.0  85.8  47.8  90.3\\n\\nà la carte:              4800    81.8  84.3  93.8   87.6  89.0  86.7  48.1  90.9\\n\\n1: Kiros et al. '15,\\n2: Hill et al. '16,\\n3: Gan et al. '17,\\n4: Logeswaran and Lee '18,\\n5: Arora et al. '18,\\n6: Pagliardini et al. '18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "ACL 2018\\n\\nConclusions\\n- Simple and efficient method for inducing embeddings for many kinds of features, given at least one context of usage.\\n- Embeddings produced are in the same semantic space as word embeddings.\\n- Good empirical performance for rare words, n-grams and synsets.\\n- Text embeddings that compete with unsupervised LSTMs.\\n\\nCode is on GitHub: https://github.com/NLPrinceton/ALaCarte\\n\\nCRW dataset available: http://nlp.cs.princeton.edu/CRW/"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "ACL 2018\\n\\nFuture work\\n- Zero shot learning of feature embeddings\\n- Compositional approaches\\n- Harder to annotate features (synsets)\\n- Contexts based on other syntactic structures"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "ACL 2018\\n\\nThank you!\\n\\nQuestions?\\n{nsaunshi, mkhodak}@cs.princeton.edu"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 370,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Motivation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "B IUN LPMotivation\\n- Processing long, complex sentences is hard!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "B | UaaN LPe Processing long, complex sentences is hard!\\n\\nChildren, people with reading disabilities, L2 learners...\\n\\nSimple English WIKIPEDIA\\n\\nWhen writing articles here:\\n- Use Basic English vocabulary and shorter sentences.\\nThis allows people to understand normally complex terms or phrases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Processing long, complex sentences is hard!\\n\\nChildren, people with reading disabilities, L2 learners...\\n\\nSentence level NLP systems: Simple English\\n\\nWhen writing articles here: Use Basic English vocabulary and shorter sentences.\\nThis allows people to understand normally complex terms or phrases."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Bl UaaN LPMotivatie\\n\\nProcessing long, complex sentences is hard! Children, people with reading disabilities, L2 learners...\\n- Sentence level NLP systems:\\n- Dependency Parsers\\n\\nMcDonald & Nivre, 2011"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "aN LPMotivatione Processing long, complex sentences is hard!\\n\\nBLEU Scores with Varying Sentence Length\\n\\nChildren, people with reading disabilities, L2 learners...\\n\\nBe a Re\\n\\nSentence level NLP systems:\\n\\nDependency Parsers\\n\\nNeural Machine Translation\\n\\nKoehn & Knowles, 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "aN LPM | Motivation Processing long, complex sentences is hard!\\n\\nBLEU Scores with Varying Sentence Lengths\\n- Children, people with reading disabilities, L2 learners: 34.7\\n- e a ifn: 32.3\\n- Sentence level NLP systems: B 30 296-68\\n- Dependency Parsers: 26.9\\n\\nNeural Machine Translation\\n\\nCan we automatically break a complex sentence into several simple ones while preserving its meaning?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "The Split and Rephrase Task"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "B I UN LP The Split and Rephrase Task\\nNarayan, Gardent, Cohen & Shimorina, EMNLP 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "The Split and Rephrase Task\\nNarayan, Gardent, Cohen & Shimorina, EMNLP 2017\\n- Dataset, evaluation method, baseline models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "The Split and Rephrase Task\\nNarayan, Garden, Cohen & Shimorina, EMNLP 2017\\n\\nDataset, evaluation methods, baseline models\\n\\nTask definition: complex sentence -> several simple sentences with the same meaning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "The Split and Rephrase Task\\nNarayan, Gardent, Cohen & Shimorina, EMNLP 2017\\n\\nDataset, evaluation method, baseline models\\n\\nTask definition: complex sentence -> several simple sentences with the same meaning\\n\\nAlan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as backup pilot and David Scott as commander."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "BluaaN LP\\nThe Split and Rephrase Task\\nNarayan, Gardent, Cohen & Shimorina, EMNLP 2017\\n- Dataset\\n- Evaluation method\\n- Baseline models\\n\\nTask definition: complex sentence -> several simple sentences with the same meaning\\n\\nAlan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as backup pilot and David Scott as commander.\\nAlan Bean served as a crew member of Apollo\\n12. Alfred Worden was the backup pilot of Apollo\\n12. Apollo 12 was commanded by David Scott. Alan Bean was selected by NASA in 1963."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "The Split and Rephrase Task\\nNarayan, Gardent, Cohen & Shimorina, EMNLP 2017\\n\\nDataset, evaluation method, baseline models\\n\\nTask definition: complex sentence -> several simple sentences with the same meaning\\n\\nRequires\\n(a) identifying independent semantic units\\n(b) rephrasing those units to single sentences\\n\\nAlan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as backup pilot and David Scott as commander.\\nAlan Bean served as a crew member of Apollo\\n12.\\nAlfred Worden was the backup pilot of Apollo\\n12.\\nApollo 12 was commanded by David Scott.\\nAlan Bean was selected by NASA in 1963."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "This Work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "B I UA]NLPe We show that simple neural models seem to perform very well on the original benchmark due to memorization of the training set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "We show that simple neural models seem to perform very well on the original benchmark due to memorization of the training set.\\nWe propose a more challenging data split for the task to discourage memorization."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "We show that simple neural models seem to perform very well on the original benchmark due to memorization of the training set.\\nWe propose a more challenging data split for the task to discourage memorization.\\nWe perform automatic evaluation and error analysis on the new benchmark, showing that the task is still far from being solved."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "B I UN LPWeb Split Dataset Construction (Narayan et al. 2017)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "B I UaaN LPWebSplit Dataset Construction (Narayan et al.\\n2017)\\n\\nSimple RDF Triples (facts from DBpedia)\\n\\n<Alan_Bean | nationality | United_States>\\n\\n<Alan_Bean | mission | Apollo_12>\\n\\n<Alan_Bean | NASA selection | 1963>"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "B I UaaN LPWebSplit Dataset Construction (Narayan et al.\\n2017)\\n\\nSimple RDF Triples (facts from DBpedia)\\n- <Alan_Bean | nationality | United_States> Alan Bean is a US national.\\n- <Alan_Bean | mission | Apollo_12> Alan Bean was on the crew of Apollo\\n12.\\n- <Alan_Bean | NASA selection | 1963> Alan Bean was hired by NASA in 1963."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "B I UaaN LPWebSplit Dataset Construction (Narayan et al.\\n2017)\\n\\nSimple RDF Triples (facts from DBpedia)\\n\\nSIMple Setteriegy\\n\\n<Alan_Bean | nationality | United_States> Alan Bean is a US national.\\n<Alan_Bean | mission | Apollo_12> Alan Bean was on the crew of Apollo\\n12.\\n<Alan_Bean | NASA selection | 1963> Alan Bean was hired by NASA in\\n1963.\\n\\nSets of RDF triples\\n<Alan_Bean | nationality | United_States,\\n<Alan_Bean | mission | Apollo_12,\\n<Alan_Bean | NASA selection | 1963>"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "B I UaaN LPWebSplit Dataset Construction (Narayan et al.\\n2017)\\n\\nSimple RDF Triples (facts from DBpedia)\\n- <Alan_Bean | nationality | United_States> Alan Bean is a US national.\\n- <Alan_Bean | mission | Apollo_12> Alan Bean was on the crew of Apollo\\n12.\\n- <Alan_Bean | NASA selection | 1963> Alan Bean was hired by NASA in\\n1963.\\n\\nComplex Sets of RDF triples Sentences\\n- Alan Bean, born in the United States, was selected by NASA in 1963 as a crew member of"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "B I UaaN LPWebSplit Dataset Construction (Narayan et al.\\n2017)\\n\\nSimple RDF Triples (facts from DBpedia)\\n- <Alan_Bean | nationality | United_States> Alan Bean is a US national.\\n- <Alan_Bean | mission | Apollo_12> Alan Bean was on the crew of Apollo\\n12.\\n- <Alan_Bean | NASA selection | 1963> Alan Bean was hired by NASA in\\n1963.\\n\\nMatching via RDFs ~1M examples\\n\\nComplex Alan_B t I United_States,\\n- Alan Bean, born in the United States, was selected by NASA in 1963 as a crew member of"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "B I U Preliminary Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "B I UN LP Preliminary Experiments\\n\\n1 M training examples\\n\\n\"Vanilla\" LSTM seq2seq with attention\\n\\nGoal of 1 simple 2 simple 3 complex sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "B I U1NLPe 1M training examples \"Vanilla\" LSTM seq2seq with attention Shared vocabulary between the encoder and the decoder Go simple 1 simple 2 simple 3 complex sentence OS eseeninnensesess unease"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "B I Uan LPe ~1M training examples \"Vanilla\" LSTM seq2seq with attention\\n\\nShared vocabulary between the encoder and the decoder.\\n\\nSimple sentences predicted as a single sequence:\\n- simple 1\\n- simple 2\\n- simple 3\\n- complex sentence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "B I U a N L P e ~1 M training examples \"Vanilla\" LSTM seq2seq with attention Shared vocabulary between the encoder and the decoder\\n- Simple sentences predicted as a single sequence Evaluated using single-sentence, multi-reference BLEU as in Narayan et al.\\n2017 Go simple 1 simple 2 simple 3 complex sentence O S seen in sentences unease"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Bl UN LP Preliminary Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "B I UaaNLP Preliminary Results\\n\\nOur simple seq2seq baseline outperformed all but one of the baselines from Narayan et al.\\n2017.\\n- 60\\n- 200 TM seq2seq (ours)\\n- hybrid-seq2seq\\n- multi-seq2seq\\n- split-multi\\n- split-seq2seq"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "B I UaaN LP Preliminary Results\\n\\nOur simple seq2seq Text Only: Text + RDFs baseline outperform all but one of the baselines from Narayan et al.\\n2017. Their best baselines were 4, using the RDF structures as additional information.\\n- 3Mi seq2seq (ours)\\n- Mf hybrid-seq2seq\\n- W multi-seq2seq\\n- split-multi\\n- M split-seq2seq"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "B I UaaN LP Preliminary Results\\n\\nOur simple seq2seq Text Only: Text + RDFs baseline outperform all but one of the baselines from Narayan et al.\\n2017. Their best baselines were using the RDF structures as additional information.\\n\\nDo the simple seq2seq model really perform so well?\\n\\nseq2seq (ours)\\n- hybrid-seq2seq\\n- multi-seq2seq\\n- split-multi\\n- split-seq2seq"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "BLEU can be misleading"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "B BLEU can be misleading. In spite of the high BLEU scores, our neural models suffer from:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "In spite of the high BLEU scores, our neural models suffer from:\\n- Missing facts\\n- appeared in the input but not in the output\\n\\nInput Prediction\\n\\nA Fortress of Grey Ice with ISBN 0-7653-0633-6 has 672 pages. A Fortress of Grey Ice has 672 pages.\\nThe address, 11 Diagonal Street is located in South Africa where the leader is Cyril Ramaphosa.\\nThe leader of South Africa is called Cyril Ramaphosa and some Asian South Africans live.\\nThe leader of South Africa is called Cyril Ramaphosa."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "In spite of the high BLEU scores, our neural models suffer from:\\n- Missing facts\\n- appeared in the input but not in the output\\n- Unsupported facts\\n- appeared in the output but not in the input\\n- Repeated facts\\n- appeared several times in the output\\n\\nInput Prediction\\n\\nA Fortress of Grey Ice with ISBM 0-7653-0633-6 has 672 pages. A Fortress of Grey Ice has 672 pages.\\nThe address, 11 Diagonal Street is located in South Africa.\\nThe leader of South Africa is called Cyril Ramaphosa and some Asian South Africans live.\\nThe leader of South Africa is called Cyril Ramaphosa."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "B I UNLPA Closer Look"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Blu1NLPA Closer Look\\n\\nVisualizing the attention weights we find an unexpected pattern"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "B I U = aN LPaoRSe\\n\\nVisualizing the attention weights, we find an unexpected pattern.\\nThe network mainly attends to a single token instead of spreading the attention.\\n\\nPublished: The Wizard of Mars, ISBN number 978-0-15-204770-2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Bl UaaN LPaeSe Visualizing the attention weights, we find an unexpected pattern.\\nThe network mainly attends to a single token instead of spreading the attention.\\nThis token was usually a name, part of the first mentioned entity.\\n\\nISBN number 978-0-15-204770-2"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Bl UaaN LPov\\n- Visualizing the attention weights we find an unexpected pattern.\\nThe network mainly attends to a single token instead of spreading the attention.\\nThis token was usually a part of the first mentioned entity. Consistent among different input examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "BiU = aN LP & x xe Visualizing the attention & SoBe & Codon weights we find an unexpected pattern located\\n- The network mainly attends to a single token instead of spreading the attention.\\nThis token was usually a part of the first mentioned entity. Consistent among different input examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "aN LPA Closer Looking? °, & Ge\"e Visualizing the attention BS SES SES PS. weights we find an unexpected pattern.\\nThe network mainly attends to a single token instead of spreading the attention.\\nThis token was usually a part of the first mentioned conference entity. Consistent among different input examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Bl UN LP Testing for Over-Memorization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "BluNL PTesting for Over-Memorization\\n\\nIn this stage we suspect that the network heavily memorizes entity-fact pairs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "BluaNLP Testing for Over-Memorization\\n\\nIn this stage we suspect that the network heavily memorizes entity-fact pairs.\\nWe test this by introducing it with inputs consisting of repeated entities alone.\\n\\nInput Prediction\\n\\nAlan Shepard\\nAlan Shepard\\nAlan Shepard"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Blu1NLP Testing for Over-Memorization\\n\\nIn this stage we suspect that the network heavily memorizes entity-fact pairs.\\nWe test this by introducing it with inputs consisting of repeated entities alone.\\nThe network indeed generates facts it memorized about those specific entities.\\n\\nInput Prediction\\n\\nAlan Shepard\\n\\nAlan Shepard\\n\\nAlan Shepard\\n\\nAlan Shepard is dead.\\n\\nAlan Shepard was a test pilot."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Blu1 NLP Testing for Over-Memorization\\n\\nIn this stage we suspect that the network heavily memorizes entity-fact pairs.\\nWe test this by introducing it with inputs consisting of repeated entities alone.\\nThe network indeed generates facts it memorized about those specific entities.\\n\\nInput Prediction\\n- Alan Shepard Alan Shepard Alan Shepard Alan Shepard is dead.\\n- Alan Shepard was a test pilot.\\n- AFC Ajax AFC Ajax AFC Ajax AFC Ajax's manager is Jong Ajax.\\n- AFC Ajax N.V. owns Sportpark De Toekomst."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Bl UN LPSearching for the Cause: Dataset Artifacts"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "Bl UN LPSearching for the Cause: Dataset Artifacts The original dataset included overlap between the training/development/test sets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "BluaNL P\\n\\nSearching for the Cause: Dataset Artifacts\\n\\nThe original dataset included overlap between the training/development/test sets.\\nWhen looking at the complex sentences side, there is no overlap.\\n\\nDev Complex Train source | Complex Test Complex"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "BluaNL PSearching for the Cause: Dataset Artifacts\\n\\nThe original dataset included overlap between the training/development/test sets.\\nWhen looking at the complex sentences side, there is no overlap.\\nOn the other hand, most of the simple sentences did overlap (~90%).\\n\\nDev (cov Complex laTrain\\n- source | Complex Train Simple) target Test Crest Complex (Simo)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Searching for the Cause: Dataset Artifacts\\n\\nThe original dataset included overlap between the training/development/test sets.\\nWhen looking at the complex sentences side, there is no overlap.\\nOn the other hand, most of the simple sentences did overlap (~90%).\\n\\nMakes memorization very effective\\n- \"leakage\" from train on the target side."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "B I UN LP New Data Split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Bl UaN LP New Data Split\\n- To remedy this, we construct a new data split by using the RDF information:"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "Bl UaaN LP New Data Split\\n- To remedy this, we construct a new data split by using the RDF information:\\n- Ensuring that all RDF relation types appear in the training set (enable generalization)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Bl UaN LP New Data Split\\n- To remedy this, we construct a new data split by using the RDF information:\\n- Ensuring that all RDF relation types appear in the training set (enable generalization)\\n- Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Bl UaaN LP\\n\\nNew Data Split\\n\\nTo remedy this, we construct a new data split by using the RDF information:\\n- Ensuring that all RDF relation types appear in the training set (enable generalization)\\n- Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)\\n\\nThe resulting dataset has no overlapping simple sentences.\\n\\nOriginal Split  New Split\\n\\nunique dev simple sentences in train  90.9%  0.09%\\nunique test simple sentences in train  89.8%  0%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Bl UN LP\\n\\nNew Data Split\\n\\nTo remedy this, we construct a new data split by using the RDF information:\\n- Ensuring that all RDF relation types appear in the training set (enable generalization)\\n- Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)\\n- The resulting dataset has no overlapping simple sentences\\n- Has more unknown symbols in dev/test\\n- need better models!\\n\\nOriginal Split\\n\\nNew Split\\n\\nunique dev simple sentences in train 0.09%\\nunique test simple sentences in train 0%\\ndev vocabulary in train 63%\\ntest vocabulary in train 96.3%\\n61.7%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Bl UN LPCopy Mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "B IUaNLPCopy Mechanism To help with the increase in unknown words in the harder split, we incorporate a copy mechanism"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "BluaNLPCopy Mechanism\\n\\nTo help with the increase in unknown words in the harder split, we incorporate a copy mechanism\\n- Gu et al. 2016, See et al. 2017, Merity et al. 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "BluaaNLPCopy Mechanisme\\n\\nTo help with the increase in unknown words in the harder split, we incorporate a copy mechanism\\n- Gu et al. 2016, See et al. 2017, Merity et al. 2017\\n- Uses a \"copy switch\"\\n- feed-forward NN component with a sigmoid-activated scalar output."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "BluaNLPCopy Mechanisme\\n\\nTo help with the increase in unknown words in the harder split, we incorporate a copy mechanism (Gu et al.\\n2016, See et al. 2017, Merity et al. 2017).\\n- Uses a \"copy switch\"\\n- feed-forward NN component with a sigmoid-activated scalar output.\\n- Controls the interpolation of the softmax probabilities and the copy probabilities over the input tokens in each decoder step.\\n\\ncopy attention\\n- copy softmax\\n- switch weights (copy)\\n- switch output\\n- p(w) = D(z = i (w)) + D(z =\\nO) Peo fim (w)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Results\\n- New Split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "B IUNLP Results\\n- New Split\\n- seq2seq ff +copy\\n- Baseline seq2seq models completely break (BLEU <\\n7) on the new split ae4522.50\\n- original split\\n- new split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "B IUaaNLP Results\\n- New SplitM seq2seq ff + copy\\n- Baseline seq2seq models completely break (BLEU <\\n7) on the new split.\\n\\nCopy mechanism helps to generalize AS 22.50 original split new split."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Baseline seq2seq models completely break (BLEU <\\n7) on the new split.\\n\\nCopy mechanism helps to generalize.\\n\\nMuch lower than the original benchmark\\n- memorization was crucial for the high BLEU on the original split compared to the new split."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Copying and Attention"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "B I U F ay N L P No-Copy With-Copy & > & s & Ss & Ss & ad om oe oe? ee es a oe. & ar ok oe oe ee Os A ee.\\nA mdavad nieoui cuts eis is SIMtsted located The copy-enhanced sia curt = | models spread the = * TM = a oul attention across the oe sa: a input tokens while a sa i, 1 i India: improving results eet nsog rp n: Thakurpre Was: ia Ul \" indian: : | |; India leader} | EOS EOS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Error Analysis"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "B I U = aN LPMi correct | repeated On the original split the missing unsupported models did very well (due to memorization) with up to 91% correct simple sentences ar 2512.50 Original split new split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 73,
        "texts": [
          "Bl U=aN LPMi correct | repeated On the original split, the missing unsupported models did very well (due to 50 memorization) with up to 91% correct simple sentences.\\nOn the new benchmark, the S79 best model got only up to 20% correct simple sentences.\\n\\n12.50 Original split new split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 74,
        "texts": [
          "Bl UaaN LPMi correct | repeated On the original split the missing unsupported models did very well (due to memorization) with up to 91% correct simple sentences.\\nOn the new benchmark the best model got only up to 20% correct simple sentences.\\nThe task is much more challenging than previously demonstrated.\\n\\nOriginal split new split"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 75,
        "texts": [
          "B I U Conclusions"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 76,
        "texts": [
          "Bl UN LP Conclusions\\n\\nSimple neural models seem to perform well due to memorization"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 77,
        "texts": [
          "B IU=aNL Pe Simple neural models seem to perform well due to memorization.\\nWe propose a more challenging data split for the task to discourage this."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 78,
        "texts": [
          "B IU=aNL Pe Simple neural models seem to perform well due to memorization.\\nWe propose a more challenging data split for the task to discourage this.\\nA similar update was proposed by Narayan et al. in parallel to our work (WebSplit v1.0)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 79,
        "texts": [
          "Simple neural models seem to perform well due to memorization.\\nWe propose a more challenging data split for the task to discourage this.\\nA similar update was proposed by Narayan et al. in parallel to our work (WebSplit v1.0).\\nWe perform automatic evaluation and error analysis on the new benchmarks, showing that the task is still far from being solved."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 80,
        "texts": [
          "Bl UMore Broadly"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 81,
        "texts": [
          "B I UN LP More Broadly\\n- Creating datasets is hard!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 82,
        "texts": [
          "B IUNLP More Broadly\\n- Creating datasets is hard! Think how models can \"cheat\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 83,
        "texts": [
          "BluaaNL P\\n- Creating datasets is hard!\\nThink how models can \"cheat.\" Create a challenging evaluation environment to capture generalization."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 84,
        "texts": [
          "BluaaNL P\\n- Creating datasets is hard!\\n\\nThink how models can \"cheat\".\\n\\nCreate a challenging evaluation environment to capture generalization.\\n\\nLook for leakage of train to dev/test.\\n\\nNumbers can be misleading!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 85,
        "texts": [
          "B I UN LP More Broadly\\n- Creating datasets is hard!\\nThink how models can \"cheat.\" Create a challenging evaluation environment to capture generalization.\\nLook for leakage of train to dev/test. Numbers can be misleading! Look at the data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 88,
        "texts": [
          "B IUNLP Link to code and data is available in the paper :)"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 381,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "MULTIMODAL LEARNING\\n\\nAUSTRALIA\\n\\nWHITE STRIPES ON WINGS\\n\\nBLACK CROWN\\n\\nBROWN CROWN\\n\\nSTRIPED BELLY\\n\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "MULTIMODAL LEARNING\\n\\nChickadee Sparrow\\n- WHITE STRIPES ON WINGS\\n- BLACK CROWN\\n- BROWN CROWN\\n- STRIPED BELLY\\n\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "MULTIMODAL LEARNING\\n\\nBlack-Capped Chickadee\\nCarolina Chickadee\\n\\nWHITE STRIPES ON WINGS\\nWHITE STRIPES ON WINGS\\nBLACK CROWN\\nBLACK CROWN\\n\\nPALE TAN BELLY\\n\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "MULTIMODAL LEARNING\\n\\nBlack-Capped Chickadee\\nCarolina Chickadee\\n- \"MORE WHITE EDGING ON WINGS\"\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "MULTIMODAL LEARNING\\n\\n\"Black-Capped Chickadee\"\\n\"Carolina Chickadee\"\\n\"MORE WHITE EDGING ON WINGS\"\\n\"LESS ORANGISH ON SIDES\"\\n\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "MULTIMODAL LEARNING\\n\\nBlack-Capped Chickadee\\nCarolina Chickadee\\n\\nEDGING ON WINGS\\nON SIDES\\nWHITE STRIPES ON WINGS\\n\\nImage Credit: allaboutbirds.org, txtbba.tamu.edu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "COMPARATIVE ADJECTIVES\\n\\nATTRIBUTES VS. COMPARATIVES\\n- Attribute: set of feature values in isolation \"Dark teal\"\\n- Comparative: strength of feature with respect to a reference \"Darker teal\"\\n\\nmiSy Soumya Uawyarsy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "COMPARATIVE ADJECTIVES\\n\\nAttribute: set of feature values in isolation\\n\"Dark teal\"\\n\\nComparative: strength of feature with respect to a reference\\nComparatives frequently used to distinguish similar colors\\n[Monroe et al 2017]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "COMPARATIVE ADJECTIVES\\nREFERENCE-BASED COMPARISONS\\nPG aPeds aie Le"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "COMPARATIVE ADJECTIVES\\nCOLUMBIA MS Saas"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Ground comparative adjectives as directions in colorspace, dependent on the reference color, such that colors along the vector, when rooted at the reference color, satisfy the comparative criteria."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "SlSU Contextual color descriptions [McMahan and Stone 2015, Monroe et al 2017]\\nImage ranking [Parikh and Grauman 2011, Yu and Grauman 2014]\\nComparisons of set sizes [Pezzelle et al 2018]\\nSize ranking via knowledge graph [Bagherinezhad et al 2016]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "METHOD LIGHT BLUE LIGHTER\\n- comparative tuples\\n- unique reference labels\\n- unique comparatives\\n\\nSource: McMahan and Stone, 2015"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "METHOD MODEL x aiE 1Gs -5,\\n0)\\n\\nOutput:\\n\\nyAG & IN | a rcya: | om\\n- : ! ve IA 1 I\"1 | (apI riene aaa snsee | ! ] I ra) 255, 255, 0] | [245, 245,\\n\\nInput <PAD> ora ai l aaa:\\n\\nPe asW comparative adj: 300 dim. word2vec reference color: 3D RGB datapoint Tee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "METHOD GOLD TO PYRO LASER SCANNING COSINE SIMILARITY DISTANCE ORO RNLIEN UNIVERSITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "ANALYSIS\\n\\nRGB Dist:\\n151.\\nCosine Similarity\\n2. Distance: Delta-E: Delta-E | Perception\\n\\n<1.0 | Imperceptible\\n1-2 Requires close observation\\n2-10 / Perceivable\\n11-49\\nExact opposites\\n\\nCOLUMBIA UNIVERSITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "ANALYSIS\\nAmati Ves) LU\\nData # Tuples | # Dtpts\\nUvexinitig Woot mbeY = 1 211 MCV) eV ALK)\\n\\nTest (Seen Pairings) 24M3] RU)\\nTest (Unseen Pairings) 0.29M\\nTraining\\nTest (Unseen Ref.) 2.4M\\nTesting\\nTest (Unseen Comparative) 0.38M\\nTest (Fully Unseen) 11 58k\\nCSUN LESS"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "ANALYSIS SLUMS\\n\\nTest Condition       Avg Cos | Avg Delta-E\\nTest (Seen Pairings)                 6.1\\nTest (Unseen Pairings)               79\\nTest (Unseen Ref.)                 i ee!\\nTest (Unseen Comparison)             10.5\\nTest (Fully Unseen)                 15.9\\nOverall                             0.65     6.8\\n\\nAvg Cos: 50% above 0.80; 30% above 0.90"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ANALYSIS TEST TYPE | REF COMPARATIVE GOLD | COSSIM | DELTA-E |\\n\\nSeen in LS | training an 0.94\\n\\nUnseen tamer | Vial lighter 0.93\\n\\nUnseen reference blue -0.93\\n\\nUnseen comparative neon |\\n\\nReference & unseen for |\\n\\nCOLUMBIA UNIVERSITY IN THE CITY OF NEW YORK"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "ANALYSIS REF COMPARATIVE GOLD greener ->\\n- | ii ~ UO darker -> 8\\n2) ee UNIVERSITY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "ANALYSIS Lem AUTRE espaler pastel / REFERENCE powder TARGET tanner lighter ST"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "RU TRUSS\\n- New paradigm for grounding comparatives in colorspace\\n- New dataset of comparative colors\\n- Average cosine similarity: 0.65, with 50% above 0.80\\n- Model provides plausible comparative descriptions\\n\\nFUTURE WORK\\n- Apply to fine-grained object recognition\\n- Expand to other attribute domains"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "QUESTIONS?"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 368,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "We've Great purchase. Works fast and has all the applications I might need for general work, school, and play.\\n\\nBy Nick on July 19, 2017\\nStyle: Tablet\\nVerified Purchase\\n\\nSo much more reliable so far than my laptop which was more expensive. Great purchase.\\nWorks fast and has all the applications I might need for general work, school, and play. 33 people found this helpful.\\n\\n---\\n\\nGreat unit!\\nBy Thinking Independently on April 12, 2018\\nStyle: Tablet\\nVerified Purchase\\n\\nThis is a great tablet! Setup was super easy, I had it going in short order. I've been using it a lot with no issues.\\nBattery life is great, lasts a few hours with constant use.\\nI don't know how long the battery would last in standby mode because I haven't left it unused for more than a few hours.\\n\\nThe screen is nice and bright for reading. I've watched a number of videos, they look fine both visually and audio.\\nI don't know the frame rate and the other technical specs off the top of my head, but I am well pleased with the display and the audio performance.\\n\\nI have run some apps from the App Store and it runs fine for those.\\nI'm not a big app person, I primarily use it for email, web browsing, and to stream video and music and I've been very happy with it, and have had no issues.\\nI've paired it with a small Bluetooth speaker and it worked fine with no issues also.\\n\\nThe Samsung Galaxy Tab E 16 GB WiFi works fine for me, it does everything I want it to do.\\nI'm happy with my purchase and would buy it again.\\n\\n5 people found this helpful."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Help user write reviews in an easier way?\\n- Expand and rewrite phrases\\n- Estimate reactions and provide suggestions\\n\\nSamsung Galaxy Tab A 8\" 32 GB Wifi Tablet...\\n\\nthe battery is also good and it can last for around 8 hours."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Incorporate information & knowledge\\n\\nUser and item attribute\\n\\nDong et al. EACL\\n2017. Learning to Generate Product Reviews from Attributes.\\n\\nTang et al. Arxiv\\n2016. Context-aware Natural Language Generation with Recurrent Neural Networks.\\n\\nRich auxiliary information!\\n\\nShort phrases (user input)\\n\\nProduct title\\n\\nAspect preference"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Incorporate information & knowledge\\nAspect preference\\nUser-aspect preference\\nItem-aspect relation\\nService vendor seller supplier reply refund\\nPrice price value overall dependable reliable aspect\\nPreference\\nScreen\\n- screen touchscreen browse\\nScore o display scrolling\\nCase case cover briefcase portfolio\\nDrive drive disk copying copied fat32\\nTable 1 Representative words of aspects"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "et ee ee ee eee eee ae i =e TTS SS Se Seeee eel i | . aeI l I I 1 Il I I !\\n1 l; f * R * | * CinriboteTatenefactor] 1 ' [Aspecraware factor]| felzfeleleleted py 1 embed |! , a a, easy to use !\\nnope : earner one oceaniaI I !!\\n1 usey Lofolo|.fafo} fojafo[..[o]o] item 1i 1 ; nS 1: SequenceEncoder i 'Attribute Encoder: ' Aspect Encoder ;| pean ee meee er age ee ed Sopa eS to--- eee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "the display is beautiful and easy to use.\\n- Sequence Encoder\\n- Attribute Encoder\\n- Aspect Encoder"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "the 'display' is beautiful and easy to use\\n\\nB(display) + Pasusman(Ax) = Pa(display): Petit ttt ft | PMaISpiay) + PaoinadAe) = Pa(cisplay) Be FR tt :| 1 ! 2 Ano |\\n\\nthe !\\ndisplay is beautiful and easy to: Oe EEE OE TTI I : t | 1; ft H * | + CinriboteTatentfactor] 1 ' [Aspecraware factor]l2 |- | 2fej2b i ___ aon ogee ane fencing Aspect preference score\"th (Dd) Cd\\ni) Ed eeeuo I! easy to use ! ! _ : oer! 1 uset [ofofo]..fa}o} jojtfo].fofo]\\n\\nitem 1i 1 ; nS 11 Sequence Encoder\\n\\n' Attribute Encoder:\\n\\n' Aspect Encoder\\n\\nUsnenacodeeeeen [toKGtdosnee ee lene eee nee eee"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Experiment setting = Dataset: Amazon Electronics\\n- Vocabulary of 30,000 tokens: 182,850 users, 59,043 items, and 992,172 reviews\\n- Much sparser than previous work\\n\\nTraining\\n- Use teacher-forcing and masked cross-entropy loss\\n\\nTesting\\n- Greedy decoding"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Automatic evaluation metrics\\n\\nRand / 20.24 0.45 0.390 desl 13.681\\nGRU-LM 35.35 30.79 1.20\\nAtt2Seq 34.21 26.16 123 0.403 0.014 0.051\\n+aspect 34.26 26.87 1.51 0.397 0.018 0.069\\nExpansionNet 34.18 26.05 2.21 0.404 0.096 0.789\\n+title 30.70 27.90 2.50 0.415 0.099 0.911\\n+attribute & 31.70 30.33 2.63 0.408 0.133 1.134\\n\\naspect Table 2 Comparison of different algorithms"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "User/item Review user A3G831BTCLWGVQ and item B0OO07M50PTM\\n\\nSummary easy to use and nice standard apps.\\n\\nTitle samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model.\\n\\nReal review the display is beautiful and the tablet is very easy to use. It comes with some really nice standard apps.\\n\\nAttr2Seq I bought this for my wife's new iPad Air. It fits perfectly and looks great.\\nThe only thing I don't like is that the cover is a little too small for the iPad Air.\\n\\nExpansionNet I love this tablet. It is fast and easy to use. I have no complaints.\\nI would recommend this tablet to anyone.\\n\\n+title I love this tablet. It is fast and easy to use. I have a galaxy tab 2 and I love it.\\n\\n+attribute & aspect I love this tablet. It is easy to use and the screen is very responsive.\\nI love the fact that it has a micro SD slot. I have not tried the tablet app yet but I don't have any problems with it.\\nI am very happy with this tablet."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "User/item Review user A3G831BTCLWGVQ and item BOO7M50PTMSummary\\n\\neasy to use and nice standard apps\\n\\nTitle\\n\\nsamsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model\\n\\nReal review\\n\\nthe display is beautiful and the tablet is very easy to use. it comes with some really nice standard apps.\\n\\nAttr2Seq\\n\\ni bought this for my wife’s new ipad air. it fits perfectly and looks great.\\nthe only thing i don’t like is that the cover is a little too small for the ipad air.\\n\\nExpansionNet\\n\\ni love this tablet. it is fast and easy to use. i have no complaints. i would recommend this tablet to anyone.\\n\\n+title\\n\\ni love this tablet. it is fast and easy to use. i have a galaxy tab 2 and i love it.\\n\\n+attribute & aspect\\n\\ni love this tablet. it is easy to use and the screen is very responsive. i love the fact that it has a micro sd slot.\\ni have not tried the tablet app yet but i don’t have any problems with it. i am very happy with this tablet."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "User Item Review user A3G831BTCLWGVQ and item BO07M50PTM\\n\\nSummary\\n\\nEasy to use and nice standard apps\\n\\nTitle\\n\\nSamsung Galaxy Tab 2 (10.1-Inch, Wi-Fi) 2012 model\\n\\nReal review\\n\\nThe display is beautiful and the tablet is very easy to use. It comes with some really nice standard apps.\\n\\nAttr2Seq\\n\\nI bought this for my wife. It fits perfectly and looks great.\\nThe only thing I don't like is that the cover is a little too small for the iPad Air.\\n\\nExpansionNet\\n\\nI love this tablet. It is fast and easy to use. I have no complaints. I would recommend this tablet to anyone.\\n\\n+ Title\\n\\nI love this tablet. It is fast and easy to use. I have a Galaxy Tab 2 and I love it.\\n\\n+ Attribute & Aspect\\n\\nI love this tablet. It is easy to use and the screen is very responsive. I love the fact that it has a micro SD slot.\\nI have not tried the tablet app yet but I don't have any problems with it. I am very happy with this tablet."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Broader aspect coverage in generation = # aspect plus one, if the review covers the representative words from that aspect = Our model covers more real review's aspects.\\n\\nModel # aspects # aspects # aspects in generated\\n\\nfe\\n\\nfe\\n\\nYin on arden review\\n\\nAttr2Seq 2.875 2.744 0.686\\n\\nExpansionNet 2.675 1.804 0.807\\n\\n+ title 2.875 1.721 0.894\\n\\n+ attribute & aspect 2.875"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Conclusion and future work\\n\\nConclusion\\n- Build ExpansionNet to incorporate short phrases, product title and aspect preference in review generation.\\n- Show aspect embedding and aspect extraction can be used in personalized text generation.\\n\\nFuture work\\n- Combine text expansion task with text rewriting techniques.\\n- Generate longer text such as product recommendation articles."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Thank you!\\n\\nCode and data available: https://github.com/nijianmo/textExpansion"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 374,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Name Reading Comprehension\\n\\nThe task: to answer questions given a passage of\\n\\nDatasets\\n- CNN/Daily Mail [Hermann et al. 2015]\\n- Children's Book Test [Hill et al. 2016]\\n- SQUAD [Rajpurkar 2016]\\n- MCTest [Richardson et al. 2013]\\n- RACE [Lai et al. 2017]\\n- Multi-choice\\n- NarrativeQA [Kocisky et al. 2018]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "RACE Passage: My father wasn't a king, he was a taxi driver, but I met Blandy at a party and he asked if I'd like to buy the island.\\nOf course I said yes but I had no money! I was just an art teacher.\\nI tried to find some business partners, who all thought I was crazy.\\nSo I sold some of my possessions, put my savings together and bought it.\\n\\nQuestion: How did the author get the island?\\n- a. It was a present from Blandy.\\n- b. The king sold it to him.\\n- c. He bought it from Blandy.\\n- d. He inherited it from his father."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Related Work\\n- Converted to sequence pair matching [Yin et al., 2016]\\n- Each candidate answer is concatenated with the question\\n- The concatenated sequences are matched against the passage\\n\\nLimitation: Question and answers = ranking are not clearly separated.\\nInteraction information between a question and an answer is lost.\\n\\n07/18/2018 ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "- Matching sequences pair by pair [Lai et al., 2017]\\n- Match passage and question first\\n- Then this representation is used to match candidate answers\\n\\nLimitation: Matching P & Q may not give meaningful ranking representations for statements of the following \"07/18/2018 ACL 2018 is true?\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Our Solution\\n- Co-match each sentence in the passage with the question and the candidate's answers separately.\\n- Make use of the alignments between sequences as follows:\\n\\nQuestion: How did the author get the island?\\n\\nCandidate Answer: He bought it from Blandy.\\n- Hierarchically aggregate the co-matching representations of (sentence, question, answer) triplets for final scoring.\\n\\n07/18/2018 ACL 2018 6"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Co-Matching\\n- For every word in the sentence, we match it with the attention-weighted vectors computed based on the question and the candidate answer, respectively.\\n\\nQuestion: How did the author get the island?\\n\\nCo-Matching attention state mechanism\\n\\nCandidate Answer: He bought it from Blandy\\n\\n07/18/2018 ACL 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Co-Matching states\\nMatching an states\\nAttention-weighted vectors\\nAttention weights\\nLSTM states\\nEmbedding. 1st Sentence Candidate\\no7/ Question of Passage answer ACL 2018 8"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "FameCWO rk Representation for ranking candidates Hierarchical LSTM.\\nCo-Matching states Matching aTM states with NNAttention-weighted vectors Attention weights LAX LSTM states Embedding.\\n2nd h. 1st Sentence Candidate Nth Sentence of Passage answer Sentence of Passage = °"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Experiments\\n\\nRACE-M          RACE-H         RACE\\nRandom          34.6           25.0           24.9\\nOur Hier-Co-Matching achieved the\\nSliding Window   37.3           30.4           32.2\\nbest performance compared with\\nStanford AR      44.2           43.0           43.3\\nGA               43.7           44.2           44.1\\nElimiNet         44.7\\nHAF              45.3           47.9           47.2\\nMUSIC            51.5           45.7           47.4\\n\\nWe studied two key factors:\\n- (1) the co-matching module\\nHier-Co-Matching       55.8           48.2           50.4\\n- (2) the hierarchical aggregation approach\\nHier-Aggregation       34.2           46.2           48.5\\n- Co-Matching          50.7           45.6           46.4\\n\\nTurkers          85.1           69.4           73.3\\nCeiling          95.4           94.2           94.5\\n\\n07/18/2018 ACL 2018 10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Conclusions\\n- We proposed a hierarchical co-matching model for answering multi-choice reading comprehension questions.\\n- We showed that our model could achieve state-of-the-art performance on the RACE dataset.\\n- There is still much room for improvement on RACE given the low absolute performance.\\n- Latest results by OpenAI: 59%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "References\\n- Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy.\\n2017. \"RACE: Large-scale reading comprehension dataset from examinations.\" In Proceedings of EMNLP.\\n- Weopeng Yin, Sebastian Ebert, and Hinrich Schutze.\\n2016. \"Attention-based relational neural network for machine comprehension.\" In Proceedings of\\n- Soham Parikh, Ananya B. Sai, Preksha Nema, Mitesh M. Khapra.\\n2018.\\n\"ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions.\" In Proceedings of IJCAI.\\n- Haichao Zhou, Wei Furu, Qin Bing, and Liu Ting.\\n2018. \"Hierarchical attention flow for multiple-choice reading comprehension.\" In Proceedings of AAAI.\\n- Yichong Xu, Jingjing Liu, Jianfeng Gao, Yelong Shen, and Xiaodong Liu.\\n2017. \"Towards human-level machine reading comprehension: Reasoning and inference with multiple strategies.\"\\n2018. arXiv. 07/18/2018 ACL 2018 12"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 74,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction\\n\\nBilingual transfer learning is important for overcoming data sparsity in the target language.\\nBilingual word embeddings eliminate the gap between source and target language vocabulary.\\nResources required for bilingual methods are often out-of-domain:\\n- Texts for embeddings\\n- Source language training samples\\n\\nWe focused on domain adaptation of word embeddings and better use of unlabeled data."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Motivation: Cross-lingual sentiment analysis of tweets.\\n\\nBuenosupertriste, superbakorblemalo mugJame'red. toddy 3/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Motivation: Cross-lingual sentiment analysis of tweets. Be free, super triste, slippery bad problem. A mug = 3/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Motivation: Cross-lingual sentiment analysis of tweets about Supertriste, slipper, adorable, and mug on Gar."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Motivation: Cross-lingual sentiment analysis of tweets\\n\\nCombination of two methods:\\n- Domain adaptation of bilingual word embeddings\\n- Semi-supervised system for exploiting unlabeled data\\n\\nNo additional annotated resource is needed:\\n- Cross-lingual sentiment classification of tweets\\n- Medical bilingual lexicon induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Word Embedding Adaptations\\n\\nSource: Butotdonein, Romain, PETE Mapping, Target, Out-of-domain\\n\\nGoal: domain-specific bilingual word embeddings with general domain semantic knowledge"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Word Embedding Adaptation\\n\\nSource | Out-of-domain | In-domain\\n\\nPETE Mapping | Target | Out-of-domain | In-domain\\n\\nGoal: domain-specific bilingual word embeddings with general domain semantic knowledge\\n1. Monolingual word embeddings on concatenated data (Mikolov et al., 2013):\\n- Easily accessible general (out-of-domain) data\\n- Domain-specific data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Word Embedding Adaptation Source | Out-of-domain | In-domain Mapping | Target | Out-of-domain | In-domain\\n\\nGoal: domain-specific bilingual word embeddings with general domain semantic knowledge\\n1. Monolingual word embeddings on concatenated data (Mikolov et al., 2013):\\n- Easily accessible general (out-of-domain) data\\n- Domain-specific data\\n2. Map monolingual embeddings to a common space using post-hoc mapping (Mikolov et al., 2013):\\n- Small seed lexicon containing word pairs is needed\\n- Simple and intuitive but crucial for the next step!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Semi-Supervised Approach\\n\\nGoal: Unlabeled samples for training\\n\\nTailored system from computer vision to NLP (Hausser et al.,\\n2017)\\n\\nLabeled/unlabeled samples in the same class are similar\\n\\nSample representation is given by the n-1 layer\\n\\nWalking cycles: labeled + unlabeled\\n- labeled\\n\\nMaximize the number of correct cycles\\n\\nL = A1 * Lclassification + A2 * Lwalker + A3 * Lvisit"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Semi-Supervised Approach\\n\\nGoal: Unlabeled samples for training\\n\\nTailored system from computer vision to NLP (Hausser et al.,\\n2017)\\n\\nLabeled/unlabeled samples in the same class are similar\\n\\nSample representation is given by the n-1 layer\\n\\nWalking cycles: labeled + unlabeled\\n- labeled\\n\\nMaximize the number of correct cycles\\n\\nL = 2X1 * Lclassification + A2 * Lwalker + A3 * Lvisit\\n\\nAdapted bilingual word embeddings make the models able to find correct cycles at the beginning of the training and improve them later on."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Cross-Lingual Sentiment Analysis of Tweets\\n\\nRepLab 2013 sentiment classification (+/0/-) of En/Es tweets (Amigé et al.,\\n2013)\\n\\n@churcaballero jajaja con lo bien que iba el volvo...\\n\\nGeneral domain data: 49.2M OpenSubtitles sentences (Lison and Tiedemann,\\n2016)\\n\\nTwitter specific data:\\n- 22M downloaded tweets\\n\\nRepLab Background\\n- Seed lexicon: frequent English words from BNC (Kilgarriff,\\n1997)\\n- Labeled data: RepLab En training set\\n- Unlabeled data: RepLab Es training set"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Cross-Lingual Sentiment Analysis of Tweets\\n\\nOur method is easily applicable to word embedding-based off-the-shelf classifiers my (OO)\\n- LEOR (OP esC000 shido gd Kd? © PerYicsia (@@@)\\n- d46\" te 2 CNN classifier (Kim, 2014)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Medical Bilingual Lexicon Induction\\n\\nMine Dutch translations of English medical words (Heyman et al.,\\n2017)\\n\\nsciatica\\n- ischias\\n\\nGeneral domain data: 2M Europarl (v7) sentences\\n\\nMedical data: 73.7K medical Wikipedia sentences\\n\\nMedical seed lexicon (Heyman et al.,\\n2017)\\n\\nUnlabeled\\n1. En word in BNC\\n- 5 most similar and 5 random Du pair\\n2. En word in medical lexicon + 3 most similar Du\\n- 5 most similar and 5 random En"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Medical Bilingual Lexicon Induction\\nClassifier based approach (Heyman et al.,\\n2017)\\n- Word pairs as training set (negative sampling)\\n- Character level LSTM to learn orthographic similarity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Medical Bilingual Lexicon Induction\\n\\nClassifier based approach (Heyman et al.,\\n2017)\\n\\nWord pairs as training set (negative sampling)\\n\\nWord embeddings to learn semantic similarity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Medical Bilingual Lexicon Induction: Classifier based approach (Heyman et al.,\\n2017)\\nWord pairs as training set (negative sampling)\\nDense-layer scores word pairs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Results: Sentiment Analysis labeled data\\nUnlabeled data\\n- Baseline | 59.05%\\n- BACKGROUND | 58.50%\\n- 22M tweets | 61.14%\\n- Subtitle + BACKGROUND | 59.34%\\n- Subtitle + 22M tweets | 61.06%\\n\\nTable 1: Accuracy on cross-lingual sentiment analysis of tweets\\n10/14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Results: Sentiment Analysis\\n\\nlabeled data\\nEn\\nEn\\nEn + Es\\n\\nunlabeled data\\n- Es\\n- Baseline | 59.05% 58.67% (-0.38%)\\n- BACKGROUND | 58.50% 57.41% (-1.09%)\\n- 22M_tweets | 61.14% 60.19% (-0.95%)\\n- Subtitle + BACKGROUND | 59.34% 60.31% (0.97%) 62.92% (2.61%)\\n- Subtitle + 22M_tweets | 61.06% 63.23% (2.17%) 63.82% (0.59%)\\n\\nTable 1: Accuracy on cross-lingual sentiment analysis of tweets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Results: Bilingual Lexicon Induction\\n\\nlabeled lexicon | medical BNC\\nunlabeled lexicon\\n- Baseline | 35.70 20.73\\n- Europarl + Medical | 40.71 22.10\\n\\nTable 2: Fy scores of medical bilingual lexicon induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Results: Bilingual Lexicon Induction\\n\\nlabeled lexicon | medical BNC\\nmedical\\nunlabeled lexicon\\n- medical BNC\\n\\nBaseline | 35.70 20.73 | 36.20 (0.50) 35.04 (-0.66)\\nEuroparl + Medical | 40.71 22.10 | 41.44 (0.73) 41.01 (0.30)\\n\\nTable 2: Fy scores of medical bilingual lexicon induction"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Conclusions:\\n\\nBilingual transfer learning yields poor results when using out-of-domain resources.\\n\\nWe showed that performance can be increased by using only additional unlabeled monolingual data.\\n\\nDelightfully simple approach to adapt embeddings.\\n\\nBroadly applicable method to exploit unlabeled data.\\n\\nLanguage and task independent approaches."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Thank you for your attention!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "References\\n\\n[1] Enrique Amigé, Jorge Carrillo de Albornoz, Irina Chugur, Adolfo Corujo, Julio Gonzalo, Tamara Martin, Edgar Meij, Maarten de Rijke, Damiano Spina, Enrique Amigo, Jorge Carrillo de Albornoz, Tamara Martin, and Maarten de Rijke.\\n2013. Overview of replab 2013: Evaluating online reputation monitoring systems. In Proc. CLEF.\\n\\n[2] Philip Hausser, Alexander Mordvintsev, and Daniel Cremers.\\n2017. Learning by association\\n- A versatile semi-supervised training method for neural networks. In Proc. CVPR.\\n\\n[3] Geert Heyman, Ivan Vulié, and Marie-Francine Moens.\\n2017. Bilingual lexicon induction by learning to combine word-level and character-level representations. In Proc. EACL.\\n\\n[4] Adam Kilgarriff.\\n1997. Putting frequencies in the dictionary. International Journal of Lexicography.\\n\\n[5] Yoon Kim.\\n2014. Convolutional neural networks for sentence classification. In Proc. EMNLP.\\n\\n[6] Pierre Lison and Jorg Tiedemann.\\n2016. Opensubtitles2016: Extracting large parallel corpora from movie and TV subtitles. In Proc. LREC.\\n\\n[7] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.\\n2013. Efficient estimation of word representations in vector space. In Proc. ICLR.\\n\\n[8] Tomas Mikolov, Quoc V. Le, and Ilya Sutskever.\\n2013. Exploiting similarities among languages for machine translation. CoRR, abs/1309.4168."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 7,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "This is NOT an architecture search paper!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Bier Google AI\\n\\nA Brief History of NMT Models\\n\\n2014\\n2015\\n2016\\n2017\\n2018\\n- Sutskever et al. (Google-NMT)\\n- Wu et al. (Transformer)\\n- Vaswani et al. (Seq2Seq)\\n- Cho et al.\\n- Chen et al. (RNMT+ and Hybrids)\\n- Bahdanau et al.\\n- Gehring et al. (Attention)\\n- (Conv-Seq2Seq)\\n\\nquality = f(X, A, ps)\\nX: Data\\n@: Model\\n[4: Hyperparameters"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "e . oS =: * 28 Google Al\"e ioThe Best of Both Worlds\\n-\\n\\nEach new approach is:\\naccompanied by a set of modeling and training techniques.\\n\\nGoal:\\n1. Tease apart architectures and their accompanying techniques.\\n2. Identify key modeling and training techniques.\\n3. Apply them on RNN based Seq2Seq\\n- RNMT+\\n\\nConclusion:\\nRNMT+ outperforms all previous three approaches."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "e > oS ° 28 Google AI\\n\\nThe Best of Both Worlds\\n- II\\n\\nAlso, each new approach has a fundamental architecture (signature wiring of neural network).\\n\\nGoal:\\n1. Analyse properties of each architecture.\\n2. Combine their strengths.\\n3. Devise new hybrid architectures\\n- Hybrids\\n\\nConclusion:\\n\\nHybrids obtain further improvements over all the others."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Bed Google AI Building Blocks\\n- RNN Based NMT\\n- RNMT\\n- Convolutional NMT\\n- ConvS2S\\n- Conditional Transformation Based NMT\\n- Transformer"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "28 Google AlGNMT\\n- Wu et al.\\n\\nCore Components:\\n- Meo Attention (Additive)\\n- biLSTM + uniLSTM\\n- Dabo LSTMs\\n- Deep residuals\\n\\nGPG:\\n- Async Training\\n\\nPros:\\n- GPU3\\n- De facto standard\\n- Modelling state space\\n\\nCons:\\n- Temporal dependence\\n- Not enough gradients\\n\\nThe Best of Both Worlds\\n\\nFigure from \"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\" Wu et al.\\n2016"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "28 Google AlConvS2\\n- Gehring et al. They agree.\\n\\nEmbeddings\\n- Core Components:\\n- Convolutions\\n- Multi-hop attention\\n- Gates\\n- Positional embeddings\\n- Units\\n- Careful initialization\\n- Careful normalization\\n- Sync Training\\n\\nPros:\\n- No temporal dependence\\n- More interpretable than RNN\\n- Parallel decoder outputs during training\\n\\nCons:\\n- Need to stack more to increase the receptive field\\n\\nFigure from \"Convolutional Sequence to Sequence Learning\" Gehring et al. 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "£8 Google Al Transformer\\n- Vaswani et al.\\nGiput e Core Components:\\n- Probabilities\\n- Self-Attention\\n- Multi-headed attention\\n- Layout: N->f()->D->R\\n- Careful normalization\\n- Careful batching\\n- Sync training\\n- Label Smoothing\\n- Per-token loss\\n\\nAttention Nx\\n- Learning rate schedule\\n- Checkpoint Averaging\\n- Masked Pros:\\n- Gradients everywhere\\n- faster optimization\\n- Parallel encoding both training/inference\\n- Positional Encoding\\n- Combines many advances at once\\n\\nInputs Outputs\\nFragile (shifted right)\\nFigure from \"Attention is All You Need\" Vaswani et al. 2017"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "28 Google AI\\nThe Best of Both Worlds\\n- I: RNMT + Output Probs;\\nThe Architecture:\\n- Bi-directional encoder 6 x LSTM (Dropout)\\n- Uni-directional decoder 8 x LSTM\\n- Layer normalized LSTM cell\\n- Per-gate normalization\\n- Multi-head attention\\n- Multi-headed 4 heads\\n- Additive (Bahdanau) attention\\nSource Embedding\\nTarget Embedding\\nThe Best of Both Worlds P10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "28 Google AI Model Comparison\\n- |: BLEU Scores WMT'14 En-Fr WMT'14 En-De\\n(35M sentence pairs) (4.5M sentence pairs)\\n\\nTraining\\nModel Test BLEU Time\\nGNMT 38.95\\n-\\n-\\nGNMT 24.67\\n-\\n-\\n\\nConvS2S\\n39.49 +0.11 62.2 438h\\nConvS2S\\n25.01 +0.17 38 20h\\n\\nTrans. Base\\n39.43 +0.17 20.7 90h\\nTrans. Base\\n27.26 +0.15 38 17h\\n\\nTrans. Big\\n40.73 +0.19 8.3 120h\\nTrans. Big\\n27.94 +0.18 26.9 48h\\n\\nRNMT+\\n41.00 +0.05 8.5 120h\\nRNMT+\\n28.49 +0.05 24.6 40h\\n\\ne RNMT+/ConvS2S: 32 GPUs, 4096 sentence pairs/batch.\\ne Transformer Base/Big: 16 GPUs, 65536 tokens/batch.\\n\\nThe Best of Both Worlds"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "28 Google AI Model Comparison\\n- II: Speed and Size\\n\\nWMT'14 En-Fr (35M sentence pairs)      WMT'14 En-De (4.5M sentence pairs)\\n\\nModel              | Test BLEU    | Time       | Model              | Test BLEU    | Time\\nGNMT               38.95\\n-\\n-        | GNMT               24.67\\n-\\n-\\n\\nConvS2S           39.49 +0.11     62.2 438h  | ConvS2S           25.01 +0.17     38 20h\\n\\nTrans. Base       39.43 +0.17     20.7 90h   | Trans. Base       27.26 +0.15     38 17h\\n\\nTrans. Big        40.73 +0.19     8.3 120h   | Trans. Big        27.94 +0.18     26.9 48h\\n\\nRNMT+             41.00 +0.05     8.5 120h   | RNMT+             28.49 +0.05     24.6 40h\\n\\nModel Params\\n- RNMT+/ConvS2S: 32 GPUs,\\n- ConvS2S 80 15.7B 263.4M .cia. case 160 628 8 aM 4096 sentence pairs/batch.\\n- Trans. Big 50 31.28 | 375.4M\\n- Transformer Base/Big: 16 GPUs,\\n- RNMT+ 30 28.1B 378.9M 65536 tokens/batch.\\n\\nThe Best of Both Worlds P12"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "28 Google AI Stability: Ablations Evaluate importance of four key techniques:\\n1. Label smoothing\\n- Significant for both Model RNMT+ | Trans. Big Baseline 41.00 40.73\\n2. Multi-head attention\\n- Label Smoothing 40.33 40.49\\n- Significant for both Multi-head Attention | 40.44 39.83\\n3. Layer Normalization\\n- Critical to stabilize training (especially with multi-head attention)*\\n- Indicates an unstable training run\\n4. Synchronous training\\n- Critical for Transformer\\n- Significant quality drop for RNMT+\\n- Successful only with a tailored learning-rate schedule\\n\\nThe Best of Both Worlds P13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "£8 Google AI\\nThe Best of Both Worlds\\n- II: Hybrids\\n\\nStrengths of each architecture:\\n- RNMT\\n- Highly expressive\\n- continuous state space representation.\\n- Transformer\\n- Full receptive field\\n- powerful feature extractor.\\n\\nCombining individual architecture strengths:\\n- Capture complementary information\\n- \"Best of Both Worlds\".\\n- Trainability\\n- important concern with hybrids.\\n\\nConnections between different types of layers need to be carefully designed.\\n\\nThe Best of Both Worlds P14"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Bed Google Al Encoder\\n- Decoder Hybrid\\n- Conditional LMst ret e Encoder\\n- build feature representations\\n- BNMT Transformer\\n- Designed to contrast the roles.\\n\\nEncoder En->Fr Test BLEU (last two rows)\\n- Trans. Big | Trans. Big 40.73 + 0.19\\n- RNMT+ | RNMT+ 41.00 + 0.05\\n- Trans. Big | RNMT+ 41.12 + 0.16\\n- RNMT+ | Trans. Big 39.92 + 0.21\\n\\nThe Best of Both Worlds P15"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Bed Google AlEncoder Layer Hybrids\\n\\nImproved feature extraction: RNMT+\\n\\nEnrich stateful representations with global self-attention.\\n\\nIncreased capacity Encoder x4.\\n\\nDetails: Layer Norm Es Transformer RNMT+.\\n\\nEncoder\\n\\nPre-trained components to improve trainability.\\n\\nLayer normalization at layer boundaries.\\n\\nSource sequence\\n\\nSevere Cascaded Hybrid\\n- vertical combination.\\n\\nMulti-Column Hybrid\\n- horizontal combination.\\n\\n(a) Cascaded Encoder\\n\\n(b) Multi-Column Encoder\\n\\nThe Best of Both Worlds P16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Bier Google AlEncoder Layer Hybrids ENNIS RNMT+ Model En-Fr BLEU | En-De BLEU Decoder Decoder; Trans.\\nBig | 40.73 +0.19 27.94 +0.182:\\n\\nRNMT+ 41.00 +0.05 28.59 +0.05\\n\\nMerge Cascaded | 41.67 +0.11 | 28.62 +0.06\\n\\nMultiCol | 41.66 +0.11 28.84 +0.06 Layer Norm Transformer RNMT+ Encoder Encoder Encoder x6 A\\n- S Source Sequence Source Sequence\\n\\n(a) Cascaded Encoder\\n\\n(b) Multi-Column Encoder\\n\\nThe Best of Both Worlds P17"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "28 Google AI Lessons Learnt\\n\\nNeed to separate other improvements from the architecture itself:\\n\\nYour good ol' architecture may shine with new modelling and training techniques.\\n\\nStronger baselines (Denkowski and Neubig,\\n2017)\\n\\nDull Teachers\\n- Smart Students\\n\\n\"A model with a sufficiently advanced Ir-schedule is indistinguishable from magic.\"\\n\\nExpressivity or trainability\\n\\nUnderstanding and Criticism\\n\\nHybrids have the potential, more than duct taping.\\n\\nGame is on for the next generation of NMT architectures\\n\\nquality = f(X, 9,\\n1)\\n\\nThe Best of Both Worlds"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "28 Google AI\\nThank You\\n~~Open source implementation coming soon!\\n- https://ai.google/research/join-us/\\n- https://ai.google/research/join-us/ai-residency/\\nThe Best of Both Worlds"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 89,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "a | Outline\\n\\nSS0 Introduction\\n\\n0 Experiment\\n\\nTask\\n\\nDataset\\n\\nChallenge\\n\\nDetails\\n\\nResults\\n\\n0 Background\\n\\n0 Analysis\\n\\nState-of-the-Art Approaches\\n\\nY> Incremental Analysis\\n\\nC1 Approach\\n\\nError Analysis\\n\\nOverview\\n\\n0 Conclusion\\n\\nNeutralization Module\\n\\nEmotionalization Module\\n\\nReinforcement Learning\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach\\n\\n15-07-2018\\nEY"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "| Introduction ["
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "a | Sentiment-to-Sentiment Translation SSExamples:\\n1) The movie is amazing!\\n- The movie is boring!\\n2) I went to this restaurant last week, the staff was friendly, and I were so happy to have a great meal!\\n- I went to this restaurant last week, the staff was rude, and I were so angry to have a terrible meal!\\n\\nDefinition\\n\\nThe goal of sentiment-to-sentiment \"translation\" is to change the underlying sentiment of a sentence while keeping its content.\\nThe parallel data is usually lacking."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Applications: Dialogue Systems\\n\\nI am sad about the failure of the badminton player A. The badminton player B defeats A. Congratulations!\\n\\nSentiment-to-sentiment translation: I'm sorry to see that the badminton player B defeats A."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Applications: Personalized News Writing\\n- Sentiment-to-sentiment translation can save a lot of human labor!\\n\\nThe visiting team defeated the home team.\\n\\nNews for fans of the visiting team: The players of the home team performed badly and lost this game.\\n\\nNews for fans of the home team: Although the players of the home team have tried their best, they lost this game regretfully."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "a Challenge: Can a sentiment dictionary handle this task?\\n\\nThe simple replacement of emotional words causes low-quality sentences.\\n\\nThe food is terrible like rock. The food is delicious like rocks."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "a Challenge: Can a sentiment dictionary handle this task?\\nFor some emotional words, word sense disambiguation is necessary.\\n\\nFor example, \"good\" has three antonyms: \"evil\", \"bad\", and \"ill\" in WordNet.\\nChoosing which word needs to be decided by the semantic meaning of \"good\" based on the given content."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "a | Challenge: Can a sentiment dictionary handle this task? Some common emotional words do not have antonyms.\\nFor example, we find that WordNet does not annotate the antonym of \"delicious\"."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "| Background ["
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "a\\n\\nBackground: State-of-the-Art Methods\\n- Key Idea:\\n1. They first separate the non-emotional information from the emotional information in a hidden vector.\\n2. They combine the non-emotional context and the inverse sentiment to generate a sentence.\\n- Advantage: The models can automatically generate appropriate emotional antonyms based on the non-emotional context.\\n- Drawback: Due to the lack of supervised data, most existing models only change the underlying sentiment and fail in keeping the semantic content.\\n\\nIt's a Bad, The food is delicious\\nWhat a bad movie\\nBad, Bad, a Bad Movie"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "| Approach ["
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Approach: Overview\\n\\nEmotionalization Module\\n\\nNeutralization Module\\n\\nThe food is terrible and tasteless.\\n\\nExtract non-emotional semantic information.\\n\\nThe food is very delicious.\\n\\nEmotionalization Module\\n\\nFinale: Add sentiment to the neutralized semantic content.\\n\\nCycled reinforcement learning: Combine and train two modules.\\n\\nClassifier: The food is very delicious.\\n\\nNeutralization Module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Neutralization Module SS1 Long-Short Term Memory Network\\n\\nGenerate the probability of being neutral or being polar.\\n\\nPre-train\\n\\nThe learned attention are the supervisory signal.\\n\\nThe cross entropy loss is computed as follows:\\n\\nClassifier Lo =\\n- Pyg(@i\\xi)WHAH HHI\\n\\nThe food is very delicious.\\n\\nNeutralization Module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "a | Emotionalization Module SSCI Bi-decoder based encoder-decoder network Emotionalization Module\\n\\nThe encoder compresses the context.\\n\\nThe food is terrible and tasteless.\\n\\nThe decoder generates sentences.\\n\\nThe food is very delicious.\\n\\nPre-train at\\n\\nThe input is the neutralized input sequence.\\n\\nThe supervisory signal is the original sentence.\\n\\nThe cross entropy loss is computed as TLg = Pro (x|f_i)s_i=1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "a Cycled Reinforcement Learning\\n1) Neutralize an emotional sentence to non-emotional semantic content.\\n\\nFA | (X) Classifier\\n\\nThe food is very delicious\\n\\nNeutralization Module"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "a Cycled Reinforcement Learning Reconstruct the original sentence by adding the source Pepa is very delicious.\\nThe food is very delicious.\\nNeutralization Module Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 15-07-2018 SET L"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "a | Cycled Reinforcement Learning\\n\"The food is very delicious\"\\n\\nPositive ARLUCYCIE COnsHONE TONG\\n3) Train the emotionalization module using the peer reconstruct loss.\\n\\ni. The food is very delicious\\n\\nNeutralization Module\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach\\n\\n15-07-2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "a | Cycled Reinforcement Learning SSEmotionalization Module\\n\\nTesting © 4\\n\\nThe food is terrible and tasteless\\n- Negative\\n\\nThe food is very delicious\\n- Positive\\n\\nP-L1 SVCIE Constance Dw DY(X) Classifier\\n4) Train the neutralization module using reinforcement learning.\\n\\nThe food is very delicious\\n\\nNeutralization Module\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach\\n\\n15-07-2018 PA ey."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "a | Reward SSO) Add different sentiment to the semantic content > Positive > Negative C1 Use the quality of the generated text as reward > The confidence score of a sentiment classifier > BLEU"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "| Experiment ["
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "a | Dataset SSO Yelp Review Dataset (Yelp)\\nYelp Dataset Challenge.\\nAmazon Food Review Dataset (Amazon)\\nProvided by McAuley and Leskovec (2013). It consists of amounts of food reviews from Amazon."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Baselines SSO Cross-Alignment Auto-Encoder (CAAE)\\nRefined alignment of latent.\\n\\nMulti-Decoder with Adversarial Learning (MDAL)\\nA multi-decoder model with adversarial.\\n\\nDecoder GRU A\\nDecoder GRU B\\nClassifier"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "a | Evaluation Metrics\\n\\nSSC1 Automatic Evaluation\\n- Accuracy\\n- BLEU\\n- G-score\\n\\nHuman Evaluation: The annotators are asked to score the transformed text in terms of sentiment and semantic similarity.\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach 15-07-2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Evaluation Metrics\\n\\nSSO1 Automatic Evaluation\\n- Accuracy\\n- BLEU\\n- G-score\\n\\nHuman Evaluation\\n- sentiment and semantic similarity."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "| Results SSet\\nCAAE 93.22 1.17 10.44\\nMDAL 85.65 1.64 11.85\\nProposed Method 80.00 22.46 42.38\\nBLEU\\nCAAE 84.19 0.56 6.87\\nMDAL 70.50 0.27 4.36\\nProposed Method 70.37 14.06 31.45\\n\\nAutomatic evaluations of the proposed method and baselines."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "| Results\\nSSCAAE 7.67 3.87 5.45\\nMDAL 7.12 3.68 5.12\\nProposed Method 6.99 5.08 5.96\\nCAAE 8.61 3.15 5.21\\nMDAL 7.93 3.22 5.05\\nProposed Method 7.92 4.67 6.08\\n\\nHuman evaluations of the proposed method and baselines."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "| Generated Examples\\n\\nInput: I would strongly advise against using this company.\\n\\nCAAE: Great food and great service!\\n\\nMDAL: Great food, outstanding job experience here.\\n\\nInput: Most boring show I've ever been.\\n\\nCAAE: Great place is the best place in town.\\n\\nProposed Method: I would love using this company.\\n\\nMDAL: Great place I've ever had.\\n\\nProposed Method: Most amazing show I've ever been."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "| Analysis ["
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "a | Analysis of the neutralization module SSMichael is absolutely wonderful.\\n\\nI would strongly advise against using this company. Horrible experience! Worst cleaning job ever!\\nMost boring show I've ever been. Hainan chicken was really good.\\n\\nI really don't understand all the negative reviews for this dentist. Smells so weird in there.\\nThe service was nearly non-existent and extremely rude."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "a | Conclusion\\n\\nSSA. Enable training with unpaired data.\\n\\nB. Tackle the bottleneck of keeping semantic.\\n\\nC. State-of-the-art results.\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach\\n15-07-2018\\n33 of 34"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Thank You! If you have any questions, please send an e-mail to jingjingxu@pku.edu.cn\\n\\nUnpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 311,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Multiword Expressions\\n- Expressions of multiple words that can exhibit an idiomatic meaning\\n- Ivory tower\\n- Hit up\\n- Take a walk\\n- Verb noun combinations\\n- See stars\\n- Kick the bucket"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Idiomatic vs Literal\\n- Pull plug\\n(I) They pulled the plug on the Department of Health funding\\n(L) Unfortunately someone pulled the sink plug\\n- See stars\\n(I) It caught him on the head and he went down seeing little sparkling stars\\n(L) It's still dark enough to see the brightest stars"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Idiom Token Classification\\n- Determine if an MWE instance is idiomatic\\n- They pulled the plug on the project\\n- Applications\\n- Machine translation\\n- Kick the bucket m [mourir/frapper avec le pied]\\n- Sentence completion\\n- Keegan is ready to pull the plug on [a deal / the tv]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Overview of Approach\\n- Supervised approach\\n- VNC token instances are represented via use of an embedding model\\n- Embedding models\\n- Skip-thoughts\\n- Word2vec\\n- Siamese CBOW\\n- SVM classifier"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Lexico-Syntactic Fixedness\\n- The idiomatic meaning of an expression is typically restricted to a small number of lexico-syntactic patterns.\\n- See star (Idiomatic)\\n- Active voice, no determiner, plural noun.\\n- See stars.\\n- See star (Literal)\\n- Active voice, determiner, singular noun.\\n- See a star.\\n- Passive voice, plural noun.\\n- Stars were seen."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Patterns\\n\\nPattern No. Pattern Signature Example\\n\\n1 Vact det:NULL Ny give money\\n\\n2 Vact det:a/an Nsg give a book\\n\\n3 Vace det:the Neg give the book\\n\\n4 Vace Gdet:DEM Neg give this book\\n\\n5 Vact det:POSS Neg give my book\\n\\n6 Vacte det:NULL Ny give books\\n\\n7 Vace det:the Ny give the books\\n\\n8 Vace Gdet:DEM Ny give those books\\n\\n9 Vact det:POSS Np give my books\\n\\n10 Vact det:OTHER give many books\\n\\n11 Upass det:ANY Ng a/the/this/my book/books was/were given\\n\\nAfsaneh Fazly et al. 2009"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Canonical Form\\n- Lexico-syntactic patterns that idiomatic usages tend to occur in C(v,\\nn) = {pt € P | z(v, n, pt\\ne) > T.}(v, n,\\n7)\\n- f z(0, n, pty) = Le TM Pie) = f"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Integrating Canonical Forms\\n- Unsupervised method used in Fazly et al. to identify canonical forms\\n- One-dimensional binary vector representing if the expression is in the canonical form"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "VNC-Tokens Dataset\\nCook et al. 2008\\n\\nDev\\nTest\\n- 14 MWEs\\n- 14 MWEs\\n- Training\\n- Training\\n- 270 Idiom\\n- 298 Idiom\\n- 179 Literal\\n- 172 Literal\\n\\nTesting\\nTesting\\n- 92 Idiom\\n- 90 Idiom\\n- 53 Literal\\n- 53 Literal"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Accuracy DEV TEST\\nwo CF\\n+CFC Form\\n- 0.721\\n- 0.749\\n\\nWord2vec 0.830 0.854 | 0.804 0.852\\n\\nSiamese CBOW | 0.763 0.774 | 0.717 0.779\\n\\nSkip-thoughts 0.803 0.827 | 0.786 0.842"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Results per class\\n\\nIdiomatic Literal\\n- macKte\\n- P: 0.815\\n- R: 0.879\\n- F: 0.830\\n- Word2vec\\n- CF\\n- P: 0.627\\n- R: 0.542\\n- F: 0.556\\n- Word2vec + CF\\n- P: 0.830\\n- R: 0.892\\n- F: 0.848\\n- Word2vec + CF\\n- P: 0.758\\n- R: 0.676\\n- F: 0.691"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Conclusion\\n- Averaging word2vec embeddings outperforms all other models used.\\n- Canonical form feature improves results.\\n- Future work.\\n- Unseen MWEs.\\n- Other embedding models."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Thank you\\n\\nThis work was financially supported by NSERC, NBIF, and University of New Brunswick"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Results per class\\n\\nIdiomati c           Literal\\nModel          P       R       F           P       R       F\\nCForm      0.766  0.901  0.794   0.668  0.587  0.576\\nWord2vec -CF  0.815  0.879  0.830   0.627  0.542  0.556\\nWord2vec +CF  0.830  0.892  0.848   0.758  0.676  0.691"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 82,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Image Captioning\\n\\nCaption: Two young kids with backpacks sitting on the porch."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Visual Storytelling\\n\\nThe brother did not want to talk to his sister. The siblings made up. They started to talk and smile.\\nTheir parents showed up. They were happy to see them.\\n\\nImagination\\nEmotion\\nSubjectiveness"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Visual Storytelling\\n\\nThe brother and sister were ready for the first day of school.\\nThey were excited to go to their first day and meet new friends. They told their mom how happy they were.\\nThey said they were going to make a lot of new friends. Then they got up and got ready to get in the car."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Behavioral cloning methods (e.g. MLE) are not good enough for visual storytelling"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Reinforcement Learning\\nDirectly optimize the existing metrics\\n- BLEU, METEOR, ROUGE, CIDE\\nReduce exposure bias\\nReward A. Optimal\\nGanean | Rennie 2017, \"Self-critical Sequence Training for Image Captioning\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "We had a great time to have a lot of the. They were to be a of the. They were to be in the. The and it were to be the.\\nThe, and it were to be the. Average METEOR score: 40.2 (SOTA model: 35.0)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Base Faust after Power as ée if AEE) I had a great time at the restaurant today. The food was delicious.\\nI had a lot of food. I had a great time. BLEU-4 score: 0"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "No Metrics Are Perfect!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Inverse Reinforcement Learning\\nFunction Policy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Adversarial Reward Learning (AREL)\\nIt is I1 | Adversarial Generated; Inverse RL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "My brother recently graduated college.\\n\\nIt was a formal cap and gown event.\\n\\nMy mom and dad attended.\\n\\nLater, my aunt and grandma showed up.\\n\\nWhen the event was over he even got congratulated by the mascot."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Reward Model Rgos tsP Ls A =\\n\\nReward attended | +\\n\\nStory Convolution Pooling FC layer Kim 2014, \"Convolutional Neural Networks for Sentence Classification\" 13"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Associating Reward with Story\\n\\nEnergy-based models associate an energy value Eg(x) with a sample x, modeling the data as a Boltzmann distribution:\\n\\nexp(-E9(x)) Do(x) = zy Reward Boltzmann Distribution\\n\\nStory Reward Function Gi@)\\n- exp, (W) D\\nW)\\n- = (Zo) Zo = > exp(Re(W)) W.\\n\\nApproximate data distribution Partition function\\n\\nOptimal reward function R@(W) is achieved when po(W) = p*(W)\\n\\nLeCun et al. 2006, \"A tutorial on energy-based learning\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "AREL Objective\\n\\nTherefore, we define an adversarial objective with KL-divergence\\n\\nReward Boltzmann distribution\\n- ni OD DEDEmpirical distribution\\n- Policy distribution\\n\\nThe objective of Reward Model Re:Pe(W) mm = amt po (W) = m 78(W)\\n\\nThe objective of Policy Model zg:7TM3(W) amp = aa po (W)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Reward Visualization\\n3.0% M69) ground truth\\n2.5% || MM generated stories\\nWM 2.0%\\noOOWJ [1.5%\\nwo: & 1.0%\\n0.5%\\n0.0%\\n-0.8 -0.6 -0.4 -0.2 0.0 0.2 0.4 0.6\\nIRL rewards\\n16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Automatic Evaluation\\n\\nCe Ye YO Ye ct 00d\\n\\nSeq2seq (Huang et al.)\\n- 31.4\\n\\nHierAttRNN (Yu et al.)\\n- 21.0\\n- 34.1\\n- 29.5\\n- 7.5\\n\\nXE\\n- 62.3\\n- 38.2\\n- 22.5\\n- 13.7\\n- 34.8\\n- 29.7\\n- 8.7\\n\\nBLEU-RL\\n- 62.1\\n- 38.0\\n- 22.6\\n- 13.9\\n- 34.6\\n- 29.0\\n- 8.9\\n\\nMETEOR-RL\\n- 68.1\\n- 35.0\\n- 15.4\\n- 6.8\\n- 40.2\\n- 30.0\\n- 1.2\\n\\nROUGE-RL\\n- 58.1\\n- 18.5\\n- 1.6\\n- 0.0\\n- 27.0\\n- 33.8\\n- 0.0\\n\\nCIDEr-RL\\n- 61.9\\n- 37.8\\n- 22.5\\n- 13.8\\n- 34.9\\n- 29.7\\n- 8.1\\n\\nGAN\\n- 62.8\\n- 38.8\\n- 23.0\\n- 14.0\\n- 35.0\\n- 29.5\\n- 9.0\\n\\nHuang et al. 2016, \"Visual Storytelling\"\\n\\nYu et al. 2017, \"Hierarchically-Attentive RNN for Album Summarization and Storytelling\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Human Evaluation\\n\\nTuring Test\\n\\n50%\\noe\\n40%\\nag\\nae\\n=\\n30%\\n-\\n26.1\\n20%\\n10%\\n0%\\n\\nXE\\nBLEU\\n-\\nRL\\nCIDEr\\n-\\nRL\\nGAN\\nA\\nREL\\nTM\\nWin\\nTM\\nUnsure"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Human Evaluation\\n\\nPairwise Comparison\\n- AREL vs XE-ss\\n- AREL vs BLEU-RL\\n- AREL vs CIDEr-RL\\n- AREL vs GAN\\n\\nChoice (%)\\n- AREL 61.7\\n- XE-ss 25.1\\n- Tie 13.2 | AREL 55.8\\n- BLEU-RL 27.9\\n- Tie 163 | AREL 56.1\\n- CIDEr-RL 28.2\\n- Tie 15.7 | AREL 52.9\\n- GAN 35.8\\n- Tie 11.3\\n\\n66.1 188 151 | 591 264 145 | 591 266 143 | 485 32.2 193\\n\\n63.9 20.3 15.8 | 60.1 26.3 13.6 | 59.5 246 15.9 | 498 35.8 14.4\\n\\nRelevance: the story accurately describes what is happening in the photostream and covers the main objects.\\n\\nExpressiveness: coherence, grammatically and semantically correct, no repetition, expressive language style.\\n\\nConcreteness: the story should narrate concretely what is in the images rather than giving very general descriptions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "There were many different kinds of things to see the beautiful scenery.\\n\\nAt the end of the day, we were able to take a picture of the countryside.\\n\\nWe took a trip to the mountains.\\n\\nWe had a great time.\\n\\nHe was a great time.\\n\\nIt was a beautiful day.\\n\\nThere were a lot of strange plants created while we were hiking.\\n\\nWe drank a lot of water while we were hiking.\\n\\nThe view was spectacular."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Takeaway\\n\\nGenerating and evaluating stories are both challenging due to the complicated nature of stories.\\nNo existing metrics are perfect for either training or testing.\\nAREL is a better learning framework for visual storytelling. It can be applied to other generation tasks.\\nOur approach is model-agnostic. Advanced models lead to better performance."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Thanks!\\n\\nPaper: https://arxiv.org/abs/1804.09160\\nCode: https://github.com/littlekobe/AREL"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 77,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Neural Question Answering\\n\\nQuestion: \"What color is the sky?\"\\n\\nPassage: \"Air is made mainly from molecules of nitrogen and oxygen.\\nThese molecules scatter the blue colors of sunlight more effectively than the green and red colors.\\nTherefore, a clean sky appears blue.\"\\n- ALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Fast Progress on Paragraph Datasets\\n\\nAccuracy on SQUAD 1.19"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "What Next: ALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Open Question Answering\\n\\nQuestion: \"What color is the sky?\"\\n\\nRelevant Text\\n\\nModel Answer Span\\n\\nDocument Retrieval\\n\\nALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Challenge: Scaling Models to Documents\\n\\nModern reading comprehension models have many layers and parameters.\\nThe trend is continuing in this direction, for example with the use of large language models.\\nReduced efficiency as the paragraph length increases due to long RNN chains or transformers/self-attention modules limits the model to processing short paragraphs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Two Possible Approaches\\n- Pipelined Systems: Select a single paragraph from the input, and run the model on that paragraph. Confidence = 0.68.\\n- Confidence Systems: Run the model on many paragraphs from the input, and have it assign a confidence score to its results on each paragraph.\\nConfidence = 0.83. %BIZ 2s reliance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "This Work Improved Pipeline Method\\n- Improve several of the key design decisions that arise when training on document-level data.\\n\\nImproved Confidence Method\\n- Study ways to train models to produce correct confidence scores.\\n\\nBAZ, 2oSMINSTTET ence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Pipeline Method: Paragraph Selection\\n\\nTrain a shallow linear model to select the best paragraphs.\\n\\nFeatures include TF-IDF, word occurrences, and its position within the document.\\n\\nIf there is just one document, TF-IDF alone is effective.\\n\\nImproves chance of selecting an answering-containing paragraph from 83.0 to 85.1 on TriviaQA WebPAD BASE TTT."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Pipeline Method: Noisy Supervision\\n\\nDocument level data can be expected to be distantly supervised.\\n\\nQuestion: Which British general was killed at Khartoum in 1885?\\n\\nPassage: In February 1884, Gordon returned to the Sudan to evacuate Egyptian forces.\\nRebels broke into the city, killing Gordon and the other defenders.\\nThe British public reacted to his death by acclaiming 'Gordon of Khartoum, a saint.' However, historians have since suggested that Gordon defied orders and...."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Pipeline Method: Noisy Supervision\\n\\nNeed a training objective that can handle multiple (noisy) answer spans.\\nUse the summed objective from Kadlec et al (2016), that optimizes the log sum of the probability of all answer spans.\\nRemains agnostic to how probability mass is distributed among the answer spans."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "End Scores: Pipeline Method: Model\\n- Bi-GRU (Concat). We construct a fast, competitive model.\\n\\nUse some key ideas from prior work, including bidirectional attention, self-attention, character embeddings, variational dropout.\\n\\nBi-GRU: Also added learned tokens for document and paragraph starts.\\n- \"<5 hours to train for 26 epochs on SQUAD.\"\\n- Bi-GRU BLGRUCS\\n- CNN + Max Pool\\n- Embed\\n- Char Embed"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Confidence Methods= We can derive confidence scores from the logit scores given to each span by the model, i.e., the scores given before the softmax operator is applied.\\nWithout re-training this can work poorly."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Example from SQUAD\\n\\nQuestion: \"When is the Members Debate held?\"\\n\\nModel Extraction: \"..majority of the Scottish electorate voted for it in a referendum to be held on 1 March 1979 that represented at least...\"\\n\\nCorrect Answer: \"Immediately after Decision Time a 'Members Debate' is held, which lasts for 45 minutes...\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Learning Well-Calibrated Confidence Scores:\\n- Train the model on both answering-containing and non-answering containing paragraphs and use a modified objective function.\\n- Merge: Concatenate sampled paragraphs together.\\n- No-Answer: Process paragraphs independently, and allow the model to place probability mass on a \"no-answer\" output.\\n- Sigmoid: Assign an independent probability on each span using the sigmoid operator.\\n- Shared-Norm: Process paragraphs independently, but compute the span probability across spans in all paragraphs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "ALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Datasets\\n- TriviaQA: Datasets of trivia questions and related documents found by web search.\\nIncludes three settings: Web (a single document for each question), Wiki (multiple Wikipedia documents for each question), and Unfiltered (multiple documents for each question).\\n- SQUAD: Turker-generated questions about Wikipedia articles. We use the questions paired with the entire article.\\nManual annotation shows most (90%) of questions are answerable as given the document it was generated from."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Pipeline Method: Results on TriviaQA\\n\\nWeb70 Baseline implementation:\\n- Uses BiDAF as the model\\n- Select paragraphs by truncating documents\\n- Select answer-spans randomly\\n- 72.14 EM / 81.05 F1 on SQUAD\\n- 78.58 EM / 85.83 F1 with contextualized word embeddings (Peters et al.,\\n2017)\\n\\nTriviaQA Our\\n+TF-IDF\\n+Sum\\n+TF-IDF\\n+Model Baseline\\nBaseline\\n+Sum\\n+TF-IDF\\n+Sum\\n\\nALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "SQUAD F1 vs. Number of Paragraphs\\n\\n0.725\\n0.700\\n0.675\\n0.650\\n0.625\\n- none\\n0.600\\n- merge\\n0.575\\n- no-answer\\n0.550\\n\\n1\\n3\\n5\\n7\\n9\\n11\\n13\\n15\\n\\nNumber of Paragraphs\\nPAZ, Ais MUNSTT eT ence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "TriviaQA Web F1 vs. Number of Paragraphs\\n\\n0.70 0.68\\n0.66\\n- none\\n- sigmoid\\n- merge\\n0.64\\n- no-answer\\n- shared-norm\\n0.62\\n\\n1 3 5 7 9 11 13 15\\nNumber of Paragraphs\\nBad ASMUNSTUTET Bence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Unfiltered TriviaQA Fl vs. Number of Paragraphs\\n\\n0.66\\n0.64\\nOoo2\\n0.62\\niC\\n- none\\n0.60\\n- sigmoid\\n- merge\\n0.58\\n- no-answer\\n- shared-norm\\n\\n0.56\\n5\\n10\\n15\\n20\\n25\\n30\\nNumber of Paragraphs\\nBa? SEN UNSTTSTE ace"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "TriviaQA Leaderboard (Exact Match Scores)\\n\\nWeb-All           Web-Verified           Wiki-All           Wiki-Verified\\n\\nBest leaderboard entry (\"mingyan\")         68.65           87.44           66.56           74.33\\n\\nLeaderboard entry (\"dirkweissen\")          67.46           77.63           64.60           72.77\\n\\nShared-Norm (Ours)                          66.37           79.97           63.99           67.98\\n\\nDynamic Integration of Background Knowledge  50.56           63.20           48.64           53.42\\n(Weissenborn et al., 2017a)\\n\\nNeural Cascades                              (Swayamdipta et al.,\\n2017)        53.75           63.20           51.59           58.90\\n\\nMnemonic Reader                               (Hue et al.,\\n2017)                 46.65           56.96           46.94           54.45\\n\\nSMARNET                                      (Chen et al.,\\n2017)                 40.87           51.11           42.41           50.51"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Error Analysis\\n- Manually annotated 200 errors made by the TriviaQA Web model\\n- 40.5% are due to noise or lack of context in the relevant documents\\nOf the remaining...\\nDA2 AUSENUINSTUUTE nce"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Missing background\\nacknowledge\\nPart of answer extracted\\nALLEN INSTITUTE for ARTIFICIAL INTELLIGENCE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Building an Open Question Answering System\\n- Use Bing web search and a Wikipedia entity linker to locate relevant documents.\\n- Extract the top 12 paragraphs, as found using the linear paragraph ranker.\\n- Use the model trained for TriviaQA Unfiltered to find the final answer."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Curated Trec Results\\n\\nYodaQA with Bing\\nYodaQA (Baudis, 2015), DrQA+DS (Chen et al., 2017a)\\nS-Norm (ours) (Baudis, 2015)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Thank You\\n\\nDemo: https://documentga.allenai.org/Question\\n\\nGithub: https://github.com/allenai/document-qa"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 113,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "ACL 2018 Outline\\n\\nLatent Meaning Models\\n\\nExperimental Setup\\n\\nSue\\n\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "ACL 2018 aCP 5 OS SS aNFEISSre (ee oh a aevA mee es) = i.\\nBs a i ge sA) ae eee 'Introduction' shed a 1' aes en Ly thi RUN aa \"2 A 4 \" 3 y bo x; pens os a 4 as aed Be Pewife eeKe"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "a) Word-level Word Embedding ACL 2018\\n1) Neural Network-Based e.g., GloVe (Pennington et al.)\\n\\nINPUT = PROJECTION. OUTPUT\\n\\nINPUT PROJECTION OUTPUT\\n\\ne.g., CBOW, Skip-gram (Mikolov et al.) or\\n- Matrix Factorization\\n- Based (Spectral Methods)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Morphology-based Word Embedding\\n\\nSufiEmbeddings\\n\\nTraining Model-on Sore Embeddings\\n\\nIncredible Generated Morpheme SEE"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Our Original Intention\\n\\nACL2018\\n- Word-level models: Input Words; Output Word Embeddings.\\n- Morphology-based models: Input Words + Morphemes; Output Word Embeddings + Morpheme Embeddings.\\n- Our Latent Meaning Models: Input Words + Latent Meanings of Morphemes; Output Word Embeddings (no by-product, e.g., morpheme embedding).\\n\\nPURPOSE: to not only encode morphological properties into words, but also enhance the semantic similarities among word embeddings."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Explicit Models & Our Models Not wLGE\\n*Note: The lookup table can be derived from morphological lexicons."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "CBOW with Negative Sampling\\nACL2018\\n\\nSequence of tokens\\nObjective Function:\\n1 La\\n2 log p(t; | Context(t,)) rd)\\n\\nNegative Sampling:\\n(Context Words)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Three Specific Models\\nACL2018i) cyLMM-A\\nLMM-M (Latent Meaning Model-Average)\\n(Latent Meaning Model-Max)\\n(Latent Meaning Model-Similarity)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Word Map\\nWord Map\\nincredible\\nnot be able\\ncapable\\nrows = vocabulary\\nFun\\n\\n*Note: The derivational morphemes, not the inflectional morphemes, are mainly concerned"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Latent Meaning Model-Average (LMM-A) ACL 2018\\n\\nSequence of tokens\\n\\nThe latent meanings of morphemes have equal contributions to a paradigm of LMM-A.\\n\\nLatent Meaning Context (t;)\\n\\nThe modified embedding of a set of latent meanings of morphemes is utilized for training."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Latent Meaning Model-Similarity (LMM-S) ACL 2018\\n\\nSequence of tokens\\n\\nThe latent meanings of morphemes are assigned with different weights: A paradigm of LMM-S.\\n\\nThe modified embedding of a set of latent meanings of morphemes."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Latent Meaning Model-Max (LMM-M) ACL2018\\n\\nSequence of tokens\\n\\nKeep the latent meanings that have maximum similarities to: A paradigm of LMM-Mie) = argmax cos(t,, 7} eS a end eeaiite OT edatRe argmax cos(v;, 9} TaeRp argmax cos(v,,\\n7) wes;\\n\\nThe modified embedding of: 1 Ea = oie ee aere"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Update Rules for LMMs ACL2018\\n\\nNew Objective Function (After modifying the input layer of CBOW):\\n\\nA1 = AL = e2 oly XC | > U;\\n\\nAll parameters introduced by our models can be directly derived using the word map and word embeddings.\\n\\nUpdate not just the embeddings of the latent meanings with the same weights as they are assigned in the forward propagation period."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "ACL 2018 FEIS She aila Vs neA Da eee Dy= Gee 2; Wags iPn | ees o as Le ee \"Experimental\" setup ROSES oh ae 16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Corpus & Word Map ACL2018\\nCorpus Word Map\\n- News corpus g&2009 (2013 ACL * Morpheme segmentation using Eighth Workshop) Morefessor (Creutz & Lagus,\\n2007)\\n- Size: 1.7GB\\n- Assign latent meanings\\n- ~500 million tokens\\n- Lookup table\\n- Derived from the resources provided\\n- ~600,000 words by Michigan State University\\n- 90 prefixes, 382 roots, 67 suffixes\\nFiltered\\nResources web link: https://msu.edu/~defores1/gre/roots/gre_rts_afx1.htm"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Baselines & Parameter Settings\\n\\nACL2018\\n\\nWord-level models: CBOW, Skip-gram, GloVe\\n\\nExplicitly Morpheme-related Model (EMM)\\n\\nA paradigm of EMM Morphemes\\n\\nSuper-parameter Settings:\\n- Equal settings to all models\\n- Vector Dimension: 200\\n- Context window size: 5\\n- # Negative Samples: 2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Evaluation Benchmarks (1/2)\\n\\nACL 2018 Q Word Similarity:\\n- Dataset err\\n- Team cronies\\n- SCWS | 2003\\n- WS-353-Related Gold Standard Datasets\\n- Widely-used Datasets\\n\\nQ Syntactic Analogy:\\n- \"abasc _?(d)\" e.g., Queen : King as Woman : Man\\n- Microsoft Research Syntactic Analogies dataset (8000 items)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Evaluation Benchmarks (2/2)\\n\\nACL2018Q Text Classification:\\n- 20 Newsgroups dataset (19000 documents of 20 different topics)\\n- 4 text classification tasks, each involves 10 topics\\n- Training/Validation/Test subsets (6:2:2)\\n- Feature vector: average word embedding of words in each document\\n- L2-regularized logistic regression classifier"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ACL2018"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "The Results on Word Similarity\\n- Not wLGECBOW\\n- Skip-gram\\n- LMM-A\\n- LMM-S\\n- LMM-M\\n\\nCST ee OSL my rol 60.01 62.05 63.13 61.54 Zt 36.42 33.40 ZUR ce) 43.12 ZO \"TOSRG-65 56.50 oes ny 60.85 ond 62.49 SRSCWS (SK) 60.20 47.98 60.28 Coto 61.71 63.02 ROM 66.30 eto oo Xe 68.36 Cre) WS-353-Related 49.72 57.05\\n\\nCORN Bet nome Se I 55.19 (Given different models) Spearman's rank correlation (%) on different datasets"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "The Results on Syntactic Analogy ACL 2018\\n\\nQuestion: \"abasc (d)\" PATA) PANIES\\n\\nSyntactic analogy performance (%) 23"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "The Results on Text Classification ACL 2018\\n\\nClassification Average text classification accuracy across the 4 tasks (%)\\n24"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "The Impact of Corpus Size\\n\\nResults on Wordsim-353 task with different corpus size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "© The Impact of Context Window Size ACL2018 | CBOW | 624\\n\\nResults on Wordsim-353 task with different context window size"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Word Embedding Visualization ACL2018\\n\\ncapablisible\\n\\nlatent meanings of morphemes\\n- edible\\n- small\\n- agreeable\\n\\nBy Aprescient\\n\\nprefix\\n\\npreview before\\n\\nVisualization of word embeddings based on PCA"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "ACL 2018 a NGGs OS Se, be OE es eene ae eek NOE as Oi | +! vans F9 sa . KY 4 so, ee Conclusioa SS fy ROADS VES AS eG i!\\nie} ae eae ' wi Peta ;5 pe eee ag 5S Fa aes j EB ie SERIE 28"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "ACL201> Conclusions\\n- Employ latent meanings of morphemes rather than the internal compositions themselves to train word embeddings.\\n- By modifying the input layer and update rules of CBOW, we proposed three latent meaning models (LMM-A, LMM-S, LMM-M).\\n- The comprehensive quality of word embeddings is enhanced by incorporating latent meanings of morphemes.\\n- In the future, we intend to evaluate our models for some morpheme-rich languages like Russian, German, etc."
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 255,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "McGill University\\nSchool of Computer Science\\n\\nHeard on the campaign trail:\\nHillary Clinton vs. Donald Trump.\\n\\n\"Make the middle class mean Make America great again. Something again, with rising incomes and broader horizons.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "eZ McGill\\n\\nWhat Is presupposition\\n- Presuppositions: assumptions shared by discourse participants in an utterance (Frege 1892, Strawson 1950, Stalnaker 1973, Stalnaker 1998).\\n- Presupposition triggers: expressions that indicate the presence of presuppositions.\\n\\nExample:\\n\\nOops! I did it again + Trigger Be\\n- e Presupposes Britney did it before me yet"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "GF © McGill\\n\\nLinguistic Analysis\\n- Presuppositions are preconditions for statements to be true or false (Kaplan 1970; Strawson, 1950).\\n\\nClasses of construction that can trigger presupposition (Zare et al., 2012):\\n- Definite descriptions (Kabbara et al., 2016), e.g.: \"The queen of the United Kingdom\".\\n- Stressed constituents (Krifka, 1998), e.g.: \"Yes, Peter did eat pasta.\"\\n- Factive verbs, e.g.: \"Michael regrets eating his mother's cookies.\"\\n- Implicative verbs, e.g.: \"She managed to make it to the airport on time.\"\\n- Relations between verbs (Tremper and Frank, 2013; Bos, 2003), e.g.: won >> played."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "GF © McGill\\n\\nMotivation & Applications\\n- Interesting testbed for pragmatic reasoning: investigating presupposition triggers requires understanding preceding context.\\n- Presupposition triggers influencing political discourse:\\n- The abundant use of presupposition triggers helps to better communicate political messages and consequently persuade the audience (Liang and Liu, 2016).\\n- To improve the readability and coherence in language generation applications (e.g., summarization, dialogue systems)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "GF © McGill\\n\\nAdverbial Presupposition Triggers\\n\\nAdverbial presupposition triggers such as again, also, and still.\\n- Indicate the recurrence, continuation, or termination of an event in the discourse context, or the presence of a similar event.\\n- The most commonly occurring presupposition triggers (after existential triggers) (Khaleel, 2010).\\n- Little work has been done on these triggers in the computational literature from a statistical, corpus-driven perspective.\\n\\nExistential=\\n- All others (lexical and structural)\\n- Adverbial clauses"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "OF & McGill\\n\\nThis Work\\n- Computational approach to detecting presupposition triggers.\\n- Create new datasets for the task of detecting adverbial presupposition triggers.\\n- Control for potential confounding factors such as class balance and syntactic governor of the triggering adverb.\\n- Present a new weighted pooling attention mechanism for the task."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "OF & McGill\\nOutline\\nTask Definition\\nLearning Model\\nExperiments & Results"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "GF © McGill\\n\\nTask\\n- Detect contexts in which adverbial presupposition triggers can be used.\\nRequires detecting recurring or similar events in the discourse context.\\n- Five triggers of interest: too, again, also, still, yet.\\n- Frame the learning problem as a binary classification for predicting the presence of an adverbial presupposition (as opposed to the identity of the adverb)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Sample Configuration 3-tuple: label, list of tokens, list of POS tags.\\n- Back to our example: Make America great again.\\n- Trigger"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "eZ McGill Sample Configuration\\n\\n3-tuple: label, list of tokens, list of POS tags.\\n- Back to our example: Make America great again.\\n- Trigger: Headword (aka governor of \"again\")"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "GF © McGill\\n\\nSample Configuration\\n\\n3-tuple: label, list of tokens, list of POS tags.\\n- Back to our example: Make America great again.\\n- Trigger Headword (aka governor of \"again\")\\n- Special token: to identify the candidate context in the passage to the model."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Sample Configuration: 3-tuple: label, list of tokens, list of POS tags.\\n\\nBack to our example: ('again', -- Trigger ['@@@@', 'Make', 'America', 'great'],\\n- Tokens ['@@@@', 'vB', 'NNP', 4'] )\\n- POS tags"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "GF © McGill\\n\\nPositive vs Negative Samples\\n\\nNegative samples\\n- Same governors as in the positive cases but without triggering presupposition.\\n\\nExample of positive sample:\\n- Juan is coming to the event too.\\n\\nExample of negative sample:\\n- Whitney is coming tomorrow."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "GF © McGill\\n\\nExtracting Positive Samples\\n- Scan through all the documents to search for target adverbs.\\n- For each occurrence of a target adverb:\\n- Store the location and the governor of the adverb.\\n- Extract 50 unlemmatized tokens preceding the governor, together with the tokens right after it up to the end of the sentence (where the adverb is).\\n- Remove adverb."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "OF & McGill\\n\\nExtracting Negative Samples\\n- Extract sentences containing the same governors (as in the positive cases) but not any of the target adverbs.\\n- Number of samples in the positive and negative classes roughly balanced.\\n- Negative samples are extracted/constructed in the same manner as the positive examples."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "GF © McGill\\n\\nPosition-Related Confounding Factors\\n\\nWe try to control position-related confounding factors by two randomization approaches:\\n1. Randomize the order of documents to be scanned.\\n2. Within each document, start scanning from a random location in the document."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "OF & McGill\\n\\nLearning Model\\n- Presupposition involves reasoning over multiple spans of text.\\nAt a high level, our model extends a bidirectional LSTM model by:\\n1. Computing correlations between the hidden states at each timestep.\\n2. Applying an attention mechanism over these correlations.\\n- No new parameters compared to standard bidirectional LSTM."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "A °eZ = McGille e School of Computer Science\\nLearning Model: Overview\\n\\nColumn-wise softmax\\nRow-wise softmax\\n\\nColumn-wise average\\nsoftmax\\n\\nAttention vector\\nfrom vector/matrix multiplication states\\nconcatenated to\\nWeighted H matrix\\nSum over time\\n\\nInput:\\nsteruncateusties\\n(11 encoding and\\nPOS tag one-hot encoding\\nFully connected layer\\nembeddings concatenated:\\nword embedding lookup\\n\\nOutput\\nThe Old Granary...\\nincluded Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "ed 2 Mill Learning Model: Input° Embed input. Optionally concatenate with POS tags. The Old Granary...\\nincluded Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "OF © McGill Learning Model: RNN Bidirectional LSTM:\\n\\nIt concatenates all hidden states.\\n\\nE.g.: We continue to feel that the stock market is the place to be for long-term appreciation.\\n\\nInput embeddings: The Old Granary... included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "eZ = McGill° Pair-wise matching matrix M\\n\\n---\\n\\ntt ttt yt\\n\\nff\\n-\\n\\n{|\\n\\ntt\\n\\n[<4 >\\n\\n[TTT TTT|\\n\\ntt ttt tt\\n\\n{|\\n\\nft\\n\\ntt\\n\\ntT\\n\\nLe\\n\\nTt\\n\\ntT\\n\\nTY\\n\\nHTM = HTH\\n\\nrt\\n\\n{|\\n\\n{\\n\\nf|\\n\\ntT\\n\\ntT\\n\\ntT\\n\\ntT biLSTM: hidden CoH i Wee) states:\\n\\n[\\n\\n|\\n\\nconcatenated to :\\n\\nono\\n\\n[POS tag one-not encoding) embeddings:\\n\\ntf\\n\\nf f\\n\\nfF\\n\\nft\\n\\nt\\n\\nft\\n\\nThe Old Granary...\\n\\n@@@@\\n\\nincluded Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "eZ = McGill\\n- Column-wise softmax:\\n- Learn how to aggregate.\\n- isoftmax.\\n- Tt Cfstates: concatenated to: one [POS tag one-hot encoding) embeddings:\\n\\nThe Old Granary... included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "eZ = McGill\\n\\nColumn-wise softmax: Learn how to aggregate.\\n\\nRow-wise softmax: Attention distribution over words.\\n\\nStates: concatenated to one-hot encoding embeddings:\\n\\nThe Old Granary included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "eZ = McGill\\n\\nColumn-wise softmax\\n\\nRow-wise softmax\\n- The columns of M' are then {2-427 40 [{2\\n411.\\n\\ntf averaged, forming vector [.\\n\\nTsdftmax!\\n\\nsoftmax}\\n\\nCfbi LSTM: hidden 'CH 4 eed states:\\n\\nconcatenated to: cnc sng\\n\\nPOStag one-shot encoding +\\nd) iu embeddings\\n\\nThe Old Granary...\\n\\nincluded Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "eZ McGill\\n\\nColumn-wise softmax\\nRow-wise softmax\\n\\nThe columns of M are then averaged, forming vector.\\nFinal attention vector a: a = M B or based on (Cui et al., biLSTM: hidden 'CH 4 eed2 0 1 7).\\n\\nconcatenated to one-shot encoding embedding.\\n\\nThe Old Granary... included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Column-wise softmax\\nRow-wise softmax\\n\\nAttend:\\n- a form of self-attention (Paulus 2017, Vaswani 2017).\\n\\neebi LSTM: hidden states; concatenated to POS tag one-shot encoding and embeddings.\\n\\nThe Old Granary... included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "A °eZ = McGille e School of Computer Science\\n\\nLearning Model: Predict\\n- eaming Model: Predict\\n- Column-wise softmax\\n- Row-wise softmax\\n\\nPredict: [| | tal TT Y | [| | [ [ T ]' rt { ttt fT Y | {| | [ { f || | | tit TT Yt | | ft ft yt\\n\\nColumn-wise average\\n- Dense layer: softmax\\n- Softmax -->\\n\\nAttention vector from vector/matrix y = s(Waz + ba).\\n\\nSum over time encoding and POS tag one-hot encoding\\n\\nFully connected layer embeddings concatenated: word embedding lookup\\n\\nOutput\\n\\nThe Old Granary... included Bertrand Russell"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "eS Mccill Datasets\\n\\nNew datasets extracted from:\\n- The English Gigaword corpus:\\n- Individual sub-datasets (i.e., presence of each adverb vs. absence).\\n- ALL (i.e., presence of one of the 5 adverbs vs. absence).\\n- The Penn Tree Bank (PTB) corpus: ALL.\\n\\n5,175 48263,843 1584085,745 2150185,944 21762194,661 48741537,626 132928"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "eZ McGill\\n\\nResults Overview\\n- Our model outperforms all other models in 10 out of 14 scenarios (combinations of datasets and whether or not POS tags are used).\\n- WP outperforms regular LSTM without introducing additional parameters.\\n- For all models, we find that including POS tags benefits the detection of adverbial presupposition triggers in Gigaword and PTB datasets."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "eZ McGill* WP best on WSJ.\\n- MFC: Most Frequent Class\\n- RNNs outperform Logistic baselines by large; 51.66 Regression margin.\\n- POS 52.81 LSTM: bidirectional LSTM\\n- POS 54.47 CNN: Convolutional\\n- POS 58.8A Network based on (Kim CNN,\\n2014)\\n- POS 62.16\\n- POS 74.23\\n- SAY\\n- POS 73.18\\n- POS 76.09\\n- am\\n- POS 74.84"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "eF 2 McGill Results\\n- Gigaword* Baselines for Gigaword\\n- Accuracy All adverbs Again\\n\\nSy ail Too Nea\\n\\nAlso\\n- 50.24 50.25 50.29 65.06 50.19 | 50.32 to steg + POS 53.65 59.49 56.36 69.77 61.05 | 52.00\\n\\nLogReg\\n- POS 52.86 58.60 55.29 67.60 58.60 | 56.07 + POS 59.12 60.26 59.54 67.53 61.53\\n- POS 57.21 57.28 56.95 67.84 56.53 | 59.76"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "eF 2 McGill Results\\n- Gigaword LSTM with accuracy Attention\\n- WP: 50.24 50.25 50.29 65.06 50.19 50.32\\n- POS: 53.65 59.49 56.36 69.77 61.05 52.00\\n- POS: 52.86 58.60 55.29 67.60 58.60 56.07\\n- CNN + POS: 59.12 60.26 59.54 67.53 59.69 61.53\\n- POS: 57.21 57.28 56.95 67.84 56.53 59.76\\n- Sty: 60.58 61.81 60.72 69.70 59.13 81.48\\n- POS: 58.86 59.93 58.97 68.32 55.71 81.16\\n- POS: 60.62 61.59 61.00 69.38 57.68 82.42\\n- POS: 58.87 58.49 59.03 68.37 56.68 81.64"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "eF 2 McGill Results\\n- Gigaword\\n- WP, in 10 out of 14 cases.\\n- 50.24\\n- 50.25\\n- 50.29\\n- 65.06\\n- 50.19\\n- 50.32\\n- POS 53.65\\n- 59.49\\n- 56.36\\n- 69.77\\n- 61.05\\n- 52.00\\n\\n* Better\\n- POS 52.86\\n- 58.60\\n- 55.29\\n- 67.60\\n- 58.60\\n- 56.07\\n- performance\\n- POS 59.12\\n- 60.26\\n- 59.54\\n- 67.53\\n- 59.69\\n- 61.53 with POS.\\n- POS 57.21\\n- 57.28\\n- 56.95\\n- 67.84\\n- 56.53\\n- 59.76\\n- POS 60.58\\n- 61.81\\n- 60.72\\n- 69.70\\n- 59.13\\n- 81.48\\n- POS 58.86\\n- 59.93\\n- 58.97\\n- 68.32\\n- 55.71\\n- 81.16\\n- POS 60.62\\n- 61.59\\n- 61.00\\n- 69.38\\n- 57.68\\n- 82.42\\n- POS 58.87\\n- 58.49\\n- 59.03\\n- 68.37\\n- 56.68\\n- 81.64"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "OF © McGill Qualitative Analysis\\n\\nPositive sample: We continue to feel that the stock market is the place to be for long-term appreciation.\\n\\nNegative sample: Careers count most for the well-to-do.\\nMany affluent people place personal success and money above family."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "OF & McGill\\n\\nFuture Directions\\n- Incorporate such a system in an NLG pipeline (e.g., dialogue or summarization with text rewriting).\\n- Discourse analysis with presupposition (e.g., political speech).\\n- Investigate other types of presupposition."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "QF F McGill\\n\\nThank you!\\n\\nThank you to our co-authors:\\n\\nThank you to our sponsors:\\n\\nYulan Feng\\n- Prof. Jackie CK Cheung\\n\\nLeFen CRIM\\n\\nSee . 7: NSERC | CRSNG a NPP)\\n\\nQuébec"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 78,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "NLP / ML models are getting smarter: VQA = 2EH Visual7A [Zhu et al 2016]."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "NLP / ML models are getting smarter: MC(SQUAD)\\n\\nThe biggest city (GNM) is Cologne, Germany with a population of more than 1,050,000 people.\\n\\nERE is in Central and Western Europe (after about 1,230 km (760 | BiDAF [Seo et al 2017] = mia ae"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "a EUG ata htniecr ee Pee esa i ee Pte tee Met oe\\n\\ngibbon 57.7% confidence\\n\\n99.3% confidence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Adversarial examples"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "What about text? en el an, eee? eg = -A &.= _pet TT: = : zea What cybepefatosabsisiigis isrs shovwnh? eS eae"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "What about text? The sign shown is a road sign."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Semantics matter"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "How long is the Rhine? The biggest city is Cologne, Germany with a population of more than 1,050,000 people.\\n\\nIt emerges in Central and Western Europe, about 1,230 km (760 miles)."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Adversarial Rules"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Generalizing adversaries, =\\n2) ees of road sign is show"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Semantics matter--Cs ey Ss"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "How long is the Rhine?\\nThe biggest city in the Rhineland is Cologne, Germany with a population of more than 1,050,000 people.\\nIt is located in Central and Western Europe.\\n\\nThe Rhine is about 1,230 km (760 miles) long."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "What is the oncorhynchus also called?\\nDetailed investigation showed that these fish digest ctenophores 20 times as fast as an equal weight of shrimps."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Ingredient semantic score function black box model Semantically Different | Equivalent prediction AL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Revisiting adversaries max Axy) t s£. SEA(x,\\ny) =;"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "semantic similarity: paraphrasing\\n-\\na) POY[ a\\n- ee | a score! Harrotaurutt translators back translators good movie film] PCX 0.35 comes for free."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Finding an adversary\\n\\nWhat color is the tray? Pink\\n\\nWhat color is the tray? Green\\n\\nWhat color is the tray? Green\\n\\nWhat color is the tray? Green"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Semantically Equivalent."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "From SEAs to Rules\\n- a\\n- ah mn Rule get ASS."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "Proposing Candidate Rules\\n\\nWhat type of road sign is shown?\\n\\nCandidate\\n\\nWhich type of road sign is shown?\\n\\nWhat are you looking at?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "From SEAs to Rules"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "semantically Equivalent Adversarial Rules (SEARS)\\nHigh Adversary Count\\nNon-Redundancy\\n[Seen]\\n- {TS --> elk aC h."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Examples: VQA a p CS Q isual 7 a\\n- Telling [Zhu et al 2016] SEAR Questions / SEAs f(x)\\n\\nFlips\\nWP VBZ > WP's Whethes What's been cut? Cake Pizza 3.3%\\n\\nWhat\\nNOUN > Whet Which kind of floor is it? Wood Marble 3.9%\\n\\nWhich\\nNOUN \"color > colour What\\n-\\n- e/er colour is the tray? Pink Green 2.2%\\n\\nADV is > ADV's Where is Where's the jet? Sky Airport 2.1%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Examples: Machine Comprehension\\n\\nBiDAF [Seo et al 2017]\\n\\nSEAR Questions / SEAs\\n\\nWhat VBZ > What is What's the NASUWT?\\n\\nWhat NOUN > What resource was coal mined in the Newcastle area?\\n\\nWhat VERB > What was Ghandi's work called? Civil Disobedience\\n\\nWhat VBD > And what was Kenneth Swezey's job?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Examples: Movie Review Sentiment Analysis FastText [Joulin et al 2016] SEAR Reviews / SEAs\\n\\nf(x) Flips movie > film\\n\\nYeah, the movie film pretty much sucked.\\n- 5% Pos film -> movie Excellent\\n- 1% Neg\\n\\n'5 > was Ray Charles\\n- was legendary.\\n- 4% Neg this > that\\n\\nNow\\n- 4% that is a movie I really dislike.\\n- 1% Pos"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Experiments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "Set up Humans (Q) Top scored SEA (3) SEA (top\\n5) + Humanos of 2 0x jxK 7? Evaluate adversaries for semantic equivalence"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "How often can SEAs be produced?\\n\\nVisual Question Answering\\nSentiment Analysis\\n\\n46\\n45\\n34.5\\n33.23\\n42.5\\n11.5\\n33.8\\n33\\n25.\\n260\\n25\\n\\nHuman SEA\\nHuman + SEA\\nHuman SEA\\nHuman + SEA\\nMi Human\\n[§ SEA fi)\\nHuman + SEA\\nMi Human\\n[ SEA ff)\\nHuman + SEA\\n32"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Humans produce different adversaries: Sect\\n\\nThey are so easy to love... What kind of meat is on the boy's plate?\\n\\nWere on point. How many suitcases on the shelf?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "1. Part 1: experts come up with rules.\\n\\nIndividual predictions\\n\\nRules\\nTry different rules\\n\\nResults\\nList of POS tags\\n\\nReplace first instance of:\\nreplace (What NOUN, Which NOUN)\\nWith: Which NOUN\\n\\nSubmit\\n\\nMistake examples (click images to see them in more detail)\\n\\n2\\n\\n3\\n\\n4\\n\\n> Compact\\nSaved Rules\\n\\nImage Original After rule\\nreplace (Who is, Who's)\\nreplace (color, x on *Ls\\n\\nQ: What color is the lampshade?\\nq: Which color is the lampshade?\\n\\nAnswer:\\na) A bright red.\\nb) A bright red.\\nc) A subtle green.\\nd) A vivid orange.\\n\\nQ: What food item is above the burger?\\nQ: Which food item is above the burger?\\n\\nAnswer:\\nb) Chips.\\nc) Cole slaw.\\nd) Ketchup."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Part 2: experts evaluate our SEARS:\\n\\nRules to evaluate Results\\n\\nList of POS tags\\n\\nPlease look at the rule re:\\nThe current grepl\\n\\nDoes the\\n\\nNo\\nYes\\n\\nImage = Original\\n\\nAfter rule:\\n\\nProgress all\\n\\nQ: What color are the pots?\\nQ: Which color are the pots?\\n\\nSee Answer:\\nAnswer:\\n-\\na) Silver.\\n-\\nb) Black.\\n-\\nc) White.\\n-\\nd) Gold.\\n\\nQ: What color is the lampshade?\\nQ: Which color is the lampshade?\\n\\nAnswer:\\n-\\na) A light yellow.\\n-\\nb) A bright red.\\n-\\nc) A subtle green.\\n-\\nd) A vivid orange.\\n\\nQ: What animal is running in the background?\\nQ: Which animal is running in the background?\\n\\nAnswer:\\n-\\na) A dog.\\n-\\nb) A cat.\\n-\\nc) A llama.\\n-\\nd) A kangaroo."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "% correct predictions flipped\\n\\nTime (minutes) 16 2014.2 16.9 B 10.9 a 12.9 10.18 105.44 3 3.3 5\\n\\nVisual QA\\n\\nSentiment\\n\\nVisual QA\\n\\nSentiment\\n\\nMi Experts\\n\\nSEARs\\n\\nMi Finding Rules\\n\\nEvaluating SEARs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "Closing the loop (color > colour)\\n\\nme ey (WP VBZ\\n- WP's)\\n\\nRetrain model | Filter out bad rules\\n\\nAugment training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "10.5\\n3.5 au. 01.42 rm Visual QA Sentiment Original Augmented"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Conclusione 41"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "semantically Equivalent Adversarial Rules for Debugging NLP Models\\nSameer Singh (UC Irvine)\\nCarlos Guestrin"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "semantic scoring is still a research problem...\\n\\nSEAR Questions / SEAs\\n\\nf(x) on -> in . ; .\\n\\nWhat is ef in? Lights the television.\\n\\nWhere are the water bottles?\\n\\nFable vending machine\\n\\nWhere are the people gathered? Living room kitchen\\n\\nWhat is ea the background? A building mountains\\n\\nERD Chi <> ane\\n\\nWhere are the planes parked?\\n\\nConcrete landing strip"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Problem: not comparable across instances X = good movie Z 2 good. oodgee MOVE PICK IX) | SOx.) Zéreat AZ'lz) | Sscx,x).\\nvs 0.97 vs 0.29 0.29 0.074 0.05 Sx) = vein (1, POOL)\\nx) SORT"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "Examples:\\n\\nVQASEAR Questions / SEAs\\n\\nf(x) Flips Wheat has\\n\\nWhat's been cut?\\n- Cake\\n- Pizza\\n\\nWP VEZ > WP?\\n\\nwho is\\n- Wikele holding the baby?\\n- Woman laden\\n\\n\"What NOUN\\n- What which kind of floor is it?\\n- Weed\\n- Marble\\n\\n3 OH\\n- Which NOUN\\n- What which color is the jet?\\n- Gray\\n- White\\n\\nWhat color is the tray?\\n- Pink\\n- Green\\n\\nCOlOl \"> SENGUE\\n\\nWhat color is the jet?\\n- Gray\\n- Blue\\n\\n2.2%\\n\\nWhere's the jet?\\n- Sky\\n- Airport\\n\\nHew is\\n- How's the desk?\\n- Messy\\n- Empty\\n\\n2.1%"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Examples: Movie Review Sentiment Analysis FastText [Joulin et al 2016] SEAR Reviews / SEAs\\n\\nf(x) Flips\\n\\nYeah, the review film pretty much sucked. Neg Pos\\n\\nThis is not a movie film making. Neg Pos\\n\\nExcellent fit-movie. Pes Neg\\n\\nI'll give this movie 10 out of 10! Pes Neg\\n\\nRay Charles was legendary. Pes Neg\\n\\nIt was a really good show to watch. Pes Neg\\n\\nNow this is a movie I really dislike. Neg Pos\\n\\nThe camera really likes her in that movie. Pes Neg"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 168,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nSituation Overview\\n\\nSituation: deployed system (e.g. QA, MT...)\\n\\nGoal: improve system using human feedback\\n\\nPlan: create a log of user-system interactions & improve system offline (safety)\\n\\nHere: Improve a Neural Semantic Parser"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nContrast to Previous Approaches\\n\\nDatabase Answers\\n\\nParser Comparison"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Introduction\\nTask\\nObjectives\\nExperiments\\nConclusion\\n\\nAyeySir\\nSomaadh\\n\\nOur Approach\\nQuestions required\\nData question x for 1...n"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nOur Approach\\n\\nNo supervision: given an input, the gold output is unknown.\\n\\nBandit: feedback is given for only one system output.\\n\\nBias: log D is biased to the decisions of the deployed system.\\n\\nSolution: Counterfactual / Off-policy Reinforcement Learning"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Introduction\\nTask\\nObjectives\\nExperiments\\nConclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nA natural language interface to OpenStreetMap\\n\\nOpenStreetMap (OSM): geographical database\\n\\nNLMaps v2: extension of the previous corpus, now totaling 28,609 question-parse pairs"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nA natural language interface to OpenStreetMap\\n\\nExample question: \"How many hotels are there in Paris?\"\\n\\nAnswer: 951\\n\\nCorrectness of answers are difficult to judge\\n- Judge parses by making them human-understandable\\n- Feedback collection setup:\\n1. Automatically convert a parse to a set of statements\\n2. Humans judge the statements"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nA: jeiavaere) erpktee\\n\\nExample: Feedback Formula\\n\\nGag os\\n\\nQuestion #216: What are the names of cinemas that are within walking distance from the Place de la République in Paris?\\n\\nInformation found in Question?\\n\\nTown: Paris | Reference Point name: Place de la République\\n\\nQuestion Type: What is the name?\\n\\nProximity: Around/Near\\n\\nDistance: Walking distance\\n\\nSubmit query (around(center(area(keyval('name','Paris')), nwr(keyval('name', 'Place de la République'))), search(nwr(keyval('amenity','parking!'))), maxdist(WALKING_DIST)), qtype(keyval('name')))"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Introduction\\n\\nTask\\n\\nObjectives\\n\\nExperiments\\n\\nConclusion\\n\\nObjectives"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Introduction\\nTask\\nObjectives\\nExperiments\\nConclusion\\n\\nA' Lev) yercengoae\\nCounterfactual Learning\\n\\nResources collected log\\nDog = {(%t, Ye, Jr)}\\n\\nwith xe: input\\nye: most likely output of deployed system\\nd- € [-1,0]: loss (i.e. negative reward) received from user\\n\\nDeterministic Propensity Matching (DPM)\\n- minimize the expected risk for a target policy\\n- tw1 nRopm(tTMw) = A\\n- 5eTw(velxt)t=1\\n- improve 7, using (stochastic) gradient descent\\n- high variance + use multiplicative control variate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nMultiplicative Control Variate\\n\\nBayes theorem for random variables X and Y, with Y the expectation of Y: E(X) = E[Y]\\n- Y. RHS has lower variance if Y positively correlates with X.\\n\\nDPM with REWEIGHTING (DPM-+R)\\n\\nReweight Sum R:\\n\\nData T(WelXe) reduces variance but introduces a bias of order o(4) that decreases as n increases.\\nn should be as large as possible.\\n\\nProblem: in stochastic minibatch learning, n is too small."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nAsuas\\n\\nOne-Step Late (OSL) Reweighting\\n\\nPerform gradient descent updates & reweighting asynchronously.\\n\\nEvaluate reweight sum F on the entire log of size n using parameters w.\\n\\nUpdate using minibatches of size m, m<n.\\n\\nPeriodically update R\\n- retains all desirable properties.\\n\\nDPM + OSL"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nat Token-Level\\n\\nFeedback\\n\\nway oe DPM+T.\\n\\n1 n ly | Ropm + t(tw) = a > []arw(yl)t = 1 \\ j = 1\\n\\nDPM + T + OSL a.)\\n\\n2 (112, Srmw(vilxt))\\n\\nDPM + T + OSL (%w) = --WZen oFv- Ta tw (vel Xe)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nExperimental Setup\\n- sequence-to-sequence neural network NEMATUS\\n- deployed system: pre-trained on 2k question-parse pairs\\n- feedback collection:\\n1. humans judged 1k system outputs\\n- average time to judge a parse: 16.4s\\n- most parses (>70%) judged in <10s\\n2. simulated feedback for 23k system outputs\\n- token-wise comparison to gold parse\\n- bandit-to-supervised conversion (B2S): all instances in log with reward 1 are used as supervised training"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nExperimental Results\\n\\nDPM + T + OSL 65.45 + 6.96 64.45 is 63.45 45.77 62.45 61.45 at L 60.45 59.45 + 0.99 57.45\\n\\nHuman Feedback (1k)\\n\\nLarge-Scale Simulated Feedback (23k)\\n\\n17/18"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Introduction\\n\\nTask Objectives\\n\\nExperiments\\n\\nConclusion\\n\\nTake Away\\n\\nCounterfactual Learning\\n- safely improve a system by collecting interaction logs\\n- applicable to any task if the underlying model is differentiable\\n\\nDPM-OSL\\n- new objective for stochastic minibatch learning\\n\\nImproving a Semantic Parser\\n- collect feedback by making parses human-understandable\\n- judging a parse is often easier & faster than formulating a parse or answer\\n\\nNLmMaps v2\\n- large question-parse corpus for QA in the geographical domain\\n\\nFuture Work\\n- integrate feedback form in the online NL interface to OSM"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 104,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Power laws of natural language: exponent=0.6891.\\n\\nVocabulary Population:\\n\\nZipf's law\\n\\nHeaps' law\\n\\nBurstiness\\n\\nAbout how the words are aligned. Words occur in clusters. These can be analyzed through power laws.\\nOccurrences of words fluctuate. Today's talk is about quantifying the degree of fluctuation.\\nHow these could be useful will be presented at the end."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Fluctuation underlying text\\n\\nAny words (any word, any set of words) occur in clusters.\\n\\nOccurrences of rare words in Moby Dick (below 3162th).\\n\\nIE WE ITE EEE EE2000th 2500th.\\n\\nTwo ways of analysis:\\n- Fluctuation analysis\\n- Long range correlation > weaknesses 3"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Fluctuation underlying text > Look at variance in AtAny words (any word, any set of words) occur in clusters.\\n\\nOccurrences of rare words in Moby Dick (below 3162th).\\n\\nVariance is larger when events are clustered vs. random.\\n\\nTwo ways of analysis:\\n- Fluctuation Analysis (Ebeling\\n1994)\\n- Fluctuation analysis variance w.r.t. At\\n- Taylor's analysis = Our achievements\\n- Long range correlation variance w.r.t. mean"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Taylor's law (Smith, 1938; Taylor,\\n1961) Power law between standard deviation and mean of event occurrences within (space or) time Atao x p® Empirically 0.5 < a < 1.0 (but a < 0.5 is of course possible, too)\\n\\nEmpirically known to hold in vast fields (Eisler,\\n2007) ecology, life science, physics, finance, human dynamics ...\\n\\nThe only application to language is Gerlach & Altmann (2014) <€ not really Taylor analysis We devised a new method based on the original concept of Taylor's laws"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Our method Word sequence (text) a\\n- At1 For every word kind w;, € W\\n\\nEstimate a@ using the least squares method in log scale within given length At.\\n- @ = argmin, ,€(c, a),2\\n\\nObtain mean Ll, and |W |.\\n- 1 standard deviation ox, of Wx.\\n\\nE(c,a) = TPG: Ox\\n- log cu%)?.\\n\\nPlot uz, and o;, for all words."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Taylor's law of natural language. 'Moby Dick', English, 250k words, vocabulary size 20k words.\\n\\nMy Wor Taylor's law in log scale. Here, At ~\\n5000. Every point is a word kind.\\n\\nEstimated Taylor exponent a = 0.57."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Taylor's law of natural language\\nMoby Dick (English)\\nTaylor's law in log scale\\na = 0.57\\n€ = 0.0610<sup>-10</sup> + 10<sup>0</sup> 10<sup>! ~ 107</sup>"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Theoretical analysis of the exponent Empirically 0.5 <a@< 1.0@=0.5 if all words are independent and identically distributed (i.i.d.).\\n\\nShuffled 'Moby Dick' at ~\\n5000.\\n\\nTaylor Exponent a = 0.5 because shuffled text is equivalent to i.i.d. process. E = 0.0310°\" 10° 10! 104lL 9"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Theoretical analysis of the exponent a = 1.0 if words always co-occur with the same proportion.\\n\\nSuppose that W = {w, w.}, and w occurs always twice as w.\\n\\ngradient At a = 1, py = 2uy, 05 = 20, el sen eeremenaet 3 = > aoXuor loge10"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Taylor's law for other data\\n\\nChild directed speech\\n\\nProgramming source code\\n\\nThomas, English, CHILDES Lisp, crawled and parsed 450k words (8.2k diff. words) 3.7m words (160k diff. words)\\n\\n210\" ear] fis} 0] | [platform} awe Dae\\n\\n10\" alae\\n\\n10! arhet liaso\\n\\n7 }10°\\n\\n7 \"0oft a=0.66\\n\\nof a=0.72\\n\\nwe € =0.09\\n1071) oz € =0.09\\n\\n10°' 10° 10! 102 10° 10°! 10° 10!lL lL st"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Datasets Languages Number | Average size of texts\\n\\nGutenberg & Aozora\\n14 (En, Fr, ...)\\n1142\\n311,483\\n\\n'Moby Dick' (Long, single author)\\n'Les Miserables'\\n\\nNewspapers\\n3 (En, Zh, Ja)\\n4\\n580,488,956\\n\\nWSJ Tagged Wiki\\n1 (En + tag)\\n1\\n14,637,848\\n\\nenwiki8 CHILDES\\n10 (En, Fr, ...)\\n10\\n193,434\\n\\nThomas (English)\\n\\nMusic\\n- 12\\n135,993\\n\\nMatthaus (Bach)\\n\\nProgram Codes\\n4\\n4\\n34,161,018\\nC++, Lisp, Haskell, Python"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Taylor exponents of various data kinds\\n\\nMean(a@) = 0.58\\n\\nSingle author texts = 0.70\\n\\nRandom = 0.60\\n\\naana = 0.50\\n\\nNone of the real texts showed the exponent 0.5"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Summary thus far:\\n- Taylor's law holds in vast fields including natural/social science.\\n- Taylor's law also holds in languages and other linguistic-related sequential data.\\n- Taylor exponent shows the degree of co-occurrence among words.\\n- Taylor exponent a differs among text categories (no such quality for Zipf's law, Heaps' law).\\n\\nHow can our results be useful?\\n- Do machine-generated texts produce a > 0.5?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Machine generated text by n-grams bigrams of Moby Dick."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Machine generated texts by character-based LSTM language model\\n\\nLearning: Shakespeare by naive setting\\n\\nStacked LSTM (3 LSTM layers)\\n\\nGeneration: Probabilistic generation\\n\\nDistribution of following character of succeeding characters (2 million characters)\\n\\n10!\\n\\nLSTM fi256, nodes ©4099ie a = 0.50 = -0.0110°77 10° 10! = 104iu128 preceding characters\\n\\nState-of-the-art models present different results (in another paper) 16"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Texts generated by machine translation\\n\\nLes Miserables\\n\\nLes Miserables translated by (original, French) Google translator (in English)\\n\\nFluctuation that derives from the context is provided by the source text"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Conclusion\\n- Taylor's law holds in vast fields including natural/social science.\\n- Taylor's law also holds in languages and other linguistic related sequential data.\\n- Taylor exponent shows the degree of co-occurrence among words.\\n- Taylor exponent a differs among text categories (no such quality for Zipf's law, Heaps' law).\\n\\nHow can our results be useful?\\n- Do machine-generated texts produce a > 0.5?\\n- The nature of a > 0.5: context and long memory.\\n\\nOne limitation of CL-Taylor analysis would possibly evaluate machine outputs.\\nKnowing mathematical characteristic of texts serves for language engineering."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Thank you"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 102,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Background\\n- Naturally and consistently converse with human beings on open-domain topics.\\n- Data-driven\\n- Retrieval-based methods\\n- Generation-based methods\\n- System ensemble"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Context-Response Matching\\nContext c(ip|p(is_good|c,r)\\nResponse r\"ipBalto"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "EEERetrieval-based Chatbot\\n\\nAn information retrieval approach to short text conversation. Ji et al., 2014"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Adversarial Dialogue Generation\\n\\ny = Dialogue 'a: p(is_good|c,\\nr) Real Conversation\\n\\nPAY: Sampled <c, r> Tas.\\n\\nDiscriminator Generator G(r*|c) Adversarial Learning for Neural Dialogue Generation. Li et al., EMNLP-2017 Bai Oak"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "novo S DE nnSDE ESSE ESUSE SESE SSUEESSSESSEEESSSSESSSESSSSEESSEESSSEDESESESESSESESESESESEEEESSNEEESSEEESEEEEE\\n\\nChallenges\\n- Detecting truly matched segment pairs across context and response.\\n- Segment pairs could be matched at different granularities.\\n- Segment pairs, across context and response, could be matched because of textual relevance or semantic dependency."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Oe EEO Conversation Context\\n\\nSpeaker A: Hi I am looking to see what packages are installed on my system, I don't see a path, is the list being held somewhere else?\\n\\nSpeaker B: Try dpkg --get-selections\\n\\nSpeaker A: What is that like? A database for packages instead of a flat file structure? Matching with dependency\\n\\nSpeaker B: dpkg is the debian package manager --get-selections simply shows you what packages are handled by it\\n\\nResponse of Speaker A: No clue what do you need it for, it's just reassurance as I don't know the debian package manager"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Oe EEO Conversation Context\\n\\nSpeaker A: Hi, I am looking to see what packages are installed on my system.\\nI don't see a path; is the list being held somewhere else?\\n\\nSpeaker B: Try dpkg --get-selections.\\n\\nSpeaker A: What is that like? A database for packages instead of a flat file.\\n\\nSpeaker B: Dpkg is the Debian package manager; its selections simplify shows you what packages are handled by it.\\n\\nResponse of Speaker A: No clue what do you need it for, as I don't know the Debian package manager."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "novo S DE nnSDE ESSE ESUSE SESE SSUEESSSESSEEESSSSESSSESSSSEESSEESSSEDESESESESSESESESESESEEEESSNEEESSEEESEEEE\\n\\nMotivation\\n- Use GRU/LSTM to encode segments and match context with response only considering textual relevance.\\n- Self-Attention: Using intra-attention of utterance/response to gradually construct multi-grained semantic representations.\\n- Cross-Attention: Using attention across context and response to match with dependency information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Oe EEO\\n\\nConversation Context\\n\\nSpeaker A: Hi I am looking to see what packages are installed on my system, I don't see a path, is the list being held somewhere else?\\n\\nSpeaker B: Try dpkg --get-selections\\n\\nSpeaker A: What is that like? A database for packages instead of a flat file structure?\\n\\nSpeaker B: dpkg is the debian package manager --get-selections simply shows you what packages are handled by it\\n\\nResponse of Speaker A: No. What do you need it for? It's just reassurance as I don't know the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Oe EEO\\n\\nConversation Context\\n\\nSpeaker A: Hi, I am looking to see what packages are installed on my system, I don't see a path, is the list being held somewhere else?\\n\\nSpeaker B: Try dpkg --get-selections\\n\\nSpeaker A: What is that like? A database for packages instead of a flat file structure?\\n\\nSpeaker B: dpkg is the debian package manager -- get-selections simply shows you what packages are handled by it.\\n\\nResponse of Speaker A: No, well what do you need it for? It's just reassurance as the debian package manager."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Oe EEO Conversation Context\\n\\nSpeaker A: Hi I am looking to see what packages are installed on my system, I don't see anything in the list being held somewhere else?\\n\\nSpeaker B: dpkg --get-selections\\n\\nSpeaker A: What is that like? A database for packages instead of a flat file structure?\\n\\nSpeaker B: dpkg is the Debian package manager\\n- get-selections simply shows you what packages are handled by it.\\n\\nResponse of Speaker A: No clue what do you mean, it’s reassuring as I don't know the Debian package manager."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Conversation Context\\n\\nSpeaker A: Hi I am looking to see what packages are installed on my system, I don't see anything in the list being held somewhere else?\\n\\nSpeaker B: dpkg is the Debian package manager\\n- 'get-selections' simply shows you what packages are handled by it.\\n\\nResponse of Speaker A: No clue what do you need reassurance as I don't know the Debian package manager."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Ll UL. Input Attentive Module\\nQ = feos renga\\nK = leoses€me-a}\\nV = leos.es€myaaeiaieieminietaienl aieieeteienaien,\\n\\nAttentive Module (Q, K,\\nV)\\nT| Sum & Norm\\n1 Q\\n- K\\ne Vat = softmax(--) V7 : -___\\n\\nV dr! '| Feed-Forward\\nO att = Layer Norm (Vate +\\nQ)\\n\\n> See 'Sum & Norm © FF N(Qatt)!\\nSe Se | = max(0, OattW1 + b1)W2 + bey enm = Aw\\n\\nLayer Norm (F' FN (Qatt) + Qatt)\\n\\nSummary\\nCapture structures across Q and K\\n- V\\nComposite semantic representations of captured Attention is All You Need.\\nVaswani et al., NIPS-2017\\nstructures with input embedding E"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "aesiee'te"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "ee CI \" \" * UUUUUUOOti ( \"#\" a # \"(\" # TMNY . NC _ \" _ A' lM i\\n- niUp ; life ): peas. ' \\ iq o ' ie NEE f | Ed / ioe EE) | ACelelelaH ?\\nlel a < + elee } ' i fl a fl a \" delelel ' @ 1 \\ @ ' tian as * an : re, '\\n- U ? = uj, <= word-level ASA A / SU Be : aaaa ee TE 7 a ew ( fe lal wee \" 8 Bae : lela a she < + felelale |\\n- 1 ; 1\\n- 1 qzrl\\n- 1 qrl\\n- 1 aaceck A } j LB a : Ng jsis / S = U ; = AttentiveModule ( U ; ° , U ; ° , U ; \" ) , ? <\\n- phrase-level ' ae | \\ ' Uu ; ' a g } E \" U , a 0 l Se . ) SS . _ = _ eee eit , 0 UY = AttentiveModule ( UY ut ' Ut a <\\n- sent .\\n- level ' Aeon eny ' i \" ma rem 4 = fi iR a Ua\\nA) ( etextaf on a K 7 a | aie ( fe ) Olio BA ( CBA felele ! V ea | eae | ' Adslele | Un Ni f } a f j 4 He , Gea . ee .\\nAAIistelek < g E ac\\n- 8 f a fererete ve mt eet all | e !\\n1 A EY py He HD x | O } O } ; _ = es UGA a Gua i a tg lejeje | = \\ R = AttentiveModule ( RTM , RTM , RTM ) , Tr Hg ' a & i HOO } if / 00 4 TMWord Soe ee ee eee Soe R RL = AttentiveModule ( R \" ' , R * ~ ' , R \" * ' ) : .\\nMulti-grained eeEmbedding Representation Representations Bai ' tsModule cu"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "OOOOsey oI Ss ale) wie © ie | an an llan 1 (2 DDAOL!HO AE (SAE: slelste. (Gees Welezere) | Ne MAE i YICIOOOO! M7oOOO}!\\nwy SoC Ee HM elexolelma i elereye) tatalalalalalatalalalalalanetaiaiaieiananaiaianaenald t OOO OOOO} : (gama, aaa | ti etatatatatatatatataiataiataiatatatatataanet\" > < ; { iN ya \" Iere if.\\n_ 1 Ce\"JA a {a i: elelel Peie eae lela Te --Mag Jeg a!\\n'ee a: d | | \\| WEA GRAAA !u, WE \"@ 4 NIGIOO OO) goo Oo} : i \\GES 7 E80 Ui = IGGQOQO} goo oo}wri.\\ni HWG@OOOQ) LgoOOO!:'dina 'ees. i (OOOO OOOO!7 'a | A\\na) J | Nannon e once ene n ena?a {\\\" AY i 1 (@lalaraL |! U4 57 UWio7\"ee Eee ee ERE eee 1!\\n\"4 u'Fagin tan die ofa!) Maciz = MorosVata eat ie: \"gisigies: uy CURE PGE E \"eesn Se baccapeanenepenmpeih i ee eee ES, SS ee ee eee I{ LA_ fA) 6 E\\ Oy Ga 'ee aa ech re ER Ny le a 4 4 Y a Aa A ''@m con OR oo W\\ITIOO OO] MGOO OO} a\" fj: a7 {J \\ | Gis 1 ICdO0OOO| KgoOOo!' eM fin' ee aig: ferereral \"S488 92 Wexexerel| Vaan Baa pees soso \"oooo} r a a: ul A a Ndeisie| Toone s eens nnn secs ccna aa\" wu Co} RWord moran nnn seen eens ere errr : : : : .\\n\\nMulti-grained Word-word Matching\\n\\n66Embedding a Representations with Cross-Attention Bi ai daeodule"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "EE HSL SSIS1 l we Ef im!\\nHE | ER (4 i@le} i (2_ [D(X (EN _(N_ (EN iaH Ach cat chem GGL: d_sWelele) W@aeaaL GaAs:Sislolox- a eS o HEE se |e2)\\n\\n{GOO OO (OO OO}!\\nSelf-Attention MatchNie | ' i YGqG2OOO; dOOOO!uy Ge Ce MiQ@QQQ} GIQQQQ sewiiel lar alpeneceeneneamenreneinnrens hE SS LEE | Mecif = {UIA -R le}n., xn,f rw : * ' |, cae i: i aAD A ie D: (qea He ac 8 Bee (fe |@j@|\\n\\n------------------f----., Match with textual informationN gil 7\" i JU SisisieN Ss, GSNEY Ee : NIGdOO OO) JOD OO:Uj PQeUe Guele U; IKGOO OO 199 9 9pagngsnzsnses\\n\\n~~\" ~agageeasaiss i {IQQOOMF GIOO OO!an ey it SOOGH| \"OOOO!z fj. ! AY { 1 @iaae i!\\nUy ,T WitOe a a SS ay 4\"4B 4 AC fe a 1K 19} i!\\nMy cif WassVAT Vette i: \"eSisisis}:un *E Pele Yc cecceesceeeSEe Snes ten en es\\n- Gheres cesses i es <= BEES /Pe ig cr lini a \\!\\n- CA LNA!'@m on) MB oa WOOO] OOOO!ih !\\nAD I: Gia, | H4qQOQO) fgQO OO; 'sunny slain: Krejorepal 48 88 960 06Vaan Baa pees soso \"oooo}r Mi i a i ; J: sisisi Soon nsm nsec essences sessORCS PSsWord ae : : ::\\n\\nMulti-grained Word-word Matching eeEmbedding a Representations with Cross-Attention Bi ai daeodule"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "We are looking for a large-scale research opportunity in 2020; do not miss it!\\n- Match with textual information\\n- Cross-Attention Match\\n- Attentive Module (U, R')\\n- Attentive Module (R',\\nU)\\n- Match with dependency info\\n- Multi-Embedding Representation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "ame ee |e): / 'ep Gb ERE) : -Celele} (AaBaea AAALa ee = oe a ee a Gal | onl IRA AA CAA ASL |Sislelel qin eat a Welelela.\\neee 40.0 OO} | \"BT H YICGOOOO} f7oOOO},U4 Ww NO {iOO OO {iO O OO}\\n\\nSana ae a 'S0000) SOOOO! (gama, aaa | tietatatatatatatatataiataiataiataiatatatatataanet\\n\\nLT: if if.\\n\\mr i @IAIAIa \\seek ey Ali 1 pe Go|] | eannnveeeeennnnneennane Oease Ae: i slslele | i FER IOeB SB El Sdelelala!\\nCocoa «IGS le] eae er ey ,| dati fi \"elele| 'NIGGSSSO] MS06o} SK HAAS | \\yuewa 6UeU U; = !tqoooo) Cgoooo} | (F 1 | rats O} \\\"rrr i HGGQOOO} WaQOOO!\\nZz-e=ae=We=b i\\n\\n(c r)'(hes ine. i \"OOOO! OOOO} | am ain aoe [XCA m CBROR: eee Uc eee Aeae Wart fh i: Gejerere i Mer Mee\" oD S|\\n\\n/ Matching-11 BY ey Sais A RY ey a 2 od < NOIOlOl®@ self carat ror / Scoreot BB a\\n\\nOBA iE: 1Seleee |! /aul ; Nag | i qe|e|2 i\" LW WW OUn we f 2 gu\"\\n- *:\\n\\nS-> Hee <eeRee cee. fA .vo nennlesssn MigSesy ease.)\\n\\n3P Matching(ea ihe a i wiq{Oo OO 1109 OO}: Image QRA SAA eae) sess aee Ss a' ae pe\\n\\n(fe Isley | COOO OOOO}: WG BB tb GC BLE Yl }; Kyejee kane cenenee nensnee saanNEL :\\n\\n@i@}rtf AG 3 RWord MoU Ge Se eee oe , ; ;:\\n\\nMulti-grained Word-word Matching eeEmbedding a Representations with Cross-Attention B ai daeModule"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "a ELEHet Vt se ==ut i Wee | & | ie HE i > ele i [2S (S (2 _[E5_ ' yoo 1~ 1 y Aa s a 11 lela WW@sseL esse} isee a 1 Ea 1: \"olelele SSS) fdSSSO)\\n\\nMulti-grained matching, including both textual and dependency information, of a segment pair across context and response.\\n\\nGreat\\n\\nan: Th if fejejeje\\n\\n------------------------\\n\\n©8 a eae sed © EY eee el < elelel a ' 'KEE IO\\ie ee } el: islelele VISE GEES SS Tk Yea ee 'u;\\n\\n\"EL : iH NGeSSo KSddq, Ate OAS |= \\i ~au Gu? U; !Wqgoooo! Mgoo00}:\\n\\n(F Tt | ro \\ace aoe oe ee eer I aq aq Se ee KE\\nC)\\n\\n\\wii gaia Hesse) Wess bey lo] (cx)4 y aaa \" ~ aay, % Bi I Y L qAe oe: Ae Oe: I seater! ta cel Ie :ADGA AUN pose xr ren,\\n\\nIS\\n2) actin4 iae q far As if lolole) |! self Cross expeceeceecalt @) ScoreU 'aul 'eue |\\n\\n\"Glelel iM -_- O/ea & / (ab } ee f 'n Eee Eee e one ee eee eee i iG\\n- aS\\n- JL\\n\\n3D Matchingi oe eS\\n\\nWve CA LACS CALA CA!Cea e Che i a: H\\ITIOOOO] MGoOOO!/\\n\\nImage Q. fj: ai {J (IR: qo | 'qoooo) ooo}fee Bil ieW ila: Krejorepal 48 88 (506 OOa\\n7. a«-§ Ald | xdelele! / 1 JOOO00 OOOO!r Se ie 'eye ; a N(Sleic|\\n\\nDorner e nnn nnn nnn\"i OU }E vert Reresentation uit rained Word-word Matching 0embedding T haiul 100 Representations with Cross-Attention Bai Sagodule"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 20,
        "texts": [
          "EEE SEL | SSS\\n- Ubuntu Corpus\\nOne-one multi-turn conversation\\nUbuntu Corpus V1\\nDouban Conversation\\nUbuntu troubleshooting\\nDouban Corpus\\n\\nResponse candidates\\nAvg. #words per utterance\\n10.34\\n18.56\\n18.50\\n20.74\\n\\nSelect the best candidate based on matching score"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Ll UL Experiment\\n- DAM setup\\n- Test stacking 3-7 self-attention layers\\n- Comparison\\n- Sequential Matching Network (SMN) (Wu et al., ACL-2017), Multi-view Matching (Zhou et al., EMNLP-2016), DE2R (Yan et al., SIGIR-2016), Dual Encoder (Rowe et al., SigDial-2015)\\n- Ablation\\n- DAM first: without stacked self-attention\\n- DAM last: only using the last layer of stacked self-attention\\n- DAM seiz: only using self-attention match\\n- DAM cross: only using cross-attention match"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "elEvaluation Results\\n\\nbunt Corpus «| dDouban Conversation Corpus\\n\\nP   T  PRGT  |  RivGT  |  RivG@2  |  RivG5  |  MAP  |  MRR  |  P@1  |  RG1  |  RG2  |  RvG5\\n\\nDualEncoderisim  0.901  0.638  0.784  0.949  0.485  |  0.527  |  0.320  |  0.187  |  0.343  |  0.720\\n\\nDualEncoderpiistm  0.895  0.630  0.780  0.944  0.479  |  0.514  |  0.313  |  0.184  |  0.330  |  0.716\\n\\nMV-LSTM  0.906  0.653  0.804  0.946  0.498  |  0.538  |  0.348  |  0.202  |  0.351  |  0.710\\n\\nMatch-LSTM  0.904  0.653  0.799  0.944  0.500  |  0.537  |  0.345  |  0.202  |  0.348  |  0.720\\n\\nMultiview  0.908  0.662  0.801  0.951  0.505  |  0.543  |  0.342  |  0.202  |  0.350  |  0.729\\n\\nDL2R  0.899  0.626  0.783  0.944  0.488  |  0.527  |  0.330  |  0.193  |  0.342  |  0.705\\n\\nSMNaynamic  0.926  0.726  0.847  0.961  0.529  |  0.569  |  0.397  |  0.233  |  0.396  |  0.724\\n\\n'DAM.  |  0.938  |  0.767  |  0.874  |  0.969  |  0.550  |  0.601  |  0.427  |  0.254  |  0.410  |  0.757\\n\\nDAM first  0.927  0.736  0.854  0.962  0.528  |  0.579  |  0.400  |  0.229  |  0.396  |  0.741\\n\\nDAMiuast  0.932  0.752  0.861  0.965  0.539  |  0.583  |  0.408  |  0.242  |  0.407  |  0.748\\n\\nDAMseif  0.931  0.741  0.859  0.964  0.527  |  0.574  |  0.382  |  0.221  |  0.403  |  0.750\\n\\nDAM scans  0.932  0.749  0.863  0.966  0.535  |  0.585  |  0.400  |  0.234  |  0.411  |  0.733"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Self-Attention Match V1\\n\\nmanager\\n- manager\\n- num a Ae\\n\\non\\n\\ndebain\\n- debain\\n- debain\\n\\nthe\\n- the\\n\\nknow\\n- know\\n- don't\\n- don't\\n- don't\\n\\nof\\n\\nreassurance\\n- reassurance -ices\\n\\njust\\n\\nits\\n- its\\n- its\\n\\nfor\\n\\nneed\\n- need\\n- need\\n\\nyou\\n- you\\n- do\\n- li\\n\\ndo\\n- do\\n\\nwhat\\n- what\\n- what\\n\\nclue\\n- clue\\n- clue\\n\\nno\\n- no\\n- no\\n\\nStack-0 ---------------> Stack-2 -------------> Stack-46"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "a CUD Cross-Attention Match Visualization manager\\n-\\n- Self-Attention Match\\n- Cross-Attention Match"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "novo S DE nnSDE ESSE ESUSE SESE SSUEESSSESSEEESSSSESSSESSSSEESSEESSSEDESESESESSESESESESESEEEESSNEEESSEEESEEEEESummary\\n- We propose a novel deep attention matching network for multi-turn response selection that is entirely based on attention.\\n- We use stacked self-attention to construct multi-grained semantic representations.\\n- We use cross-attention to match context with its candidate response considering both textual and dependency information."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "Code & Data: https://github.com/baidu/Dialogue/DAM\\n\\nOur Authors"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 20,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Debates and Arguments\\n\\nThe Peas pie."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Debates and Arguments\\n\\nUK would be better outside the EU."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Debates and Arguments\\n\\nA Leaving will cause a shock to Britain's economy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Debates and Arguments\\n- a year\\n- a late.\\n\\nInstead, we will have £350 million more to spend a week."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Debates and Arguments:\\n\\nWe will be less favorable as an investment prospect due to loss of EU consumers."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "Debates and Arguments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 6,
        "texts": [
          "Motivation\\n- Argumentation is crucial in communication.\\n- We want to avoid biased perception and uninformed decisions.\\n- Persuasion is complicated.\\n- Being informative is already non-trivial, not to mention being persuasive."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Research Question\\n\\nHow can we automate human argumentation process?"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Our Goal\\n- We generate a specific type of argument: counterargument."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Our Goal\\n- We generate a specific type of argument: counterargument.\\n\\nInput: a statement of belief on some controversial topic\\n\\nOutput: a counterargument refuting the statement"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Our Goal\\n- We generate a specific type of argument: counterargument.\\n\\nInput: Humans are not designed to be vegan.\\n\\nOutput: We are not designed to be anything, evolution is directionless. You imply unnatural is bad, that is wrong.\\nDriving and using smartphone are also unnatural.\\n\\nTalking points"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Our Goal\\n- We generate a specific type of argument: counterargument.\\n\\nChallenges:\\n1. Understanding the topic and stance\\n2. Application of common sense knowledge\\n3. Generating arguments in natural language texts"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Outline\\n- Prior Work\\n- Data\\n- System Pipeline\\n- Experimental Setup\\n- Evaluation\\n- Future Directions and Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 13,
        "texts": [
          "Outline: Prior Work"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Prior Work\\n- Argument Component Detection\\n- Evidence detection [Rinott et al, 2015]\\n- Classification of types of supports [Hua and Wang, 2017]\\n- Argument and Evidence Retrieval\\n- Argument search engine [Wachsmuth et al, 2017; Stab et al, 2018]\\n- Argument Component Generation\\n- Retrieval based argument generation [Sato et al, 2015]\\n- Argument strategy based generation [Zukerman et al, 2000]"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Outline: Data"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "Data- r/changemyview\\n- A subreddit for open discussion and debate"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Data© reddit Ce r/changemyviewa\\n\\nI believe the government should be allowed to view my emails for national security concerns. CMV.\\nI have nothing to hide. I don't break the law, I don't write hate emails...\\n\\nSeriously, whether or not ... is a good thing, it runs up against the protections offered in the Fourth Amendment:\\n\\n“Giving up privacy means giving up some of your right to free speech.” Knowing that you might be listened in on may change what you say and how you say it..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Data© reddit Ce r/changemyviewa | believe the government should be allowed to view my emails for national security concerns.\\nCMV. | have nothing to hide. | don't break the law, | don't write hate e-mails...\\n\\nSeriously, whether or not ... is a good thing, it runs up against the protections offered in the Fourth Amendment:\\n\\n\"Giving up privacy means giving up some of your right to free speech.\" Knowing that you might be listened in on may change what you say and how you say it...\\n\\nI saved this answer for a Reddit Gold. It did change my opinion\\n- I never thought that..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "Data Collection:\\n- Jan 2013\\n- Jun 2017, about 27K in total.\\n- We selected the politics and policy related topics for study.\\n- We only consider \"high quality\" replies (with delta or more upvotes).\\n\\nStatistics as below after removing non-root and low quality replies:\\nInput statement: Human argument\\nAvg number of sentences\\nAvg number of tokens 356.4 161.1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Outline\\n- System Pipeline"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 23,
        "texts": [
          "Pipel wv right to privacy\\n\\nI believe the\\n\\nEdward Snowden\\n\\nyou are ignoring the\\n\\nInput statement\\n\\nEvidence sentences\\n\\nI believe the government\\n\\nNothing to hide argument\\n1. Edward Snowden: \"Arguing\\n2. Political corruption\\n\\nshould be allowed to view\\n\\nPolitical corruption is the use of powers by government officials for illegitimate private gain.\\n\\nI have nothing to hide. I don't break the law...\\n\\nSurveillance (or /serverlens/) is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 24,
        "texts": [
          "Pp @( : ( A right to privacy ~ I believe the\\n1. Document Retrieval\\n- Evidence sentences I am; II * T believe the government has\\n\\nNothing to hide argument\\n1. Edward Snowden: \"Arguing the\\n2. Political corruption is the use of powers by government\\n- I have nothing to hide. I don't break the law...\\n\\nSurveillance is the m"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 25,
        "texts": [
          "Pp @ [ @( : { <phz> right to privacy <phz>\\n\\nI believe the\\n1. Sentence Reranking\\nInput statement 8: Evidence sentences or; \"I believe the government\\n2. Nothing to hide argument\\nEdward Snowden: \"Arguing\\n3. Political corruption.\\n\\nFrom Wikipedia, he should be allowed to view my emails for national security concerns.\\n2. Political corruption is the use of powers by government officials for illegitimate private interests.\\n\\nI have nothing to hide. I don't break the law...\\n\\nSurveillance (/ser'ver.ans/ or /ser'veriens/) is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 26,
        "texts": [
          "@PIPEHIME\\n5. Encoding (bits)\\n\\nI have a right to privacy.\\n\\nI believe the\\nEdward Snowden\\n\\nYou are ignoring the concerns.\\n\\nInput statement 8\\n\\nEvidence sentences:\\n\\nI believe the government should be allowed to view my emails for national security concerns.\\n\\nSurveillance\\n2. Political corruption is the use of powers by government officials for illegitimate private gain.\\n\\nI have nothing to hide. I don't break the law.\\n\\nSurveillance ( /sar'vet.ans/ or /ser'verlens/) is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 27,
        "texts": [
          "e e eeP { pel ine\\n4. Keyphrase Decoding (LSTM)\\n\\nI believe the\\n\\nedward snowden\\n\\nyou are ignoring the\\n\\nInput statement\\n\\nEvidence sentences\\n\\nI believe the government,\\n\\nNothing to hide argument\\n1. Edward Snowden: \"Arguing should be allowed to view Political corruption about right...\\nto privacy because my emails for national security concerns.\"\\n2. Political corruption is the use of powers by government officials for illegitimate private interests.\\n\\nSurveillance (/sar'vet.ans/ or /ser'verlens/) is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 28,
        "texts": [
          "Pipeline; B i Z 1 A\\n\\nRight to privacy\\n5. Argument Decoding (LSTM)\\n\\nI believe the Edward Snowden\\n\\nInput statement\\n\\n8 Evidence sentences\\n\\nI believe the government ed Nothing to hide argument.\\n1. Edward Snowden: \"Arguing 3.3k. WIKIPEDIA OE. I don't care.\"\\n2. Political corruption is the use of powers by governments for illegitimate private interests.\\n\\nThis article is about observing individuals of interest.\\n\\nSurveillance (/sar'vet.ans/ or /ser'verlens/) is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 29,
        "texts": [
          "Pipell right to privacy\\n\\nI believe the\\n\\nEdward Snowden\\n\\nyou are ignoring the\\n1. Document Retrieval\\n\\nEvidence\\n\\nI believe the government has nothing to hide argument.\\n2. Edward Snowden: \"Arguing should be allowed to view my emails for national security concerns.\"\\n3. Political corruption is the use of powers by government officials for illegitimate private gain.\\n\\nSurveillance is the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 30,
        "texts": [
          "Step 1: Document Retrieval\\nGoal: to extract relevant evidence for counterarguments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 31,
        "texts": [
          "Step 1: Document Retrieval\\n\\nQuery construction =\\n- Formed from topic signatures [Lin and Hovy, 2000]\\n- Representative of the text, measured by log-likelihood ratio\\n\\nE.g. \"government\", \"emails\", \"national security\", etc. in the following post:\\nI believe the government should be allowed to view my emails for national security concerns. CMV.\\nI have nothing to hide. I don't break the law..."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 32,
        "texts": [
          "Step 2: Sentence Reranking\\n\\nSee Rerank sentences. Returned articles are broken into paragraphs and sentences.\\nSentences are ranked by TF-IDF similarity against the post.\\n\\nEvidence sentences\\n\\nNothing to hide argument\\n1. Edward Snowden: \"Arguing political corruption that you all care about privacy because...\"\\n2. Political corruption is the use of powers by government officials for illegitimate private gains.\\n\\nSurveillance (/sar ver.ens/ or /sarverlans/)!"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 33,
        "texts": [
          "- Neural Encoder\\n- Bi-directional LSTM network\\n- Encode input statement and evidence sentences, separated by <evd> token\\nI believe the\\n<evd>\\nedward snowden"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 34,
        "texts": [
          "Step 4: Keyphrase Decoding\\n- Decoder: Generate keyphrase as an intermediate step.\\n- Aim to inform the model of the major talking points.\\n- Mimic keyphrases that are likely reused by humans.\\n\\nOCP\\n- right to privacy.\\n\\nI believe the Edward Snowden see."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 35,
        "texts": [
          "Step 4: Keyphrase Decoding\\n\\n°C: 08\\n- Decoder\\n- We extract noun phrases and verb phrases.\\n- The length has to be between 2 to 10 tokens.\\n- Phrase has to contain non-stop words."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 36,
        "texts": [
          "Step 4: Keyphrase Decoding\\n- Decoder\\n- We extract noun phrases and verb phrases.\\n- The length has to be between 2 to 10 tokens.\\n- Phrase has to contain non-stop words.\\n\\nNumerous civil rights groups and privacy groups oppose surveillance as a violation of people's right to privacy."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 37,
        "texts": [
          "a mgt\\n\\nStep 5: Argument Decoding\\n- Decoder: Generate argument based on encoder or keyphrase last hidden state\\n- Attention mechanism over both input and keyphrase results,\\n- Right to privacy\\n\\nI believe the Edward Snowden\\nyou are ignoring the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 38,
        "texts": [
          "Outline\\n\\nExperimental Setup"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 39,
        "texts": [
          "e@Experiments\\n- Pre-training: Initialize first layers of encoders and argument decoders\\n- Warm up the system with a good argumentation language model\\n\\nData:\\n- All training data + non-politics threads + non-root replies\\n- Sequence-to-sequence without evidence sentences or keyphrases\\n- Input: input statement\\n- Output: human argument"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 40,
        "texts": [
          "Experiments\\n- Models\\n- Baselines and comparisons\\n\\nRETRIEVAL-BASED: concatenate evidence sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 41,
        "texts": [
          "Experiments\\n- Models\\n- Baselines and comparisons\\n\\nRETRIEVAL-BASED: concatenate evidence sentences\\n\\nSEQ2SEQ: encode the input statement only"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 42,
        "texts": [
          "Experiments\\n- Models\\n- Baselines and comparisons\\n- RETRIEVAL-BASED: concatenate evidence sentences\\n- SEQ2SEQ: encode the input statement only\\n- SEQ2SEQ + encode evidence: encode statement and evidence sentences"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 43,
        "texts": [
          "Experiments\\n- Models\\n- Baselines and comparisons\\n- RETRIEVAL-BASED: concatenate evidence sentences\\n- SEQ2SEQ: encode the input statement only\\n- SEQ2SEQ + encode evidence: encode statement and evidence\\n- SEQ2SEQ + encode keyphrase: encode statement and keyphrases"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 44,
        "texts": [
          "Experiments\\n- Models\\n- Baselines and comparisons\\n\\nRETRIEVAL-BASED: concatenate evidence sentences\\n\\nSEQ2SEQ: encode the input statement only\\n\\nSEQ2SEQ + encode evidence: encode statement and evidence sentences\\n\\nSEQ2SEQ + encode keyphrase: encode statement and keyphrases\\n\\nStronger baseline, because keyphrases are actually reused by human arguments."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 45,
        "texts": [
          "e@Experiments\\n- Models\\n\\nOur models\\n- DEC-SHARED: Argument decoder initialized by keyphrase decoder Attention JESSE SESS ICSE SSS SSS\\n\\nSere ween>/ : y, is : ¥- / y y ' <phz> right to privacy <pb oesC e oy = © © o oOvA > [> L pe \\ Ps ; 4 -| .\\n\\nbelieve\\n- the * a <evd>\\n- edward snowden ae\\n- ~s aq %a a aa .Ateenttan <arg> you are ignoring the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 46,
        "texts": [
          "Experiments\\n- Model\\n\\nOur models\\n- DEC-SHARED: Argument decoder initialized by keyphrase decoder\\n\\nDEC-SHARED + attend keyphrase: with attention on keyphrase decoder\\n\\nI believe\\n- the Stee Seve edward snowden"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 47,
        "texts": [
          "Experiments\\n- Models\\n- Our models\\n- DEC-SHARED: Argument decoder initialized by keyphrase decoder\\n- DEC-SHARED + attend keyphrase: with attention on keyphrase decoder\\n- DEC-SEPARATE: Argument decoder initialized by encoder\\n\\nAttention is right to privacy\\n\\nI believe the vs Edward Snowden"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 48,
        "texts": [
          "Experiments\\n- Models\\n- Our models\\n- DEC-SHARED: Argument decoder initialized by keyphrase decoder\\n- DEC-SHARED + attend keyphrase: with attention on keyphrase decoder\\n- DEC-SEPARATE: Argument decoder initialized by encoder\\n- DEC-SEPARATE + attend keyphrase: with attention on keyphrase decoder\\n\\nAttention right to privacy\\n\\nI believe the\\n\\nyou are ignoring the"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 49,
        "texts": [
          "Experimentse System vs. Oracle retrieval\\n- In reality, during test time evidence can only be obtained by input statement.\\n- In Oracle setup, we retrieve evidence based on human arguments' queries."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 50,
        "texts": [
          "E ri te System vs. Oracle retrieval\\n\\nIn reality, during test time evidence can only be obtained by input statement.\\n- In Oracle setup, we retrieve evidence based on human arguments' queries.\\n\\nInput statement: \"I believe the government\"\\n\\nHuman argument: Giving up privacy means should be allowed to view my emails...\\ngiving up some of your right to free speech.\\n\\nNothing to hide argument\\n\\nFreedom of speech\\n\\nPrivacy"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 51,
        "texts": [
          "Outline> Evaluation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 52,
        "texts": [
          "Automatic Evaluation\\n- Generation Quality\\n- Argument generation quality\\n- BLEU: n-gram precision based measure\\n- METEOR: unigram precision and recall based on alignment\\n- Gold-standard: user generated arguments\\n- Multi-reference setup: best aligned one -> multiple plausible arguments exist"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 53,
        "texts": [
          "Automatic Evaluation\\n- Generation Quality\\n- BLEU/METEOR: The higher the better\\n\\nBaseline\\n- RETRIEVAL: 15.32, 12.19, 151.2\\n\\nComparisons\\n- SEQ2SEQ: 10.21, 5.74, 34.9\\n\\nOur Models\\n- DEC-SHARED: 21.22, 8.91, 69.1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 54,
        "texts": [
          "Automatic Evaluation\\n- Generation Quality\\n\\n* BLEU/METEOR: The higher the better\\n\\nBaseline\\nThe generated content is more likely to be found in human arguments.\\n\\nComparisons\\n- RETRIEVAL 15.32 12.19 151.2\\n- SEQ2SEQ 10.21 5.74 34.9\\n- Our Models DEC-SHARED 8.91 69.1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 55,
        "texts": [
          "Automatic Evaluation\\n- Generation Quality\\n- BLEU/METEOR: The higher the better\\n- BLEU-2 METEOR Length\\n- Our models have better precision. The generated content is more likely to be found in human arguments.\\n- Comparisons\\n- EQ2SE 10.21 5.74 34.9\\n- BEQZSEG.\\n- Retrieval baseline generation has better METEOR, which considers both precision and recall.\\n- Our Models\\n- DEC-SHARED 21.22 8.91 69.1"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 56,
        "texts": [
          "QualAutomatic Evaluation Generation Quality ASEM cide el Ye], WMO) e-al=MaXei ea (ea) BLEU-2 METEOR Length\\n\\nBLEU-2 METEOR Length Baseline RETRIEVAL 15.32 151.2 10.24 132.7\\n\\nComparisons\\n\\nOur Models_vatendee | aaa aoas | aa | uae | aoe | wos Dicsenawe [mH [we [we [ve | a [ae-_vatenaie | a0s2 | uua7 [asa | mao | ser] aca"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 57,
        "texts": [
          "Automatic Evaluation\\n- Generation Quality\\n- BLEU/METEOR: The higher the better\\n- ASEM cide el Ye], WMO) e-al=MaXei ea (ea)\\n- BLEU-2\\n- METEOR\\n- Length\\n- Baseline\\n- RETRIEVAL\\n12.19\\n151.2\\n16.22\\n132.7\\n\\nComparisons\\n\\nOur Models"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 58,
        "texts": [
          "Automatic Evaluation\\n- Topic Relevance\\n- Motivation: Generic arguments can still have high BLEU scores."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 59,
        "texts": [
          "Automatic Evaluation\\n- Topic Relevance\\n- Motivation: Generic arguments can still have high BLEU scores.\\nE.g. \"I don't agree with you.\", \"You are missing evidence.\", \"This is wrong.\""
        ]
      },
      {
        "section_index": 0,
        "slide_index": 60,
        "texts": [
          "Automatic Evaluation\\n- Topic Relevance\\n- Motivation: Generic arguments can still have high BLEU scores.\\n- Topic relevance\\n- Semantic similarity model [Huang et al, 2013]\\n- Represents the semantic relatedness of two pieces of text\\n- Model tuned on training set\\n- Evaluated by mean reciprocal ranking (MRR) and Precision at 1 (P@1)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 61,
        "texts": [
          "Automatic Evaluation\\n- Topic Relevance\\nThe higher the better\\n\\nTS P@1\\nBaseline\\nRETRIEVAL 81.08 65.45\\nComparisons\\nSEQ2SEQ 74.46 57.06\\nOur Models\\nDEC-SHARED 95.18 90.91"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 62,
        "texts": [
          "Automatic Evaluation\\n- Topic Relevance\\nThe higher the better\\nWt P@1\\nBaseline\\nRETRIEVAL\\n81.08\\n65.45\\n74.46\\n57.06\\nSEQ2SEQ\\nOur models produce more topic relevant outputs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 63,
        "texts": [
          "Human Evaluation\\n\\nMotivation: Automatic evaluation can't really evaluate the overall coherence and informativeness of the generation.\\n\\nSetup:\\n- 3 trained judges that are fluent in English\\n- 3 systems: RETRIEVAL-BASED, SEQ2SEQ, OUR MODEL\\n\\nAspects (each on a scale of 1 to 5, the higher the better):\\n- Grammaticality: if the output is fluent and grammatical English\\n- Informativeness: whether the output is informative or generic\\n- Relevance: if the output is on-topic and of correct stance"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 64,
        "texts": [
          "Human Evaluation\\n\\n* Each on a scale of 1 to 5, the higher the better\\n1 (low quality) 5 (high quality)\\n\\nCarel checked criminal taxi. The food security is not an issue of speed limit lanes to how much food we produce.\\nIsraelis are under a much more persistent and realistic security threat.\\nMinority groups who endure everyday discrimination often suffer high rates of chronic diseases.\\n\\nRelevance (Topic: racial profiling) Gun control deters crime."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 65,
        "texts": [
          "Human Evaluation (ECan):\\n\\nGrammaticality:\\n\\nInformativeness:\\n\\nRelevance:\\n\\n* Each on a scale of 1 to 5, the higher the better"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 66,
        "texts": [
          "Human Evaluation (ECan): Grammaticality | Informativeness | Relevance\\n- RETRIEVAL-BASED: 4.5 +0.6 | 3.7409 | 3.3411 | 3.3411 | 1.2 +0.5 | 1440.725 +0.8 | 1.6 +0.8 | 1.8 +0.8\\n- Human judges favor the RETRIEVAL-BASED model in all aspects.\\n- RETRIEVAL-BASED is human-written and relevant.\\n- OUR MODEL is favored over SEQ2SEQ except in Grammaticality."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 67,
        "texts": [
          "Sample Argument\\n\\nOriginal Post\\n\\nPutin is trying to re-form a \"Soviet Union\" with his past actions in Georgia and current actions in Ukraine.\\nThere are two reasons you are so far beyond. There is no reason to see the military army.\\nYou can infer what they assume it, so they tend to protect up.\\n\\nI firmly believe that Putin and the Russian Federation (RF) are trying to re-form a Soviet Union type regime.\\nThe Russian Army invaded certain regions of Georgia. The fact of the matter is not bad. I would also assume it.\\nHowever, the government cannot be reminded of the world."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 68,
        "texts": [
          "Outline: Future Directions and Conclusion"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 69,
        "texts": [
          "Future Directions\\n- Knowledge Retrieval\\n- Better evidence retrieval system\\n- Reasoning and interpretability\\n- Text Generation\\n- Prone to incoherence, inaccurate information, generic generation etc\\n- Discourse-aware argument generation"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 70,
        "texts": [
          "Conclusion\\n- We study a novel neural argument generation task.\\n\\nWe collect and release a new dataset from r/ChangeMyView and accompanying Wikipedia evidence for argument generation research.\\n\\nWe propose an end-to-end argument generation system, enhanced with Wikipedia retrieved evidence sentences."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 71,
        "texts": [
          "Thank you for your attention!\\n- Dataset: https://xinyuhua.github.io/Resources/\\n- Project page: https://xinyuhua.github.io/neural-argument-generation/\\n- Contact: Xinyu Hua (hua.x@husky.neu.edu)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 72,
        "texts": [
          "- Conclusion of Jat:\\n- We study a novel neural argument generation task.\\n- We collect and release a new dataset from r/ChangeMyView and accompanying Wikipedia evidence for argument generation research.\\n- We propose an end-to-end argument generation system, enhanced with Wikipedia retrieved evidence sentences.\\n\\nProject page: https://xinyuhua.github.io/neural-argument-generation/"
        ]
      }
    ]
  },
  {
    "conf": "acl18",
    "idd": 10,
    "slides": [
      {
        "section_index": 0,
        "slide_index": 0,
        "texts": [
          "Intro\\n\\nApproach\\n\\nExperiments\\n\\nSummary\\n\\nACL-18: 15-20 July 2018, Melbourne, Australia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 1,
        "texts": [
          "Knowledge graph\\n\\nA directed graph composed of entities (nodes) and relations (edges).\\n\\n(Cristiano Ronaldo, bornIn, Funchal)\\n(Cristiano Ronaldo, playsFor, Real Madrid)\\n(Cristiano Ronaldo, teammates, Sergio Ramos)\\n(Sergio Ramos, bornIn, Camas)\\n(Sergio Ramos, playsFor, Real Madrid)\\n(Funchal, locatedIn, Portugal)\\n(Real Madrid, locatedIn, Spain)\\n(Camas, locatedIn, Spain)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 2,
        "texts": [
          "Knowledge graph embedding\\n\\nLearn to represent entities and relations in continuous vector spaces.\\n\\nEntities as points in vector spaces (vectors)\\n- Cristiano Ronaldo, HE EEER008; DD.\\nCH Sergio Ramos, Sooo 'esand located, Funchal, So oooex Real Madrid, Camas, BREEPpp & Portugal, ST aooo/Or Spain, BRE EEREEeteammates.\\nSatie located in % 'ous:\\n\\nRelations as operations between entities wo = (vectors/matrices/tensors) Sade Ps teammates [][T] or HH or oH[i bornIn EA is bornIn [[TT] or a or AQa playsFor [TJ] or as or AlocatedIn [TTT] or as or A"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 3,
        "texts": [
          "Knowledge graph embedding (cont.)\\n- Easy computation and inference on knowledge graphs.\\n- Is Spain more similar to Camas (a municipality located in Spain) or Portugal (both Portugal and Spain are European countries)?\\nSpain Camas? Spain Portugal.\\n\\nWhat is the relationship between Cristiano Ronaldo and Portugal?\\nRonaldo Portugal teammates nationality located in plays for."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 4,
        "texts": [
          "Previous approaches\\n- Early works: Simple models developed over RDF triples, e.g., TransE, RESCAL, DistMult, ComplEx, etc.\\n- Recent trends:\\n- Designing more complicated triple scoring models, usually with higher computational complexity.\\n- Incorporating extra information beyond RDF triples, not always applicable to all knowledge graphs."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 5,
        "texts": [
          "This work\\n\\nUsing simple constraints to improve knowledge graph embedding\\n- Non-negativity constraints on entity representations\\n- Approximate entailment constraints on relation representations\\n\\nBenefits\\n- More predictive embeddings\\n- More interpretable embeddings\\n- Low computational complexity"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 7,
        "texts": [
          "Basic embedding model: ComplEx\\nEntity and relation representations: complex-valued vectors.\\n\\nEntity: e = 7 + 1 =\\nRelation: r = + t\\nRe(e) Im(e) Re(r) Im(r)\\n\\nTriple scoring function: multi-linear dot product\\nscore(e;, Tks e;) = Re((e;, Tk; ;)) = Re()\\n\\nTriples with higher scores are more likely to be true."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 8,
        "texts": [
          "Non-negativity of entity representations\\n\\nIntuition\\n- Uneconomical to store negative properties of an entity/concept\\n\\nPositive properties of cats\\n- Cats are mammals\\n- Cats eat fishes\\n- Cats have four legs\\n\\nNegative properties of cats\\n- Cats are not vehicles\\n- Cats do not have wheels\\n- Cats are not used for communication\\n\\nNon-negativity constraints\\nnon-negativity\\n0 < Re(e), Im(e) < 1, ∀e ∈ ℝ\\nsparsity & interpretability"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 9,
        "texts": [
          "Approximate entailment for relations\\n\\nApproximate entailment: relation 7, approximately entails relation 7, with confidence level A- in 2%; nationality: a person born in a country is very likely, but not necessarily, to have a nationality of that country.\\n- Can be derived automatically by modern rule mining systems"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 10,
        "texts": [
          "Approximate entailment for relations (cont.)\\n\\nApproximate entailment constraints\\n- Strict entailment rp > Tq (A = +00) Ges, Te, Lj) = Cente, ey), Vexeget i- A sufficient condition for (*) Re(rp) < Re(rg), Im(rp) = Im(rg) (**)\\n- Introducing confidence 4 and allowing slackness in (+*) A higher confidence level A(Re(rp) _ Re(rq)) < a\\n- Avoid groundings shows less tolerance for 2 Handi 3 violating the constraints \\(Im(rp) _ Im(rq)) = B\\n\\nACL-18: 15-20 July 2018, Melbourne, Australia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 11,
        "texts": [
          "Overall model: Basic embedding model of ComplEx + non-negativity constraints + approximate entailment constraints.\\n\\ny = -log(1 + exp(-yijrO(Ei, Ties e;)))\\n\\nto Bt pt op\\n- Qe ~ 9 logistic loss for ComplEx +\\n\\nu\\nd) 1 (a +\\nA) + nllOlls, at. A(Re(rp)\\n- Re(rq)) <= o y,\\n\\n7 soins entailment constraints on relation representations.\\n\\nA(Im(rp)\\n- Im(rq)) < B, a, 8 > 0, Yrp x Tr ET, 0 < Re(e), Im(e) < 1, Ve € €.\\n- non-negativity constraints on entity representations."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 12,
        "texts": [
          "Complexity analysis\\n\\nSpace complexity: O(nd + md)\\n- the same as that of Complex\\n- n is the number of entities\\n- m is the number of relations\\n- d is the dimensionality of the embedding\\n\\nTime complexity per iteration: O(sd + nd + td) ~ O(sd)\\n- s is the average number of triples in a mini-batch\\n- n is the average number of entities in a mini-batch\\n- t is the total number of approximate entailments"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 14,
        "texts": [
          "Experimental setups\\n\\nDatasets\\n\\nDataset | #Ent # Rel # Train/Valid/Test # Cons-\\nWN18: subset of WordNet\\nWN18 | 40,943 18 141,442 5,000 5,000\\n\\nFBIS5K | 14,951 1,345 483,142 50,000 59,071\\n\\nFB15K: subset of Freebase\\nDB100K | 99,604 470 597,572 50,000 50,000\\n\\nDB100K: subset of DBpedia\\n- hypernym\\n- hyponym\\n- Training/validation/test split\\n- synset_domain_topic_of\\n- member_of_domain_topic\\n- instance_hypernym\\n- instance_hyponym\\n\\nApproximate entailment\\n- /people/place_of_birth\\n- location/people_born_here\\n- /film/directed_by\\n- /director/film\\n\\nAutomatically extracted by\\n- /country/admin_divisions\\n- /country/1st_level_divisions\\n- AMIE+ with confidence level\\n- owner\\n- owning_company\\n- child\\n- parent higher than 0.8\\n- distributing_company\\n- distributing_label"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 15,
        "texts": [
          "Experimental setups (cont.)\\n\\nLink prediction\\n- To complete a triple (e₁, e₂, e₃) with e₁ or e₃ missing\\n\\nBaselines\\n- Simple embedding models based on RDF triples\\n- Other extensions of ComplEx incorporating logic rules\\n- Recently developed neural network architectures\\n\\nOur approaches\\n- ComplEx-NNE: only with non-negativity constraints\\n- ComplEx-NNE+AER: also with approximate entailment constraints"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 16,
        "texts": [
          "WN18 FB15K DB100K\\n\\nMRR HITS@1 HITS@3 MRR HITS@1 HITS@3 MRR HITS@1 HITS@3\\n\\nTransE (2013) 0.454 0.089 0.823 0.380 0.231 0.472 0.111 0.016 0.164\\n\\nDistMult (2015) 0.822 0.728 0.914 0.654 0.546 0.733 0.233 0.115 0.301\\n\\nHolE (2016) 0.938 0.930 0.945 0.524 0.402 0.613 0.260 0.182 0.309\\n\\nComplEx (2016) 0.941 0.936 0.945 0.692 0.599 0.759 0.242 0.126 0.312\\n\\nANALOGY (2017) 0.942 0.939 0.944 0.725 0.646 0.785 0.252 0.143 0.323\\n\\nComplEx-NNE 0.941 0.937 0.944 0.727 ~=-0.659 0.772 0.298 0.229 0.330\\n\\nComplEx-NNE+AER 0.943 0.940 0.945 0.803 0.761 0.831 0.306 0.244 0.334\\n- Simple embedding models Incorporating logic rules\\n- Neural network architectures\\n\\nComplEx-NNE+AER can beat very strong baselines just by introducing the simple constraints\\n\\nACL-18: 15-20 July 2018, Melbourne, Australia"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 17,
        "texts": [
          "Analysis on entity representations\\n\\nVisualization of entity representations\\n- Pick 4 types: reptile, wine region, species, programming language, and randomly select 30 entities from each type.\\n- Visualize the representations of these entities learned by ComplEx and ComplEx-NNE.\\n\\nCompact and interpretable entity representations\\n\\nEach entity is represented by only a relatively small number of \"active\" dimensions.\\nEntities with the same type tend to activate the same set of dimensions."
        ]
      },
      {
        "section_index": 0,
        "slide_index": 18,
        "texts": [
          "Analysis on entity representations (cont.)\\n- Semantic purity of latent dimensions\\n- For each latent dimension, pick top K percent of entities with the highest activation values on this dimension\\n- Calculate the entropy of the type distribution of these entities as latent dimensions with higher semantic purity\\n- A lower entropy means entities along this dimension tend to have the same type (higher semantic purity)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 19,
        "texts": [
          "Analysis on relation representations\\n\\nVisualization of relation representations\\n\\nReal Component\\nImaginary Component\\n\\nEncode logical regularities quite well\\n- Equivalence\\n\\nrp ++ Tq\\nlocation_country\\nRe(rp) _ Re(rq)\\nowning_company 0.60, 0.30 0.22 0.56\\nowner 0.60 0.30 0.22 0.57\\n\\nIm(rp) _ Im(rq)\\nspouse\\nTM}\\n- 0.15 0.00 0.00 -0.00 0.00 -0.00\\n- I\\nuymo el a ee nversion\\nTp ++ Tq= _ oe\\nRe(rp) = Re(rq)\\n\\nchild\\n~}\\n- 0.33 0.47 0.45 4 0.08 0\\nparent\\n- 0.33 0.47 0.45 0.13 0.04 0.20 0.02\\n\\nIm(rp) = -Im(rq)\\nposition .01 0.23 0.16\\n- r=\\n- Ordinary entailment\\nhonours 0.30 0.01 0.23 0.16\\nRe(rp) < Re(rq)\\nofficial_language 0.02 0.09 -0.0\\nlanguage 0.0: 0.09 0.01\\nIm(rp) = Im(rq)"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 21,
        "texts": [
          "This work\\n\\nUsing simple constraints to improve knowledge graph embedding\\n- Non-negativity constraints on entity representations\\n- Approximate entailment constraints on relation representations\\n\\nExperimental results\\n- Effective\\n- Efficient\\n- Interpretable embeddings\\n\\nCode and data available at https://github.com/iieir-km/ComplEx-NNE AER"
        ]
      },
      {
        "section_index": 0,
        "slide_index": 22,
        "texts": [
          "Thank you! Q&A wangquan@iile.ac.cn ACL-18: 15-20 July 2018, Melbourne, Australia"
        ]
      }
    ]
  }
]
